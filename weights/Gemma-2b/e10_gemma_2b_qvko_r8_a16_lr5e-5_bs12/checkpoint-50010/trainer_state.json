{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 50010,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.24143537878990173,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 0.6459,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.2472335696220398,
      "learning_rate": 2.666666666666667e-06,
      "loss": 0.5959,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.2364300936460495,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.6332,
      "step": 24
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.2816077768802643,
      "learning_rate": 5.333333333333334e-06,
      "loss": 0.6172,
      "step": 32
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.29912033677101135,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.6738,
      "step": 40
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.249250590801239,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.6092,
      "step": 48
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.2965880334377289,
      "learning_rate": 9.333333333333334e-06,
      "loss": 0.614,
      "step": 56
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.46303820610046387,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 0.633,
      "step": 64
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.309923380613327,
      "learning_rate": 1.2e-05,
      "loss": 0.6098,
      "step": 72
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.37677791714668274,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.5987,
      "step": 80
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.24933458864688873,
      "learning_rate": 1.4666666666666668e-05,
      "loss": 0.5682,
      "step": 88
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.25531166791915894,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.5711,
      "step": 96
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2667256295681,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 0.5471,
      "step": 104
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2821418046951294,
      "learning_rate": 1.866666666666667e-05,
      "loss": 0.553,
      "step": 112
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2695710062980652,
      "learning_rate": 2e-05,
      "loss": 0.538,
      "step": 120
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2957484722137451,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 0.5135,
      "step": 128
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.42678552865982056,
      "learning_rate": 2.2666666666666668e-05,
      "loss": 0.496,
      "step": 136
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4111417829990387,
      "learning_rate": 2.4e-05,
      "loss": 0.4975,
      "step": 144
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2893507182598114,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 0.4744,
      "step": 152
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.32691410183906555,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.4452,
      "step": 160
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3170139491558075,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.4825,
      "step": 168
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3100413978099823,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 0.4689,
      "step": 176
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3523889183998108,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.4584,
      "step": 184
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3352666199207306,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.458,
      "step": 192
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4200054407119751,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.4468,
      "step": 200
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3382682502269745,
      "learning_rate": 3.466666666666667e-05,
      "loss": 0.4529,
      "step": 208
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3515879213809967,
      "learning_rate": 3.6e-05,
      "loss": 0.4535,
      "step": 216
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4336322844028473,
      "learning_rate": 3.733333333333334e-05,
      "loss": 0.4592,
      "step": 224
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.36572617292404175,
      "learning_rate": 3.866666666666667e-05,
      "loss": 0.4781,
      "step": 232
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.42819225788116455,
      "learning_rate": 4e-05,
      "loss": 0.4778,
      "step": 240
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.43568071722984314,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.4511,
      "step": 248
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5093626976013184,
      "learning_rate": 4.266666666666667e-05,
      "loss": 0.4497,
      "step": 256
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3977808952331543,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.4225,
      "step": 264
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.44592997431755066,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 0.4006,
      "step": 272
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.43540599942207336,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.4229,
      "step": 280
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.38028445839881897,
      "learning_rate": 4.8e-05,
      "loss": 0.4233,
      "step": 288
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4539943039417267,
      "learning_rate": 4.933333333333334e-05,
      "loss": 0.4134,
      "step": 296
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4364908039569855,
      "learning_rate": 5e-05,
      "loss": 0.4487,
      "step": 304
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.42028915882110596,
      "learning_rate": 5e-05,
      "loss": 0.4287,
      "step": 312
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4493330419063568,
      "learning_rate": 5e-05,
      "loss": 0.4202,
      "step": 320
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.39179810881614685,
      "learning_rate": 5e-05,
      "loss": 0.3949,
      "step": 328
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4946478307247162,
      "learning_rate": 5e-05,
      "loss": 0.4229,
      "step": 336
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4921341836452484,
      "learning_rate": 5e-05,
      "loss": 0.4321,
      "step": 344
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.47139596939086914,
      "learning_rate": 5e-05,
      "loss": 0.415,
      "step": 352
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5145672559738159,
      "learning_rate": 5e-05,
      "loss": 0.4042,
      "step": 360
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.48216742277145386,
      "learning_rate": 5e-05,
      "loss": 0.461,
      "step": 368
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.41667380928993225,
      "learning_rate": 5e-05,
      "loss": 0.4255,
      "step": 376
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6124529838562012,
      "learning_rate": 5e-05,
      "loss": 0.4047,
      "step": 384
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.47695767879486084,
      "learning_rate": 5e-05,
      "loss": 0.421,
      "step": 392
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4411948323249817,
      "learning_rate": 5e-05,
      "loss": 0.448,
      "step": 400
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4248618483543396,
      "learning_rate": 5e-05,
      "loss": 0.4159,
      "step": 408
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4173220992088318,
      "learning_rate": 5e-05,
      "loss": 0.4202,
      "step": 416
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5304524302482605,
      "learning_rate": 5e-05,
      "loss": 0.4166,
      "step": 424
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4801962077617645,
      "learning_rate": 5e-05,
      "loss": 0.4064,
      "step": 432
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.44316813349723816,
      "learning_rate": 5e-05,
      "loss": 0.4215,
      "step": 440
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4866090714931488,
      "learning_rate": 5e-05,
      "loss": 0.4199,
      "step": 448
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5606065988540649,
      "learning_rate": 5e-05,
      "loss": 0.411,
      "step": 456
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4673297703266144,
      "learning_rate": 5e-05,
      "loss": 0.4153,
      "step": 464
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.45093387365341187,
      "learning_rate": 5e-05,
      "loss": 0.4095,
      "step": 472
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6274799108505249,
      "learning_rate": 5e-05,
      "loss": 0.4073,
      "step": 480
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5730473399162292,
      "learning_rate": 5e-05,
      "loss": 0.4482,
      "step": 488
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5826826095581055,
      "learning_rate": 5e-05,
      "loss": 0.4058,
      "step": 496
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5925338864326477,
      "learning_rate": 5e-05,
      "loss": 0.4375,
      "step": 504
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4882834851741791,
      "learning_rate": 5e-05,
      "loss": 0.4041,
      "step": 512
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.509181797504425,
      "learning_rate": 5e-05,
      "loss": 0.3925,
      "step": 520
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5000987648963928,
      "learning_rate": 5e-05,
      "loss": 0.445,
      "step": 528
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4371197819709778,
      "learning_rate": 5e-05,
      "loss": 0.406,
      "step": 536
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7119228839874268,
      "learning_rate": 5e-05,
      "loss": 0.4146,
      "step": 544
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5746567845344543,
      "learning_rate": 5e-05,
      "loss": 0.4258,
      "step": 552
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5083961486816406,
      "learning_rate": 5e-05,
      "loss": 0.4091,
      "step": 560
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5534496903419495,
      "learning_rate": 5e-05,
      "loss": 0.4342,
      "step": 568
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5308454036712646,
      "learning_rate": 5e-05,
      "loss": 0.4427,
      "step": 576
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.465870201587677,
      "learning_rate": 5e-05,
      "loss": 0.3777,
      "step": 584
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5409905314445496,
      "learning_rate": 5e-05,
      "loss": 0.3767,
      "step": 592
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4379894733428955,
      "learning_rate": 5e-05,
      "loss": 0.4021,
      "step": 600
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.533363401889801,
      "learning_rate": 5e-05,
      "loss": 0.4289,
      "step": 608
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.653228223323822,
      "learning_rate": 5e-05,
      "loss": 0.3946,
      "step": 616
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5099853277206421,
      "learning_rate": 5e-05,
      "loss": 0.3935,
      "step": 624
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5417746901512146,
      "learning_rate": 5e-05,
      "loss": 0.4203,
      "step": 632
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.546052098274231,
      "learning_rate": 5e-05,
      "loss": 0.4252,
      "step": 640
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4992561638355255,
      "learning_rate": 5e-05,
      "loss": 0.4054,
      "step": 648
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5687839388847351,
      "learning_rate": 5e-05,
      "loss": 0.4011,
      "step": 656
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47953471541404724,
      "learning_rate": 5e-05,
      "loss": 0.3801,
      "step": 664
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.531091034412384,
      "learning_rate": 5e-05,
      "loss": 0.4169,
      "step": 672
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5083421468734741,
      "learning_rate": 5e-05,
      "loss": 0.4011,
      "step": 680
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.471312552690506,
      "learning_rate": 5e-05,
      "loss": 0.4045,
      "step": 688
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7170818448066711,
      "learning_rate": 5e-05,
      "loss": 0.4041,
      "step": 696
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5586820840835571,
      "learning_rate": 5e-05,
      "loss": 0.3968,
      "step": 704
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5666413903236389,
      "learning_rate": 5e-05,
      "loss": 0.4442,
      "step": 712
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5205560326576233,
      "learning_rate": 5e-05,
      "loss": 0.4097,
      "step": 720
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5761955976486206,
      "learning_rate": 5e-05,
      "loss": 0.394,
      "step": 728
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6032946109771729,
      "learning_rate": 5e-05,
      "loss": 0.3977,
      "step": 736
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5904003977775574,
      "learning_rate": 5e-05,
      "loss": 0.3967,
      "step": 744
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6065666675567627,
      "learning_rate": 5e-05,
      "loss": 0.4355,
      "step": 752
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6280517578125,
      "learning_rate": 5e-05,
      "loss": 0.3915,
      "step": 760
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5013232231140137,
      "learning_rate": 5e-05,
      "loss": 0.4053,
      "step": 768
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6173021793365479,
      "learning_rate": 5e-05,
      "loss": 0.404,
      "step": 776
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5329601168632507,
      "learning_rate": 5e-05,
      "loss": 0.4173,
      "step": 784
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6704656481742859,
      "learning_rate": 5e-05,
      "loss": 0.3774,
      "step": 792
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5940672755241394,
      "learning_rate": 5e-05,
      "loss": 0.4354,
      "step": 800
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4520357847213745,
      "learning_rate": 5e-05,
      "loss": 0.4282,
      "step": 808
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5604348182678223,
      "learning_rate": 5e-05,
      "loss": 0.3937,
      "step": 816
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6334150433540344,
      "learning_rate": 5e-05,
      "loss": 0.3874,
      "step": 824
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6019077897071838,
      "learning_rate": 5e-05,
      "loss": 0.4112,
      "step": 832
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4843190312385559,
      "learning_rate": 5e-05,
      "loss": 0.3934,
      "step": 840
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6495702862739563,
      "learning_rate": 5e-05,
      "loss": 0.4054,
      "step": 848
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.47830939292907715,
      "learning_rate": 5e-05,
      "loss": 0.45,
      "step": 856
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5367005467414856,
      "learning_rate": 5e-05,
      "loss": 0.3917,
      "step": 864
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5625686645507812,
      "learning_rate": 5e-05,
      "loss": 0.3982,
      "step": 872
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5134758949279785,
      "learning_rate": 5e-05,
      "loss": 0.4135,
      "step": 880
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5079184770584106,
      "learning_rate": 5e-05,
      "loss": 0.3742,
      "step": 888
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5753551721572876,
      "learning_rate": 5e-05,
      "loss": 0.4322,
      "step": 896
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5508925914764404,
      "learning_rate": 5e-05,
      "loss": 0.3826,
      "step": 904
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4682897925376892,
      "learning_rate": 5e-05,
      "loss": 0.4115,
      "step": 912
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4519505202770233,
      "learning_rate": 5e-05,
      "loss": 0.4027,
      "step": 920
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5191996097564697,
      "learning_rate": 5e-05,
      "loss": 0.3969,
      "step": 928
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5402015447616577,
      "learning_rate": 5e-05,
      "loss": 0.3829,
      "step": 936
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6117361783981323,
      "learning_rate": 5e-05,
      "loss": 0.401,
      "step": 944
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5983314514160156,
      "learning_rate": 5e-05,
      "loss": 0.3789,
      "step": 952
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5873628258705139,
      "learning_rate": 5e-05,
      "loss": 0.4113,
      "step": 960
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5010546445846558,
      "learning_rate": 5e-05,
      "loss": 0.407,
      "step": 968
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5085048079490662,
      "learning_rate": 5e-05,
      "loss": 0.4267,
      "step": 976
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7057944536209106,
      "learning_rate": 5e-05,
      "loss": 0.3814,
      "step": 984
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5603216290473938,
      "learning_rate": 5e-05,
      "loss": 0.3709,
      "step": 992
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5397158265113831,
      "learning_rate": 5e-05,
      "loss": 0.3918,
      "step": 1000
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4278487265110016,
      "learning_rate": 5e-05,
      "loss": 0.3857,
      "step": 1008
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7391152381896973,
      "learning_rate": 5e-05,
      "loss": 0.4134,
      "step": 1016
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5431184768676758,
      "learning_rate": 5e-05,
      "loss": 0.3938,
      "step": 1024
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6744566559791565,
      "learning_rate": 5e-05,
      "loss": 0.3984,
      "step": 1032
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5427542328834534,
      "learning_rate": 5e-05,
      "loss": 0.403,
      "step": 1040
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5901840329170227,
      "learning_rate": 5e-05,
      "loss": 0.4128,
      "step": 1048
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5814626216888428,
      "learning_rate": 5e-05,
      "loss": 0.373,
      "step": 1056
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6415109038352966,
      "learning_rate": 5e-05,
      "loss": 0.3656,
      "step": 1064
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6378155946731567,
      "learning_rate": 5e-05,
      "loss": 0.3815,
      "step": 1072
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5991031527519226,
      "learning_rate": 5e-05,
      "loss": 0.4249,
      "step": 1080
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.500542402267456,
      "learning_rate": 5e-05,
      "loss": 0.3872,
      "step": 1088
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5452626347541809,
      "learning_rate": 5e-05,
      "loss": 0.3929,
      "step": 1096
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6464059948921204,
      "learning_rate": 5e-05,
      "loss": 0.4068,
      "step": 1104
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.46498554944992065,
      "learning_rate": 5e-05,
      "loss": 0.3945,
      "step": 1112
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5821170210838318,
      "learning_rate": 5e-05,
      "loss": 0.3957,
      "step": 1120
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5749747157096863,
      "learning_rate": 5e-05,
      "loss": 0.3919,
      "step": 1128
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5607484579086304,
      "learning_rate": 5e-05,
      "loss": 0.3849,
      "step": 1136
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6181458234786987,
      "learning_rate": 5e-05,
      "loss": 0.3776,
      "step": 1144
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5613293051719666,
      "learning_rate": 5e-05,
      "loss": 0.4177,
      "step": 1152
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5554724931716919,
      "learning_rate": 5e-05,
      "loss": 0.4142,
      "step": 1160
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4915931820869446,
      "learning_rate": 5e-05,
      "loss": 0.3529,
      "step": 1168
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4778289496898651,
      "learning_rate": 5e-05,
      "loss": 0.3828,
      "step": 1176
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5697522163391113,
      "learning_rate": 5e-05,
      "loss": 0.3815,
      "step": 1184
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5608448386192322,
      "learning_rate": 5e-05,
      "loss": 0.41,
      "step": 1192
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.465880423784256,
      "learning_rate": 5e-05,
      "loss": 0.3686,
      "step": 1200
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6057308316230774,
      "learning_rate": 5e-05,
      "loss": 0.4245,
      "step": 1208
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5478179454803467,
      "learning_rate": 5e-05,
      "loss": 0.4123,
      "step": 1216
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5199862122535706,
      "learning_rate": 5e-05,
      "loss": 0.3713,
      "step": 1224
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5230967402458191,
      "learning_rate": 5e-05,
      "loss": 0.406,
      "step": 1232
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5693303942680359,
      "learning_rate": 5e-05,
      "loss": 0.412,
      "step": 1240
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5122774839401245,
      "learning_rate": 5e-05,
      "loss": 0.4241,
      "step": 1248
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5852788090705872,
      "learning_rate": 5e-05,
      "loss": 0.4008,
      "step": 1256
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6500278115272522,
      "learning_rate": 5e-05,
      "loss": 0.3766,
      "step": 1264
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.527764618396759,
      "learning_rate": 5e-05,
      "loss": 0.3961,
      "step": 1272
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6855109333992004,
      "learning_rate": 5e-05,
      "loss": 0.3699,
      "step": 1280
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5719074606895447,
      "learning_rate": 5e-05,
      "loss": 0.4109,
      "step": 1288
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5986074209213257,
      "learning_rate": 5e-05,
      "loss": 0.3924,
      "step": 1296
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.660051703453064,
      "learning_rate": 5e-05,
      "loss": 0.4011,
      "step": 1304
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7998953461647034,
      "learning_rate": 5e-05,
      "loss": 0.4005,
      "step": 1312
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5576145052909851,
      "learning_rate": 5e-05,
      "loss": 0.3697,
      "step": 1320
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5149469971656799,
      "learning_rate": 5e-05,
      "loss": 0.4191,
      "step": 1328
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5616046190261841,
      "learning_rate": 5e-05,
      "loss": 0.3754,
      "step": 1336
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5885199308395386,
      "learning_rate": 5e-05,
      "loss": 0.3858,
      "step": 1344
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5487523078918457,
      "learning_rate": 5e-05,
      "loss": 0.4028,
      "step": 1352
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.516200602054596,
      "learning_rate": 5e-05,
      "loss": 0.3811,
      "step": 1360
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5711460113525391,
      "learning_rate": 5e-05,
      "loss": 0.3986,
      "step": 1368
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5493947267532349,
      "learning_rate": 5e-05,
      "loss": 0.387,
      "step": 1376
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5594437718391418,
      "learning_rate": 5e-05,
      "loss": 0.3699,
      "step": 1384
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5981267690658569,
      "learning_rate": 5e-05,
      "loss": 0.4467,
      "step": 1392
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7665478587150574,
      "learning_rate": 5e-05,
      "loss": 0.3939,
      "step": 1400
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5214836597442627,
      "learning_rate": 5e-05,
      "loss": 0.3752,
      "step": 1408
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7257180213928223,
      "learning_rate": 5e-05,
      "loss": 0.4123,
      "step": 1416
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5002092123031616,
      "learning_rate": 5e-05,
      "loss": 0.3964,
      "step": 1424
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6611246466636658,
      "learning_rate": 5e-05,
      "loss": 0.3998,
      "step": 1432
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.548430860042572,
      "learning_rate": 5e-05,
      "loss": 0.4037,
      "step": 1440
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5451266169548035,
      "learning_rate": 5e-05,
      "loss": 0.3831,
      "step": 1448
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5614047646522522,
      "learning_rate": 5e-05,
      "loss": 0.3838,
      "step": 1456
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5117180943489075,
      "learning_rate": 5e-05,
      "loss": 0.3676,
      "step": 1464
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6426647901535034,
      "learning_rate": 5e-05,
      "loss": 0.404,
      "step": 1472
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5904093384742737,
      "learning_rate": 5e-05,
      "loss": 0.4427,
      "step": 1480
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5427354574203491,
      "learning_rate": 5e-05,
      "loss": 0.3658,
      "step": 1488
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6426519751548767,
      "learning_rate": 5e-05,
      "loss": 0.3764,
      "step": 1496
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5430707335472107,
      "learning_rate": 5e-05,
      "loss": 0.4005,
      "step": 1504
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5247192978858948,
      "learning_rate": 5e-05,
      "loss": 0.4095,
      "step": 1512
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5719732642173767,
      "learning_rate": 5e-05,
      "loss": 0.4022,
      "step": 1520
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.527255654335022,
      "learning_rate": 5e-05,
      "loss": 0.3685,
      "step": 1528
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5916329622268677,
      "learning_rate": 5e-05,
      "loss": 0.3853,
      "step": 1536
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5653153657913208,
      "learning_rate": 5e-05,
      "loss": 0.3994,
      "step": 1544
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6286762952804565,
      "learning_rate": 5e-05,
      "loss": 0.3881,
      "step": 1552
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5679059624671936,
      "learning_rate": 5e-05,
      "loss": 0.3882,
      "step": 1560
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6501833200454712,
      "learning_rate": 5e-05,
      "loss": 0.3685,
      "step": 1568
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5935968160629272,
      "learning_rate": 5e-05,
      "loss": 0.3845,
      "step": 1576
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6241245865821838,
      "learning_rate": 5e-05,
      "loss": 0.3934,
      "step": 1584
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5434229373931885,
      "learning_rate": 5e-05,
      "loss": 0.3778,
      "step": 1592
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5396613478660583,
      "learning_rate": 5e-05,
      "loss": 0.407,
      "step": 1600
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.556045413017273,
      "learning_rate": 5e-05,
      "loss": 0.3577,
      "step": 1608
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6386162042617798,
      "learning_rate": 5e-05,
      "loss": 0.3853,
      "step": 1616
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5276755094528198,
      "learning_rate": 5e-05,
      "loss": 0.4138,
      "step": 1624
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5727963447570801,
      "learning_rate": 5e-05,
      "loss": 0.3582,
      "step": 1632
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6436756253242493,
      "learning_rate": 5e-05,
      "loss": 0.4005,
      "step": 1640
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6801229119300842,
      "learning_rate": 5e-05,
      "loss": 0.4101,
      "step": 1648
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5246322154998779,
      "learning_rate": 5e-05,
      "loss": 0.3915,
      "step": 1656
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6270157098770142,
      "learning_rate": 5e-05,
      "loss": 0.392,
      "step": 1664
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5341548323631287,
      "learning_rate": 5e-05,
      "loss": 0.3599,
      "step": 1672
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6022641658782959,
      "learning_rate": 5e-05,
      "loss": 0.3734,
      "step": 1680
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6603118181228638,
      "learning_rate": 5e-05,
      "loss": 0.3933,
      "step": 1688
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7052502036094666,
      "learning_rate": 5e-05,
      "loss": 0.3399,
      "step": 1696
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4983758330345154,
      "learning_rate": 5e-05,
      "loss": 0.3948,
      "step": 1704
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7602158188819885,
      "learning_rate": 5e-05,
      "loss": 0.3697,
      "step": 1712
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6058089733123779,
      "learning_rate": 5e-05,
      "loss": 0.3992,
      "step": 1720
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5349518656730652,
      "learning_rate": 5e-05,
      "loss": 0.3849,
      "step": 1728
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5216469764709473,
      "learning_rate": 5e-05,
      "loss": 0.3608,
      "step": 1736
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6780779957771301,
      "learning_rate": 5e-05,
      "loss": 0.3909,
      "step": 1744
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5234096050262451,
      "learning_rate": 5e-05,
      "loss": 0.3504,
      "step": 1752
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5727269053459167,
      "learning_rate": 5e-05,
      "loss": 0.4119,
      "step": 1760
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5616229176521301,
      "learning_rate": 5e-05,
      "loss": 0.3788,
      "step": 1768
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6083842515945435,
      "learning_rate": 5e-05,
      "loss": 0.36,
      "step": 1776
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5594242215156555,
      "learning_rate": 5e-05,
      "loss": 0.3731,
      "step": 1784
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6609058976173401,
      "learning_rate": 5e-05,
      "loss": 0.3676,
      "step": 1792
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5656469464302063,
      "learning_rate": 5e-05,
      "loss": 0.3552,
      "step": 1800
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5179153084754944,
      "learning_rate": 5e-05,
      "loss": 0.3885,
      "step": 1808
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.600010097026825,
      "learning_rate": 5e-05,
      "loss": 0.3761,
      "step": 1816
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6119586229324341,
      "learning_rate": 5e-05,
      "loss": 0.3742,
      "step": 1824
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.549519956111908,
      "learning_rate": 5e-05,
      "loss": 0.3766,
      "step": 1832
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5820218324661255,
      "learning_rate": 5e-05,
      "loss": 0.3711,
      "step": 1840
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.600985050201416,
      "learning_rate": 5e-05,
      "loss": 0.3925,
      "step": 1848
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6206485629081726,
      "learning_rate": 5e-05,
      "loss": 0.4179,
      "step": 1856
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6917864680290222,
      "learning_rate": 5e-05,
      "loss": 0.4125,
      "step": 1864
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7255344986915588,
      "learning_rate": 5e-05,
      "loss": 0.4098,
      "step": 1872
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5712417364120483,
      "learning_rate": 5e-05,
      "loss": 0.4,
      "step": 1880
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.567142903804779,
      "learning_rate": 5e-05,
      "loss": 0.3629,
      "step": 1888
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5125579237937927,
      "learning_rate": 5e-05,
      "loss": 0.4091,
      "step": 1896
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5126217603683472,
      "learning_rate": 5e-05,
      "loss": 0.3672,
      "step": 1904
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5565463900566101,
      "learning_rate": 5e-05,
      "loss": 0.3816,
      "step": 1912
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6486559510231018,
      "learning_rate": 5e-05,
      "loss": 0.3946,
      "step": 1920
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6468684673309326,
      "learning_rate": 5e-05,
      "loss": 0.3588,
      "step": 1928
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5388001203536987,
      "learning_rate": 5e-05,
      "loss": 0.3766,
      "step": 1936
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5922123193740845,
      "learning_rate": 5e-05,
      "loss": 0.3906,
      "step": 1944
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4926656484603882,
      "learning_rate": 5e-05,
      "loss": 0.3669,
      "step": 1952
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5758693218231201,
      "learning_rate": 5e-05,
      "loss": 0.3798,
      "step": 1960
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7154409289360046,
      "learning_rate": 5e-05,
      "loss": 0.3943,
      "step": 1968
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4877222776412964,
      "learning_rate": 5e-05,
      "loss": 0.3733,
      "step": 1976
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6126779913902283,
      "learning_rate": 5e-05,
      "loss": 0.3736,
      "step": 1984
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5798994898796082,
      "learning_rate": 5e-05,
      "loss": 0.389,
      "step": 1992
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5974281430244446,
      "learning_rate": 5e-05,
      "loss": 0.3974,
      "step": 2000
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.758792519569397,
      "learning_rate": 5e-05,
      "loss": 0.3763,
      "step": 2008
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6795257925987244,
      "learning_rate": 5e-05,
      "loss": 0.3587,
      "step": 2016
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5487764477729797,
      "learning_rate": 5e-05,
      "loss": 0.3874,
      "step": 2024
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.736642599105835,
      "learning_rate": 5e-05,
      "loss": 0.3777,
      "step": 2032
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5303991436958313,
      "learning_rate": 5e-05,
      "loss": 0.338,
      "step": 2040
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6177852749824524,
      "learning_rate": 5e-05,
      "loss": 0.3695,
      "step": 2048
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5618902444839478,
      "learning_rate": 5e-05,
      "loss": 0.3768,
      "step": 2056
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7104151844978333,
      "learning_rate": 5e-05,
      "loss": 0.3965,
      "step": 2064
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5704423189163208,
      "learning_rate": 5e-05,
      "loss": 0.3835,
      "step": 2072
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.529854953289032,
      "learning_rate": 5e-05,
      "loss": 0.3546,
      "step": 2080
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5998002290725708,
      "learning_rate": 5e-05,
      "loss": 0.3785,
      "step": 2088
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.479072242975235,
      "learning_rate": 5e-05,
      "loss": 0.3738,
      "step": 2096
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5688881874084473,
      "learning_rate": 5e-05,
      "loss": 0.3813,
      "step": 2104
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.621194064617157,
      "learning_rate": 5e-05,
      "loss": 0.3756,
      "step": 2112
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5653874278068542,
      "learning_rate": 5e-05,
      "loss": 0.383,
      "step": 2120
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5413981676101685,
      "learning_rate": 5e-05,
      "loss": 0.3862,
      "step": 2128
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5866512060165405,
      "learning_rate": 5e-05,
      "loss": 0.4032,
      "step": 2136
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5199511647224426,
      "learning_rate": 5e-05,
      "loss": 0.3738,
      "step": 2144
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5875186920166016,
      "learning_rate": 5e-05,
      "loss": 0.4003,
      "step": 2152
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5867213606834412,
      "learning_rate": 5e-05,
      "loss": 0.3788,
      "step": 2160
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5304619669914246,
      "learning_rate": 5e-05,
      "loss": 0.3573,
      "step": 2168
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6420231461524963,
      "learning_rate": 5e-05,
      "loss": 0.3599,
      "step": 2176
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5786098837852478,
      "learning_rate": 5e-05,
      "loss": 0.4215,
      "step": 2184
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5137288570404053,
      "learning_rate": 5e-05,
      "loss": 0.3647,
      "step": 2192
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6985302567481995,
      "learning_rate": 5e-05,
      "loss": 0.383,
      "step": 2200
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6880848407745361,
      "learning_rate": 5e-05,
      "loss": 0.3602,
      "step": 2208
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5581952333450317,
      "learning_rate": 5e-05,
      "loss": 0.3607,
      "step": 2216
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.649761438369751,
      "learning_rate": 5e-05,
      "loss": 0.3729,
      "step": 2224
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5252882242202759,
      "learning_rate": 5e-05,
      "loss": 0.3621,
      "step": 2232
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5796079635620117,
      "learning_rate": 5e-05,
      "loss": 0.3834,
      "step": 2240
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5609112977981567,
      "learning_rate": 5e-05,
      "loss": 0.3884,
      "step": 2248
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4302780330181122,
      "learning_rate": 5e-05,
      "loss": 0.3488,
      "step": 2256
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6766378879547119,
      "learning_rate": 5e-05,
      "loss": 0.3585,
      "step": 2264
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6534774303436279,
      "learning_rate": 5e-05,
      "loss": 0.3734,
      "step": 2272
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6187124848365784,
      "learning_rate": 5e-05,
      "loss": 0.3896,
      "step": 2280
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6015236973762512,
      "learning_rate": 5e-05,
      "loss": 0.3819,
      "step": 2288
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6376507878303528,
      "learning_rate": 5e-05,
      "loss": 0.4118,
      "step": 2296
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6800397634506226,
      "learning_rate": 5e-05,
      "loss": 0.4015,
      "step": 2304
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6130414009094238,
      "learning_rate": 5e-05,
      "loss": 0.3862,
      "step": 2312
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4870285093784332,
      "learning_rate": 5e-05,
      "loss": 0.3842,
      "step": 2320
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5562127828598022,
      "learning_rate": 5e-05,
      "loss": 0.3498,
      "step": 2328
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6637508273124695,
      "learning_rate": 5e-05,
      "loss": 0.3694,
      "step": 2336
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5816512703895569,
      "learning_rate": 5e-05,
      "loss": 0.3869,
      "step": 2344
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6156788468360901,
      "learning_rate": 5e-05,
      "loss": 0.3792,
      "step": 2352
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5873692631721497,
      "learning_rate": 5e-05,
      "loss": 0.404,
      "step": 2360
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5839155912399292,
      "learning_rate": 5e-05,
      "loss": 0.3663,
      "step": 2368
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5056508183479309,
      "learning_rate": 5e-05,
      "loss": 0.3848,
      "step": 2376
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5761997103691101,
      "learning_rate": 5e-05,
      "loss": 0.3818,
      "step": 2384
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5598558187484741,
      "learning_rate": 5e-05,
      "loss": 0.3607,
      "step": 2392
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5906513929367065,
      "learning_rate": 5e-05,
      "loss": 0.3891,
      "step": 2400
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6031843423843384,
      "learning_rate": 5e-05,
      "loss": 0.3996,
      "step": 2408
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6188597679138184,
      "learning_rate": 5e-05,
      "loss": 0.3774,
      "step": 2416
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5733513236045837,
      "learning_rate": 5e-05,
      "loss": 0.4015,
      "step": 2424
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6181842088699341,
      "learning_rate": 5e-05,
      "loss": 0.3766,
      "step": 2432
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6390984654426575,
      "learning_rate": 5e-05,
      "loss": 0.3928,
      "step": 2440
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4844450354576111,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 2448
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.622024655342102,
      "learning_rate": 5e-05,
      "loss": 0.3913,
      "step": 2456
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5153866410255432,
      "learning_rate": 5e-05,
      "loss": 0.3943,
      "step": 2464
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5795977115631104,
      "learning_rate": 5e-05,
      "loss": 0.3998,
      "step": 2472
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.645358681678772,
      "learning_rate": 5e-05,
      "loss": 0.37,
      "step": 2480
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5190269947052002,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 2488
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5772053599357605,
      "learning_rate": 5e-05,
      "loss": 0.3673,
      "step": 2496
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6557765603065491,
      "learning_rate": 5e-05,
      "loss": 0.3614,
      "step": 2504
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6292911171913147,
      "learning_rate": 5e-05,
      "loss": 0.388,
      "step": 2512
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5035672783851624,
      "learning_rate": 5e-05,
      "loss": 0.3735,
      "step": 2520
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.520801842212677,
      "learning_rate": 5e-05,
      "loss": 0.3697,
      "step": 2528
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5682325959205627,
      "learning_rate": 5e-05,
      "loss": 0.3851,
      "step": 2536
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6113422513008118,
      "learning_rate": 5e-05,
      "loss": 0.3314,
      "step": 2544
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5739313960075378,
      "learning_rate": 5e-05,
      "loss": 0.3845,
      "step": 2552
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.637407124042511,
      "learning_rate": 5e-05,
      "loss": 0.3678,
      "step": 2560
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6562245488166809,
      "learning_rate": 5e-05,
      "loss": 0.4004,
      "step": 2568
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5265894532203674,
      "learning_rate": 5e-05,
      "loss": 0.3931,
      "step": 2576
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6341988444328308,
      "learning_rate": 5e-05,
      "loss": 0.3643,
      "step": 2584
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.591012179851532,
      "learning_rate": 5e-05,
      "loss": 0.3825,
      "step": 2592
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7030534148216248,
      "learning_rate": 5e-05,
      "loss": 0.3627,
      "step": 2600
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.620255172252655,
      "learning_rate": 5e-05,
      "loss": 0.3618,
      "step": 2608
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.459275484085083,
      "learning_rate": 5e-05,
      "loss": 0.3925,
      "step": 2616
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5745649933815002,
      "learning_rate": 5e-05,
      "loss": 0.3852,
      "step": 2624
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.59456866979599,
      "learning_rate": 5e-05,
      "loss": 0.3972,
      "step": 2632
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5437700748443604,
      "learning_rate": 5e-05,
      "loss": 0.3562,
      "step": 2640
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.784271240234375,
      "learning_rate": 5e-05,
      "loss": 0.3486,
      "step": 2648
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5255110263824463,
      "learning_rate": 5e-05,
      "loss": 0.3778,
      "step": 2656
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7270928621292114,
      "learning_rate": 5e-05,
      "loss": 0.3559,
      "step": 2664
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6065828204154968,
      "learning_rate": 5e-05,
      "loss": 0.4092,
      "step": 2672
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.512862503528595,
      "learning_rate": 5e-05,
      "loss": 0.3777,
      "step": 2680
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.595648467540741,
      "learning_rate": 5e-05,
      "loss": 0.3804,
      "step": 2688
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6055711507797241,
      "learning_rate": 5e-05,
      "loss": 0.3939,
      "step": 2696
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6517634987831116,
      "learning_rate": 5e-05,
      "loss": 0.3495,
      "step": 2704
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5845239162445068,
      "learning_rate": 5e-05,
      "loss": 0.3697,
      "step": 2712
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6512972712516785,
      "learning_rate": 5e-05,
      "loss": 0.3946,
      "step": 2720
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5918008089065552,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 2728
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5442565083503723,
      "learning_rate": 5e-05,
      "loss": 0.366,
      "step": 2736
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6275639533996582,
      "learning_rate": 5e-05,
      "loss": 0.3814,
      "step": 2744
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4831700026988983,
      "learning_rate": 5e-05,
      "loss": 0.3722,
      "step": 2752
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5250324010848999,
      "learning_rate": 5e-05,
      "loss": 0.3774,
      "step": 2760
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5956652760505676,
      "learning_rate": 5e-05,
      "loss": 0.3684,
      "step": 2768
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5964152812957764,
      "learning_rate": 5e-05,
      "loss": 0.3724,
      "step": 2776
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5483466982841492,
      "learning_rate": 5e-05,
      "loss": 0.3883,
      "step": 2784
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6872438192367554,
      "learning_rate": 5e-05,
      "loss": 0.3862,
      "step": 2792
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7109268307685852,
      "learning_rate": 5e-05,
      "loss": 0.3576,
      "step": 2800
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4904407858848572,
      "learning_rate": 5e-05,
      "loss": 0.3912,
      "step": 2808
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6339721083641052,
      "learning_rate": 5e-05,
      "loss": 0.373,
      "step": 2816
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.84218430519104,
      "learning_rate": 5e-05,
      "loss": 0.378,
      "step": 2824
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7349323034286499,
      "learning_rate": 5e-05,
      "loss": 0.3944,
      "step": 2832
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.605637788772583,
      "learning_rate": 5e-05,
      "loss": 0.3506,
      "step": 2840
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7720818519592285,
      "learning_rate": 5e-05,
      "loss": 0.3563,
      "step": 2848
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5383459329605103,
      "learning_rate": 5e-05,
      "loss": 0.3614,
      "step": 2856
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6028696298599243,
      "learning_rate": 5e-05,
      "loss": 0.3978,
      "step": 2864
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5193788409233093,
      "learning_rate": 5e-05,
      "loss": 0.3522,
      "step": 2872
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7402640581130981,
      "learning_rate": 5e-05,
      "loss": 0.3767,
      "step": 2880
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5021522641181946,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 2888
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6210490465164185,
      "learning_rate": 5e-05,
      "loss": 0.3803,
      "step": 2896
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6406670808792114,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 2904
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5688474178314209,
      "learning_rate": 5e-05,
      "loss": 0.3551,
      "step": 2912
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5783625245094299,
      "learning_rate": 5e-05,
      "loss": 0.3891,
      "step": 2920
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7755634784698486,
      "learning_rate": 5e-05,
      "loss": 0.3734,
      "step": 2928
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6137913465499878,
      "learning_rate": 5e-05,
      "loss": 0.3654,
      "step": 2936
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6216821074485779,
      "learning_rate": 5e-05,
      "loss": 0.3866,
      "step": 2944
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.542413592338562,
      "learning_rate": 5e-05,
      "loss": 0.3565,
      "step": 2952
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6382929682731628,
      "learning_rate": 5e-05,
      "loss": 0.3712,
      "step": 2960
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6498731970787048,
      "learning_rate": 5e-05,
      "loss": 0.3497,
      "step": 2968
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5086306929588318,
      "learning_rate": 5e-05,
      "loss": 0.3594,
      "step": 2976
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5820601582527161,
      "learning_rate": 5e-05,
      "loss": 0.3766,
      "step": 2984
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6069422364234924,
      "learning_rate": 5e-05,
      "loss": 0.3523,
      "step": 2992
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.49583250284194946,
      "learning_rate": 5e-05,
      "loss": 0.3878,
      "step": 3000
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6406127214431763,
      "learning_rate": 5e-05,
      "loss": 0.3916,
      "step": 3008
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5835070013999939,
      "learning_rate": 5e-05,
      "loss": 0.3667,
      "step": 3016
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5110674500465393,
      "learning_rate": 5e-05,
      "loss": 0.3829,
      "step": 3024
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6187220811843872,
      "learning_rate": 5e-05,
      "loss": 0.3681,
      "step": 3032
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5111606121063232,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 3040
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.732969343662262,
      "learning_rate": 5e-05,
      "loss": 0.386,
      "step": 3048
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6955947875976562,
      "learning_rate": 5e-05,
      "loss": 0.3777,
      "step": 3056
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5437219738960266,
      "learning_rate": 5e-05,
      "loss": 0.3866,
      "step": 3064
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6390591859817505,
      "learning_rate": 5e-05,
      "loss": 0.3527,
      "step": 3072
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6205664277076721,
      "learning_rate": 5e-05,
      "loss": 0.3605,
      "step": 3080
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.544156014919281,
      "learning_rate": 5e-05,
      "loss": 0.4132,
      "step": 3088
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5916967988014221,
      "learning_rate": 5e-05,
      "loss": 0.3899,
      "step": 3096
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5450756549835205,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 3104
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6259794235229492,
      "learning_rate": 5e-05,
      "loss": 0.3538,
      "step": 3112
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6717710494995117,
      "learning_rate": 5e-05,
      "loss": 0.3502,
      "step": 3120
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5862123966217041,
      "learning_rate": 5e-05,
      "loss": 0.3893,
      "step": 3128
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5562939047813416,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 3136
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5428516864776611,
      "learning_rate": 5e-05,
      "loss": 0.3682,
      "step": 3144
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6708892583847046,
      "learning_rate": 5e-05,
      "loss": 0.4094,
      "step": 3152
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5910276770591736,
      "learning_rate": 5e-05,
      "loss": 0.3658,
      "step": 3160
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.646064281463623,
      "learning_rate": 5e-05,
      "loss": 0.3606,
      "step": 3168
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6046662330627441,
      "learning_rate": 5e-05,
      "loss": 0.3716,
      "step": 3176
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6068945527076721,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 3184
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6746262907981873,
      "learning_rate": 5e-05,
      "loss": 0.3909,
      "step": 3192
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5978808999061584,
      "learning_rate": 5e-05,
      "loss": 0.3957,
      "step": 3200
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6191290616989136,
      "learning_rate": 5e-05,
      "loss": 0.373,
      "step": 3208
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.532682478427887,
      "learning_rate": 5e-05,
      "loss": 0.367,
      "step": 3216
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5923565030097961,
      "learning_rate": 5e-05,
      "loss": 0.3992,
      "step": 3224
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.537261962890625,
      "learning_rate": 5e-05,
      "loss": 0.3545,
      "step": 3232
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.587615966796875,
      "learning_rate": 5e-05,
      "loss": 0.3598,
      "step": 3240
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6204034090042114,
      "learning_rate": 5e-05,
      "loss": 0.3882,
      "step": 3248
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.48009026050567627,
      "learning_rate": 5e-05,
      "loss": 0.3886,
      "step": 3256
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5286311507225037,
      "learning_rate": 5e-05,
      "loss": 0.3795,
      "step": 3264
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.589332640171051,
      "learning_rate": 5e-05,
      "loss": 0.373,
      "step": 3272
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7380439043045044,
      "learning_rate": 5e-05,
      "loss": 0.3777,
      "step": 3280
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5601157546043396,
      "learning_rate": 5e-05,
      "loss": 0.3537,
      "step": 3288
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6216224431991577,
      "learning_rate": 5e-05,
      "loss": 0.377,
      "step": 3296
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5332857370376587,
      "learning_rate": 5e-05,
      "loss": 0.3561,
      "step": 3304
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.555673360824585,
      "learning_rate": 5e-05,
      "loss": 0.3399,
      "step": 3312
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5437247157096863,
      "learning_rate": 5e-05,
      "loss": 0.3924,
      "step": 3320
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5820500254631042,
      "learning_rate": 5e-05,
      "loss": 0.3768,
      "step": 3328
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7405074238777161,
      "learning_rate": 5e-05,
      "loss": 0.3716,
      "step": 3336
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5826177597045898,
      "learning_rate": 5e-05,
      "loss": 0.3726,
      "step": 3344
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5971702933311462,
      "learning_rate": 5e-05,
      "loss": 0.3613,
      "step": 3352
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5798519253730774,
      "learning_rate": 5e-05,
      "loss": 0.3916,
      "step": 3360
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6392762064933777,
      "learning_rate": 5e-05,
      "loss": 0.3582,
      "step": 3368
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6125460267066956,
      "learning_rate": 5e-05,
      "loss": 0.3769,
      "step": 3376
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7877257466316223,
      "learning_rate": 5e-05,
      "loss": 0.3859,
      "step": 3384
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6025648713111877,
      "learning_rate": 5e-05,
      "loss": 0.3647,
      "step": 3392
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6992126703262329,
      "learning_rate": 5e-05,
      "loss": 0.3482,
      "step": 3400
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6048790812492371,
      "learning_rate": 5e-05,
      "loss": 0.3567,
      "step": 3408
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6033861041069031,
      "learning_rate": 5e-05,
      "loss": 0.3728,
      "step": 3416
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.631150484085083,
      "learning_rate": 5e-05,
      "loss": 0.3762,
      "step": 3424
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5445570945739746,
      "learning_rate": 5e-05,
      "loss": 0.3628,
      "step": 3432
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5770473480224609,
      "learning_rate": 5e-05,
      "loss": 0.367,
      "step": 3440
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6046950817108154,
      "learning_rate": 5e-05,
      "loss": 0.3931,
      "step": 3448
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6474387645721436,
      "learning_rate": 5e-05,
      "loss": 0.3647,
      "step": 3456
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.592641294002533,
      "learning_rate": 5e-05,
      "loss": 0.3769,
      "step": 3464
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6064008474349976,
      "learning_rate": 5e-05,
      "loss": 0.371,
      "step": 3472
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6094073057174683,
      "learning_rate": 5e-05,
      "loss": 0.3716,
      "step": 3480
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.561212420463562,
      "learning_rate": 5e-05,
      "loss": 0.3783,
      "step": 3488
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6977812647819519,
      "learning_rate": 5e-05,
      "loss": 0.3832,
      "step": 3496
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.598319947719574,
      "learning_rate": 5e-05,
      "loss": 0.3622,
      "step": 3504
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6150346398353577,
      "learning_rate": 5e-05,
      "loss": 0.3598,
      "step": 3512
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.626431405544281,
      "learning_rate": 5e-05,
      "loss": 0.3816,
      "step": 3520
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5620126724243164,
      "learning_rate": 5e-05,
      "loss": 0.3764,
      "step": 3528
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5329760909080505,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 3536
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6248601675033569,
      "learning_rate": 5e-05,
      "loss": 0.3605,
      "step": 3544
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.617912232875824,
      "learning_rate": 5e-05,
      "loss": 0.3745,
      "step": 3552
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4754418432712555,
      "learning_rate": 5e-05,
      "loss": 0.3657,
      "step": 3560
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5911908745765686,
      "learning_rate": 5e-05,
      "loss": 0.3617,
      "step": 3568
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5107258558273315,
      "learning_rate": 5e-05,
      "loss": 0.3471,
      "step": 3576
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6004649996757507,
      "learning_rate": 5e-05,
      "loss": 0.3906,
      "step": 3584
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5187152028083801,
      "learning_rate": 5e-05,
      "loss": 0.3615,
      "step": 3592
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5438922643661499,
      "learning_rate": 5e-05,
      "loss": 0.3348,
      "step": 3600
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5268060564994812,
      "learning_rate": 5e-05,
      "loss": 0.3672,
      "step": 3608
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6725350618362427,
      "learning_rate": 5e-05,
      "loss": 0.3594,
      "step": 3616
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6217457056045532,
      "learning_rate": 5e-05,
      "loss": 0.3848,
      "step": 3624
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8438531756401062,
      "learning_rate": 5e-05,
      "loss": 0.35,
      "step": 3632
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6210736632347107,
      "learning_rate": 5e-05,
      "loss": 0.363,
      "step": 3640
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.624305009841919,
      "learning_rate": 5e-05,
      "loss": 0.3835,
      "step": 3648
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.526938259601593,
      "learning_rate": 5e-05,
      "loss": 0.3905,
      "step": 3656
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6067880392074585,
      "learning_rate": 5e-05,
      "loss": 0.3389,
      "step": 3664
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7149994373321533,
      "learning_rate": 5e-05,
      "loss": 0.353,
      "step": 3672
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7504158616065979,
      "learning_rate": 5e-05,
      "loss": 0.3618,
      "step": 3680
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6988388299942017,
      "learning_rate": 5e-05,
      "loss": 0.4161,
      "step": 3688
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5817334055900574,
      "learning_rate": 5e-05,
      "loss": 0.3659,
      "step": 3696
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6734567880630493,
      "learning_rate": 5e-05,
      "loss": 0.4098,
      "step": 3704
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5594524145126343,
      "learning_rate": 5e-05,
      "loss": 0.3587,
      "step": 3712
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6046500205993652,
      "learning_rate": 5e-05,
      "loss": 0.3678,
      "step": 3720
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6625332832336426,
      "learning_rate": 5e-05,
      "loss": 0.3879,
      "step": 3728
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7345660924911499,
      "learning_rate": 5e-05,
      "loss": 0.4103,
      "step": 3736
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5997243523597717,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 3744
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5704938769340515,
      "learning_rate": 5e-05,
      "loss": 0.3965,
      "step": 3752
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5932504534721375,
      "learning_rate": 5e-05,
      "loss": 0.3664,
      "step": 3760
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7440085411071777,
      "learning_rate": 5e-05,
      "loss": 0.3744,
      "step": 3768
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7819765210151672,
      "learning_rate": 5e-05,
      "loss": 0.3532,
      "step": 3776
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5796692371368408,
      "learning_rate": 5e-05,
      "loss": 0.3326,
      "step": 3784
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6262866854667664,
      "learning_rate": 5e-05,
      "loss": 0.3589,
      "step": 3792
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.578029215335846,
      "learning_rate": 5e-05,
      "loss": 0.3479,
      "step": 3800
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6334495544433594,
      "learning_rate": 5e-05,
      "loss": 0.3627,
      "step": 3808
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6797861456871033,
      "learning_rate": 5e-05,
      "loss": 0.3489,
      "step": 3816
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7752485275268555,
      "learning_rate": 5e-05,
      "loss": 0.3634,
      "step": 3824
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5845540165901184,
      "learning_rate": 5e-05,
      "loss": 0.378,
      "step": 3832
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5739538669586182,
      "learning_rate": 5e-05,
      "loss": 0.387,
      "step": 3840
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6501076817512512,
      "learning_rate": 5e-05,
      "loss": 0.3579,
      "step": 3848
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5585381984710693,
      "learning_rate": 5e-05,
      "loss": 0.375,
      "step": 3856
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.60853511095047,
      "learning_rate": 5e-05,
      "loss": 0.3673,
      "step": 3864
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5908211469650269,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 3872
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6255670785903931,
      "learning_rate": 5e-05,
      "loss": 0.3429,
      "step": 3880
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6694207787513733,
      "learning_rate": 5e-05,
      "loss": 0.3821,
      "step": 3888
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7013923525810242,
      "learning_rate": 5e-05,
      "loss": 0.3767,
      "step": 3896
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7502742409706116,
      "learning_rate": 5e-05,
      "loss": 0.3755,
      "step": 3904
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5641376972198486,
      "learning_rate": 5e-05,
      "loss": 0.3525,
      "step": 3912
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5676360130310059,
      "learning_rate": 5e-05,
      "loss": 0.3411,
      "step": 3920
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5674182176589966,
      "learning_rate": 5e-05,
      "loss": 0.3701,
      "step": 3928
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5222844481468201,
      "learning_rate": 5e-05,
      "loss": 0.3529,
      "step": 3936
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5447665452957153,
      "learning_rate": 5e-05,
      "loss": 0.3821,
      "step": 3944
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.612508237361908,
      "learning_rate": 5e-05,
      "loss": 0.3627,
      "step": 3952
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5350823402404785,
      "learning_rate": 5e-05,
      "loss": 0.379,
      "step": 3960
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.715728223323822,
      "learning_rate": 5e-05,
      "loss": 0.3516,
      "step": 3968
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5637520551681519,
      "learning_rate": 5e-05,
      "loss": 0.3631,
      "step": 3976
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7447178363800049,
      "learning_rate": 5e-05,
      "loss": 0.3651,
      "step": 3984
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5280184149742126,
      "learning_rate": 5e-05,
      "loss": 0.39,
      "step": 3992
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.496010422706604,
      "learning_rate": 5e-05,
      "loss": 0.3698,
      "step": 4000
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.681063711643219,
      "learning_rate": 5e-05,
      "loss": 0.3652,
      "step": 4008
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.8148801326751709,
      "learning_rate": 5e-05,
      "loss": 0.3685,
      "step": 4016
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5934609174728394,
      "learning_rate": 5e-05,
      "loss": 0.3898,
      "step": 4024
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5636022090911865,
      "learning_rate": 5e-05,
      "loss": 0.3459,
      "step": 4032
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6289224624633789,
      "learning_rate": 5e-05,
      "loss": 0.3883,
      "step": 4040
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5254249572753906,
      "learning_rate": 5e-05,
      "loss": 0.3497,
      "step": 4048
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5793301463127136,
      "learning_rate": 5e-05,
      "loss": 0.3298,
      "step": 4056
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6917692422866821,
      "learning_rate": 5e-05,
      "loss": 0.3751,
      "step": 4064
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5536271333694458,
      "learning_rate": 5e-05,
      "loss": 0.3689,
      "step": 4072
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6953570246696472,
      "learning_rate": 5e-05,
      "loss": 0.3621,
      "step": 4080
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6018871068954468,
      "learning_rate": 5e-05,
      "loss": 0.342,
      "step": 4088
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.569123387336731,
      "learning_rate": 5e-05,
      "loss": 0.3576,
      "step": 4096
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5977156162261963,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 4104
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5691630840301514,
      "learning_rate": 5e-05,
      "loss": 0.3696,
      "step": 4112
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5835095643997192,
      "learning_rate": 5e-05,
      "loss": 0.3835,
      "step": 4120
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5003004670143127,
      "learning_rate": 5e-05,
      "loss": 0.3373,
      "step": 4128
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6183885931968689,
      "learning_rate": 5e-05,
      "loss": 0.3867,
      "step": 4136
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6489753723144531,
      "learning_rate": 5e-05,
      "loss": 0.3833,
      "step": 4144
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6354680061340332,
      "learning_rate": 5e-05,
      "loss": 0.3714,
      "step": 4152
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.626227617263794,
      "learning_rate": 5e-05,
      "loss": 0.3518,
      "step": 4160
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6387676000595093,
      "learning_rate": 5e-05,
      "loss": 0.3463,
      "step": 4168
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5173450112342834,
      "learning_rate": 5e-05,
      "loss": 0.3716,
      "step": 4176
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5576667189598083,
      "learning_rate": 5e-05,
      "loss": 0.3822,
      "step": 4184
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6349327564239502,
      "learning_rate": 5e-05,
      "loss": 0.36,
      "step": 4192
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6602625846862793,
      "learning_rate": 5e-05,
      "loss": 0.3957,
      "step": 4200
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6087417006492615,
      "learning_rate": 5e-05,
      "loss": 0.3682,
      "step": 4208
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6355285048484802,
      "learning_rate": 5e-05,
      "loss": 0.3596,
      "step": 4216
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.700975775718689,
      "learning_rate": 5e-05,
      "loss": 0.37,
      "step": 4224
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6179533004760742,
      "learning_rate": 5e-05,
      "loss": 0.3912,
      "step": 4232
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5765446424484253,
      "learning_rate": 5e-05,
      "loss": 0.3599,
      "step": 4240
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5425381064414978,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 4248
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6093931198120117,
      "learning_rate": 5e-05,
      "loss": 0.3632,
      "step": 4256
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6451171040534973,
      "learning_rate": 5e-05,
      "loss": 0.3709,
      "step": 4264
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5856810212135315,
      "learning_rate": 5e-05,
      "loss": 0.3838,
      "step": 4272
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5591624975204468,
      "learning_rate": 5e-05,
      "loss": 0.3649,
      "step": 4280
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5765906572341919,
      "learning_rate": 5e-05,
      "loss": 0.3551,
      "step": 4288
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5996723175048828,
      "learning_rate": 5e-05,
      "loss": 0.3418,
      "step": 4296
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7033903002738953,
      "learning_rate": 5e-05,
      "loss": 0.3862,
      "step": 4304
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5477246642112732,
      "learning_rate": 5e-05,
      "loss": 0.3659,
      "step": 4312
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6740657091140747,
      "learning_rate": 5e-05,
      "loss": 0.3562,
      "step": 4320
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5353357791900635,
      "learning_rate": 5e-05,
      "loss": 0.3758,
      "step": 4328
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8465714454650879,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 4336
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.659356951713562,
      "learning_rate": 5e-05,
      "loss": 0.3726,
      "step": 4344
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6197179555892944,
      "learning_rate": 5e-05,
      "loss": 0.3824,
      "step": 4352
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5892958641052246,
      "learning_rate": 5e-05,
      "loss": 0.3469,
      "step": 4360
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6582675576210022,
      "learning_rate": 5e-05,
      "loss": 0.352,
      "step": 4368
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5388155579566956,
      "learning_rate": 5e-05,
      "loss": 0.3543,
      "step": 4376
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5954020023345947,
      "learning_rate": 5e-05,
      "loss": 0.3707,
      "step": 4384
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6944409012794495,
      "learning_rate": 5e-05,
      "loss": 0.3862,
      "step": 4392
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5826597809791565,
      "learning_rate": 5e-05,
      "loss": 0.3596,
      "step": 4400
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5372472405433655,
      "learning_rate": 5e-05,
      "loss": 0.3589,
      "step": 4408
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5769539475440979,
      "learning_rate": 5e-05,
      "loss": 0.374,
      "step": 4416
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5628166794776917,
      "learning_rate": 5e-05,
      "loss": 0.352,
      "step": 4424
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6481004357337952,
      "learning_rate": 5e-05,
      "loss": 0.3834,
      "step": 4432
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6103420257568359,
      "learning_rate": 5e-05,
      "loss": 0.3642,
      "step": 4440
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6502674221992493,
      "learning_rate": 5e-05,
      "loss": 0.3715,
      "step": 4448
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5401626825332642,
      "learning_rate": 5e-05,
      "loss": 0.3479,
      "step": 4456
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5532200336456299,
      "learning_rate": 5e-05,
      "loss": 0.3873,
      "step": 4464
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.49590885639190674,
      "learning_rate": 5e-05,
      "loss": 0.371,
      "step": 4472
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5856391787528992,
      "learning_rate": 5e-05,
      "loss": 0.348,
      "step": 4480
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5424610376358032,
      "learning_rate": 5e-05,
      "loss": 0.3608,
      "step": 4488
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7910908460617065,
      "learning_rate": 5e-05,
      "loss": 0.3623,
      "step": 4496
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5697240829467773,
      "learning_rate": 5e-05,
      "loss": 0.3711,
      "step": 4504
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6328216195106506,
      "learning_rate": 5e-05,
      "loss": 0.3613,
      "step": 4512
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6186020970344543,
      "learning_rate": 5e-05,
      "loss": 0.3568,
      "step": 4520
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.668321967124939,
      "learning_rate": 5e-05,
      "loss": 0.3615,
      "step": 4528
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6719413995742798,
      "learning_rate": 5e-05,
      "loss": 0.3809,
      "step": 4536
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5288121104240417,
      "learning_rate": 5e-05,
      "loss": 0.367,
      "step": 4544
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5939645767211914,
      "learning_rate": 5e-05,
      "loss": 0.359,
      "step": 4552
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7219897508621216,
      "learning_rate": 5e-05,
      "loss": 0.3493,
      "step": 4560
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5643470287322998,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 4568
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6158863306045532,
      "learning_rate": 5e-05,
      "loss": 0.3519,
      "step": 4576
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5422260761260986,
      "learning_rate": 5e-05,
      "loss": 0.3551,
      "step": 4584
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6258586049079895,
      "learning_rate": 5e-05,
      "loss": 0.3774,
      "step": 4592
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5193554162979126,
      "learning_rate": 5e-05,
      "loss": 0.3974,
      "step": 4600
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6053996682167053,
      "learning_rate": 5e-05,
      "loss": 0.3754,
      "step": 4608
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5593486428260803,
      "learning_rate": 5e-05,
      "loss": 0.3593,
      "step": 4616
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5403149127960205,
      "learning_rate": 5e-05,
      "loss": 0.3703,
      "step": 4624
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7462954521179199,
      "learning_rate": 5e-05,
      "loss": 0.3633,
      "step": 4632
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.593892514705658,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 4640
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.587394654750824,
      "learning_rate": 5e-05,
      "loss": 0.3481,
      "step": 4648
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6243960857391357,
      "learning_rate": 5e-05,
      "loss": 0.3451,
      "step": 4656
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5046678781509399,
      "learning_rate": 5e-05,
      "loss": 0.3494,
      "step": 4664
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5341074466705322,
      "learning_rate": 5e-05,
      "loss": 0.3659,
      "step": 4672
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6476245522499084,
      "learning_rate": 5e-05,
      "loss": 0.3591,
      "step": 4680
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.49033352732658386,
      "learning_rate": 5e-05,
      "loss": 0.3709,
      "step": 4688
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5814931392669678,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 4696
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5847153067588806,
      "learning_rate": 5e-05,
      "loss": 0.3692,
      "step": 4704
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.47053995728492737,
      "learning_rate": 5e-05,
      "loss": 0.3837,
      "step": 4712
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6946582794189453,
      "learning_rate": 5e-05,
      "loss": 0.3943,
      "step": 4720
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.594685435295105,
      "learning_rate": 5e-05,
      "loss": 0.3732,
      "step": 4728
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6791764497756958,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 4736
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6300022602081299,
      "learning_rate": 5e-05,
      "loss": 0.3281,
      "step": 4744
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6508093476295471,
      "learning_rate": 5e-05,
      "loss": 0.3598,
      "step": 4752
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5523666739463806,
      "learning_rate": 5e-05,
      "loss": 0.3603,
      "step": 4760
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6224042773246765,
      "learning_rate": 5e-05,
      "loss": 0.3785,
      "step": 4768
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8043243885040283,
      "learning_rate": 5e-05,
      "loss": 0.3524,
      "step": 4776
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6268855333328247,
      "learning_rate": 5e-05,
      "loss": 0.3531,
      "step": 4784
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.602414608001709,
      "learning_rate": 5e-05,
      "loss": 0.337,
      "step": 4792
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7838016748428345,
      "learning_rate": 5e-05,
      "loss": 0.3875,
      "step": 4800
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6895694136619568,
      "learning_rate": 5e-05,
      "loss": 0.3642,
      "step": 4808
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6339758634567261,
      "learning_rate": 5e-05,
      "loss": 0.4029,
      "step": 4816
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6325401663780212,
      "learning_rate": 5e-05,
      "loss": 0.3642,
      "step": 4824
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.60548335313797,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 4832
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6281307935714722,
      "learning_rate": 5e-05,
      "loss": 0.3467,
      "step": 4840
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5848056077957153,
      "learning_rate": 5e-05,
      "loss": 0.3481,
      "step": 4848
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6219514608383179,
      "learning_rate": 5e-05,
      "loss": 0.3651,
      "step": 4856
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6804084181785583,
      "learning_rate": 5e-05,
      "loss": 0.3402,
      "step": 4864
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5110087990760803,
      "learning_rate": 5e-05,
      "loss": 0.3557,
      "step": 4872
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5846076607704163,
      "learning_rate": 5e-05,
      "loss": 0.359,
      "step": 4880
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5556555986404419,
      "learning_rate": 5e-05,
      "loss": 0.3456,
      "step": 4888
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6334839463233948,
      "learning_rate": 5e-05,
      "loss": 0.353,
      "step": 4896
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5439375042915344,
      "learning_rate": 5e-05,
      "loss": 0.3674,
      "step": 4904
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.573937714099884,
      "learning_rate": 5e-05,
      "loss": 0.3384,
      "step": 4912
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6489399075508118,
      "learning_rate": 5e-05,
      "loss": 0.355,
      "step": 4920
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6669545769691467,
      "learning_rate": 5e-05,
      "loss": 0.3863,
      "step": 4928
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.48860082030296326,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 4936
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6368935108184814,
      "learning_rate": 5e-05,
      "loss": 0.3637,
      "step": 4944
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6718161106109619,
      "learning_rate": 5e-05,
      "loss": 0.3538,
      "step": 4952
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6308802366256714,
      "learning_rate": 5e-05,
      "loss": 0.3616,
      "step": 4960
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6465697884559631,
      "learning_rate": 5e-05,
      "loss": 0.3704,
      "step": 4968
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5954138040542603,
      "learning_rate": 5e-05,
      "loss": 0.3382,
      "step": 4976
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5879426598548889,
      "learning_rate": 5e-05,
      "loss": 0.3509,
      "step": 4984
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6044078469276428,
      "learning_rate": 5e-05,
      "loss": 0.3558,
      "step": 4992
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6343244910240173,
      "learning_rate": 5e-05,
      "loss": 0.3775,
      "step": 5000
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6933174729347229,
      "learning_rate": 5e-05,
      "loss": 0.3703,
      "step": 5008
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6722953915596008,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 5016
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6266788840293884,
      "learning_rate": 5e-05,
      "loss": 0.3878,
      "step": 5024
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5664046406745911,
      "learning_rate": 5e-05,
      "loss": 0.3763,
      "step": 5032
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6683749556541443,
      "learning_rate": 5e-05,
      "loss": 0.3468,
      "step": 5040
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6518334746360779,
      "learning_rate": 5e-05,
      "loss": 0.3516,
      "step": 5048
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5932533740997314,
      "learning_rate": 5e-05,
      "loss": 0.384,
      "step": 5056
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7625011801719666,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 5064
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6598358154296875,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 5072
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6907387971878052,
      "learning_rate": 5e-05,
      "loss": 0.3658,
      "step": 5080
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6106390953063965,
      "learning_rate": 5e-05,
      "loss": 0.3674,
      "step": 5088
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6598876714706421,
      "learning_rate": 5e-05,
      "loss": 0.3481,
      "step": 5096
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7029162645339966,
      "learning_rate": 5e-05,
      "loss": 0.3599,
      "step": 5104
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5726357102394104,
      "learning_rate": 5e-05,
      "loss": 0.3449,
      "step": 5112
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5939725041389465,
      "learning_rate": 5e-05,
      "loss": 0.381,
      "step": 5120
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5740622878074646,
      "learning_rate": 5e-05,
      "loss": 0.3566,
      "step": 5128
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6265860199928284,
      "learning_rate": 5e-05,
      "loss": 0.3571,
      "step": 5136
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6339547634124756,
      "learning_rate": 5e-05,
      "loss": 0.3851,
      "step": 5144
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6440486311912537,
      "learning_rate": 5e-05,
      "loss": 0.3543,
      "step": 5152
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.670076847076416,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 5160
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5866201519966125,
      "learning_rate": 5e-05,
      "loss": 0.3467,
      "step": 5168
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5064319968223572,
      "learning_rate": 5e-05,
      "loss": 0.3473,
      "step": 5176
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5966705679893494,
      "learning_rate": 5e-05,
      "loss": 0.3738,
      "step": 5184
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6519707441329956,
      "learning_rate": 5e-05,
      "loss": 0.3741,
      "step": 5192
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5459244251251221,
      "learning_rate": 5e-05,
      "loss": 0.3506,
      "step": 5200
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5847277045249939,
      "learning_rate": 5e-05,
      "loss": 0.3665,
      "step": 5208
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6336643099784851,
      "learning_rate": 5e-05,
      "loss": 0.3922,
      "step": 5216
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5543423295021057,
      "learning_rate": 5e-05,
      "loss": 0.3515,
      "step": 5224
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.559566855430603,
      "learning_rate": 5e-05,
      "loss": 0.3577,
      "step": 5232
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5954195261001587,
      "learning_rate": 5e-05,
      "loss": 0.3855,
      "step": 5240
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6118185520172119,
      "learning_rate": 5e-05,
      "loss": 0.3742,
      "step": 5248
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6938015222549438,
      "learning_rate": 5e-05,
      "loss": 0.3474,
      "step": 5256
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6585535407066345,
      "learning_rate": 5e-05,
      "loss": 0.3815,
      "step": 5264
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6644339561462402,
      "learning_rate": 5e-05,
      "loss": 0.3679,
      "step": 5272
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6405429840087891,
      "learning_rate": 5e-05,
      "loss": 0.3538,
      "step": 5280
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6031171083450317,
      "learning_rate": 5e-05,
      "loss": 0.3674,
      "step": 5288
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.557439923286438,
      "learning_rate": 5e-05,
      "loss": 0.3556,
      "step": 5296
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5385639071464539,
      "learning_rate": 5e-05,
      "loss": 0.379,
      "step": 5304
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5778435468673706,
      "learning_rate": 5e-05,
      "loss": 0.3528,
      "step": 5312
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.598552405834198,
      "learning_rate": 5e-05,
      "loss": 0.3559,
      "step": 5320
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5344844460487366,
      "learning_rate": 5e-05,
      "loss": 0.3431,
      "step": 5328
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5855515003204346,
      "learning_rate": 5e-05,
      "loss": 0.3775,
      "step": 5336
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5578524470329285,
      "learning_rate": 5e-05,
      "loss": 0.4022,
      "step": 5344
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.574910581111908,
      "learning_rate": 5e-05,
      "loss": 0.3797,
      "step": 5352
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6020411252975464,
      "learning_rate": 5e-05,
      "loss": 0.3931,
      "step": 5360
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5987209677696228,
      "learning_rate": 5e-05,
      "loss": 0.3588,
      "step": 5368
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6338961124420166,
      "learning_rate": 5e-05,
      "loss": 0.3688,
      "step": 5376
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5801267027854919,
      "learning_rate": 5e-05,
      "loss": 0.3714,
      "step": 5384
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6628265380859375,
      "learning_rate": 5e-05,
      "loss": 0.3491,
      "step": 5392
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6502863764762878,
      "learning_rate": 5e-05,
      "loss": 0.3363,
      "step": 5400
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5543188452720642,
      "learning_rate": 5e-05,
      "loss": 0.3519,
      "step": 5408
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.606001079082489,
      "learning_rate": 5e-05,
      "loss": 0.341,
      "step": 5416
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5632416605949402,
      "learning_rate": 5e-05,
      "loss": 0.3625,
      "step": 5424
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5403155088424683,
      "learning_rate": 5e-05,
      "loss": 0.3642,
      "step": 5432
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6284400224685669,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 5440
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.654181182384491,
      "learning_rate": 5e-05,
      "loss": 0.3465,
      "step": 5448
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5567167401313782,
      "learning_rate": 5e-05,
      "loss": 0.3671,
      "step": 5456
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6209814548492432,
      "learning_rate": 5e-05,
      "loss": 0.3673,
      "step": 5464
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5596505403518677,
      "learning_rate": 5e-05,
      "loss": 0.3362,
      "step": 5472
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6360599398612976,
      "learning_rate": 5e-05,
      "loss": 0.3548,
      "step": 5480
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6070075035095215,
      "learning_rate": 5e-05,
      "loss": 0.3352,
      "step": 5488
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6785553097724915,
      "learning_rate": 5e-05,
      "loss": 0.3285,
      "step": 5496
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5920276045799255,
      "learning_rate": 5e-05,
      "loss": 0.3348,
      "step": 5504
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6288107633590698,
      "learning_rate": 5e-05,
      "loss": 0.3412,
      "step": 5512
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6177977919578552,
      "learning_rate": 5e-05,
      "loss": 0.3419,
      "step": 5520
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6534387469291687,
      "learning_rate": 5e-05,
      "loss": 0.3876,
      "step": 5528
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8152582049369812,
      "learning_rate": 5e-05,
      "loss": 0.4044,
      "step": 5536
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5217374563217163,
      "learning_rate": 5e-05,
      "loss": 0.3374,
      "step": 5544
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6934604048728943,
      "learning_rate": 5e-05,
      "loss": 0.3669,
      "step": 5552
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7119637131690979,
      "learning_rate": 5e-05,
      "loss": 0.375,
      "step": 5560
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5922262072563171,
      "learning_rate": 5e-05,
      "loss": 0.3582,
      "step": 5568
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6170105934143066,
      "learning_rate": 5e-05,
      "loss": 0.3485,
      "step": 5576
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6404053568840027,
      "learning_rate": 5e-05,
      "loss": 0.3601,
      "step": 5584
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5757104158401489,
      "learning_rate": 5e-05,
      "loss": 0.3469,
      "step": 5592
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6085199117660522,
      "learning_rate": 5e-05,
      "loss": 0.3713,
      "step": 5600
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5983723998069763,
      "learning_rate": 5e-05,
      "loss": 0.3588,
      "step": 5608
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5860595107078552,
      "learning_rate": 5e-05,
      "loss": 0.381,
      "step": 5616
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6989970207214355,
      "learning_rate": 5e-05,
      "loss": 0.3429,
      "step": 5624
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5570116639137268,
      "learning_rate": 5e-05,
      "loss": 0.368,
      "step": 5632
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5894924402236938,
      "learning_rate": 5e-05,
      "loss": 0.3409,
      "step": 5640
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5745004415512085,
      "learning_rate": 5e-05,
      "loss": 0.359,
      "step": 5648
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6287571787834167,
      "learning_rate": 5e-05,
      "loss": 0.3727,
      "step": 5656
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6242244839668274,
      "learning_rate": 5e-05,
      "loss": 0.3579,
      "step": 5664
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6111618280410767,
      "learning_rate": 5e-05,
      "loss": 0.3442,
      "step": 5672
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6190316677093506,
      "learning_rate": 5e-05,
      "loss": 0.3529,
      "step": 5680
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6077950596809387,
      "learning_rate": 5e-05,
      "loss": 0.36,
      "step": 5688
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5599620938301086,
      "learning_rate": 5e-05,
      "loss": 0.3607,
      "step": 5696
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5490062236785889,
      "learning_rate": 5e-05,
      "loss": 0.35,
      "step": 5704
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.572725772857666,
      "learning_rate": 5e-05,
      "loss": 0.3511,
      "step": 5712
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5715057253837585,
      "learning_rate": 5e-05,
      "loss": 0.3615,
      "step": 5720
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5513268113136292,
      "learning_rate": 5e-05,
      "loss": 0.3497,
      "step": 5728
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7172395586967468,
      "learning_rate": 5e-05,
      "loss": 0.3526,
      "step": 5736
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5528473258018494,
      "learning_rate": 5e-05,
      "loss": 0.3273,
      "step": 5744
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6507661938667297,
      "learning_rate": 5e-05,
      "loss": 0.3594,
      "step": 5752
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6180864572525024,
      "learning_rate": 5e-05,
      "loss": 0.342,
      "step": 5760
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8701971173286438,
      "learning_rate": 5e-05,
      "loss": 0.3726,
      "step": 5768
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6584043502807617,
      "learning_rate": 5e-05,
      "loss": 0.3406,
      "step": 5776
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6453743577003479,
      "learning_rate": 5e-05,
      "loss": 0.3242,
      "step": 5784
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6983501315116882,
      "learning_rate": 5e-05,
      "loss": 0.3567,
      "step": 5792
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7659922242164612,
      "learning_rate": 5e-05,
      "loss": 0.3489,
      "step": 5800
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.600328803062439,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 5808
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5835305452346802,
      "learning_rate": 5e-05,
      "loss": 0.3515,
      "step": 5816
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5740078091621399,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 5824
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5799431204795837,
      "learning_rate": 5e-05,
      "loss": 0.3569,
      "step": 5832
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5514675378799438,
      "learning_rate": 5e-05,
      "loss": 0.3633,
      "step": 5840
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5408797264099121,
      "learning_rate": 5e-05,
      "loss": 0.3429,
      "step": 5848
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6099961996078491,
      "learning_rate": 5e-05,
      "loss": 0.3523,
      "step": 5856
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6140954494476318,
      "learning_rate": 5e-05,
      "loss": 0.3639,
      "step": 5864
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5708874464035034,
      "learning_rate": 5e-05,
      "loss": 0.3196,
      "step": 5872
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.72857666015625,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 5880
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5372282266616821,
      "learning_rate": 5e-05,
      "loss": 0.346,
      "step": 5888
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5763370394706726,
      "learning_rate": 5e-05,
      "loss": 0.3697,
      "step": 5896
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5797571539878845,
      "learning_rate": 5e-05,
      "loss": 0.3524,
      "step": 5904
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7053424715995789,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 5912
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5278441905975342,
      "learning_rate": 5e-05,
      "loss": 0.3375,
      "step": 5920
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5771918892860413,
      "learning_rate": 5e-05,
      "loss": 0.3863,
      "step": 5928
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5191749334335327,
      "learning_rate": 5e-05,
      "loss": 0.3424,
      "step": 5936
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6407923698425293,
      "learning_rate": 5e-05,
      "loss": 0.3525,
      "step": 5944
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5572529435157776,
      "learning_rate": 5e-05,
      "loss": 0.3422,
      "step": 5952
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6302818059921265,
      "learning_rate": 5e-05,
      "loss": 0.3676,
      "step": 5960
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6769126057624817,
      "learning_rate": 5e-05,
      "loss": 0.3462,
      "step": 5968
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5630389451980591,
      "learning_rate": 5e-05,
      "loss": 0.394,
      "step": 5976
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6010197997093201,
      "learning_rate": 5e-05,
      "loss": 0.3555,
      "step": 5984
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5520468950271606,
      "learning_rate": 5e-05,
      "loss": 0.3336,
      "step": 5992
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5351448655128479,
      "learning_rate": 5e-05,
      "loss": 0.3659,
      "step": 6000
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5210369229316711,
      "learning_rate": 5e-05,
      "loss": 0.3296,
      "step": 6008
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7123698592185974,
      "learning_rate": 5e-05,
      "loss": 0.3497,
      "step": 6016
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.561368465423584,
      "learning_rate": 5e-05,
      "loss": 0.3654,
      "step": 6024
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7848602533340454,
      "learning_rate": 5e-05,
      "loss": 0.3546,
      "step": 6032
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5996608138084412,
      "learning_rate": 5e-05,
      "loss": 0.3653,
      "step": 6040
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6210663318634033,
      "learning_rate": 5e-05,
      "loss": 0.3444,
      "step": 6048
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5748615860939026,
      "learning_rate": 5e-05,
      "loss": 0.3465,
      "step": 6056
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5750020146369934,
      "learning_rate": 5e-05,
      "loss": 0.3841,
      "step": 6064
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6624456644058228,
      "learning_rate": 5e-05,
      "loss": 0.3468,
      "step": 6072
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6409837007522583,
      "learning_rate": 5e-05,
      "loss": 0.3537,
      "step": 6080
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6411604285240173,
      "learning_rate": 5e-05,
      "loss": 0.3455,
      "step": 6088
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.570838212966919,
      "learning_rate": 5e-05,
      "loss": 0.3521,
      "step": 6096
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6419001817703247,
      "learning_rate": 5e-05,
      "loss": 0.3627,
      "step": 6104
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6823618412017822,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 6112
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5863112807273865,
      "learning_rate": 5e-05,
      "loss": 0.3402,
      "step": 6120
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7078675627708435,
      "learning_rate": 5e-05,
      "loss": 0.3553,
      "step": 6128
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7732614874839783,
      "learning_rate": 5e-05,
      "loss": 0.388,
      "step": 6136
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5900639295578003,
      "learning_rate": 5e-05,
      "loss": 0.3597,
      "step": 6144
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7023693919181824,
      "learning_rate": 5e-05,
      "loss": 0.3328,
      "step": 6152
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6209189891815186,
      "learning_rate": 5e-05,
      "loss": 0.3586,
      "step": 6160
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7013123035430908,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 6168
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7470307946205139,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 6176
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5452154278755188,
      "learning_rate": 5e-05,
      "loss": 0.3457,
      "step": 6184
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5055367946624756,
      "learning_rate": 5e-05,
      "loss": 0.3564,
      "step": 6192
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6416140198707581,
      "learning_rate": 5e-05,
      "loss": 0.3724,
      "step": 6200
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6052671670913696,
      "learning_rate": 5e-05,
      "loss": 0.3644,
      "step": 6208
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7494964599609375,
      "learning_rate": 5e-05,
      "loss": 0.3387,
      "step": 6216
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7010308504104614,
      "learning_rate": 5e-05,
      "loss": 0.3602,
      "step": 6224
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5866555571556091,
      "learning_rate": 5e-05,
      "loss": 0.3745,
      "step": 6232
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.668093204498291,
      "learning_rate": 5e-05,
      "loss": 0.3727,
      "step": 6240
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5539557933807373,
      "learning_rate": 5e-05,
      "loss": 0.3694,
      "step": 6248
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.711258053779602,
      "learning_rate": 5e-05,
      "loss": 0.3609,
      "step": 6256
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6690407395362854,
      "learning_rate": 5e-05,
      "loss": 0.3291,
      "step": 6264
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5393860340118408,
      "learning_rate": 5e-05,
      "loss": 0.368,
      "step": 6272
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7008528113365173,
      "learning_rate": 5e-05,
      "loss": 0.3552,
      "step": 6280
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.541908860206604,
      "learning_rate": 5e-05,
      "loss": 0.3466,
      "step": 6288
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5263568162918091,
      "learning_rate": 5e-05,
      "loss": 0.3386,
      "step": 6296
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5984251499176025,
      "learning_rate": 5e-05,
      "loss": 0.3675,
      "step": 6304
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6556429266929626,
      "learning_rate": 5e-05,
      "loss": 0.3682,
      "step": 6312
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5526572465896606,
      "learning_rate": 5e-05,
      "loss": 0.3533,
      "step": 6320
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.601842999458313,
      "learning_rate": 5e-05,
      "loss": 0.3616,
      "step": 6328
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7034745216369629,
      "learning_rate": 5e-05,
      "loss": 0.3394,
      "step": 6336
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6059306859970093,
      "learning_rate": 5e-05,
      "loss": 0.3788,
      "step": 6344
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6593411564826965,
      "learning_rate": 5e-05,
      "loss": 0.3551,
      "step": 6352
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7152368426322937,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 6360
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.584262490272522,
      "learning_rate": 5e-05,
      "loss": 0.388,
      "step": 6368
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6130170226097107,
      "learning_rate": 5e-05,
      "loss": 0.3438,
      "step": 6376
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.66304612159729,
      "learning_rate": 5e-05,
      "loss": 0.3688,
      "step": 6384
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.868206262588501,
      "learning_rate": 5e-05,
      "loss": 0.3696,
      "step": 6392
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6213858127593994,
      "learning_rate": 5e-05,
      "loss": 0.3729,
      "step": 6400
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7415663003921509,
      "learning_rate": 5e-05,
      "loss": 0.3561,
      "step": 6408
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6048742532730103,
      "learning_rate": 5e-05,
      "loss": 0.3931,
      "step": 6416
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.596523642539978,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 6424
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6243599653244019,
      "learning_rate": 5e-05,
      "loss": 0.3692,
      "step": 6432
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6253889799118042,
      "learning_rate": 5e-05,
      "loss": 0.3749,
      "step": 6440
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6568957567214966,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 6448
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6138812303543091,
      "learning_rate": 5e-05,
      "loss": 0.3682,
      "step": 6456
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5102739930152893,
      "learning_rate": 5e-05,
      "loss": 0.3822,
      "step": 6464
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5828747749328613,
      "learning_rate": 5e-05,
      "loss": 0.3456,
      "step": 6472
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5488832592964172,
      "learning_rate": 5e-05,
      "loss": 0.3689,
      "step": 6480
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6685381531715393,
      "learning_rate": 5e-05,
      "loss": 0.3495,
      "step": 6488
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5547995567321777,
      "learning_rate": 5e-05,
      "loss": 0.3409,
      "step": 6496
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6326066255569458,
      "learning_rate": 5e-05,
      "loss": 0.3612,
      "step": 6504
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6222307682037354,
      "learning_rate": 5e-05,
      "loss": 0.3256,
      "step": 6512
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6293895840644836,
      "learning_rate": 5e-05,
      "loss": 0.3402,
      "step": 6520
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5700721740722656,
      "learning_rate": 5e-05,
      "loss": 0.341,
      "step": 6528
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6425430178642273,
      "learning_rate": 5e-05,
      "loss": 0.3671,
      "step": 6536
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6327005624771118,
      "learning_rate": 5e-05,
      "loss": 0.3821,
      "step": 6544
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5904926657676697,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 6552
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6158030033111572,
      "learning_rate": 5e-05,
      "loss": 0.3531,
      "step": 6560
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5695927739143372,
      "learning_rate": 5e-05,
      "loss": 0.3604,
      "step": 6568
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6373934745788574,
      "learning_rate": 5e-05,
      "loss": 0.3476,
      "step": 6576
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7011004090309143,
      "learning_rate": 5e-05,
      "loss": 0.351,
      "step": 6584
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.602225661277771,
      "learning_rate": 5e-05,
      "loss": 0.3758,
      "step": 6592
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6868135929107666,
      "learning_rate": 5e-05,
      "loss": 0.3549,
      "step": 6600
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5941131114959717,
      "learning_rate": 5e-05,
      "loss": 0.3276,
      "step": 6608
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7466349601745605,
      "learning_rate": 5e-05,
      "loss": 0.3989,
      "step": 6616
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5245662927627563,
      "learning_rate": 5e-05,
      "loss": 0.3421,
      "step": 6624
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7494786977767944,
      "learning_rate": 5e-05,
      "loss": 0.3546,
      "step": 6632
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6232408285140991,
      "learning_rate": 5e-05,
      "loss": 0.3566,
      "step": 6640
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.569436252117157,
      "learning_rate": 5e-05,
      "loss": 0.3453,
      "step": 6648
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6287713050842285,
      "learning_rate": 5e-05,
      "loss": 0.372,
      "step": 6656
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6652557849884033,
      "learning_rate": 5e-05,
      "loss": 0.3694,
      "step": 6664
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7804819345474243,
      "learning_rate": 5e-05,
      "loss": 0.3664,
      "step": 6672
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5826248526573181,
      "learning_rate": 5e-05,
      "loss": 0.3774,
      "step": 6680
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6282849311828613,
      "learning_rate": 5e-05,
      "loss": 0.3688,
      "step": 6688
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4883749485015869,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 6696
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5250711441040039,
      "learning_rate": 5e-05,
      "loss": 0.3381,
      "step": 6704
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6777974963188171,
      "learning_rate": 5e-05,
      "loss": 0.3457,
      "step": 6712
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6012282967567444,
      "learning_rate": 5e-05,
      "loss": 0.3632,
      "step": 6720
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5453338623046875,
      "learning_rate": 5e-05,
      "loss": 0.3511,
      "step": 6728
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6007276773452759,
      "learning_rate": 5e-05,
      "loss": 0.3693,
      "step": 6736
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5461999773979187,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 6744
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.567751407623291,
      "learning_rate": 5e-05,
      "loss": 0.3449,
      "step": 6752
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6049940586090088,
      "learning_rate": 5e-05,
      "loss": 0.364,
      "step": 6760
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6169165372848511,
      "learning_rate": 5e-05,
      "loss": 0.3746,
      "step": 6768
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.624072253704071,
      "learning_rate": 5e-05,
      "loss": 0.3606,
      "step": 6776
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6352782249450684,
      "learning_rate": 5e-05,
      "loss": 0.381,
      "step": 6784
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7292031049728394,
      "learning_rate": 5e-05,
      "loss": 0.3694,
      "step": 6792
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6273316144943237,
      "learning_rate": 5e-05,
      "loss": 0.3451,
      "step": 6800
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.557575523853302,
      "learning_rate": 5e-05,
      "loss": 0.3778,
      "step": 6808
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5688517689704895,
      "learning_rate": 5e-05,
      "loss": 0.3595,
      "step": 6816
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6336917877197266,
      "learning_rate": 5e-05,
      "loss": 0.3247,
      "step": 6824
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6194690465927124,
      "learning_rate": 5e-05,
      "loss": 0.352,
      "step": 6832
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5887450575828552,
      "learning_rate": 5e-05,
      "loss": 0.3357,
      "step": 6840
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6544482707977295,
      "learning_rate": 5e-05,
      "loss": 0.3561,
      "step": 6848
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6526637673377991,
      "learning_rate": 5e-05,
      "loss": 0.3565,
      "step": 6856
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.891618549823761,
      "learning_rate": 5e-05,
      "loss": 0.3329,
      "step": 6864
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5822259187698364,
      "learning_rate": 5e-05,
      "loss": 0.3653,
      "step": 6872
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6897250413894653,
      "learning_rate": 5e-05,
      "loss": 0.3239,
      "step": 6880
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5891435742378235,
      "learning_rate": 5e-05,
      "loss": 0.3728,
      "step": 6888
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5777029395103455,
      "learning_rate": 5e-05,
      "loss": 0.3608,
      "step": 6896
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.553629457950592,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 6904
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5325490236282349,
      "learning_rate": 5e-05,
      "loss": 0.3416,
      "step": 6912
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6086377501487732,
      "learning_rate": 5e-05,
      "loss": 0.3324,
      "step": 6920
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6219669580459595,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 6928
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.542865514755249,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 6936
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.594450056552887,
      "learning_rate": 5e-05,
      "loss": 0.3536,
      "step": 6944
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6255719065666199,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 6952
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5688394904136658,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 6960
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5831891298294067,
      "learning_rate": 5e-05,
      "loss": 0.3337,
      "step": 6968
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7512842416763306,
      "learning_rate": 5e-05,
      "loss": 0.3562,
      "step": 6976
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5885868668556213,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 6984
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6957432627677917,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 6992
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5821425318717957,
      "learning_rate": 5e-05,
      "loss": 0.3387,
      "step": 7000
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7242659330368042,
      "learning_rate": 5e-05,
      "loss": 0.3414,
      "step": 7008
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7569436430931091,
      "learning_rate": 5e-05,
      "loss": 0.3692,
      "step": 7016
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6930930614471436,
      "learning_rate": 5e-05,
      "loss": 0.335,
      "step": 7024
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6011356711387634,
      "learning_rate": 5e-05,
      "loss": 0.3775,
      "step": 7032
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6574671864509583,
      "learning_rate": 5e-05,
      "loss": 0.3516,
      "step": 7040
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6840088367462158,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 7048
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7356491684913635,
      "learning_rate": 5e-05,
      "loss": 0.3565,
      "step": 7056
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5695561170578003,
      "learning_rate": 5e-05,
      "loss": 0.3419,
      "step": 7064
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6669720411300659,
      "learning_rate": 5e-05,
      "loss": 0.3595,
      "step": 7072
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5124131441116333,
      "learning_rate": 5e-05,
      "loss": 0.3668,
      "step": 7080
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5204052329063416,
      "learning_rate": 5e-05,
      "loss": 0.3407,
      "step": 7088
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.662809431552887,
      "learning_rate": 5e-05,
      "loss": 0.3451,
      "step": 7096
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5884864330291748,
      "learning_rate": 5e-05,
      "loss": 0.3284,
      "step": 7104
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6299489736557007,
      "learning_rate": 5e-05,
      "loss": 0.3731,
      "step": 7112
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6530448794364929,
      "learning_rate": 5e-05,
      "loss": 0.378,
      "step": 7120
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5637719631195068,
      "learning_rate": 5e-05,
      "loss": 0.3433,
      "step": 7128
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6477360129356384,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 7136
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6362443566322327,
      "learning_rate": 5e-05,
      "loss": 0.3351,
      "step": 7144
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5921796560287476,
      "learning_rate": 5e-05,
      "loss": 0.3459,
      "step": 7152
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0410271883010864,
      "learning_rate": 5e-05,
      "loss": 0.3432,
      "step": 7160
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6236830949783325,
      "learning_rate": 5e-05,
      "loss": 0.339,
      "step": 7168
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8012858033180237,
      "learning_rate": 5e-05,
      "loss": 0.3556,
      "step": 7176
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5903409123420715,
      "learning_rate": 5e-05,
      "loss": 0.3444,
      "step": 7184
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6022192239761353,
      "learning_rate": 5e-05,
      "loss": 0.3613,
      "step": 7192
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6217748522758484,
      "learning_rate": 5e-05,
      "loss": 0.347,
      "step": 7200
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6185138821601868,
      "learning_rate": 5e-05,
      "loss": 0.3741,
      "step": 7208
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5401825308799744,
      "learning_rate": 5e-05,
      "loss": 0.3463,
      "step": 7216
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6466178894042969,
      "learning_rate": 5e-05,
      "loss": 0.3529,
      "step": 7224
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5977393984794617,
      "learning_rate": 5e-05,
      "loss": 0.3672,
      "step": 7232
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5838562250137329,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 7240
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5590260028839111,
      "learning_rate": 5e-05,
      "loss": 0.3626,
      "step": 7248
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.601106584072113,
      "learning_rate": 5e-05,
      "loss": 0.3463,
      "step": 7256
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6098788380622864,
      "learning_rate": 5e-05,
      "loss": 0.3387,
      "step": 7264
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4962191879749298,
      "learning_rate": 5e-05,
      "loss": 0.3759,
      "step": 7272
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6601049900054932,
      "learning_rate": 5e-05,
      "loss": 0.3356,
      "step": 7280
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6261628270149231,
      "learning_rate": 5e-05,
      "loss": 0.3687,
      "step": 7288
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6546595692634583,
      "learning_rate": 5e-05,
      "loss": 0.3498,
      "step": 7296
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6441331505775452,
      "learning_rate": 5e-05,
      "loss": 0.3645,
      "step": 7304
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6424397826194763,
      "learning_rate": 5e-05,
      "loss": 0.346,
      "step": 7312
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6707794666290283,
      "learning_rate": 5e-05,
      "loss": 0.3479,
      "step": 7320
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5831230282783508,
      "learning_rate": 5e-05,
      "loss": 0.3412,
      "step": 7328
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5564189553260803,
      "learning_rate": 5e-05,
      "loss": 0.3408,
      "step": 7336
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.54982590675354,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 7344
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6322117447853088,
      "learning_rate": 5e-05,
      "loss": 0.3471,
      "step": 7352
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6549745798110962,
      "learning_rate": 5e-05,
      "loss": 0.3334,
      "step": 7360
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6492270827293396,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 7368
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6040534377098083,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 7376
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4976804554462433,
      "learning_rate": 5e-05,
      "loss": 0.3575,
      "step": 7384
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6672009825706482,
      "learning_rate": 5e-05,
      "loss": 0.3604,
      "step": 7392
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6064351201057434,
      "learning_rate": 5e-05,
      "loss": 0.3581,
      "step": 7400
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5703521370887756,
      "learning_rate": 5e-05,
      "loss": 0.3723,
      "step": 7408
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6185021996498108,
      "learning_rate": 5e-05,
      "loss": 0.3424,
      "step": 7416
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6735872626304626,
      "learning_rate": 5e-05,
      "loss": 0.341,
      "step": 7424
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6495489478111267,
      "learning_rate": 5e-05,
      "loss": 0.3652,
      "step": 7432
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6465815305709839,
      "learning_rate": 5e-05,
      "loss": 0.3519,
      "step": 7440
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6248384714126587,
      "learning_rate": 5e-05,
      "loss": 0.3436,
      "step": 7448
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.690941333770752,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 7456
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6432768702507019,
      "learning_rate": 5e-05,
      "loss": 0.3601,
      "step": 7464
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5738213658332825,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 7472
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6164145469665527,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 7480
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5354952216148376,
      "learning_rate": 5e-05,
      "loss": 0.3286,
      "step": 7488
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5957325100898743,
      "learning_rate": 5e-05,
      "loss": 0.3734,
      "step": 7496
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5275541543960571,
      "learning_rate": 5e-05,
      "loss": 0.3385,
      "step": 7504
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5589298009872437,
      "learning_rate": 5e-05,
      "loss": 0.3745,
      "step": 7512
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5141000151634216,
      "learning_rate": 5e-05,
      "loss": 0.3534,
      "step": 7520
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.647366464138031,
      "learning_rate": 5e-05,
      "loss": 0.3709,
      "step": 7528
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5387702584266663,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 7536
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6217681765556335,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 7544
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.62913578748703,
      "learning_rate": 5e-05,
      "loss": 0.3599,
      "step": 7552
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5133370757102966,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 7560
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6101593971252441,
      "learning_rate": 5e-05,
      "loss": 0.3513,
      "step": 7568
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6290757060050964,
      "learning_rate": 5e-05,
      "loss": 0.3324,
      "step": 7576
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6897355318069458,
      "learning_rate": 5e-05,
      "loss": 0.3097,
      "step": 7584
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6404970288276672,
      "learning_rate": 5e-05,
      "loss": 0.3268,
      "step": 7592
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6246362924575806,
      "learning_rate": 5e-05,
      "loss": 0.3747,
      "step": 7600
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5835902690887451,
      "learning_rate": 5e-05,
      "loss": 0.3493,
      "step": 7608
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6250380873680115,
      "learning_rate": 5e-05,
      "loss": 0.3118,
      "step": 7616
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.687962532043457,
      "learning_rate": 5e-05,
      "loss": 0.3604,
      "step": 7624
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.607012152671814,
      "learning_rate": 5e-05,
      "loss": 0.3517,
      "step": 7632
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7046197056770325,
      "learning_rate": 5e-05,
      "loss": 0.386,
      "step": 7640
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6579168438911438,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 7648
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6439909338951111,
      "learning_rate": 5e-05,
      "loss": 0.3384,
      "step": 7656
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.575372040271759,
      "learning_rate": 5e-05,
      "loss": 0.3389,
      "step": 7664
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1167999505996704,
      "learning_rate": 5e-05,
      "loss": 0.3357,
      "step": 7672
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6073970794677734,
      "learning_rate": 5e-05,
      "loss": 0.3632,
      "step": 7680
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6421475410461426,
      "learning_rate": 5e-05,
      "loss": 0.3419,
      "step": 7688
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6857643127441406,
      "learning_rate": 5e-05,
      "loss": 0.3553,
      "step": 7696
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7015168070793152,
      "learning_rate": 5e-05,
      "loss": 0.3919,
      "step": 7704
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7489351630210876,
      "learning_rate": 5e-05,
      "loss": 0.3436,
      "step": 7712
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5720611810684204,
      "learning_rate": 5e-05,
      "loss": 0.36,
      "step": 7720
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5933656096458435,
      "learning_rate": 5e-05,
      "loss": 0.3076,
      "step": 7728
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6454412341117859,
      "learning_rate": 5e-05,
      "loss": 0.4018,
      "step": 7736
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5726249814033508,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 7744
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5995859503746033,
      "learning_rate": 5e-05,
      "loss": 0.335,
      "step": 7752
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6971457004547119,
      "learning_rate": 5e-05,
      "loss": 0.3819,
      "step": 7760
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7940343618392944,
      "learning_rate": 5e-05,
      "loss": 0.3345,
      "step": 7768
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7511868476867676,
      "learning_rate": 5e-05,
      "loss": 0.3919,
      "step": 7776
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6825281381607056,
      "learning_rate": 5e-05,
      "loss": 0.3618,
      "step": 7784
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.577135443687439,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 7792
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5510308742523193,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 7800
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6098339557647705,
      "learning_rate": 5e-05,
      "loss": 0.3427,
      "step": 7808
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6129526495933533,
      "learning_rate": 5e-05,
      "loss": 0.3314,
      "step": 7816
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6180107593536377,
      "learning_rate": 5e-05,
      "loss": 0.3473,
      "step": 7824
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6397267580032349,
      "learning_rate": 5e-05,
      "loss": 0.3601,
      "step": 7832
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.631585419178009,
      "learning_rate": 5e-05,
      "loss": 0.3765,
      "step": 7840
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6268865466117859,
      "learning_rate": 5e-05,
      "loss": 0.3402,
      "step": 7848
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5828505754470825,
      "learning_rate": 5e-05,
      "loss": 0.3587,
      "step": 7856
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7241054773330688,
      "learning_rate": 5e-05,
      "loss": 0.3328,
      "step": 7864
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.687592089176178,
      "learning_rate": 5e-05,
      "loss": 0.3196,
      "step": 7872
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5485118627548218,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 7880
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6260198354721069,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 7888
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5646809935569763,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 7896
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5792361497879028,
      "learning_rate": 5e-05,
      "loss": 0.3448,
      "step": 7904
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6003931760787964,
      "learning_rate": 5e-05,
      "loss": 0.3613,
      "step": 7912
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5830269455909729,
      "learning_rate": 5e-05,
      "loss": 0.3518,
      "step": 7920
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.776450514793396,
      "learning_rate": 5e-05,
      "loss": 0.3498,
      "step": 7928
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7129718661308289,
      "learning_rate": 5e-05,
      "loss": 0.3731,
      "step": 7936
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6080146431922913,
      "learning_rate": 5e-05,
      "loss": 0.3396,
      "step": 7944
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6765956878662109,
      "learning_rate": 5e-05,
      "loss": 0.3236,
      "step": 7952
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6827810406684875,
      "learning_rate": 5e-05,
      "loss": 0.3583,
      "step": 7960
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6447938084602356,
      "learning_rate": 5e-05,
      "loss": 0.3716,
      "step": 7968
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5314803123474121,
      "learning_rate": 5e-05,
      "loss": 0.3467,
      "step": 7976
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6975467801094055,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 7984
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5331715941429138,
      "learning_rate": 5e-05,
      "loss": 0.3177,
      "step": 7992
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6285995244979858,
      "learning_rate": 5e-05,
      "loss": 0.3612,
      "step": 8000
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.8536523580551147,
      "learning_rate": 5e-05,
      "loss": 0.3397,
      "step": 8008
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7172076106071472,
      "learning_rate": 5e-05,
      "loss": 0.3376,
      "step": 8016
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5653433203697205,
      "learning_rate": 5e-05,
      "loss": 0.3763,
      "step": 8024
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5719582438468933,
      "learning_rate": 5e-05,
      "loss": 0.3315,
      "step": 8032
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7055224776268005,
      "learning_rate": 5e-05,
      "loss": 0.3469,
      "step": 8040
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5202829837799072,
      "learning_rate": 5e-05,
      "loss": 0.3333,
      "step": 8048
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5130680799484253,
      "learning_rate": 5e-05,
      "loss": 0.3449,
      "step": 8056
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6137490272521973,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 8064
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6417834758758545,
      "learning_rate": 5e-05,
      "loss": 0.3467,
      "step": 8072
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6430174708366394,
      "learning_rate": 5e-05,
      "loss": 0.3744,
      "step": 8080
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6228025555610657,
      "learning_rate": 5e-05,
      "loss": 0.3306,
      "step": 8088
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7760663032531738,
      "learning_rate": 5e-05,
      "loss": 0.3547,
      "step": 8096
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6061572432518005,
      "learning_rate": 5e-05,
      "loss": 0.3186,
      "step": 8104
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6070271730422974,
      "learning_rate": 5e-05,
      "loss": 0.3187,
      "step": 8112
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6116273999214172,
      "learning_rate": 5e-05,
      "loss": 0.3743,
      "step": 8120
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.630460262298584,
      "learning_rate": 5e-05,
      "loss": 0.3363,
      "step": 8128
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5059425234794617,
      "learning_rate": 5e-05,
      "loss": 0.3416,
      "step": 8136
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7060939073562622,
      "learning_rate": 5e-05,
      "loss": 0.3564,
      "step": 8144
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6360746622085571,
      "learning_rate": 5e-05,
      "loss": 0.336,
      "step": 8152
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7389026284217834,
      "learning_rate": 5e-05,
      "loss": 0.3741,
      "step": 8160
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5956030488014221,
      "learning_rate": 5e-05,
      "loss": 0.3649,
      "step": 8168
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6247546076774597,
      "learning_rate": 5e-05,
      "loss": 0.377,
      "step": 8176
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5925621390342712,
      "learning_rate": 5e-05,
      "loss": 0.3193,
      "step": 8184
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6367142796516418,
      "learning_rate": 5e-05,
      "loss": 0.3641,
      "step": 8192
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.632428765296936,
      "learning_rate": 5e-05,
      "loss": 0.3383,
      "step": 8200
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6842299699783325,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 8208
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6488126516342163,
      "learning_rate": 5e-05,
      "loss": 0.3756,
      "step": 8216
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5833509564399719,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 8224
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5657253265380859,
      "learning_rate": 5e-05,
      "loss": 0.3276,
      "step": 8232
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6554439067840576,
      "learning_rate": 5e-05,
      "loss": 0.359,
      "step": 8240
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8739708662033081,
      "learning_rate": 5e-05,
      "loss": 0.3611,
      "step": 8248
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6545332074165344,
      "learning_rate": 5e-05,
      "loss": 0.3554,
      "step": 8256
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6704609990119934,
      "learning_rate": 5e-05,
      "loss": 0.3889,
      "step": 8264
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5814836621284485,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 8272
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7314685583114624,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 8280
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6730906367301941,
      "learning_rate": 5e-05,
      "loss": 0.3295,
      "step": 8288
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5814905166625977,
      "learning_rate": 5e-05,
      "loss": 0.3523,
      "step": 8296
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5757113695144653,
      "learning_rate": 5e-05,
      "loss": 0.3636,
      "step": 8304
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7516657114028931,
      "learning_rate": 5e-05,
      "loss": 0.3334,
      "step": 8312
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5586227774620056,
      "learning_rate": 5e-05,
      "loss": 0.3572,
      "step": 8320
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5889323949813843,
      "learning_rate": 5e-05,
      "loss": 0.3673,
      "step": 8328
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5509456396102905,
      "learning_rate": 5e-05,
      "loss": 0.3195,
      "step": 8336
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6345747709274292,
      "learning_rate": 5e-05,
      "loss": 0.3438,
      "step": 8344
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5767418742179871,
      "learning_rate": 5e-05,
      "loss": 0.3568,
      "step": 8352
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5474343299865723,
      "learning_rate": 5e-05,
      "loss": 0.3554,
      "step": 8360
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6386330723762512,
      "learning_rate": 5e-05,
      "loss": 0.3293,
      "step": 8368
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.71001136302948,
      "learning_rate": 5e-05,
      "loss": 0.3392,
      "step": 8376
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5851548910140991,
      "learning_rate": 5e-05,
      "loss": 0.3452,
      "step": 8384
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6680157780647278,
      "learning_rate": 5e-05,
      "loss": 0.3244,
      "step": 8392
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6394854187965393,
      "learning_rate": 5e-05,
      "loss": 0.3497,
      "step": 8400
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6290327906608582,
      "learning_rate": 5e-05,
      "loss": 0.3466,
      "step": 8408
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6508530378341675,
      "learning_rate": 5e-05,
      "loss": 0.3447,
      "step": 8416
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6724895238876343,
      "learning_rate": 5e-05,
      "loss": 0.3735,
      "step": 8424
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.569744348526001,
      "learning_rate": 5e-05,
      "loss": 0.3485,
      "step": 8432
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5592843890190125,
      "learning_rate": 5e-05,
      "loss": 0.3472,
      "step": 8440
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6775091886520386,
      "learning_rate": 5e-05,
      "loss": 0.3353,
      "step": 8448
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6588370203971863,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 8456
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6746665835380554,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 8464
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6660124063491821,
      "learning_rate": 5e-05,
      "loss": 0.3509,
      "step": 8472
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5930428504943848,
      "learning_rate": 5e-05,
      "loss": 0.3326,
      "step": 8480
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.611423909664154,
      "learning_rate": 5e-05,
      "loss": 0.315,
      "step": 8488
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.565742552280426,
      "learning_rate": 5e-05,
      "loss": 0.3548,
      "step": 8496
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5568079352378845,
      "learning_rate": 5e-05,
      "loss": 0.3284,
      "step": 8504
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6151831746101379,
      "learning_rate": 5e-05,
      "loss": 0.3792,
      "step": 8512
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.528346836566925,
      "learning_rate": 5e-05,
      "loss": 0.344,
      "step": 8520
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.589053750038147,
      "learning_rate": 5e-05,
      "loss": 0.3616,
      "step": 8528
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6011514067649841,
      "learning_rate": 5e-05,
      "loss": 0.3676,
      "step": 8536
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6604706048965454,
      "learning_rate": 5e-05,
      "loss": 0.362,
      "step": 8544
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6358374357223511,
      "learning_rate": 5e-05,
      "loss": 0.3532,
      "step": 8552
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.552217423915863,
      "learning_rate": 5e-05,
      "loss": 0.3641,
      "step": 8560
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5809979438781738,
      "learning_rate": 5e-05,
      "loss": 0.3331,
      "step": 8568
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6533288359642029,
      "learning_rate": 5e-05,
      "loss": 0.3646,
      "step": 8576
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6672095656394958,
      "learning_rate": 5e-05,
      "loss": 0.3811,
      "step": 8584
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7775825262069702,
      "learning_rate": 5e-05,
      "loss": 0.363,
      "step": 8592
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5773653388023376,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 8600
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6133593320846558,
      "learning_rate": 5e-05,
      "loss": 0.3377,
      "step": 8608
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5720426440238953,
      "learning_rate": 5e-05,
      "loss": 0.3584,
      "step": 8616
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7288686037063599,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 8624
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5944106578826904,
      "learning_rate": 5e-05,
      "loss": 0.3431,
      "step": 8632
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6125343441963196,
      "learning_rate": 5e-05,
      "loss": 0.3637,
      "step": 8640
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7650557160377502,
      "learning_rate": 5e-05,
      "loss": 0.3343,
      "step": 8648
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6752827763557434,
      "learning_rate": 5e-05,
      "loss": 0.3356,
      "step": 8656
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5633997321128845,
      "learning_rate": 5e-05,
      "loss": 0.3325,
      "step": 8664
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7414013743400574,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 8672
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.647980272769928,
      "learning_rate": 5e-05,
      "loss": 0.3272,
      "step": 8680
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6650108695030212,
      "learning_rate": 5e-05,
      "loss": 0.3452,
      "step": 8688
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5537152290344238,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 8696
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5759073495864868,
      "learning_rate": 5e-05,
      "loss": 0.3558,
      "step": 8704
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.536453902721405,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 8712
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6036005020141602,
      "learning_rate": 5e-05,
      "loss": 0.3453,
      "step": 8720
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5511422157287598,
      "learning_rate": 5e-05,
      "loss": 0.3269,
      "step": 8728
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6918953061103821,
      "learning_rate": 5e-05,
      "loss": 0.391,
      "step": 8736
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6134482622146606,
      "learning_rate": 5e-05,
      "loss": 0.3536,
      "step": 8744
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6695532202720642,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 8752
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5688367486000061,
      "learning_rate": 5e-05,
      "loss": 0.3764,
      "step": 8760
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6384128928184509,
      "learning_rate": 5e-05,
      "loss": 0.3382,
      "step": 8768
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5480718612670898,
      "learning_rate": 5e-05,
      "loss": 0.3755,
      "step": 8776
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6090676188468933,
      "learning_rate": 5e-05,
      "loss": 0.3888,
      "step": 8784
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6313332319259644,
      "learning_rate": 5e-05,
      "loss": 0.339,
      "step": 8792
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5519629120826721,
      "learning_rate": 5e-05,
      "loss": 0.3431,
      "step": 8800
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7331362366676331,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 8808
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6293515563011169,
      "learning_rate": 5e-05,
      "loss": 0.3347,
      "step": 8816
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.617060124874115,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 8824
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5198825597763062,
      "learning_rate": 5e-05,
      "loss": 0.3276,
      "step": 8832
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6158912181854248,
      "learning_rate": 5e-05,
      "loss": 0.3185,
      "step": 8840
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6605769395828247,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 8848
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6875571012496948,
      "learning_rate": 5e-05,
      "loss": 0.3161,
      "step": 8856
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6639633774757385,
      "learning_rate": 5e-05,
      "loss": 0.3344,
      "step": 8864
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.576273500919342,
      "learning_rate": 5e-05,
      "loss": 0.3432,
      "step": 8872
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6854588389396667,
      "learning_rate": 5e-05,
      "loss": 0.331,
      "step": 8880
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7099196910858154,
      "learning_rate": 5e-05,
      "loss": 0.3581,
      "step": 8888
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6001710295677185,
      "learning_rate": 5e-05,
      "loss": 0.337,
      "step": 8896
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6085677742958069,
      "learning_rate": 5e-05,
      "loss": 0.3455,
      "step": 8904
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6484902501106262,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 8912
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.614024817943573,
      "learning_rate": 5e-05,
      "loss": 0.3547,
      "step": 8920
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7354898452758789,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 8928
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5752454400062561,
      "learning_rate": 5e-05,
      "loss": 0.3706,
      "step": 8936
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5394926071166992,
      "learning_rate": 5e-05,
      "loss": 0.3651,
      "step": 8944
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.668512225151062,
      "learning_rate": 5e-05,
      "loss": 0.3306,
      "step": 8952
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5941529273986816,
      "learning_rate": 5e-05,
      "loss": 0.3731,
      "step": 8960
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.63729327917099,
      "learning_rate": 5e-05,
      "loss": 0.3483,
      "step": 8968
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7011899948120117,
      "learning_rate": 5e-05,
      "loss": 0.3568,
      "step": 8976
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6345776319503784,
      "learning_rate": 5e-05,
      "loss": 0.3636,
      "step": 8984
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7651150822639465,
      "learning_rate": 5e-05,
      "loss": 0.3784,
      "step": 8992
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.588824450969696,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 9000
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5911611318588257,
      "learning_rate": 5e-05,
      "loss": 0.3504,
      "step": 9008
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6655896306037903,
      "learning_rate": 5e-05,
      "loss": 0.3555,
      "step": 9016
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7109131813049316,
      "learning_rate": 5e-05,
      "loss": 0.3387,
      "step": 9024
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6732499003410339,
      "learning_rate": 5e-05,
      "loss": 0.3772,
      "step": 9032
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5790193676948547,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 9040
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6522354483604431,
      "learning_rate": 5e-05,
      "loss": 0.3589,
      "step": 9048
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5304358601570129,
      "learning_rate": 5e-05,
      "loss": 0.3601,
      "step": 9056
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6469336152076721,
      "learning_rate": 5e-05,
      "loss": 0.3395,
      "step": 9064
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5226542353630066,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 9072
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7475666999816895,
      "learning_rate": 5e-05,
      "loss": 0.3506,
      "step": 9080
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7492047548294067,
      "learning_rate": 5e-05,
      "loss": 0.3541,
      "step": 9088
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6536954641342163,
      "learning_rate": 5e-05,
      "loss": 0.3333,
      "step": 9096
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5891969203948975,
      "learning_rate": 5e-05,
      "loss": 0.3481,
      "step": 9104
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6468742489814758,
      "learning_rate": 5e-05,
      "loss": 0.342,
      "step": 9112
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5873314738273621,
      "learning_rate": 5e-05,
      "loss": 0.3402,
      "step": 9120
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6170479655265808,
      "learning_rate": 5e-05,
      "loss": 0.3605,
      "step": 9128
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7873182892799377,
      "learning_rate": 5e-05,
      "loss": 0.3528,
      "step": 9136
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5944752097129822,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 9144
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6717749834060669,
      "learning_rate": 5e-05,
      "loss": 0.3618,
      "step": 9152
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6017326712608337,
      "learning_rate": 5e-05,
      "loss": 0.3355,
      "step": 9160
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5754019021987915,
      "learning_rate": 5e-05,
      "loss": 0.3616,
      "step": 9168
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6363253593444824,
      "learning_rate": 5e-05,
      "loss": 0.348,
      "step": 9176
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7244840264320374,
      "learning_rate": 5e-05,
      "loss": 0.3543,
      "step": 9184
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6535961031913757,
      "learning_rate": 5e-05,
      "loss": 0.35,
      "step": 9192
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5875368118286133,
      "learning_rate": 5e-05,
      "loss": 0.3127,
      "step": 9200
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6280619502067566,
      "learning_rate": 5e-05,
      "loss": 0.3482,
      "step": 9208
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7061858177185059,
      "learning_rate": 5e-05,
      "loss": 0.336,
      "step": 9216
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5930199027061462,
      "learning_rate": 5e-05,
      "loss": 0.3611,
      "step": 9224
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5667454600334167,
      "learning_rate": 5e-05,
      "loss": 0.3457,
      "step": 9232
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6227200627326965,
      "learning_rate": 5e-05,
      "loss": 0.3693,
      "step": 9240
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6817746758460999,
      "learning_rate": 5e-05,
      "loss": 0.3418,
      "step": 9248
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6109651923179626,
      "learning_rate": 5e-05,
      "loss": 0.337,
      "step": 9256
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5925818681716919,
      "learning_rate": 5e-05,
      "loss": 0.3469,
      "step": 9264
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6112819314002991,
      "learning_rate": 5e-05,
      "loss": 0.3359,
      "step": 9272
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7136321067810059,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 9280
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5647997856140137,
      "learning_rate": 5e-05,
      "loss": 0.307,
      "step": 9288
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6494283080101013,
      "learning_rate": 5e-05,
      "loss": 0.3502,
      "step": 9296
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6162636280059814,
      "learning_rate": 5e-05,
      "loss": 0.3262,
      "step": 9304
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6211550235748291,
      "learning_rate": 5e-05,
      "loss": 0.3451,
      "step": 9312
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6998536586761475,
      "learning_rate": 5e-05,
      "loss": 0.3801,
      "step": 9320
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6397119164466858,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 9328
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6087839603424072,
      "learning_rate": 5e-05,
      "loss": 0.3821,
      "step": 9336
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6075975298881531,
      "learning_rate": 5e-05,
      "loss": 0.3519,
      "step": 9344
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6807860732078552,
      "learning_rate": 5e-05,
      "loss": 0.346,
      "step": 9352
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6444447040557861,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 9360
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7180876135826111,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 9368
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5803179144859314,
      "learning_rate": 5e-05,
      "loss": 0.343,
      "step": 9376
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6235408186912537,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 9384
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8040823936462402,
      "learning_rate": 5e-05,
      "loss": 0.344,
      "step": 9392
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.649468183517456,
      "learning_rate": 5e-05,
      "loss": 0.3475,
      "step": 9400
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6502532958984375,
      "learning_rate": 5e-05,
      "loss": 0.3483,
      "step": 9408
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7133030295372009,
      "learning_rate": 5e-05,
      "loss": 0.3435,
      "step": 9416
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6149529218673706,
      "learning_rate": 5e-05,
      "loss": 0.3773,
      "step": 9424
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6910591721534729,
      "learning_rate": 5e-05,
      "loss": 0.3642,
      "step": 9432
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6084316968917847,
      "learning_rate": 5e-05,
      "loss": 0.3522,
      "step": 9440
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6535433530807495,
      "learning_rate": 5e-05,
      "loss": 0.3655,
      "step": 9448
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5648796558380127,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 9456
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5797359347343445,
      "learning_rate": 5e-05,
      "loss": 0.3348,
      "step": 9464
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5797637701034546,
      "learning_rate": 5e-05,
      "loss": 0.3414,
      "step": 9472
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5059338808059692,
      "learning_rate": 5e-05,
      "loss": 0.3642,
      "step": 9480
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6557013988494873,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 9488
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7317408323287964,
      "learning_rate": 5e-05,
      "loss": 0.3715,
      "step": 9496
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7108855843544006,
      "learning_rate": 5e-05,
      "loss": 0.3522,
      "step": 9504
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6205467581748962,
      "learning_rate": 5e-05,
      "loss": 0.37,
      "step": 9512
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.78375244140625,
      "learning_rate": 5e-05,
      "loss": 0.3733,
      "step": 9520
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5294294953346252,
      "learning_rate": 5e-05,
      "loss": 0.3433,
      "step": 9528
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6781508326530457,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 9536
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6128746867179871,
      "learning_rate": 5e-05,
      "loss": 0.332,
      "step": 9544
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6176176071166992,
      "learning_rate": 5e-05,
      "loss": 0.3546,
      "step": 9552
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6463011503219604,
      "learning_rate": 5e-05,
      "loss": 0.3338,
      "step": 9560
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6596962213516235,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 9568
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6599847674369812,
      "learning_rate": 5e-05,
      "loss": 0.3134,
      "step": 9576
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7292823195457458,
      "learning_rate": 5e-05,
      "loss": 0.3489,
      "step": 9584
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7256297469139099,
      "learning_rate": 5e-05,
      "loss": 0.3513,
      "step": 9592
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5782173871994019,
      "learning_rate": 5e-05,
      "loss": 0.3299,
      "step": 9600
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6121291518211365,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 9608
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6243419051170349,
      "learning_rate": 5e-05,
      "loss": 0.3578,
      "step": 9616
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6114562153816223,
      "learning_rate": 5e-05,
      "loss": 0.3382,
      "step": 9624
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5970224142074585,
      "learning_rate": 5e-05,
      "loss": 0.35,
      "step": 9632
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5907062292098999,
      "learning_rate": 5e-05,
      "loss": 0.3581,
      "step": 9640
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5972834825515747,
      "learning_rate": 5e-05,
      "loss": 0.3459,
      "step": 9648
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6074556708335876,
      "learning_rate": 5e-05,
      "loss": 0.3494,
      "step": 9656
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5706593990325928,
      "learning_rate": 5e-05,
      "loss": 0.356,
      "step": 9664
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6754753589630127,
      "learning_rate": 5e-05,
      "loss": 0.3503,
      "step": 9672
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6521404385566711,
      "learning_rate": 5e-05,
      "loss": 0.3409,
      "step": 9680
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7222023606300354,
      "learning_rate": 5e-05,
      "loss": 0.363,
      "step": 9688
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5881794691085815,
      "learning_rate": 5e-05,
      "loss": 0.3116,
      "step": 9696
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5398850440979004,
      "learning_rate": 5e-05,
      "loss": 0.3198,
      "step": 9704
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.581136167049408,
      "learning_rate": 5e-05,
      "loss": 0.3362,
      "step": 9712
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5956916809082031,
      "learning_rate": 5e-05,
      "loss": 0.3599,
      "step": 9720
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6803138852119446,
      "learning_rate": 5e-05,
      "loss": 0.3306,
      "step": 9728
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6729646921157837,
      "learning_rate": 5e-05,
      "loss": 0.3233,
      "step": 9736
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5663095116615295,
      "learning_rate": 5e-05,
      "loss": 0.3312,
      "step": 9744
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6365085244178772,
      "learning_rate": 5e-05,
      "loss": 0.3437,
      "step": 9752
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5770068168640137,
      "learning_rate": 5e-05,
      "loss": 0.3357,
      "step": 9760
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7388527989387512,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 9768
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7403141856193542,
      "learning_rate": 5e-05,
      "loss": 0.3202,
      "step": 9776
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6255847811698914,
      "learning_rate": 5e-05,
      "loss": 0.3465,
      "step": 9784
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8290424942970276,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 9792
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6433355212211609,
      "learning_rate": 5e-05,
      "loss": 0.3592,
      "step": 9800
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6478896141052246,
      "learning_rate": 5e-05,
      "loss": 0.3518,
      "step": 9808
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6441794633865356,
      "learning_rate": 5e-05,
      "loss": 0.343,
      "step": 9816
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7041612863540649,
      "learning_rate": 5e-05,
      "loss": 0.3394,
      "step": 9824
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6739304065704346,
      "learning_rate": 5e-05,
      "loss": 0.3545,
      "step": 9832
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6181038618087769,
      "learning_rate": 5e-05,
      "loss": 0.352,
      "step": 9840
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6259612441062927,
      "learning_rate": 5e-05,
      "loss": 0.3428,
      "step": 9848
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7800707221031189,
      "learning_rate": 5e-05,
      "loss": 0.3391,
      "step": 9856
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6328000426292419,
      "learning_rate": 5e-05,
      "loss": 0.3541,
      "step": 9864
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6658515930175781,
      "learning_rate": 5e-05,
      "loss": 0.3468,
      "step": 9872
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6509082317352295,
      "learning_rate": 5e-05,
      "loss": 0.3433,
      "step": 9880
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6005882620811462,
      "learning_rate": 5e-05,
      "loss": 0.3356,
      "step": 9888
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.589457631111145,
      "learning_rate": 5e-05,
      "loss": 0.3771,
      "step": 9896
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.529535710811615,
      "learning_rate": 5e-05,
      "loss": 0.3866,
      "step": 9904
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5138219594955444,
      "learning_rate": 5e-05,
      "loss": 0.3299,
      "step": 9912
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6838698983192444,
      "learning_rate": 5e-05,
      "loss": 0.3565,
      "step": 9920
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6393750309944153,
      "learning_rate": 5e-05,
      "loss": 0.3433,
      "step": 9928
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6215286254882812,
      "learning_rate": 5e-05,
      "loss": 0.35,
      "step": 9936
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5725412964820862,
      "learning_rate": 5e-05,
      "loss": 0.3446,
      "step": 9944
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6777254939079285,
      "learning_rate": 5e-05,
      "loss": 0.341,
      "step": 9952
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.646955132484436,
      "learning_rate": 5e-05,
      "loss": 0.3427,
      "step": 9960
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.602975606918335,
      "learning_rate": 5e-05,
      "loss": 0.3317,
      "step": 9968
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6027189493179321,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 9976
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6220915913581848,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 9984
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5722907185554504,
      "learning_rate": 5e-05,
      "loss": 0.3599,
      "step": 9992
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6302173733711243,
      "learning_rate": 5e-05,
      "loss": 0.3278,
      "step": 10000
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6362392902374268,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 10008
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5909924507141113,
      "learning_rate": 5e-05,
      "loss": 0.3536,
      "step": 10016
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5994694828987122,
      "learning_rate": 5e-05,
      "loss": 0.3464,
      "step": 10024
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5634900331497192,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 10032
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6404736042022705,
      "learning_rate": 5e-05,
      "loss": 0.351,
      "step": 10040
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6499990820884705,
      "learning_rate": 5e-05,
      "loss": 0.3365,
      "step": 10048
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6272135972976685,
      "learning_rate": 5e-05,
      "loss": 0.3473,
      "step": 10056
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5806309580802917,
      "learning_rate": 5e-05,
      "loss": 0.3242,
      "step": 10064
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5997813940048218,
      "learning_rate": 5e-05,
      "loss": 0.3235,
      "step": 10072
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7424765825271606,
      "learning_rate": 5e-05,
      "loss": 0.3255,
      "step": 10080
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.604141354560852,
      "learning_rate": 5e-05,
      "loss": 0.351,
      "step": 10088
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5992528200149536,
      "learning_rate": 5e-05,
      "loss": 0.3767,
      "step": 10096
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6392810344696045,
      "learning_rate": 5e-05,
      "loss": 0.3597,
      "step": 10104
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5479956865310669,
      "learning_rate": 5e-05,
      "loss": 0.3214,
      "step": 10112
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6016069054603577,
      "learning_rate": 5e-05,
      "loss": 0.3325,
      "step": 10120
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.564572274684906,
      "learning_rate": 5e-05,
      "loss": 0.3334,
      "step": 10128
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6454585194587708,
      "learning_rate": 5e-05,
      "loss": 0.3525,
      "step": 10136
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7716056108474731,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 10144
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.604827880859375,
      "learning_rate": 5e-05,
      "loss": 0.3281,
      "step": 10152
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6170438528060913,
      "learning_rate": 5e-05,
      "loss": 0.3335,
      "step": 10160
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.644131064414978,
      "learning_rate": 5e-05,
      "loss": 0.3702,
      "step": 10168
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6076132655143738,
      "learning_rate": 5e-05,
      "loss": 0.3312,
      "step": 10176
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.565792977809906,
      "learning_rate": 5e-05,
      "loss": 0.3783,
      "step": 10184
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5517925024032593,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 10192
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6292794346809387,
      "learning_rate": 5e-05,
      "loss": 0.3406,
      "step": 10200
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6881963014602661,
      "learning_rate": 5e-05,
      "loss": 0.376,
      "step": 10208
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5300009250640869,
      "learning_rate": 5e-05,
      "loss": 0.3407,
      "step": 10216
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6516249179840088,
      "learning_rate": 5e-05,
      "loss": 0.3377,
      "step": 10224
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.637910008430481,
      "learning_rate": 5e-05,
      "loss": 0.3558,
      "step": 10232
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6221020817756653,
      "learning_rate": 5e-05,
      "loss": 0.3292,
      "step": 10240
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5503045320510864,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 10248
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6418464779853821,
      "learning_rate": 5e-05,
      "loss": 0.3214,
      "step": 10256
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7441507577896118,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 10264
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5605108737945557,
      "learning_rate": 5e-05,
      "loss": 0.3255,
      "step": 10272
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5813406109809875,
      "learning_rate": 5e-05,
      "loss": 0.3391,
      "step": 10280
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6301025748252869,
      "learning_rate": 5e-05,
      "loss": 0.3355,
      "step": 10288
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5858177542686462,
      "learning_rate": 5e-05,
      "loss": 0.3295,
      "step": 10296
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6021513342857361,
      "learning_rate": 5e-05,
      "loss": 0.3503,
      "step": 10304
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5902355313301086,
      "learning_rate": 5e-05,
      "loss": 0.365,
      "step": 10312
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.654870331287384,
      "learning_rate": 5e-05,
      "loss": 0.3832,
      "step": 10320
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6239087581634521,
      "learning_rate": 5e-05,
      "loss": 0.3545,
      "step": 10328
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5571798086166382,
      "learning_rate": 5e-05,
      "loss": 0.3326,
      "step": 10336
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6477366089820862,
      "learning_rate": 5e-05,
      "loss": 0.3564,
      "step": 10344
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7031348943710327,
      "learning_rate": 5e-05,
      "loss": 0.3189,
      "step": 10352
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5501176118850708,
      "learning_rate": 5e-05,
      "loss": 0.3419,
      "step": 10360
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.64726722240448,
      "learning_rate": 5e-05,
      "loss": 0.3709,
      "step": 10368
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7400737404823303,
      "learning_rate": 5e-05,
      "loss": 0.3489,
      "step": 10376
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.8474286794662476,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 10384
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5797052979469299,
      "learning_rate": 5e-05,
      "loss": 0.3438,
      "step": 10392
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6199132800102234,
      "learning_rate": 5e-05,
      "loss": 0.3559,
      "step": 10400
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5519037842750549,
      "learning_rate": 5e-05,
      "loss": 0.3494,
      "step": 10408
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.554459273815155,
      "learning_rate": 5e-05,
      "loss": 0.3415,
      "step": 10416
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6183328628540039,
      "learning_rate": 5e-05,
      "loss": 0.3408,
      "step": 10424
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6297204494476318,
      "learning_rate": 5e-05,
      "loss": 0.3511,
      "step": 10432
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6594551205635071,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 10440
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6226522922515869,
      "learning_rate": 5e-05,
      "loss": 0.333,
      "step": 10448
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6478168964385986,
      "learning_rate": 5e-05,
      "loss": 0.3431,
      "step": 10456
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6940062642097473,
      "learning_rate": 5e-05,
      "loss": 0.3625,
      "step": 10464
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6314160823822021,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 10472
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6513607501983643,
      "learning_rate": 5e-05,
      "loss": 0.3843,
      "step": 10480
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5526154637336731,
      "learning_rate": 5e-05,
      "loss": 0.3455,
      "step": 10488
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.8775279521942139,
      "learning_rate": 5e-05,
      "loss": 0.3298,
      "step": 10496
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5560509562492371,
      "learning_rate": 5e-05,
      "loss": 0.3224,
      "step": 10504
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5778529047966003,
      "learning_rate": 5e-05,
      "loss": 0.3685,
      "step": 10512
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6410844326019287,
      "learning_rate": 5e-05,
      "loss": 0.3162,
      "step": 10520
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5998594760894775,
      "learning_rate": 5e-05,
      "loss": 0.3249,
      "step": 10528
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6463562250137329,
      "learning_rate": 5e-05,
      "loss": 0.3127,
      "step": 10536
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6450938582420349,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 10544
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5884114503860474,
      "learning_rate": 5e-05,
      "loss": 0.3489,
      "step": 10552
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6611165404319763,
      "learning_rate": 5e-05,
      "loss": 0.3357,
      "step": 10560
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5823475122451782,
      "learning_rate": 5e-05,
      "loss": 0.3668,
      "step": 10568
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.563648521900177,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 10576
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.9878438115119934,
      "learning_rate": 5e-05,
      "loss": 0.3521,
      "step": 10584
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6065982580184937,
      "learning_rate": 5e-05,
      "loss": 0.3222,
      "step": 10592
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6551468968391418,
      "learning_rate": 5e-05,
      "loss": 0.3203,
      "step": 10600
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7198858857154846,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 10608
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5762655138969421,
      "learning_rate": 5e-05,
      "loss": 0.3478,
      "step": 10616
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6698052883148193,
      "learning_rate": 5e-05,
      "loss": 0.3498,
      "step": 10624
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6115674376487732,
      "learning_rate": 5e-05,
      "loss": 0.3522,
      "step": 10632
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5664824843406677,
      "learning_rate": 5e-05,
      "loss": 0.3661,
      "step": 10640
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.65317302942276,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 10648
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.749488115310669,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 10656
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6492491364479065,
      "learning_rate": 5e-05,
      "loss": 0.3391,
      "step": 10664
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6170140504837036,
      "learning_rate": 5e-05,
      "loss": 0.3688,
      "step": 10672
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6336861252784729,
      "learning_rate": 5e-05,
      "loss": 0.3462,
      "step": 10680
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7694577574729919,
      "learning_rate": 5e-05,
      "loss": 0.3474,
      "step": 10688
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7011191844940186,
      "learning_rate": 5e-05,
      "loss": 0.3584,
      "step": 10696
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6249873638153076,
      "learning_rate": 5e-05,
      "loss": 0.3291,
      "step": 10704
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6357990503311157,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 10712
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5841068625450134,
      "learning_rate": 5e-05,
      "loss": 0.3428,
      "step": 10720
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5870151519775391,
      "learning_rate": 5e-05,
      "loss": 0.3487,
      "step": 10728
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6107615232467651,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 10736
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5828002691268921,
      "learning_rate": 5e-05,
      "loss": 0.3204,
      "step": 10744
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6050103902816772,
      "learning_rate": 5e-05,
      "loss": 0.3272,
      "step": 10752
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5784862041473389,
      "learning_rate": 5e-05,
      "loss": 0.3432,
      "step": 10760
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.517630398273468,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 10768
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6252790689468384,
      "learning_rate": 5e-05,
      "loss": 0.3413,
      "step": 10776
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7657874822616577,
      "learning_rate": 5e-05,
      "loss": 0.3407,
      "step": 10784
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6817314028739929,
      "learning_rate": 5e-05,
      "loss": 0.3286,
      "step": 10792
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5828979015350342,
      "learning_rate": 5e-05,
      "loss": 0.3542,
      "step": 10800
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.578768253326416,
      "learning_rate": 5e-05,
      "loss": 0.3637,
      "step": 10808
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5837962627410889,
      "learning_rate": 5e-05,
      "loss": 0.3363,
      "step": 10816
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6682158708572388,
      "learning_rate": 5e-05,
      "loss": 0.3456,
      "step": 10824
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6196942329406738,
      "learning_rate": 5e-05,
      "loss": 0.351,
      "step": 10832
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5874452590942383,
      "learning_rate": 5e-05,
      "loss": 0.3415,
      "step": 10840
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6019752025604248,
      "learning_rate": 5e-05,
      "loss": 0.3397,
      "step": 10848
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7565913200378418,
      "learning_rate": 5e-05,
      "loss": 0.328,
      "step": 10856
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5937519073486328,
      "learning_rate": 5e-05,
      "loss": 0.3564,
      "step": 10864
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5705145001411438,
      "learning_rate": 5e-05,
      "loss": 0.3422,
      "step": 10872
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7445230484008789,
      "learning_rate": 5e-05,
      "loss": 0.3433,
      "step": 10880
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6128610372543335,
      "learning_rate": 5e-05,
      "loss": 0.3488,
      "step": 10888
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6183469295501709,
      "learning_rate": 5e-05,
      "loss": 0.3564,
      "step": 10896
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6469431519508362,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 10904
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6991655826568604,
      "learning_rate": 5e-05,
      "loss": 0.3742,
      "step": 10912
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5919038653373718,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 10920
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6870927214622498,
      "learning_rate": 5e-05,
      "loss": 0.3306,
      "step": 10928
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5992401242256165,
      "learning_rate": 5e-05,
      "loss": 0.3051,
      "step": 10936
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6179762482643127,
      "learning_rate": 5e-05,
      "loss": 0.3657,
      "step": 10944
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5827714800834656,
      "learning_rate": 5e-05,
      "loss": 0.3376,
      "step": 10952
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6052665710449219,
      "learning_rate": 5e-05,
      "loss": 0.3464,
      "step": 10960
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6729798316955566,
      "learning_rate": 5e-05,
      "loss": 0.3444,
      "step": 10968
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5659819841384888,
      "learning_rate": 5e-05,
      "loss": 0.3426,
      "step": 10976
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7152904272079468,
      "learning_rate": 5e-05,
      "loss": 0.3202,
      "step": 10984
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5540343523025513,
      "learning_rate": 5e-05,
      "loss": 0.3274,
      "step": 10992
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6801552772521973,
      "learning_rate": 5e-05,
      "loss": 0.3603,
      "step": 11000
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.588629424571991,
      "learning_rate": 5e-05,
      "loss": 0.3658,
      "step": 11008
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5577260255813599,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 11016
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5970852971076965,
      "learning_rate": 5e-05,
      "loss": 0.3399,
      "step": 11024
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6134562492370605,
      "learning_rate": 5e-05,
      "loss": 0.3438,
      "step": 11032
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5613155961036682,
      "learning_rate": 5e-05,
      "loss": 0.3403,
      "step": 11040
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5898996591567993,
      "learning_rate": 5e-05,
      "loss": 0.3366,
      "step": 11048
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.567963182926178,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 11056
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.775697648525238,
      "learning_rate": 5e-05,
      "loss": 0.3446,
      "step": 11064
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.622167706489563,
      "learning_rate": 5e-05,
      "loss": 0.3612,
      "step": 11072
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6163332462310791,
      "learning_rate": 5e-05,
      "loss": 0.3266,
      "step": 11080
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5907239317893982,
      "learning_rate": 5e-05,
      "loss": 0.3474,
      "step": 11088
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6789774298667908,
      "learning_rate": 5e-05,
      "loss": 0.3648,
      "step": 11096
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6408699750900269,
      "learning_rate": 5e-05,
      "loss": 0.3579,
      "step": 11104
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5748620629310608,
      "learning_rate": 5e-05,
      "loss": 0.3277,
      "step": 11112
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6034413576126099,
      "learning_rate": 5e-05,
      "loss": 0.3517,
      "step": 11120
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6540772318840027,
      "learning_rate": 5e-05,
      "loss": 0.3806,
      "step": 11128
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6810333132743835,
      "learning_rate": 5e-05,
      "loss": 0.3594,
      "step": 11136
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.562409520149231,
      "learning_rate": 5e-05,
      "loss": 0.3254,
      "step": 11144
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5871105194091797,
      "learning_rate": 5e-05,
      "loss": 0.3604,
      "step": 11152
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7245427966117859,
      "learning_rate": 5e-05,
      "loss": 0.3305,
      "step": 11160
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6568953990936279,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 11168
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6171261072158813,
      "learning_rate": 5e-05,
      "loss": 0.3221,
      "step": 11176
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5288340449333191,
      "learning_rate": 5e-05,
      "loss": 0.3209,
      "step": 11184
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6304508447647095,
      "learning_rate": 5e-05,
      "loss": 0.3446,
      "step": 11192
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7031382322311401,
      "learning_rate": 5e-05,
      "loss": 0.3415,
      "step": 11200
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.612901508808136,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 11208
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6426002979278564,
      "learning_rate": 5e-05,
      "loss": 0.3575,
      "step": 11216
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5787346959114075,
      "learning_rate": 5e-05,
      "loss": 0.3285,
      "step": 11224
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.628742516040802,
      "learning_rate": 5e-05,
      "loss": 0.3486,
      "step": 11232
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5947917103767395,
      "learning_rate": 5e-05,
      "loss": 0.3479,
      "step": 11240
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5434396266937256,
      "learning_rate": 5e-05,
      "loss": 0.3243,
      "step": 11248
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6459410190582275,
      "learning_rate": 5e-05,
      "loss": 0.3116,
      "step": 11256
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.710117518901825,
      "learning_rate": 5e-05,
      "loss": 0.3378,
      "step": 11264
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.7025057673454285,
      "learning_rate": 5e-05,
      "loss": 0.3725,
      "step": 11272
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6564143896102905,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 11280
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6024602651596069,
      "learning_rate": 5e-05,
      "loss": 0.3489,
      "step": 11288
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.590985119342804,
      "learning_rate": 5e-05,
      "loss": 0.2998,
      "step": 11296
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.7937561869621277,
      "learning_rate": 5e-05,
      "loss": 0.3549,
      "step": 11304
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6184043288230896,
      "learning_rate": 5e-05,
      "loss": 0.3442,
      "step": 11312
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6843296885490417,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 11320
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5732327699661255,
      "learning_rate": 5e-05,
      "loss": 0.3066,
      "step": 11328
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.8154037594795227,
      "learning_rate": 5e-05,
      "loss": 0.3279,
      "step": 11336
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6709175109863281,
      "learning_rate": 5e-05,
      "loss": 0.3351,
      "step": 11344
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6492621898651123,
      "learning_rate": 5e-05,
      "loss": 0.3707,
      "step": 11352
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5709981322288513,
      "learning_rate": 5e-05,
      "loss": 0.3473,
      "step": 11360
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6829319596290588,
      "learning_rate": 5e-05,
      "loss": 0.3634,
      "step": 11368
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5756194591522217,
      "learning_rate": 5e-05,
      "loss": 0.3332,
      "step": 11376
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6401761770248413,
      "learning_rate": 5e-05,
      "loss": 0.3408,
      "step": 11384
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6658797860145569,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 11392
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5130249261856079,
      "learning_rate": 5e-05,
      "loss": 0.3273,
      "step": 11400
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6292341947555542,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 11408
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5527123212814331,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 11416
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6405094265937805,
      "learning_rate": 5e-05,
      "loss": 0.3504,
      "step": 11424
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6521744132041931,
      "learning_rate": 5e-05,
      "loss": 0.3582,
      "step": 11432
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5815507173538208,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 11440
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.547877311706543,
      "learning_rate": 5e-05,
      "loss": 0.3395,
      "step": 11448
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5339456796646118,
      "learning_rate": 5e-05,
      "loss": 0.3492,
      "step": 11456
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.7082332372665405,
      "learning_rate": 5e-05,
      "loss": 0.3579,
      "step": 11464
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5176277160644531,
      "learning_rate": 5e-05,
      "loss": 0.3488,
      "step": 11472
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.569380521774292,
      "learning_rate": 5e-05,
      "loss": 0.3233,
      "step": 11480
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.691709578037262,
      "learning_rate": 5e-05,
      "loss": 0.3291,
      "step": 11488
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6718136072158813,
      "learning_rate": 5e-05,
      "loss": 0.3506,
      "step": 11496
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.685575544834137,
      "learning_rate": 5e-05,
      "loss": 0.3278,
      "step": 11504
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.7056499123573303,
      "learning_rate": 5e-05,
      "loss": 0.3368,
      "step": 11512
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.636131227016449,
      "learning_rate": 5e-05,
      "loss": 0.3323,
      "step": 11520
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5660071969032288,
      "learning_rate": 5e-05,
      "loss": 0.3591,
      "step": 11528
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.698265552520752,
      "learning_rate": 5e-05,
      "loss": 0.3574,
      "step": 11536
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5842968821525574,
      "learning_rate": 5e-05,
      "loss": 0.3296,
      "step": 11544
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5728145837783813,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 11552
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6298828125,
      "learning_rate": 5e-05,
      "loss": 0.3555,
      "step": 11560
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5318267345428467,
      "learning_rate": 5e-05,
      "loss": 0.3126,
      "step": 11568
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6056036353111267,
      "learning_rate": 5e-05,
      "loss": 0.3488,
      "step": 11576
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.59639972448349,
      "learning_rate": 5e-05,
      "loss": 0.3416,
      "step": 11584
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6202359795570374,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 11592
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.592189610004425,
      "learning_rate": 5e-05,
      "loss": 0.3168,
      "step": 11600
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7520476579666138,
      "learning_rate": 5e-05,
      "loss": 0.3291,
      "step": 11608
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5891563892364502,
      "learning_rate": 5e-05,
      "loss": 0.3433,
      "step": 11616
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6591809988021851,
      "learning_rate": 5e-05,
      "loss": 0.3462,
      "step": 11624
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6342686414718628,
      "learning_rate": 5e-05,
      "loss": 0.3345,
      "step": 11632
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.595903217792511,
      "learning_rate": 5e-05,
      "loss": 0.3466,
      "step": 11640
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6058556437492371,
      "learning_rate": 5e-05,
      "loss": 0.301,
      "step": 11648
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7033528685569763,
      "learning_rate": 5e-05,
      "loss": 0.3442,
      "step": 11656
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6492971181869507,
      "learning_rate": 5e-05,
      "loss": 0.3532,
      "step": 11664
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6569737792015076,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 11672
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.771705687046051,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 11680
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7161868810653687,
      "learning_rate": 5e-05,
      "loss": 0.3243,
      "step": 11688
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5440450310707092,
      "learning_rate": 5e-05,
      "loss": 0.3366,
      "step": 11696
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5649595260620117,
      "learning_rate": 5e-05,
      "loss": 0.3177,
      "step": 11704
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6772236227989197,
      "learning_rate": 5e-05,
      "loss": 0.3506,
      "step": 11712
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5580647587776184,
      "learning_rate": 5e-05,
      "loss": 0.3074,
      "step": 11720
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5987511277198792,
      "learning_rate": 5e-05,
      "loss": 0.3566,
      "step": 11728
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6047521829605103,
      "learning_rate": 5e-05,
      "loss": 0.3304,
      "step": 11736
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6377179622650146,
      "learning_rate": 5e-05,
      "loss": 0.3549,
      "step": 11744
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5707436800003052,
      "learning_rate": 5e-05,
      "loss": 0.3392,
      "step": 11752
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5507115721702576,
      "learning_rate": 5e-05,
      "loss": 0.353,
      "step": 11760
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7092676162719727,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 11768
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.635123074054718,
      "learning_rate": 5e-05,
      "loss": 0.3399,
      "step": 11776
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5835289359092712,
      "learning_rate": 5e-05,
      "loss": 0.3374,
      "step": 11784
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.606419026851654,
      "learning_rate": 5e-05,
      "loss": 0.3399,
      "step": 11792
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7099804282188416,
      "learning_rate": 5e-05,
      "loss": 0.328,
      "step": 11800
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5196685194969177,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 11808
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5853439569473267,
      "learning_rate": 5e-05,
      "loss": 0.3132,
      "step": 11816
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5489302277565002,
      "learning_rate": 5e-05,
      "loss": 0.3337,
      "step": 11824
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.716905951499939,
      "learning_rate": 5e-05,
      "loss": 0.3293,
      "step": 11832
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7937130928039551,
      "learning_rate": 5e-05,
      "loss": 0.2975,
      "step": 11840
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6678540110588074,
      "learning_rate": 5e-05,
      "loss": 0.3343,
      "step": 11848
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5902584791183472,
      "learning_rate": 5e-05,
      "loss": 0.3313,
      "step": 11856
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6163379549980164,
      "learning_rate": 5e-05,
      "loss": 0.326,
      "step": 11864
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6304711103439331,
      "learning_rate": 5e-05,
      "loss": 0.3268,
      "step": 11872
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5409927368164062,
      "learning_rate": 5e-05,
      "loss": 0.3591,
      "step": 11880
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6160233616828918,
      "learning_rate": 5e-05,
      "loss": 0.3252,
      "step": 11888
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6242266297340393,
      "learning_rate": 5e-05,
      "loss": 0.3593,
      "step": 11896
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6340054273605347,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 11904
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5362910032272339,
      "learning_rate": 5e-05,
      "loss": 0.3524,
      "step": 11912
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5531531572341919,
      "learning_rate": 5e-05,
      "loss": 0.3184,
      "step": 11920
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6106785535812378,
      "learning_rate": 5e-05,
      "loss": 0.3285,
      "step": 11928
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6344780921936035,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 11936
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6520143151283264,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 11944
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.531554639339447,
      "learning_rate": 5e-05,
      "loss": 0.332,
      "step": 11952
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7452819347381592,
      "learning_rate": 5e-05,
      "loss": 0.3465,
      "step": 11960
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5295295119285583,
      "learning_rate": 5e-05,
      "loss": 0.3271,
      "step": 11968
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0487278699874878,
      "learning_rate": 5e-05,
      "loss": 0.343,
      "step": 11976
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6453499794006348,
      "learning_rate": 5e-05,
      "loss": 0.3475,
      "step": 11984
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7360194325447083,
      "learning_rate": 5e-05,
      "loss": 0.328,
      "step": 11992
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6470568776130676,
      "learning_rate": 5e-05,
      "loss": 0.3626,
      "step": 12000
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6865128874778748,
      "learning_rate": 5e-05,
      "loss": 0.3506,
      "step": 12008
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5563745498657227,
      "learning_rate": 5e-05,
      "loss": 0.3329,
      "step": 12016
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8236521482467651,
      "learning_rate": 5e-05,
      "loss": 0.3594,
      "step": 12024
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5963562726974487,
      "learning_rate": 5e-05,
      "loss": 0.3268,
      "step": 12032
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5890541076660156,
      "learning_rate": 5e-05,
      "loss": 0.3296,
      "step": 12040
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6132841110229492,
      "learning_rate": 5e-05,
      "loss": 0.34,
      "step": 12048
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8229798078536987,
      "learning_rate": 5e-05,
      "loss": 0.3399,
      "step": 12056
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6437252163887024,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 12064
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5740798115730286,
      "learning_rate": 5e-05,
      "loss": 0.3483,
      "step": 12072
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5985463261604309,
      "learning_rate": 5e-05,
      "loss": 0.3286,
      "step": 12080
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5400152206420898,
      "learning_rate": 5e-05,
      "loss": 0.3679,
      "step": 12088
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6278745532035828,
      "learning_rate": 5e-05,
      "loss": 0.3287,
      "step": 12096
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5749889016151428,
      "learning_rate": 5e-05,
      "loss": 0.3178,
      "step": 12104
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6737114191055298,
      "learning_rate": 5e-05,
      "loss": 0.3327,
      "step": 12112
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6487053632736206,
      "learning_rate": 5e-05,
      "loss": 0.3558,
      "step": 12120
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6157284379005432,
      "learning_rate": 5e-05,
      "loss": 0.3354,
      "step": 12128
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5321904420852661,
      "learning_rate": 5e-05,
      "loss": 0.3385,
      "step": 12136
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6395238041877747,
      "learning_rate": 5e-05,
      "loss": 0.3327,
      "step": 12144
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5717371702194214,
      "learning_rate": 5e-05,
      "loss": 0.3616,
      "step": 12152
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6063881516456604,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 12160
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6649309992790222,
      "learning_rate": 5e-05,
      "loss": 0.3516,
      "step": 12168
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5974660515785217,
      "learning_rate": 5e-05,
      "loss": 0.3606,
      "step": 12176
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6559849381446838,
      "learning_rate": 5e-05,
      "loss": 0.319,
      "step": 12184
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.567161500453949,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 12192
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6056874394416809,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 12200
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.7146872282028198,
      "learning_rate": 5e-05,
      "loss": 0.3642,
      "step": 12208
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6598911285400391,
      "learning_rate": 5e-05,
      "loss": 0.3412,
      "step": 12216
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6921074390411377,
      "learning_rate": 5e-05,
      "loss": 0.3213,
      "step": 12224
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6323990821838379,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 12232
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6512022614479065,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 12240
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6099566221237183,
      "learning_rate": 5e-05,
      "loss": 0.3382,
      "step": 12248
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5910882353782654,
      "learning_rate": 5e-05,
      "loss": 0.3006,
      "step": 12256
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6301530003547668,
      "learning_rate": 5e-05,
      "loss": 0.3446,
      "step": 12264
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.715918242931366,
      "learning_rate": 5e-05,
      "loss": 0.3673,
      "step": 12272
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8084911704063416,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 12280
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5876929759979248,
      "learning_rate": 5e-05,
      "loss": 0.3359,
      "step": 12288
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6956793665885925,
      "learning_rate": 5e-05,
      "loss": 0.3503,
      "step": 12296
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7090005874633789,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 12304
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5381858944892883,
      "learning_rate": 5e-05,
      "loss": 0.336,
      "step": 12312
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8120433688163757,
      "learning_rate": 5e-05,
      "loss": 0.3436,
      "step": 12320
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6244792938232422,
      "learning_rate": 5e-05,
      "loss": 0.337,
      "step": 12328
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7137452960014343,
      "learning_rate": 5e-05,
      "loss": 0.342,
      "step": 12336
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6996443271636963,
      "learning_rate": 5e-05,
      "loss": 0.376,
      "step": 12344
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5973717570304871,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 12352
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8399800658226013,
      "learning_rate": 5e-05,
      "loss": 0.3082,
      "step": 12360
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6962427496910095,
      "learning_rate": 5e-05,
      "loss": 0.3647,
      "step": 12368
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6286700963973999,
      "learning_rate": 5e-05,
      "loss": 0.3286,
      "step": 12376
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5887457132339478,
      "learning_rate": 5e-05,
      "loss": 0.3212,
      "step": 12384
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6213966012001038,
      "learning_rate": 5e-05,
      "loss": 0.3429,
      "step": 12392
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6727046966552734,
      "learning_rate": 5e-05,
      "loss": 0.3571,
      "step": 12400
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.49093547463417053,
      "learning_rate": 5e-05,
      "loss": 0.3427,
      "step": 12408
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7003321647644043,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 12416
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6371675729751587,
      "learning_rate": 5e-05,
      "loss": 0.3299,
      "step": 12424
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6463663578033447,
      "learning_rate": 5e-05,
      "loss": 0.3414,
      "step": 12432
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7057577967643738,
      "learning_rate": 5e-05,
      "loss": 0.3096,
      "step": 12440
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6851235628128052,
      "learning_rate": 5e-05,
      "loss": 0.3702,
      "step": 12448
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6244515180587769,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 12456
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6771531701087952,
      "learning_rate": 5e-05,
      "loss": 0.3431,
      "step": 12464
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6031821966171265,
      "learning_rate": 5e-05,
      "loss": 0.3085,
      "step": 12472
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5300830602645874,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 12480
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6917369961738586,
      "learning_rate": 5e-05,
      "loss": 0.3413,
      "step": 12488
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6523709893226624,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 12496
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6497446894645691,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 12504
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6984732747077942,
      "learning_rate": 5e-05,
      "loss": 0.3367,
      "step": 12512
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5801413655281067,
      "learning_rate": 5e-05,
      "loss": 0.3271,
      "step": 12520
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5526894927024841,
      "learning_rate": 5e-05,
      "loss": 0.372,
      "step": 12528
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6348097324371338,
      "learning_rate": 5e-05,
      "loss": 0.3454,
      "step": 12536
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7753379940986633,
      "learning_rate": 5e-05,
      "loss": 0.3101,
      "step": 12544
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5370038151741028,
      "learning_rate": 5e-05,
      "loss": 0.328,
      "step": 12552
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6746319532394409,
      "learning_rate": 5e-05,
      "loss": 0.3545,
      "step": 12560
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5898613333702087,
      "learning_rate": 5e-05,
      "loss": 0.3168,
      "step": 12568
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.621984601020813,
      "learning_rate": 5e-05,
      "loss": 0.3454,
      "step": 12576
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5768471360206604,
      "learning_rate": 5e-05,
      "loss": 0.3318,
      "step": 12584
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.608839213848114,
      "learning_rate": 5e-05,
      "loss": 0.3328,
      "step": 12592
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6616581082344055,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 12600
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6114498376846313,
      "learning_rate": 5e-05,
      "loss": 0.3455,
      "step": 12608
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6122312545776367,
      "learning_rate": 5e-05,
      "loss": 0.3299,
      "step": 12616
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6086902618408203,
      "learning_rate": 5e-05,
      "loss": 0.3279,
      "step": 12624
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6335570216178894,
      "learning_rate": 5e-05,
      "loss": 0.3355,
      "step": 12632
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5268168449401855,
      "learning_rate": 5e-05,
      "loss": 0.3479,
      "step": 12640
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5810368061065674,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 12648
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6622350811958313,
      "learning_rate": 5e-05,
      "loss": 0.3597,
      "step": 12656
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5566619634628296,
      "learning_rate": 5e-05,
      "loss": 0.3634,
      "step": 12664
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6710377931594849,
      "learning_rate": 5e-05,
      "loss": 0.3278,
      "step": 12672
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.840349555015564,
      "learning_rate": 5e-05,
      "loss": 0.3417,
      "step": 12680
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6069295406341553,
      "learning_rate": 5e-05,
      "loss": 0.3427,
      "step": 12688
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.55525141954422,
      "learning_rate": 5e-05,
      "loss": 0.3389,
      "step": 12696
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6987987756729126,
      "learning_rate": 5e-05,
      "loss": 0.3293,
      "step": 12704
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6269935965538025,
      "learning_rate": 5e-05,
      "loss": 0.3539,
      "step": 12712
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6381461024284363,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 12720
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6536773443222046,
      "learning_rate": 5e-05,
      "loss": 0.3424,
      "step": 12728
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6597931385040283,
      "learning_rate": 5e-05,
      "loss": 0.374,
      "step": 12736
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.7067801356315613,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 12744
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5479772090911865,
      "learning_rate": 5e-05,
      "loss": 0.3145,
      "step": 12752
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6588044166564941,
      "learning_rate": 5e-05,
      "loss": 0.3174,
      "step": 12760
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6457242369651794,
      "learning_rate": 5e-05,
      "loss": 0.3468,
      "step": 12768
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.597835123538971,
      "learning_rate": 5e-05,
      "loss": 0.3695,
      "step": 12776
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.640159547328949,
      "learning_rate": 5e-05,
      "loss": 0.351,
      "step": 12784
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6107673645019531,
      "learning_rate": 5e-05,
      "loss": 0.3362,
      "step": 12792
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.658789336681366,
      "learning_rate": 5e-05,
      "loss": 0.3339,
      "step": 12800
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5814934372901917,
      "learning_rate": 5e-05,
      "loss": 0.341,
      "step": 12808
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6060069799423218,
      "learning_rate": 5e-05,
      "loss": 0.357,
      "step": 12816
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.7148295044898987,
      "learning_rate": 5e-05,
      "loss": 0.3442,
      "step": 12824
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6135331392288208,
      "learning_rate": 5e-05,
      "loss": 0.3033,
      "step": 12832
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5604245066642761,
      "learning_rate": 5e-05,
      "loss": 0.3143,
      "step": 12840
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.610996425151825,
      "learning_rate": 5e-05,
      "loss": 0.3575,
      "step": 12848
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6522879600524902,
      "learning_rate": 5e-05,
      "loss": 0.3221,
      "step": 12856
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6367505788803101,
      "learning_rate": 5e-05,
      "loss": 0.3547,
      "step": 12864
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6158141493797302,
      "learning_rate": 5e-05,
      "loss": 0.3579,
      "step": 12872
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6268600821495056,
      "learning_rate": 5e-05,
      "loss": 0.3361,
      "step": 12880
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6379494071006775,
      "learning_rate": 5e-05,
      "loss": 0.3554,
      "step": 12888
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5740927457809448,
      "learning_rate": 5e-05,
      "loss": 0.3539,
      "step": 12896
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6430952548980713,
      "learning_rate": 5e-05,
      "loss": 0.3754,
      "step": 12904
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6251527070999146,
      "learning_rate": 5e-05,
      "loss": 0.3721,
      "step": 12912
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6260532140731812,
      "learning_rate": 5e-05,
      "loss": 0.3051,
      "step": 12920
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6182217597961426,
      "learning_rate": 5e-05,
      "loss": 0.3338,
      "step": 12928
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7064961194992065,
      "learning_rate": 5e-05,
      "loss": 0.3219,
      "step": 12936
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6281842589378357,
      "learning_rate": 5e-05,
      "loss": 0.3121,
      "step": 12944
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7901157140731812,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 12952
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6756327748298645,
      "learning_rate": 5e-05,
      "loss": 0.3123,
      "step": 12960
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6468445658683777,
      "learning_rate": 5e-05,
      "loss": 0.352,
      "step": 12968
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6575661897659302,
      "learning_rate": 5e-05,
      "loss": 0.3332,
      "step": 12976
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6398690938949585,
      "learning_rate": 5e-05,
      "loss": 0.3306,
      "step": 12984
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7061160206794739,
      "learning_rate": 5e-05,
      "loss": 0.3561,
      "step": 12992
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7768189311027527,
      "learning_rate": 5e-05,
      "loss": 0.3464,
      "step": 13000
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6080247759819031,
      "learning_rate": 5e-05,
      "loss": 0.303,
      "step": 13008
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.568785548210144,
      "learning_rate": 5e-05,
      "loss": 0.3749,
      "step": 13016
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.617634117603302,
      "learning_rate": 5e-05,
      "loss": 0.3338,
      "step": 13024
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7300850749015808,
      "learning_rate": 5e-05,
      "loss": 0.3111,
      "step": 13032
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5489813089370728,
      "learning_rate": 5e-05,
      "loss": 0.3342,
      "step": 13040
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5304684042930603,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 13048
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6757089495658875,
      "learning_rate": 5e-05,
      "loss": 0.3417,
      "step": 13056
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5326083898544312,
      "learning_rate": 5e-05,
      "loss": 0.3204,
      "step": 13064
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5400723814964294,
      "learning_rate": 5e-05,
      "loss": 0.3496,
      "step": 13072
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6855474710464478,
      "learning_rate": 5e-05,
      "loss": 0.3402,
      "step": 13080
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.675593376159668,
      "learning_rate": 5e-05,
      "loss": 0.3412,
      "step": 13088
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6486648321151733,
      "learning_rate": 5e-05,
      "loss": 0.3294,
      "step": 13096
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6330901384353638,
      "learning_rate": 5e-05,
      "loss": 0.3336,
      "step": 13104
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6656292080879211,
      "learning_rate": 5e-05,
      "loss": 0.325,
      "step": 13112
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6310739517211914,
      "learning_rate": 5e-05,
      "loss": 0.3161,
      "step": 13120
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.7094528675079346,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 13128
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6470767259597778,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 13136
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.703521728515625,
      "learning_rate": 5e-05,
      "loss": 0.3212,
      "step": 13144
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5986424088478088,
      "learning_rate": 5e-05,
      "loss": 0.3443,
      "step": 13152
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.636019766330719,
      "learning_rate": 5e-05,
      "loss": 0.3147,
      "step": 13160
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5563703179359436,
      "learning_rate": 5e-05,
      "loss": 0.3625,
      "step": 13168
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5875962972640991,
      "learning_rate": 5e-05,
      "loss": 0.3573,
      "step": 13176
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6761206388473511,
      "learning_rate": 5e-05,
      "loss": 0.3323,
      "step": 13184
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5899589657783508,
      "learning_rate": 5e-05,
      "loss": 0.3304,
      "step": 13192
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6160292625427246,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 13200
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5893645286560059,
      "learning_rate": 5e-05,
      "loss": 0.3327,
      "step": 13208
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.722973644733429,
      "learning_rate": 5e-05,
      "loss": 0.3383,
      "step": 13216
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6306309700012207,
      "learning_rate": 5e-05,
      "loss": 0.3186,
      "step": 13224
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6907533407211304,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 13232
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6854202747344971,
      "learning_rate": 5e-05,
      "loss": 0.3484,
      "step": 13240
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6367377638816833,
      "learning_rate": 5e-05,
      "loss": 0.3235,
      "step": 13248
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5603188872337341,
      "learning_rate": 5e-05,
      "loss": 0.3296,
      "step": 13256
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6324942708015442,
      "learning_rate": 5e-05,
      "loss": 0.3104,
      "step": 13264
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.568720281124115,
      "learning_rate": 5e-05,
      "loss": 0.3573,
      "step": 13272
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6612778306007385,
      "learning_rate": 5e-05,
      "loss": 0.3628,
      "step": 13280
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6704469919204712,
      "learning_rate": 5e-05,
      "loss": 0.3411,
      "step": 13288
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7068712115287781,
      "learning_rate": 5e-05,
      "loss": 0.3367,
      "step": 13296
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6891135573387146,
      "learning_rate": 5e-05,
      "loss": 0.3538,
      "step": 13304
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6896678805351257,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 13312
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6856591105461121,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 13320
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6525436639785767,
      "learning_rate": 5e-05,
      "loss": 0.379,
      "step": 13328
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6710067987442017,
      "learning_rate": 5e-05,
      "loss": 0.3182,
      "step": 13336
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6060940027236938,
      "learning_rate": 5e-05,
      "loss": 0.3373,
      "step": 13344
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7508033514022827,
      "learning_rate": 5e-05,
      "loss": 0.3297,
      "step": 13352
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6774634718894958,
      "learning_rate": 5e-05,
      "loss": 0.3367,
      "step": 13360
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6474097967147827,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 13368
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.592530369758606,
      "learning_rate": 5e-05,
      "loss": 0.3148,
      "step": 13376
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6060763597488403,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 13384
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6278625130653381,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 13392
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5591433644294739,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 13400
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5794306993484497,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 13408
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.672698974609375,
      "learning_rate": 5e-05,
      "loss": 0.3303,
      "step": 13416
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6143240332603455,
      "learning_rate": 5e-05,
      "loss": 0.3502,
      "step": 13424
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6505647301673889,
      "learning_rate": 5e-05,
      "loss": 0.3352,
      "step": 13432
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5838440656661987,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 13440
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6989253759384155,
      "learning_rate": 5e-05,
      "loss": 0.3051,
      "step": 13448
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5670658349990845,
      "learning_rate": 5e-05,
      "loss": 0.3358,
      "step": 13456
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.600796639919281,
      "learning_rate": 5e-05,
      "loss": 0.3643,
      "step": 13464
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6952493190765381,
      "learning_rate": 5e-05,
      "loss": 0.3476,
      "step": 13472
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5928500294685364,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 13480
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6590718626976013,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 13488
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6487753391265869,
      "learning_rate": 5e-05,
      "loss": 0.3344,
      "step": 13496
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7143438458442688,
      "learning_rate": 5e-05,
      "loss": 0.3182,
      "step": 13504
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7359451055526733,
      "learning_rate": 5e-05,
      "loss": 0.3451,
      "step": 13512
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5602722764015198,
      "learning_rate": 5e-05,
      "loss": 0.3532,
      "step": 13520
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6258971691131592,
      "learning_rate": 5e-05,
      "loss": 0.3375,
      "step": 13528
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6704174280166626,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 13536
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7885693907737732,
      "learning_rate": 5e-05,
      "loss": 0.3126,
      "step": 13544
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6394743323326111,
      "learning_rate": 5e-05,
      "loss": 0.329,
      "step": 13552
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6512138247489929,
      "learning_rate": 5e-05,
      "loss": 0.3235,
      "step": 13560
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.9445533752441406,
      "learning_rate": 5e-05,
      "loss": 0.3383,
      "step": 13568
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5462286472320557,
      "learning_rate": 5e-05,
      "loss": 0.2971,
      "step": 13576
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5993353724479675,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 13584
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6178168654441833,
      "learning_rate": 5e-05,
      "loss": 0.3176,
      "step": 13592
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6208893060684204,
      "learning_rate": 5e-05,
      "loss": 0.3339,
      "step": 13600
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6044240593910217,
      "learning_rate": 5e-05,
      "loss": 0.3125,
      "step": 13608
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6414117217063904,
      "learning_rate": 5e-05,
      "loss": 0.3494,
      "step": 13616
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6194561719894409,
      "learning_rate": 5e-05,
      "loss": 0.3141,
      "step": 13624
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.963716447353363,
      "learning_rate": 5e-05,
      "loss": 0.346,
      "step": 13632
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6472750902175903,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 13640
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6420692801475525,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 13648
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6100112795829773,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 13656
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6425687074661255,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 13664
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6155884265899658,
      "learning_rate": 5e-05,
      "loss": 0.2936,
      "step": 13672
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6760955452919006,
      "learning_rate": 5e-05,
      "loss": 0.3263,
      "step": 13680
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5732349753379822,
      "learning_rate": 5e-05,
      "loss": 0.3394,
      "step": 13688
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6102427840232849,
      "learning_rate": 5e-05,
      "loss": 0.3549,
      "step": 13696
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5485654473304749,
      "learning_rate": 5e-05,
      "loss": 0.3462,
      "step": 13704
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5769220590591431,
      "learning_rate": 5e-05,
      "loss": 0.3048,
      "step": 13712
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5918337106704712,
      "learning_rate": 5e-05,
      "loss": 0.3698,
      "step": 13720
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5899944305419922,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 13728
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.631452202796936,
      "learning_rate": 5e-05,
      "loss": 0.3699,
      "step": 13736
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6984722018241882,
      "learning_rate": 5e-05,
      "loss": 0.3194,
      "step": 13744
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6541369557380676,
      "learning_rate": 5e-05,
      "loss": 0.3612,
      "step": 13752
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.641700267791748,
      "learning_rate": 5e-05,
      "loss": 0.3384,
      "step": 13760
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6158364415168762,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 13768
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6352589130401611,
      "learning_rate": 5e-05,
      "loss": 0.3335,
      "step": 13776
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6964265704154968,
      "learning_rate": 5e-05,
      "loss": 0.3381,
      "step": 13784
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.7183162569999695,
      "learning_rate": 5e-05,
      "loss": 0.3417,
      "step": 13792
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6766141057014465,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 13800
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6082723140716553,
      "learning_rate": 5e-05,
      "loss": 0.3263,
      "step": 13808
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5787392258644104,
      "learning_rate": 5e-05,
      "loss": 0.3668,
      "step": 13816
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.7151544690132141,
      "learning_rate": 5e-05,
      "loss": 0.3123,
      "step": 13824
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5462286472320557,
      "learning_rate": 5e-05,
      "loss": 0.3384,
      "step": 13832
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6337451934814453,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 13840
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5825706124305725,
      "learning_rate": 5e-05,
      "loss": 0.3236,
      "step": 13848
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.8408116698265076,
      "learning_rate": 5e-05,
      "loss": 0.3717,
      "step": 13856
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6286413669586182,
      "learning_rate": 5e-05,
      "loss": 0.3347,
      "step": 13864
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5989090204238892,
      "learning_rate": 5e-05,
      "loss": 0.3249,
      "step": 13872
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.7416523098945618,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 13880
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5157090425491333,
      "learning_rate": 5e-05,
      "loss": 0.3487,
      "step": 13888
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5507614016532898,
      "learning_rate": 5e-05,
      "loss": 0.3375,
      "step": 13896
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.7078441381454468,
      "learning_rate": 5e-05,
      "loss": 0.3532,
      "step": 13904
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5865012407302856,
      "learning_rate": 5e-05,
      "loss": 0.2942,
      "step": 13912
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5893558859825134,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 13920
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7535320520401001,
      "learning_rate": 5e-05,
      "loss": 0.3395,
      "step": 13928
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5951166152954102,
      "learning_rate": 5e-05,
      "loss": 0.3407,
      "step": 13936
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7058011889457703,
      "learning_rate": 5e-05,
      "loss": 0.3468,
      "step": 13944
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6508421897888184,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 13952
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5979045033454895,
      "learning_rate": 5e-05,
      "loss": 0.3331,
      "step": 13960
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6682398319244385,
      "learning_rate": 5e-05,
      "loss": 0.3358,
      "step": 13968
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6537430286407471,
      "learning_rate": 5e-05,
      "loss": 0.3161,
      "step": 13976
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5988871455192566,
      "learning_rate": 5e-05,
      "loss": 0.3475,
      "step": 13984
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6864838600158691,
      "learning_rate": 5e-05,
      "loss": 0.336,
      "step": 13992
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6882311701774597,
      "learning_rate": 5e-05,
      "loss": 0.3512,
      "step": 14000
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6271689534187317,
      "learning_rate": 5e-05,
      "loss": 0.3164,
      "step": 14008
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6261739730834961,
      "learning_rate": 5e-05,
      "loss": 0.3432,
      "step": 14016
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5739495754241943,
      "learning_rate": 5e-05,
      "loss": 0.3383,
      "step": 14024
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5990906953811646,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 14032
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6063523292541504,
      "learning_rate": 5e-05,
      "loss": 0.3526,
      "step": 14040
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5971913933753967,
      "learning_rate": 5e-05,
      "loss": 0.3059,
      "step": 14048
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7656026482582092,
      "learning_rate": 5e-05,
      "loss": 0.3238,
      "step": 14056
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6767055988311768,
      "learning_rate": 5e-05,
      "loss": 0.3442,
      "step": 14064
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6358397603034973,
      "learning_rate": 5e-05,
      "loss": 0.3459,
      "step": 14072
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6460497975349426,
      "learning_rate": 5e-05,
      "loss": 0.3565,
      "step": 14080
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6322004795074463,
      "learning_rate": 5e-05,
      "loss": 0.3695,
      "step": 14088
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.7252414226531982,
      "learning_rate": 5e-05,
      "loss": 0.365,
      "step": 14096
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.7393078804016113,
      "learning_rate": 5e-05,
      "loss": 0.3175,
      "step": 14104
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.701934814453125,
      "learning_rate": 5e-05,
      "loss": 0.3219,
      "step": 14112
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6205943822860718,
      "learning_rate": 5e-05,
      "loss": 0.3434,
      "step": 14120
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6233163475990295,
      "learning_rate": 5e-05,
      "loss": 0.3371,
      "step": 14128
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5938499569892883,
      "learning_rate": 5e-05,
      "loss": 0.3077,
      "step": 14136
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6789815425872803,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 14144
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5949331521987915,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 14152
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.49891090393066406,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 14160
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5912777781486511,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 14168
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6043924689292908,
      "learning_rate": 5e-05,
      "loss": 0.346,
      "step": 14176
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5648824572563171,
      "learning_rate": 5e-05,
      "loss": 0.3378,
      "step": 14184
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6076279282569885,
      "learning_rate": 5e-05,
      "loss": 0.3554,
      "step": 14192
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6202168464660645,
      "learning_rate": 5e-05,
      "loss": 0.3436,
      "step": 14200
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5547422170639038,
      "learning_rate": 5e-05,
      "loss": 0.3623,
      "step": 14208
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6896571516990662,
      "learning_rate": 5e-05,
      "loss": 0.3527,
      "step": 14216
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6047708988189697,
      "learning_rate": 5e-05,
      "loss": 0.3656,
      "step": 14224
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6682305335998535,
      "learning_rate": 5e-05,
      "loss": 0.3385,
      "step": 14232
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.8274959921836853,
      "learning_rate": 5e-05,
      "loss": 0.3098,
      "step": 14240
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.7170155644416809,
      "learning_rate": 5e-05,
      "loss": 0.3317,
      "step": 14248
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6643698215484619,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 14256
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6926830410957336,
      "learning_rate": 5e-05,
      "loss": 0.3591,
      "step": 14264
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6446549296379089,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 14272
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.8057438731193542,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 14280
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7741034030914307,
      "learning_rate": 5e-05,
      "loss": 0.3301,
      "step": 14288
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5753659605979919,
      "learning_rate": 5e-05,
      "loss": 0.3146,
      "step": 14296
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7607994079589844,
      "learning_rate": 5e-05,
      "loss": 0.3256,
      "step": 14304
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.643658459186554,
      "learning_rate": 5e-05,
      "loss": 0.3398,
      "step": 14312
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6480057835578918,
      "learning_rate": 5e-05,
      "loss": 0.3173,
      "step": 14320
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6134008765220642,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 14328
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6274653077125549,
      "learning_rate": 5e-05,
      "loss": 0.3592,
      "step": 14336
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6430363059043884,
      "learning_rate": 5e-05,
      "loss": 0.3233,
      "step": 14344
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6588088870048523,
      "learning_rate": 5e-05,
      "loss": 0.3403,
      "step": 14352
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6460215449333191,
      "learning_rate": 5e-05,
      "loss": 0.3406,
      "step": 14360
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6017736196517944,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 14368
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6312772631645203,
      "learning_rate": 5e-05,
      "loss": 0.3418,
      "step": 14376
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6971310377120972,
      "learning_rate": 5e-05,
      "loss": 0.3603,
      "step": 14384
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7097848653793335,
      "learning_rate": 5e-05,
      "loss": 0.3365,
      "step": 14392
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7371177673339844,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 14400
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6874468922615051,
      "learning_rate": 5e-05,
      "loss": 0.336,
      "step": 14408
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.550162136554718,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 14416
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6348473429679871,
      "learning_rate": 5e-05,
      "loss": 0.3406,
      "step": 14424
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5614758133888245,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 14432
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6299082636833191,
      "learning_rate": 5e-05,
      "loss": 0.34,
      "step": 14440
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6924964189529419,
      "learning_rate": 5e-05,
      "loss": 0.3438,
      "step": 14448
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5224334597587585,
      "learning_rate": 5e-05,
      "loss": 0.3023,
      "step": 14456
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6675623059272766,
      "learning_rate": 5e-05,
      "loss": 0.3327,
      "step": 14464
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.7367401123046875,
      "learning_rate": 5e-05,
      "loss": 0.3208,
      "step": 14472
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6660493612289429,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 14480
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.7211965918540955,
      "learning_rate": 5e-05,
      "loss": 0.3281,
      "step": 14488
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5733621716499329,
      "learning_rate": 5e-05,
      "loss": 0.3432,
      "step": 14496
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.578900158405304,
      "learning_rate": 5e-05,
      "loss": 0.3362,
      "step": 14504
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5760042071342468,
      "learning_rate": 5e-05,
      "loss": 0.3324,
      "step": 14512
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.630338728427887,
      "learning_rate": 5e-05,
      "loss": 0.3722,
      "step": 14520
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5959977507591248,
      "learning_rate": 5e-05,
      "loss": 0.3471,
      "step": 14528
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5858907699584961,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 14536
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.7231881618499756,
      "learning_rate": 5e-05,
      "loss": 0.3334,
      "step": 14544
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6340751051902771,
      "learning_rate": 5e-05,
      "loss": 0.3354,
      "step": 14552
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5452953577041626,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 14560
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6270202994346619,
      "learning_rate": 5e-05,
      "loss": 0.3468,
      "step": 14568
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6271148920059204,
      "learning_rate": 5e-05,
      "loss": 0.3327,
      "step": 14576
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6815518140792847,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 14584
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.7207859754562378,
      "learning_rate": 5e-05,
      "loss": 0.3112,
      "step": 14592
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6768799424171448,
      "learning_rate": 5e-05,
      "loss": 0.3326,
      "step": 14600
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6510359644889832,
      "learning_rate": 5e-05,
      "loss": 0.3464,
      "step": 14608
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6733402609825134,
      "learning_rate": 5e-05,
      "loss": 0.3164,
      "step": 14616
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6138720512390137,
      "learning_rate": 5e-05,
      "loss": 0.3495,
      "step": 14624
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6035426259040833,
      "learning_rate": 5e-05,
      "loss": 0.3424,
      "step": 14632
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5780410170555115,
      "learning_rate": 5e-05,
      "loss": 0.3237,
      "step": 14640
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.65375816822052,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 14648
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5271547436714172,
      "learning_rate": 5e-05,
      "loss": 0.3396,
      "step": 14656
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6635586619377136,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 14664
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6630707383155823,
      "learning_rate": 5e-05,
      "loss": 0.3367,
      "step": 14672
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5852751135826111,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 14680
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6363378763198853,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 14688
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.7804304361343384,
      "learning_rate": 5e-05,
      "loss": 0.3013,
      "step": 14696
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.7162718772888184,
      "learning_rate": 5e-05,
      "loss": 0.3679,
      "step": 14704
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6137699484825134,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 14712
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.613239586353302,
      "learning_rate": 5e-05,
      "loss": 0.3422,
      "step": 14720
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6461473107337952,
      "learning_rate": 5e-05,
      "loss": 0.3209,
      "step": 14728
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5674158930778503,
      "learning_rate": 5e-05,
      "loss": 0.3458,
      "step": 14736
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5472066402435303,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 14744
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6640939712524414,
      "learning_rate": 5e-05,
      "loss": 0.3007,
      "step": 14752
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5756812691688538,
      "learning_rate": 5e-05,
      "loss": 0.3253,
      "step": 14760
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6964619755744934,
      "learning_rate": 5e-05,
      "loss": 0.3447,
      "step": 14768
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6198366284370422,
      "learning_rate": 5e-05,
      "loss": 0.362,
      "step": 14776
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.7361032962799072,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 14784
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.641174852848053,
      "learning_rate": 5e-05,
      "loss": 0.3432,
      "step": 14792
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6275263428688049,
      "learning_rate": 5e-05,
      "loss": 0.3327,
      "step": 14800
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.654048502445221,
      "learning_rate": 5e-05,
      "loss": 0.3362,
      "step": 14808
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5947369337081909,
      "learning_rate": 5e-05,
      "loss": 0.344,
      "step": 14816
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5171740055084229,
      "learning_rate": 5e-05,
      "loss": 0.343,
      "step": 14824
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.8174650073051453,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 14832
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6239714026451111,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 14840
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5075523257255554,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 14848
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6661487221717834,
      "learning_rate": 5e-05,
      "loss": 0.3476,
      "step": 14856
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6460945010185242,
      "learning_rate": 5e-05,
      "loss": 0.3099,
      "step": 14864
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5619222521781921,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 14872
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6421956419944763,
      "learning_rate": 5e-05,
      "loss": 0.3557,
      "step": 14880
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6210119128227234,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 14888
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6211260557174683,
      "learning_rate": 5e-05,
      "loss": 0.3531,
      "step": 14896
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5589381456375122,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 14904
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6466391682624817,
      "learning_rate": 5e-05,
      "loss": 0.3396,
      "step": 14912
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.819715142250061,
      "learning_rate": 5e-05,
      "loss": 0.3348,
      "step": 14920
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.7990780472755432,
      "learning_rate": 5e-05,
      "loss": 0.3037,
      "step": 14928
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6591547131538391,
      "learning_rate": 5e-05,
      "loss": 0.3375,
      "step": 14936
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.590907871723175,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 14944
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6510206460952759,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 14952
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6034669280052185,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 14960
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6004384160041809,
      "learning_rate": 5e-05,
      "loss": 0.3343,
      "step": 14968
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6659711599349976,
      "learning_rate": 5e-05,
      "loss": 0.3431,
      "step": 14976
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6275471448898315,
      "learning_rate": 5e-05,
      "loss": 0.3492,
      "step": 14984
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.7524515390396118,
      "learning_rate": 5e-05,
      "loss": 0.3143,
      "step": 14992
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5764949917793274,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 15000
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.665448009967804,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 15008
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6187744736671448,
      "learning_rate": 5e-05,
      "loss": 0.3458,
      "step": 15016
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.641676664352417,
      "learning_rate": 5e-05,
      "loss": 0.3391,
      "step": 15024
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5197027921676636,
      "learning_rate": 5e-05,
      "loss": 0.3757,
      "step": 15032
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.63315349817276,
      "learning_rate": 5e-05,
      "loss": 0.3379,
      "step": 15040
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5927134156227112,
      "learning_rate": 5e-05,
      "loss": 0.315,
      "step": 15048
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6712798476219177,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 15056
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6106196641921997,
      "learning_rate": 5e-05,
      "loss": 0.3097,
      "step": 15064
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.7430312037467957,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 15072
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6048809289932251,
      "learning_rate": 5e-05,
      "loss": 0.3338,
      "step": 15080
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6163102388381958,
      "learning_rate": 5e-05,
      "loss": 0.3339,
      "step": 15088
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.531665027141571,
      "learning_rate": 5e-05,
      "loss": 0.319,
      "step": 15096
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6227003335952759,
      "learning_rate": 5e-05,
      "loss": 0.301,
      "step": 15104
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6837709546089172,
      "learning_rate": 5e-05,
      "loss": 0.326,
      "step": 15112
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6226503849029541,
      "learning_rate": 5e-05,
      "loss": 0.3382,
      "step": 15120
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5145841240882874,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 15128
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5379015803337097,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 15136
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6802403330802917,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 15144
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6617621779441833,
      "learning_rate": 5e-05,
      "loss": 0.3352,
      "step": 15152
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.8279242515563965,
      "learning_rate": 5e-05,
      "loss": 0.3197,
      "step": 15160
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.7393010854721069,
      "learning_rate": 5e-05,
      "loss": 0.3537,
      "step": 15168
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.584282636642456,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 15176
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6154348254203796,
      "learning_rate": 5e-05,
      "loss": 0.3396,
      "step": 15184
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6927316188812256,
      "learning_rate": 5e-05,
      "loss": 0.3208,
      "step": 15192
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6438578367233276,
      "learning_rate": 5e-05,
      "loss": 0.3258,
      "step": 15200
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.7102755904197693,
      "learning_rate": 5e-05,
      "loss": 0.3425,
      "step": 15208
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5879109501838684,
      "learning_rate": 5e-05,
      "loss": 0.3333,
      "step": 15216
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6180247068405151,
      "learning_rate": 5e-05,
      "loss": 0.3058,
      "step": 15224
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6974659562110901,
      "learning_rate": 5e-05,
      "loss": 0.3482,
      "step": 15232
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6124638319015503,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 15240
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.7472484707832336,
      "learning_rate": 5e-05,
      "loss": 0.3586,
      "step": 15248
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5591773986816406,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 15256
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5596306920051575,
      "learning_rate": 5e-05,
      "loss": 0.3218,
      "step": 15264
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6233142018318176,
      "learning_rate": 5e-05,
      "loss": 0.3341,
      "step": 15272
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6326671242713928,
      "learning_rate": 5e-05,
      "loss": 0.3436,
      "step": 15280
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6013649702072144,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 15288
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6783411502838135,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 15296
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6246435046195984,
      "learning_rate": 5e-05,
      "loss": 0.3594,
      "step": 15304
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6873055696487427,
      "learning_rate": 5e-05,
      "loss": 0.3222,
      "step": 15312
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6353723406791687,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 15320
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.7415704131126404,
      "learning_rate": 5e-05,
      "loss": 0.3691,
      "step": 15328
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5767685174942017,
      "learning_rate": 5e-05,
      "loss": 0.347,
      "step": 15336
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.7173144221305847,
      "learning_rate": 5e-05,
      "loss": 0.3447,
      "step": 15344
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.753494381904602,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 15352
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5898199081420898,
      "learning_rate": 5e-05,
      "loss": 0.3211,
      "step": 15360
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6339695453643799,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 15368
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5876471400260925,
      "learning_rate": 5e-05,
      "loss": 0.3336,
      "step": 15376
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5861139893531799,
      "learning_rate": 5e-05,
      "loss": 0.3327,
      "step": 15384
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.548846423625946,
      "learning_rate": 5e-05,
      "loss": 0.3269,
      "step": 15392
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5897868275642395,
      "learning_rate": 5e-05,
      "loss": 0.3574,
      "step": 15400
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6897438168525696,
      "learning_rate": 5e-05,
      "loss": 0.3487,
      "step": 15408
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5661571025848389,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 15416
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7300810813903809,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 15424
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.8479360342025757,
      "learning_rate": 5e-05,
      "loss": 0.3384,
      "step": 15432
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5713685750961304,
      "learning_rate": 5e-05,
      "loss": 0.3522,
      "step": 15440
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5728732347488403,
      "learning_rate": 5e-05,
      "loss": 0.3123,
      "step": 15448
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.584173321723938,
      "learning_rate": 5e-05,
      "loss": 0.3576,
      "step": 15456
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6365965008735657,
      "learning_rate": 5e-05,
      "loss": 0.34,
      "step": 15464
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6299555897712708,
      "learning_rate": 5e-05,
      "loss": 0.3472,
      "step": 15472
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6428099274635315,
      "learning_rate": 5e-05,
      "loss": 0.3318,
      "step": 15480
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5580781698226929,
      "learning_rate": 5e-05,
      "loss": 0.298,
      "step": 15488
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.565958559513092,
      "learning_rate": 5e-05,
      "loss": 0.3188,
      "step": 15496
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5624712705612183,
      "learning_rate": 5e-05,
      "loss": 0.3099,
      "step": 15504
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7308120131492615,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 15512
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6335224509239197,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 15520
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5261327624320984,
      "learning_rate": 5e-05,
      "loss": 0.3383,
      "step": 15528
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5780175924301147,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 15536
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6513353586196899,
      "learning_rate": 5e-05,
      "loss": 0.3147,
      "step": 15544
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7251093983650208,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 15552
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5971878170967102,
      "learning_rate": 5e-05,
      "loss": 0.3546,
      "step": 15560
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6731521487236023,
      "learning_rate": 5e-05,
      "loss": 0.3391,
      "step": 15568
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7622411847114563,
      "learning_rate": 5e-05,
      "loss": 0.3305,
      "step": 15576
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5964089632034302,
      "learning_rate": 5e-05,
      "loss": 0.3564,
      "step": 15584
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5557172894477844,
      "learning_rate": 5e-05,
      "loss": 0.3371,
      "step": 15592
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6300152540206909,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 15600
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5386279225349426,
      "learning_rate": 5e-05,
      "loss": 0.3086,
      "step": 15608
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6851733922958374,
      "learning_rate": 5e-05,
      "loss": 0.3582,
      "step": 15616
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8465833067893982,
      "learning_rate": 5e-05,
      "loss": 0.3579,
      "step": 15624
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.689935028553009,
      "learning_rate": 5e-05,
      "loss": 0.3322,
      "step": 15632
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5743706822395325,
      "learning_rate": 5e-05,
      "loss": 0.3287,
      "step": 15640
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7532995939254761,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 15648
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.662663996219635,
      "learning_rate": 5e-05,
      "loss": 0.3101,
      "step": 15656
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5658909678459167,
      "learning_rate": 5e-05,
      "loss": 0.3033,
      "step": 15664
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6982936859130859,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 15672
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8146449327468872,
      "learning_rate": 5e-05,
      "loss": 0.3548,
      "step": 15680
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6518686413764954,
      "learning_rate": 5e-05,
      "loss": 0.332,
      "step": 15688
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6803175210952759,
      "learning_rate": 5e-05,
      "loss": 0.3117,
      "step": 15696
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5847231149673462,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 15704
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7453836798667908,
      "learning_rate": 5e-05,
      "loss": 0.3359,
      "step": 15712
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6290698647499084,
      "learning_rate": 5e-05,
      "loss": 0.3247,
      "step": 15720
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7103250622749329,
      "learning_rate": 5e-05,
      "loss": 0.3515,
      "step": 15728
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6969968676567078,
      "learning_rate": 5e-05,
      "loss": 0.3222,
      "step": 15736
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6142731308937073,
      "learning_rate": 5e-05,
      "loss": 0.3377,
      "step": 15744
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6525382399559021,
      "learning_rate": 5e-05,
      "loss": 0.3465,
      "step": 15752
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7036953568458557,
      "learning_rate": 5e-05,
      "loss": 0.311,
      "step": 15760
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5801391005516052,
      "learning_rate": 5e-05,
      "loss": 0.3074,
      "step": 15768
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7830306887626648,
      "learning_rate": 5e-05,
      "loss": 0.3317,
      "step": 15776
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5909987688064575,
      "learning_rate": 5e-05,
      "loss": 0.3342,
      "step": 15784
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.690406322479248,
      "learning_rate": 5e-05,
      "loss": 0.3552,
      "step": 15792
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.8771556615829468,
      "learning_rate": 5e-05,
      "loss": 0.3319,
      "step": 15800
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5432752966880798,
      "learning_rate": 5e-05,
      "loss": 0.3323,
      "step": 15808
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5515533089637756,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 15816
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7326911687850952,
      "learning_rate": 5e-05,
      "loss": 0.325,
      "step": 15824
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7262632846832275,
      "learning_rate": 5e-05,
      "loss": 0.3367,
      "step": 15832
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6966487765312195,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 15840
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7909427285194397,
      "learning_rate": 5e-05,
      "loss": 0.3193,
      "step": 15848
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7080482244491577,
      "learning_rate": 5e-05,
      "loss": 0.3704,
      "step": 15856
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7210623621940613,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 15864
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6088181138038635,
      "learning_rate": 5e-05,
      "loss": 0.3262,
      "step": 15872
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6201576590538025,
      "learning_rate": 5e-05,
      "loss": 0.3133,
      "step": 15880
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.650176465511322,
      "learning_rate": 5e-05,
      "loss": 0.3221,
      "step": 15888
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6811809539794922,
      "learning_rate": 5e-05,
      "loss": 0.3148,
      "step": 15896
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6686923503875732,
      "learning_rate": 5e-05,
      "loss": 0.3167,
      "step": 15904
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6453628540039062,
      "learning_rate": 5e-05,
      "loss": 0.3469,
      "step": 15912
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6669390201568604,
      "learning_rate": 5e-05,
      "loss": 0.3002,
      "step": 15920
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.652350127696991,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 15928
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5672979950904846,
      "learning_rate": 5e-05,
      "loss": 0.3548,
      "step": 15936
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.589064359664917,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 15944
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6388972997665405,
      "learning_rate": 5e-05,
      "loss": 0.3425,
      "step": 15952
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6002973318099976,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 15960
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6274659037590027,
      "learning_rate": 5e-05,
      "loss": 0.3573,
      "step": 15968
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6445728540420532,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 15976
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.745699405670166,
      "learning_rate": 5e-05,
      "loss": 0.3412,
      "step": 15984
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.648573637008667,
      "learning_rate": 5e-05,
      "loss": 0.3378,
      "step": 15992
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5659843683242798,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 16000
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.8168275952339172,
      "learning_rate": 5e-05,
      "loss": 0.3211,
      "step": 16008
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6253968477249146,
      "learning_rate": 5e-05,
      "loss": 0.3263,
      "step": 16016
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6533424258232117,
      "learning_rate": 5e-05,
      "loss": 0.3373,
      "step": 16024
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5862507224082947,
      "learning_rate": 5e-05,
      "loss": 0.3635,
      "step": 16032
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6541158556938171,
      "learning_rate": 5e-05,
      "loss": 0.3529,
      "step": 16040
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.756331741809845,
      "learning_rate": 5e-05,
      "loss": 0.346,
      "step": 16048
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6778120398521423,
      "learning_rate": 5e-05,
      "loss": 0.3234,
      "step": 16056
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6269719004631042,
      "learning_rate": 5e-05,
      "loss": 0.3472,
      "step": 16064
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6546394228935242,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 16072
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6268028616905212,
      "learning_rate": 5e-05,
      "loss": 0.3167,
      "step": 16080
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.615403413772583,
      "learning_rate": 5e-05,
      "loss": 0.3534,
      "step": 16088
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6077621579170227,
      "learning_rate": 5e-05,
      "loss": 0.3274,
      "step": 16096
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5370884537696838,
      "learning_rate": 5e-05,
      "loss": 0.3285,
      "step": 16104
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.580828845500946,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 16112
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6142880916595459,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 16120
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5884726643562317,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 16128
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.74069744348526,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 16136
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6540603041648865,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 16144
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6286123394966125,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 16152
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6928887367248535,
      "learning_rate": 5e-05,
      "loss": 0.3492,
      "step": 16160
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6098465323448181,
      "learning_rate": 5e-05,
      "loss": 0.3124,
      "step": 16168
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6110295653343201,
      "learning_rate": 5e-05,
      "loss": 0.3233,
      "step": 16176
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.7306426763534546,
      "learning_rate": 5e-05,
      "loss": 0.34,
      "step": 16184
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5415321588516235,
      "learning_rate": 5e-05,
      "loss": 0.3436,
      "step": 16192
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.7033743262290955,
      "learning_rate": 5e-05,
      "loss": 0.3157,
      "step": 16200
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.7959443926811218,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 16208
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6711810231208801,
      "learning_rate": 5e-05,
      "loss": 0.3421,
      "step": 16216
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.8242077231407166,
      "learning_rate": 5e-05,
      "loss": 0.338,
      "step": 16224
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6351152658462524,
      "learning_rate": 5e-05,
      "loss": 0.3328,
      "step": 16232
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5565599799156189,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 16240
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6621323823928833,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 16248
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6007250547409058,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 16256
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5802110433578491,
      "learning_rate": 5e-05,
      "loss": 0.3314,
      "step": 16264
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6424407362937927,
      "learning_rate": 5e-05,
      "loss": 0.3301,
      "step": 16272
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.580826461315155,
      "learning_rate": 5e-05,
      "loss": 0.3256,
      "step": 16280
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6664479374885559,
      "learning_rate": 5e-05,
      "loss": 0.3301,
      "step": 16288
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5391914248466492,
      "learning_rate": 5e-05,
      "loss": 0.3421,
      "step": 16296
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.7472983002662659,
      "learning_rate": 5e-05,
      "loss": 0.3511,
      "step": 16304
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6523351669311523,
      "learning_rate": 5e-05,
      "loss": 0.3462,
      "step": 16312
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6101481318473816,
      "learning_rate": 5e-05,
      "loss": 0.3515,
      "step": 16320
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5908889174461365,
      "learning_rate": 5e-05,
      "loss": 0.3035,
      "step": 16328
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6900827288627625,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 16336
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.622748613357544,
      "learning_rate": 5e-05,
      "loss": 0.3341,
      "step": 16344
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5763521194458008,
      "learning_rate": 5e-05,
      "loss": 0.3365,
      "step": 16352
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6611760854721069,
      "learning_rate": 5e-05,
      "loss": 0.3218,
      "step": 16360
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6006096601486206,
      "learning_rate": 5e-05,
      "loss": 0.3409,
      "step": 16368
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5809949040412903,
      "learning_rate": 5e-05,
      "loss": 0.3197,
      "step": 16376
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6072642207145691,
      "learning_rate": 5e-05,
      "loss": 0.3726,
      "step": 16384
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5659738779067993,
      "learning_rate": 5e-05,
      "loss": 0.3336,
      "step": 16392
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6066617369651794,
      "learning_rate": 5e-05,
      "loss": 0.3421,
      "step": 16400
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6170592308044434,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 16408
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6268186569213867,
      "learning_rate": 5e-05,
      "loss": 0.3036,
      "step": 16416
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5766618251800537,
      "learning_rate": 5e-05,
      "loss": 0.3469,
      "step": 16424
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5622395277023315,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 16432
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6166883707046509,
      "learning_rate": 5e-05,
      "loss": 0.3316,
      "step": 16440
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.7297508120536804,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 16448
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6103295683860779,
      "learning_rate": 5e-05,
      "loss": 0.3221,
      "step": 16456
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5317435264587402,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 16464
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6733061671257019,
      "learning_rate": 5e-05,
      "loss": 0.2911,
      "step": 16472
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6558738946914673,
      "learning_rate": 5e-05,
      "loss": 0.3728,
      "step": 16480
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6327794194221497,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 16488
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.7127636075019836,
      "learning_rate": 5e-05,
      "loss": 0.308,
      "step": 16496
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6946650743484497,
      "learning_rate": 5e-05,
      "loss": 0.3082,
      "step": 16504
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.7256680130958557,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 16512
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5673621296882629,
      "learning_rate": 5e-05,
      "loss": 0.3346,
      "step": 16520
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6315187215805054,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 16528
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6296806931495667,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 16536
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6235780715942383,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 16544
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6864469647407532,
      "learning_rate": 5e-05,
      "loss": 0.3105,
      "step": 16552
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5427226424217224,
      "learning_rate": 5e-05,
      "loss": 0.3074,
      "step": 16560
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5800008773803711,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 16568
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6618474125862122,
      "learning_rate": 5e-05,
      "loss": 0.3407,
      "step": 16576
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.600000262260437,
      "learning_rate": 5e-05,
      "loss": 0.3092,
      "step": 16584
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6200081706047058,
      "learning_rate": 5e-05,
      "loss": 0.3464,
      "step": 16592
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6025885939598083,
      "learning_rate": 5e-05,
      "loss": 0.3359,
      "step": 16600
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6289321780204773,
      "learning_rate": 5e-05,
      "loss": 0.3217,
      "step": 16608
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6955418586730957,
      "learning_rate": 5e-05,
      "loss": 0.313,
      "step": 16616
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.660361647605896,
      "learning_rate": 5e-05,
      "loss": 0.3271,
      "step": 16624
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6659096479415894,
      "learning_rate": 5e-05,
      "loss": 0.3142,
      "step": 16632
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5804049372673035,
      "learning_rate": 5e-05,
      "loss": 0.3245,
      "step": 16640
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6886946558952332,
      "learning_rate": 5e-05,
      "loss": 0.3281,
      "step": 16648
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6338164806365967,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 16656
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.617459774017334,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 16664
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5812491774559021,
      "learning_rate": 5e-05,
      "loss": 0.326,
      "step": 16672
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6434192657470703,
      "learning_rate": 5e-05,
      "loss": 0.335,
      "step": 16680
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5832358598709106,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 16688
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.741366446018219,
      "learning_rate": 5e-05,
      "loss": 0.3208,
      "step": 16696
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6759196519851685,
      "learning_rate": 5e-05,
      "loss": 0.3057,
      "step": 16704
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5904285311698914,
      "learning_rate": 5e-05,
      "loss": 0.3093,
      "step": 16712
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.682372510433197,
      "learning_rate": 5e-05,
      "loss": 0.3207,
      "step": 16720
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6100666522979736,
      "learning_rate": 5e-05,
      "loss": 0.323,
      "step": 16728
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6674410700798035,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 16736
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.7336931228637695,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 16744
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.7551948428153992,
      "learning_rate": 5e-05,
      "loss": 0.3339,
      "step": 16752
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.5942842364311218,
      "learning_rate": 5e-05,
      "loss": 0.3204,
      "step": 16760
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6502546072006226,
      "learning_rate": 5e-05,
      "loss": 0.2984,
      "step": 16768
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6678964495658875,
      "learning_rate": 5e-05,
      "loss": 0.3348,
      "step": 16776
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6025316715240479,
      "learning_rate": 5e-05,
      "loss": 0.3627,
      "step": 16784
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6472833752632141,
      "learning_rate": 5e-05,
      "loss": 0.3475,
      "step": 16792
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6278625726699829,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 16800
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6255613565444946,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 16808
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6054935455322266,
      "learning_rate": 5e-05,
      "loss": 0.3219,
      "step": 16816
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6662144064903259,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 16824
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.5683346390724182,
      "learning_rate": 5e-05,
      "loss": 0.3087,
      "step": 16832
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6321384906768799,
      "learning_rate": 5e-05,
      "loss": 0.306,
      "step": 16840
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6731147170066833,
      "learning_rate": 5e-05,
      "loss": 0.3106,
      "step": 16848
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.632621705532074,
      "learning_rate": 5e-05,
      "loss": 0.29,
      "step": 16856
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.7009031772613525,
      "learning_rate": 5e-05,
      "loss": 0.3184,
      "step": 16864
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6871728301048279,
      "learning_rate": 5e-05,
      "loss": 0.3352,
      "step": 16872
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.7160071730613708,
      "learning_rate": 5e-05,
      "loss": 0.3057,
      "step": 16880
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.5988547801971436,
      "learning_rate": 5e-05,
      "loss": 0.3166,
      "step": 16888
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.7102080583572388,
      "learning_rate": 5e-05,
      "loss": 0.3516,
      "step": 16896
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.7251983880996704,
      "learning_rate": 5e-05,
      "loss": 0.3129,
      "step": 16904
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.5652413368225098,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 16912
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.6960147023200989,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 16920
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6912209391593933,
      "learning_rate": 5e-05,
      "loss": 0.2857,
      "step": 16928
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6324154138565063,
      "learning_rate": 5e-05,
      "loss": 0.3197,
      "step": 16936
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6774418354034424,
      "learning_rate": 5e-05,
      "loss": 0.3254,
      "step": 16944
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.5715067386627197,
      "learning_rate": 5e-05,
      "loss": 0.3199,
      "step": 16952
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6734525561332703,
      "learning_rate": 5e-05,
      "loss": 0.3379,
      "step": 16960
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6581531763076782,
      "learning_rate": 5e-05,
      "loss": 0.3449,
      "step": 16968
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6947819590568542,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 16976
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.5777537822723389,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 16984
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.5787062048912048,
      "learning_rate": 5e-05,
      "loss": 0.3314,
      "step": 16992
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6437180638313293,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 17000
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.7003586888313293,
      "learning_rate": 5e-05,
      "loss": 0.3511,
      "step": 17008
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6186777949333191,
      "learning_rate": 5e-05,
      "loss": 0.3258,
      "step": 17016
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6450905203819275,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 17024
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6264671087265015,
      "learning_rate": 5e-05,
      "loss": 0.3014,
      "step": 17032
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6787596940994263,
      "learning_rate": 5e-05,
      "loss": 0.3128,
      "step": 17040
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.721526026725769,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 17048
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6015812158584595,
      "learning_rate": 5e-05,
      "loss": 0.3051,
      "step": 17056
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6125629544258118,
      "learning_rate": 5e-05,
      "loss": 0.3081,
      "step": 17064
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.6071047782897949,
      "learning_rate": 5e-05,
      "loss": 0.3384,
      "step": 17072
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.711497962474823,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 17080
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.6695302724838257,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 17088
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.7047427296638489,
      "learning_rate": 5e-05,
      "loss": 0.3324,
      "step": 17096
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.645087480545044,
      "learning_rate": 5e-05,
      "loss": 0.2977,
      "step": 17104
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.812227725982666,
      "learning_rate": 5e-05,
      "loss": 0.2926,
      "step": 17112
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.6892651915550232,
      "learning_rate": 5e-05,
      "loss": 0.3174,
      "step": 17120
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.628175675868988,
      "learning_rate": 5e-05,
      "loss": 0.3211,
      "step": 17128
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.6370580792427063,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 17136
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.6168696880340576,
      "learning_rate": 5e-05,
      "loss": 0.3344,
      "step": 17144
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.6543976664543152,
      "learning_rate": 5e-05,
      "loss": 0.3039,
      "step": 17152
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.5283177495002747,
      "learning_rate": 5e-05,
      "loss": 0.3252,
      "step": 17160
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.5881722569465637,
      "learning_rate": 5e-05,
      "loss": 0.3162,
      "step": 17168
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.7164663076400757,
      "learning_rate": 5e-05,
      "loss": 0.3267,
      "step": 17176
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.6386324167251587,
      "learning_rate": 5e-05,
      "loss": 0.3617,
      "step": 17184
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.670227587223053,
      "learning_rate": 5e-05,
      "loss": 0.3172,
      "step": 17192
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.5919698476791382,
      "learning_rate": 5e-05,
      "loss": 0.3179,
      "step": 17200
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.6137049794197083,
      "learning_rate": 5e-05,
      "loss": 0.3406,
      "step": 17208
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.6845241189002991,
      "learning_rate": 5e-05,
      "loss": 0.3292,
      "step": 17216
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.5896797776222229,
      "learning_rate": 5e-05,
      "loss": 0.3025,
      "step": 17224
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.6290634870529175,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 17232
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.6865530014038086,
      "learning_rate": 5e-05,
      "loss": 0.3318,
      "step": 17240
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.9367505311965942,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 17248
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.7449735999107361,
      "learning_rate": 5e-05,
      "loss": 0.3724,
      "step": 17256
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6857937574386597,
      "learning_rate": 5e-05,
      "loss": 0.3038,
      "step": 17264
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.5147548913955688,
      "learning_rate": 5e-05,
      "loss": 0.3406,
      "step": 17272
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.5676571726799011,
      "learning_rate": 5e-05,
      "loss": 0.3175,
      "step": 17280
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.5844228267669678,
      "learning_rate": 5e-05,
      "loss": 0.3226,
      "step": 17288
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6846295595169067,
      "learning_rate": 5e-05,
      "loss": 0.3134,
      "step": 17296
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.8093253374099731,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 17304
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6790793538093567,
      "learning_rate": 5e-05,
      "loss": 0.3317,
      "step": 17312
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.5805822014808655,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 17320
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.5662829875946045,
      "learning_rate": 5e-05,
      "loss": 0.3354,
      "step": 17328
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6005339026451111,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 17336
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9549669623374939,
      "learning_rate": 5e-05,
      "loss": 0.3405,
      "step": 17344
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.5750489830970764,
      "learning_rate": 5e-05,
      "loss": 0.2998,
      "step": 17352
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6604993343353271,
      "learning_rate": 5e-05,
      "loss": 0.3213,
      "step": 17360
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6073626279830933,
      "learning_rate": 5e-05,
      "loss": 0.3389,
      "step": 17368
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6278572082519531,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 17376
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6456115245819092,
      "learning_rate": 5e-05,
      "loss": 0.3417,
      "step": 17384
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6522843837738037,
      "learning_rate": 5e-05,
      "loss": 0.341,
      "step": 17392
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6588748097419739,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 17400
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6194792985916138,
      "learning_rate": 5e-05,
      "loss": 0.3083,
      "step": 17408
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6137706637382507,
      "learning_rate": 5e-05,
      "loss": 0.2987,
      "step": 17416
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6376232504844666,
      "learning_rate": 5e-05,
      "loss": 0.3162,
      "step": 17424
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6246173977851868,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 17432
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6154651045799255,
      "learning_rate": 5e-05,
      "loss": 0.3248,
      "step": 17440
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6438049674034119,
      "learning_rate": 5e-05,
      "loss": 0.3143,
      "step": 17448
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.7390748262405396,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 17456
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.7564646601676941,
      "learning_rate": 5e-05,
      "loss": 0.3451,
      "step": 17464
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6684314012527466,
      "learning_rate": 5e-05,
      "loss": 0.3236,
      "step": 17472
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.661990761756897,
      "learning_rate": 5e-05,
      "loss": 0.3543,
      "step": 17480
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.057573914527893,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 17488
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6452435851097107,
      "learning_rate": 5e-05,
      "loss": 0.3532,
      "step": 17496
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6005071401596069,
      "learning_rate": 5e-05,
      "loss": 0.3494,
      "step": 17504
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6301597356796265,
      "learning_rate": 5e-05,
      "loss": 0.3113,
      "step": 17512
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.5834594964981079,
      "learning_rate": 5e-05,
      "loss": 0.3265,
      "step": 17520
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6948506236076355,
      "learning_rate": 5e-05,
      "loss": 0.3044,
      "step": 17528
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6585435271263123,
      "learning_rate": 5e-05,
      "loss": 0.3317,
      "step": 17536
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6700494289398193,
      "learning_rate": 5e-05,
      "loss": 0.343,
      "step": 17544
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.7176799178123474,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 17552
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6695349812507629,
      "learning_rate": 5e-05,
      "loss": 0.3236,
      "step": 17560
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6968791484832764,
      "learning_rate": 5e-05,
      "loss": 0.3461,
      "step": 17568
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.5837323069572449,
      "learning_rate": 5e-05,
      "loss": 0.3536,
      "step": 17576
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.8080570101737976,
      "learning_rate": 5e-05,
      "loss": 0.3248,
      "step": 17584
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.5905181169509888,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 17592
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6111842393875122,
      "learning_rate": 5e-05,
      "loss": 0.3319,
      "step": 17600
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6023072600364685,
      "learning_rate": 5e-05,
      "loss": 0.3104,
      "step": 17608
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.628940224647522,
      "learning_rate": 5e-05,
      "loss": 0.3572,
      "step": 17616
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6610680222511292,
      "learning_rate": 5e-05,
      "loss": 0.3237,
      "step": 17624
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.5747556090354919,
      "learning_rate": 5e-05,
      "loss": 0.3205,
      "step": 17632
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6346019506454468,
      "learning_rate": 5e-05,
      "loss": 0.3367,
      "step": 17640
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6335158348083496,
      "learning_rate": 5e-05,
      "loss": 0.3092,
      "step": 17648
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6168233752250671,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 17656
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6358153223991394,
      "learning_rate": 5e-05,
      "loss": 0.3118,
      "step": 17664
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.5634334087371826,
      "learning_rate": 5e-05,
      "loss": 0.3219,
      "step": 17672
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.5836608409881592,
      "learning_rate": 5e-05,
      "loss": 0.3534,
      "step": 17680
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.5978214740753174,
      "learning_rate": 5e-05,
      "loss": 0.3356,
      "step": 17688
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.7580210566520691,
      "learning_rate": 5e-05,
      "loss": 0.309,
      "step": 17696
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.5885365009307861,
      "learning_rate": 5e-05,
      "loss": 0.3243,
      "step": 17704
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.7943918704986572,
      "learning_rate": 5e-05,
      "loss": 0.3196,
      "step": 17712
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6228454113006592,
      "learning_rate": 5e-05,
      "loss": 0.3333,
      "step": 17720
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.594898521900177,
      "learning_rate": 5e-05,
      "loss": 0.3224,
      "step": 17728
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6621488928794861,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 17736
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6252700686454773,
      "learning_rate": 5e-05,
      "loss": 0.2999,
      "step": 17744
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.6023451685905457,
      "learning_rate": 5e-05,
      "loss": 0.3207,
      "step": 17752
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.7578237652778625,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 17760
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.7209388017654419,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 17768
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6192544102668762,
      "learning_rate": 5e-05,
      "loss": 0.3348,
      "step": 17776
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6441853642463684,
      "learning_rate": 5e-05,
      "loss": 0.3303,
      "step": 17784
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6660060286521912,
      "learning_rate": 5e-05,
      "loss": 0.3351,
      "step": 17792
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.655727207660675,
      "learning_rate": 5e-05,
      "loss": 0.3488,
      "step": 17800
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.7118022441864014,
      "learning_rate": 5e-05,
      "loss": 0.3342,
      "step": 17808
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6724857687950134,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 17816
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.7232511639595032,
      "learning_rate": 5e-05,
      "loss": 0.3475,
      "step": 17824
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.7024463415145874,
      "learning_rate": 5e-05,
      "loss": 0.3149,
      "step": 17832
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6093372702598572,
      "learning_rate": 5e-05,
      "loss": 0.3169,
      "step": 17840
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.838505208492279,
      "learning_rate": 5e-05,
      "loss": 0.3482,
      "step": 17848
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.705528199672699,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 17856
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6780813336372375,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 17864
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6290048956871033,
      "learning_rate": 5e-05,
      "loss": 0.3169,
      "step": 17872
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6502906680107117,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 17880
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6182945370674133,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 17888
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6078565716743469,
      "learning_rate": 5e-05,
      "loss": 0.3002,
      "step": 17896
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6207869648933411,
      "learning_rate": 5e-05,
      "loss": 0.3222,
      "step": 17904
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.6611830592155457,
      "learning_rate": 5e-05,
      "loss": 0.3278,
      "step": 17912
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.7829094529151917,
      "learning_rate": 5e-05,
      "loss": 0.3616,
      "step": 17920
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.6284112334251404,
      "learning_rate": 5e-05,
      "loss": 0.3334,
      "step": 17928
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.6066940426826477,
      "learning_rate": 5e-05,
      "loss": 0.2914,
      "step": 17936
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.6677744388580322,
      "learning_rate": 5e-05,
      "loss": 0.3156,
      "step": 17944
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.5061570405960083,
      "learning_rate": 5e-05,
      "loss": 0.3363,
      "step": 17952
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.5920805931091309,
      "learning_rate": 5e-05,
      "loss": 0.3265,
      "step": 17960
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.6623560190200806,
      "learning_rate": 5e-05,
      "loss": 0.3336,
      "step": 17968
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.578999400138855,
      "learning_rate": 5e-05,
      "loss": 0.3044,
      "step": 17976
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.6058419942855835,
      "learning_rate": 5e-05,
      "loss": 0.2908,
      "step": 17984
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.5228121876716614,
      "learning_rate": 5e-05,
      "loss": 0.3573,
      "step": 17992
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.6056978106498718,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 18000
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.5579979419708252,
      "learning_rate": 5e-05,
      "loss": 0.337,
      "step": 18008
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.6310890913009644,
      "learning_rate": 5e-05,
      "loss": 0.3329,
      "step": 18016
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.6965747475624084,
      "learning_rate": 5e-05,
      "loss": 0.3149,
      "step": 18024
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.5327432155609131,
      "learning_rate": 5e-05,
      "loss": 0.2985,
      "step": 18032
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.8509942293167114,
      "learning_rate": 5e-05,
      "loss": 0.3232,
      "step": 18040
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.8433411121368408,
      "learning_rate": 5e-05,
      "loss": 0.3377,
      "step": 18048
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.56602543592453,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 18056
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.6479880809783936,
      "learning_rate": 5e-05,
      "loss": 0.3438,
      "step": 18064
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.5847020149230957,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 18072
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.769473671913147,
      "learning_rate": 5e-05,
      "loss": 0.3128,
      "step": 18080
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.6377515196800232,
      "learning_rate": 5e-05,
      "loss": 0.3063,
      "step": 18088
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.6480750441551208,
      "learning_rate": 5e-05,
      "loss": 0.3189,
      "step": 18096
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.5996252298355103,
      "learning_rate": 5e-05,
      "loss": 0.3231,
      "step": 18104
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.6884152889251709,
      "learning_rate": 5e-05,
      "loss": 0.3334,
      "step": 18112
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.7761998176574707,
      "learning_rate": 5e-05,
      "loss": 0.2985,
      "step": 18120
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.6409829258918762,
      "learning_rate": 5e-05,
      "loss": 0.3448,
      "step": 18128
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.5711342692375183,
      "learning_rate": 5e-05,
      "loss": 0.3409,
      "step": 18136
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.8054192662239075,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 18144
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.1214933395385742,
      "learning_rate": 5e-05,
      "loss": 0.3325,
      "step": 18152
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.624390184879303,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 18160
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.7014834880828857,
      "learning_rate": 5e-05,
      "loss": 0.306,
      "step": 18168
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.6365428566932678,
      "learning_rate": 5e-05,
      "loss": 0.3155,
      "step": 18176
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.6909453868865967,
      "learning_rate": 5e-05,
      "loss": 0.3548,
      "step": 18184
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.6581675410270691,
      "learning_rate": 5e-05,
      "loss": 0.3057,
      "step": 18192
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.5831125974655151,
      "learning_rate": 5e-05,
      "loss": 0.3075,
      "step": 18200
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.6385751366615295,
      "learning_rate": 5e-05,
      "loss": 0.3154,
      "step": 18208
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.6446970105171204,
      "learning_rate": 5e-05,
      "loss": 0.3357,
      "step": 18216
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.5893781185150146,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 18224
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.7454125285148621,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 18232
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.5973284244537354,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 18240
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.664118766784668,
      "learning_rate": 5e-05,
      "loss": 0.3571,
      "step": 18248
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.5888624787330627,
      "learning_rate": 5e-05,
      "loss": 0.3201,
      "step": 18256
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.6922762393951416,
      "learning_rate": 5e-05,
      "loss": 0.3582,
      "step": 18264
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.592682957649231,
      "learning_rate": 5e-05,
      "loss": 0.3083,
      "step": 18272
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.6055507659912109,
      "learning_rate": 5e-05,
      "loss": 0.3417,
      "step": 18280
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.6392123103141785,
      "learning_rate": 5e-05,
      "loss": 0.3007,
      "step": 18288
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.8317372798919678,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 18296
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.6993453502655029,
      "learning_rate": 5e-05,
      "loss": 0.3281,
      "step": 18304
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.6569904685020447,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 18312
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.6405863761901855,
      "learning_rate": 5e-05,
      "loss": 0.3083,
      "step": 18320
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.6116651892662048,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 18328
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.7078345417976379,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 18336
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.6994869709014893,
      "learning_rate": 5e-05,
      "loss": 0.3154,
      "step": 18344
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.7693856358528137,
      "learning_rate": 5e-05,
      "loss": 0.3538,
      "step": 18352
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.5798633098602295,
      "learning_rate": 5e-05,
      "loss": 0.3229,
      "step": 18360
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.6600204706192017,
      "learning_rate": 5e-05,
      "loss": 0.3076,
      "step": 18368
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.7896513342857361,
      "learning_rate": 5e-05,
      "loss": 0.3339,
      "step": 18376
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.5994613170623779,
      "learning_rate": 5e-05,
      "loss": 0.332,
      "step": 18384
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.5579221248626709,
      "learning_rate": 5e-05,
      "loss": 0.3268,
      "step": 18392
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.641281008720398,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 18400
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.5669394135475159,
      "learning_rate": 5e-05,
      "loss": 0.3376,
      "step": 18408
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.6501767039299011,
      "learning_rate": 5e-05,
      "loss": 0.3371,
      "step": 18416
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.6009318828582764,
      "learning_rate": 5e-05,
      "loss": 0.2918,
      "step": 18424
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.6769700646400452,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 18432
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.6189904808998108,
      "learning_rate": 5e-05,
      "loss": 0.3076,
      "step": 18440
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.6483717560768127,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 18448
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.6301385164260864,
      "learning_rate": 5e-05,
      "loss": 0.3396,
      "step": 18456
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.6084150671958923,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 18464
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.6215208768844604,
      "learning_rate": 5e-05,
      "loss": 0.3323,
      "step": 18472
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.6363072395324707,
      "learning_rate": 5e-05,
      "loss": 0.3379,
      "step": 18480
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.5992254614830017,
      "learning_rate": 5e-05,
      "loss": 0.3166,
      "step": 18488
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.6148710250854492,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 18496
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.6628890037536621,
      "learning_rate": 5e-05,
      "loss": 0.3085,
      "step": 18504
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.6379680633544922,
      "learning_rate": 5e-05,
      "loss": 0.3269,
      "step": 18512
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.6838274002075195,
      "learning_rate": 5e-05,
      "loss": 0.3272,
      "step": 18520
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.577057421207428,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 18528
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.7367382645606995,
      "learning_rate": 5e-05,
      "loss": 0.35,
      "step": 18536
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.5998861193656921,
      "learning_rate": 5e-05,
      "loss": 0.3419,
      "step": 18544
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.6751777529716492,
      "learning_rate": 5e-05,
      "loss": 0.3255,
      "step": 18552
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.5997816920280457,
      "learning_rate": 5e-05,
      "loss": 0.3478,
      "step": 18560
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.5903588533401489,
      "learning_rate": 5e-05,
      "loss": 0.3135,
      "step": 18568
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.5957323312759399,
      "learning_rate": 5e-05,
      "loss": 0.3528,
      "step": 18576
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.8244417309761047,
      "learning_rate": 5e-05,
      "loss": 0.3483,
      "step": 18584
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.5597655773162842,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 18592
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6572850942611694,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 18600
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.5776737928390503,
      "learning_rate": 5e-05,
      "loss": 0.3238,
      "step": 18608
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6380036473274231,
      "learning_rate": 5e-05,
      "loss": 0.3067,
      "step": 18616
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6480028629302979,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 18624
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.7225776314735413,
      "learning_rate": 5e-05,
      "loss": 0.3021,
      "step": 18632
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.7237406969070435,
      "learning_rate": 5e-05,
      "loss": 0.2925,
      "step": 18640
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6479849815368652,
      "learning_rate": 5e-05,
      "loss": 0.3547,
      "step": 18648
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.5793737173080444,
      "learning_rate": 5e-05,
      "loss": 0.3303,
      "step": 18656
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6025956273078918,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 18664
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.64826500415802,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 18672
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6152965426445007,
      "learning_rate": 5e-05,
      "loss": 0.2869,
      "step": 18680
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.5138940811157227,
      "learning_rate": 5e-05,
      "loss": 0.3439,
      "step": 18688
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6821191310882568,
      "learning_rate": 5e-05,
      "loss": 0.3259,
      "step": 18696
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.5783787369728088,
      "learning_rate": 5e-05,
      "loss": 0.3151,
      "step": 18704
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.8437492847442627,
      "learning_rate": 5e-05,
      "loss": 0.3298,
      "step": 18712
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.652947187423706,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 18720
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6292724609375,
      "learning_rate": 5e-05,
      "loss": 0.3342,
      "step": 18728
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6409178376197815,
      "learning_rate": 5e-05,
      "loss": 0.3173,
      "step": 18736
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.7716955542564392,
      "learning_rate": 5e-05,
      "loss": 0.3392,
      "step": 18744
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6192415952682495,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 18752
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.7029469609260559,
      "learning_rate": 5e-05,
      "loss": 0.3131,
      "step": 18760
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.5805675387382507,
      "learning_rate": 5e-05,
      "loss": 0.2967,
      "step": 18768
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6669626235961914,
      "learning_rate": 5e-05,
      "loss": 0.2974,
      "step": 18776
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.733891487121582,
      "learning_rate": 5e-05,
      "loss": 0.3221,
      "step": 18784
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.5534261465072632,
      "learning_rate": 5e-05,
      "loss": 0.3083,
      "step": 18792
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6717949509620667,
      "learning_rate": 5e-05,
      "loss": 0.3336,
      "step": 18800
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.7016657590866089,
      "learning_rate": 5e-05,
      "loss": 0.312,
      "step": 18808
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.5869370102882385,
      "learning_rate": 5e-05,
      "loss": 0.3042,
      "step": 18816
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6497921943664551,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 18824
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6311763525009155,
      "learning_rate": 5e-05,
      "loss": 0.3313,
      "step": 18832
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.5551226139068604,
      "learning_rate": 5e-05,
      "loss": 0.2993,
      "step": 18840
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6137183308601379,
      "learning_rate": 5e-05,
      "loss": 0.2999,
      "step": 18848
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.596357524394989,
      "learning_rate": 5e-05,
      "loss": 0.308,
      "step": 18856
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6210758686065674,
      "learning_rate": 5e-05,
      "loss": 0.3447,
      "step": 18864
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6976611018180847,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 18872
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6395129561424255,
      "learning_rate": 5e-05,
      "loss": 0.3792,
      "step": 18880
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6160147190093994,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 18888
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6857005953788757,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 18896
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.7007101774215698,
      "learning_rate": 5e-05,
      "loss": 0.3385,
      "step": 18904
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6449747681617737,
      "learning_rate": 5e-05,
      "loss": 0.3118,
      "step": 18912
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.6954951882362366,
      "learning_rate": 5e-05,
      "loss": 0.3276,
      "step": 18920
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.5333437323570251,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 18928
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.5535070300102234,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 18936
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.62362140417099,
      "learning_rate": 5e-05,
      "loss": 0.3318,
      "step": 18944
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.5656222701072693,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 18952
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.5879577398300171,
      "learning_rate": 5e-05,
      "loss": 0.3209,
      "step": 18960
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.6829301118850708,
      "learning_rate": 5e-05,
      "loss": 0.3358,
      "step": 18968
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.5363377332687378,
      "learning_rate": 5e-05,
      "loss": 0.3266,
      "step": 18976
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.6875190734863281,
      "learning_rate": 5e-05,
      "loss": 0.3522,
      "step": 18984
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.6180542707443237,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 18992
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.6175383925437927,
      "learning_rate": 5e-05,
      "loss": 0.3242,
      "step": 19000
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.6838096380233765,
      "learning_rate": 5e-05,
      "loss": 0.3107,
      "step": 19008
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.5988670587539673,
      "learning_rate": 5e-05,
      "loss": 0.3145,
      "step": 19016
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.7822144627571106,
      "learning_rate": 5e-05,
      "loss": 0.3181,
      "step": 19024
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.6390240788459778,
      "learning_rate": 5e-05,
      "loss": 0.3238,
      "step": 19032
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.6444752812385559,
      "learning_rate": 5e-05,
      "loss": 0.3083,
      "step": 19040
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.6014338731765747,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 19048
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.6022194027900696,
      "learning_rate": 5e-05,
      "loss": 0.2967,
      "step": 19056
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.5298599004745483,
      "learning_rate": 5e-05,
      "loss": 0.2989,
      "step": 19064
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.5969235897064209,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 19072
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.6384689211845398,
      "learning_rate": 5e-05,
      "loss": 0.3145,
      "step": 19080
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.5960732698440552,
      "learning_rate": 5e-05,
      "loss": 0.3212,
      "step": 19088
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.6408403515815735,
      "learning_rate": 5e-05,
      "loss": 0.3122,
      "step": 19096
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.6499545574188232,
      "learning_rate": 5e-05,
      "loss": 0.3291,
      "step": 19104
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.7199046611785889,
      "learning_rate": 5e-05,
      "loss": 0.3184,
      "step": 19112
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.7789640426635742,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 19120
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.6229458451271057,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 19128
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.8148741722106934,
      "learning_rate": 5e-05,
      "loss": 0.336,
      "step": 19136
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.672655463218689,
      "learning_rate": 5e-05,
      "loss": 0.3452,
      "step": 19144
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.5896703004837036,
      "learning_rate": 5e-05,
      "loss": 0.3284,
      "step": 19152
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.6947267055511475,
      "learning_rate": 5e-05,
      "loss": 0.3315,
      "step": 19160
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.6255408525466919,
      "learning_rate": 5e-05,
      "loss": 0.3339,
      "step": 19168
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.0261306762695312,
      "learning_rate": 5e-05,
      "loss": 0.3109,
      "step": 19176
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.7027266621589661,
      "learning_rate": 5e-05,
      "loss": 0.358,
      "step": 19184
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.6950393319129944,
      "learning_rate": 5e-05,
      "loss": 0.33,
      "step": 19192
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.676776111125946,
      "learning_rate": 5e-05,
      "loss": 0.3331,
      "step": 19200
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.6054086685180664,
      "learning_rate": 5e-05,
      "loss": 0.3249,
      "step": 19208
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.6562652587890625,
      "learning_rate": 5e-05,
      "loss": 0.3272,
      "step": 19216
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.7159541249275208,
      "learning_rate": 5e-05,
      "loss": 0.3545,
      "step": 19224
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.5604687929153442,
      "learning_rate": 5e-05,
      "loss": 0.3196,
      "step": 19232
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.6840490102767944,
      "learning_rate": 5e-05,
      "loss": 0.344,
      "step": 19240
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.625257134437561,
      "learning_rate": 5e-05,
      "loss": 0.3258,
      "step": 19248
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.645643413066864,
      "learning_rate": 5e-05,
      "loss": 0.3464,
      "step": 19256
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6946651935577393,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 19264
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6224473118782043,
      "learning_rate": 5e-05,
      "loss": 0.3032,
      "step": 19272
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6556541323661804,
      "learning_rate": 5e-05,
      "loss": 0.3316,
      "step": 19280
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.7015888094902039,
      "learning_rate": 5e-05,
      "loss": 0.3255,
      "step": 19288
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.5675883889198303,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 19296
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6490245461463928,
      "learning_rate": 5e-05,
      "loss": 0.2888,
      "step": 19304
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6397685408592224,
      "learning_rate": 5e-05,
      "loss": 0.2957,
      "step": 19312
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.5487937927246094,
      "learning_rate": 5e-05,
      "loss": 0.3358,
      "step": 19320
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6508837342262268,
      "learning_rate": 5e-05,
      "loss": 0.3125,
      "step": 19328
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6582667827606201,
      "learning_rate": 5e-05,
      "loss": 0.3174,
      "step": 19336
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6780726313591003,
      "learning_rate": 5e-05,
      "loss": 0.3172,
      "step": 19344
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6941160559654236,
      "learning_rate": 5e-05,
      "loss": 0.3262,
      "step": 19352
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6186566352844238,
      "learning_rate": 5e-05,
      "loss": 0.326,
      "step": 19360
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.7048497200012207,
      "learning_rate": 5e-05,
      "loss": 0.3149,
      "step": 19368
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6432734131813049,
      "learning_rate": 5e-05,
      "loss": 0.2896,
      "step": 19376
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.591423749923706,
      "learning_rate": 5e-05,
      "loss": 0.3246,
      "step": 19384
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.619489848613739,
      "learning_rate": 5e-05,
      "loss": 0.3125,
      "step": 19392
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6156842112541199,
      "learning_rate": 5e-05,
      "loss": 0.3107,
      "step": 19400
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.6160992980003357,
      "learning_rate": 5e-05,
      "loss": 0.3185,
      "step": 19408
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.5836490392684937,
      "learning_rate": 5e-05,
      "loss": 0.3559,
      "step": 19416
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.7969360947608948,
      "learning_rate": 5e-05,
      "loss": 0.3338,
      "step": 19424
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.6564459204673767,
      "learning_rate": 5e-05,
      "loss": 0.3073,
      "step": 19432
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.6591370105743408,
      "learning_rate": 5e-05,
      "loss": 0.3452,
      "step": 19440
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.6833661794662476,
      "learning_rate": 5e-05,
      "loss": 0.3176,
      "step": 19448
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.6606376767158508,
      "learning_rate": 5e-05,
      "loss": 0.3312,
      "step": 19456
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.5976373553276062,
      "learning_rate": 5e-05,
      "loss": 0.3457,
      "step": 19464
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.5834023356437683,
      "learning_rate": 5e-05,
      "loss": 0.3522,
      "step": 19472
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.6223764419555664,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 19480
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.566624104976654,
      "learning_rate": 5e-05,
      "loss": 0.3139,
      "step": 19488
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.6634210348129272,
      "learning_rate": 5e-05,
      "loss": 0.3137,
      "step": 19496
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.5922824740409851,
      "learning_rate": 5e-05,
      "loss": 0.2926,
      "step": 19504
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.0521494150161743,
      "learning_rate": 5e-05,
      "loss": 0.3169,
      "step": 19512
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.5891907811164856,
      "learning_rate": 5e-05,
      "loss": 0.3344,
      "step": 19520
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.694024384021759,
      "learning_rate": 5e-05,
      "loss": 0.3502,
      "step": 19528
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.6808968782424927,
      "learning_rate": 5e-05,
      "loss": 0.3091,
      "step": 19536
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.662672221660614,
      "learning_rate": 5e-05,
      "loss": 0.3247,
      "step": 19544
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.5817023515701294,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 19552
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.5746589303016663,
      "learning_rate": 5e-05,
      "loss": 0.3225,
      "step": 19560
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.6382030248641968,
      "learning_rate": 5e-05,
      "loss": 0.2978,
      "step": 19568
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.5973815321922302,
      "learning_rate": 5e-05,
      "loss": 0.3465,
      "step": 19576
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.7132843732833862,
      "learning_rate": 5e-05,
      "loss": 0.332,
      "step": 19584
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6555370688438416,
      "learning_rate": 5e-05,
      "loss": 0.3452,
      "step": 19592
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.676166296005249,
      "learning_rate": 5e-05,
      "loss": 0.3233,
      "step": 19600
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6717249155044556,
      "learning_rate": 5e-05,
      "loss": 0.3125,
      "step": 19608
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.625832200050354,
      "learning_rate": 5e-05,
      "loss": 0.3238,
      "step": 19616
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6811389327049255,
      "learning_rate": 5e-05,
      "loss": 0.3058,
      "step": 19624
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6814476251602173,
      "learning_rate": 5e-05,
      "loss": 0.3287,
      "step": 19632
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.5918666124343872,
      "learning_rate": 5e-05,
      "loss": 0.3355,
      "step": 19640
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.5987848043441772,
      "learning_rate": 5e-05,
      "loss": 0.2986,
      "step": 19648
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6385225653648376,
      "learning_rate": 5e-05,
      "loss": 0.3244,
      "step": 19656
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.8617262244224548,
      "learning_rate": 5e-05,
      "loss": 0.3339,
      "step": 19664
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6610432267189026,
      "learning_rate": 5e-05,
      "loss": 0.3151,
      "step": 19672
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.597335159778595,
      "learning_rate": 5e-05,
      "loss": 0.3257,
      "step": 19680
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.7323715686798096,
      "learning_rate": 5e-05,
      "loss": 0.2908,
      "step": 19688
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6391189098358154,
      "learning_rate": 5e-05,
      "loss": 0.3214,
      "step": 19696
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6369524598121643,
      "learning_rate": 5e-05,
      "loss": 0.3224,
      "step": 19704
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6551296710968018,
      "learning_rate": 5e-05,
      "loss": 0.3157,
      "step": 19712
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.5940194129943848,
      "learning_rate": 5e-05,
      "loss": 0.3074,
      "step": 19720
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6249018907546997,
      "learning_rate": 5e-05,
      "loss": 0.3563,
      "step": 19728
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6181520819664001,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 19736
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.5572195649147034,
      "learning_rate": 5e-05,
      "loss": 0.3155,
      "step": 19744
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6063381433486938,
      "learning_rate": 5e-05,
      "loss": 0.3101,
      "step": 19752
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.6214410066604614,
      "learning_rate": 5e-05,
      "loss": 0.3571,
      "step": 19760
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.5189986228942871,
      "learning_rate": 5e-05,
      "loss": 0.2763,
      "step": 19768
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.6600132584571838,
      "learning_rate": 5e-05,
      "loss": 0.3055,
      "step": 19776
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.6375646591186523,
      "learning_rate": 5e-05,
      "loss": 0.2959,
      "step": 19784
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.5925472974777222,
      "learning_rate": 5e-05,
      "loss": 0.3488,
      "step": 19792
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.6939628720283508,
      "learning_rate": 5e-05,
      "loss": 0.3184,
      "step": 19800
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.6417227387428284,
      "learning_rate": 5e-05,
      "loss": 0.3085,
      "step": 19808
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.6055023670196533,
      "learning_rate": 5e-05,
      "loss": 0.3293,
      "step": 19816
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.8054057359695435,
      "learning_rate": 5e-05,
      "loss": 0.3325,
      "step": 19824
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.5897505283355713,
      "learning_rate": 5e-05,
      "loss": 0.3506,
      "step": 19832
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.7156814336776733,
      "learning_rate": 5e-05,
      "loss": 0.3324,
      "step": 19840
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.7420186400413513,
      "learning_rate": 5e-05,
      "loss": 0.3114,
      "step": 19848
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.7355983257293701,
      "learning_rate": 5e-05,
      "loss": 0.3378,
      "step": 19856
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.7646390199661255,
      "learning_rate": 5e-05,
      "loss": 0.3383,
      "step": 19864
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.5392420291900635,
      "learning_rate": 5e-05,
      "loss": 0.3396,
      "step": 19872
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.7404673099517822,
      "learning_rate": 5e-05,
      "loss": 0.3484,
      "step": 19880
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.582068920135498,
      "learning_rate": 5e-05,
      "loss": 0.3087,
      "step": 19888
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.5800826549530029,
      "learning_rate": 5e-05,
      "loss": 0.3294,
      "step": 19896
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.6309831142425537,
      "learning_rate": 5e-05,
      "loss": 0.312,
      "step": 19904
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.9419113397598267,
      "learning_rate": 5e-05,
      "loss": 0.3234,
      "step": 19912
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.7347654700279236,
      "learning_rate": 5e-05,
      "loss": 0.3315,
      "step": 19920
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5673808455467224,
      "learning_rate": 5e-05,
      "loss": 0.3044,
      "step": 19928
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.6289803385734558,
      "learning_rate": 5e-05,
      "loss": 0.3132,
      "step": 19936
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.6722737550735474,
      "learning_rate": 5e-05,
      "loss": 0.3238,
      "step": 19944
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.6334248185157776,
      "learning_rate": 5e-05,
      "loss": 0.326,
      "step": 19952
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.530348539352417,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 19960
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.6144798398017883,
      "learning_rate": 5e-05,
      "loss": 0.3278,
      "step": 19968
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.6764091849327087,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 19976
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.6810669898986816,
      "learning_rate": 5e-05,
      "loss": 0.3294,
      "step": 19984
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.6064262390136719,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 19992
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5959944725036621,
      "learning_rate": 5e-05,
      "loss": 0.3429,
      "step": 20000
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.4970676600933075,
      "learning_rate": 5e-05,
      "loss": 0.298,
      "step": 20008
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.7446819543838501,
      "learning_rate": 5e-05,
      "loss": 0.3425,
      "step": 20016
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.6496947407722473,
      "learning_rate": 5e-05,
      "loss": 0.323,
      "step": 20024
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.6052805185317993,
      "learning_rate": 5e-05,
      "loss": 0.3168,
      "step": 20032
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.7227663397789001,
      "learning_rate": 5e-05,
      "loss": 0.3323,
      "step": 20040
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.8620650172233582,
      "learning_rate": 5e-05,
      "loss": 0.2982,
      "step": 20048
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.7111549377441406,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 20056
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.7444570064544678,
      "learning_rate": 5e-05,
      "loss": 0.3085,
      "step": 20064
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.6519389748573303,
      "learning_rate": 5e-05,
      "loss": 0.3434,
      "step": 20072
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5937464833259583,
      "learning_rate": 5e-05,
      "loss": 0.3484,
      "step": 20080
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.5424414873123169,
      "learning_rate": 5e-05,
      "loss": 0.3322,
      "step": 20088
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6057547330856323,
      "learning_rate": 5e-05,
      "loss": 0.323,
      "step": 20096
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6394705176353455,
      "learning_rate": 5e-05,
      "loss": 0.3546,
      "step": 20104
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6285820007324219,
      "learning_rate": 5e-05,
      "loss": 0.3222,
      "step": 20112
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.5673776268959045,
      "learning_rate": 5e-05,
      "loss": 0.2898,
      "step": 20120
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.5803880095481873,
      "learning_rate": 5e-05,
      "loss": 0.3269,
      "step": 20128
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6586838960647583,
      "learning_rate": 5e-05,
      "loss": 0.2954,
      "step": 20136
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6074771285057068,
      "learning_rate": 5e-05,
      "loss": 0.3276,
      "step": 20144
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6343300342559814,
      "learning_rate": 5e-05,
      "loss": 0.3192,
      "step": 20152
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6313772797584534,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 20160
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6017234325408936,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 20168
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.570087730884552,
      "learning_rate": 5e-05,
      "loss": 0.3053,
      "step": 20176
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6288925409317017,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 20184
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.7184236645698547,
      "learning_rate": 5e-05,
      "loss": 0.3069,
      "step": 20192
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6847228407859802,
      "learning_rate": 5e-05,
      "loss": 0.3322,
      "step": 20200
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.5998097658157349,
      "learning_rate": 5e-05,
      "loss": 0.3301,
      "step": 20208
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.7590932846069336,
      "learning_rate": 5e-05,
      "loss": 0.3155,
      "step": 20216
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6179046034812927,
      "learning_rate": 5e-05,
      "loss": 0.3359,
      "step": 20224
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6543842554092407,
      "learning_rate": 5e-05,
      "loss": 0.3543,
      "step": 20232
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6808105707168579,
      "learning_rate": 5e-05,
      "loss": 0.3464,
      "step": 20240
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.6732231378555298,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 20248
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.616887629032135,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 20256
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6562882661819458,
      "learning_rate": 5e-05,
      "loss": 0.3472,
      "step": 20264
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6545217037200928,
      "learning_rate": 5e-05,
      "loss": 0.2993,
      "step": 20272
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6646355986595154,
      "learning_rate": 5e-05,
      "loss": 0.3374,
      "step": 20280
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6586049199104309,
      "learning_rate": 5e-05,
      "loss": 0.3235,
      "step": 20288
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6843603849411011,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 20296
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6615413427352905,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 20304
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.5731713175773621,
      "learning_rate": 5e-05,
      "loss": 0.3509,
      "step": 20312
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6443108916282654,
      "learning_rate": 5e-05,
      "loss": 0.3208,
      "step": 20320
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.5746192932128906,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 20328
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6730265021324158,
      "learning_rate": 5e-05,
      "loss": 0.3063,
      "step": 20336
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.5524231195449829,
      "learning_rate": 5e-05,
      "loss": 0.2992,
      "step": 20344
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6211432218551636,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 20352
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6726012825965881,
      "learning_rate": 5e-05,
      "loss": 0.3431,
      "step": 20360
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6564574837684631,
      "learning_rate": 5e-05,
      "loss": 0.3375,
      "step": 20368
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6766162514686584,
      "learning_rate": 5e-05,
      "loss": 0.3285,
      "step": 20376
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6628604531288147,
      "learning_rate": 5e-05,
      "loss": 0.3366,
      "step": 20384
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.5905997157096863,
      "learning_rate": 5e-05,
      "loss": 0.3229,
      "step": 20392
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.7518863677978516,
      "learning_rate": 5e-05,
      "loss": 0.3197,
      "step": 20400
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.640023410320282,
      "learning_rate": 5e-05,
      "loss": 0.3189,
      "step": 20408
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.6471237540245056,
      "learning_rate": 5e-05,
      "loss": 0.3109,
      "step": 20416
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.6347560882568359,
      "learning_rate": 5e-05,
      "loss": 0.3277,
      "step": 20424
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.7604438662528992,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 20432
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.6380738615989685,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 20440
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.5381925106048584,
      "learning_rate": 5e-05,
      "loss": 0.2924,
      "step": 20448
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.7118204236030579,
      "learning_rate": 5e-05,
      "loss": 0.3439,
      "step": 20456
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.6128432750701904,
      "learning_rate": 5e-05,
      "loss": 0.3146,
      "step": 20464
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.7201859354972839,
      "learning_rate": 5e-05,
      "loss": 0.3265,
      "step": 20472
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.783626139163971,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 20480
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.7422025799751282,
      "learning_rate": 5e-05,
      "loss": 0.3151,
      "step": 20488
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.7035824656486511,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 20496
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.632142186164856,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 20504
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.7886537313461304,
      "learning_rate": 5e-05,
      "loss": 0.3176,
      "step": 20512
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.5843916535377502,
      "learning_rate": 5e-05,
      "loss": 0.3626,
      "step": 20520
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.8176150918006897,
      "learning_rate": 5e-05,
      "loss": 0.3079,
      "step": 20528
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.7166165113449097,
      "learning_rate": 5e-05,
      "loss": 0.3493,
      "step": 20536
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.6155292391777039,
      "learning_rate": 5e-05,
      "loss": 0.3057,
      "step": 20544
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.6036831736564636,
      "learning_rate": 5e-05,
      "loss": 0.2919,
      "step": 20552
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.6626078486442566,
      "learning_rate": 5e-05,
      "loss": 0.312,
      "step": 20560
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.5306064486503601,
      "learning_rate": 5e-05,
      "loss": 0.3116,
      "step": 20568
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.5521436333656311,
      "learning_rate": 5e-05,
      "loss": 0.2983,
      "step": 20576
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.582782506942749,
      "learning_rate": 5e-05,
      "loss": 0.2917,
      "step": 20584
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6370812654495239,
      "learning_rate": 5e-05,
      "loss": 0.3096,
      "step": 20592
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6996768116950989,
      "learning_rate": 5e-05,
      "loss": 0.2965,
      "step": 20600
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.5514832735061646,
      "learning_rate": 5e-05,
      "loss": 0.35,
      "step": 20608
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6065251231193542,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 20616
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.7979483008384705,
      "learning_rate": 5e-05,
      "loss": 0.3281,
      "step": 20624
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.5320972800254822,
      "learning_rate": 5e-05,
      "loss": 0.3202,
      "step": 20632
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6367804408073425,
      "learning_rate": 5e-05,
      "loss": 0.304,
      "step": 20640
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6636732220649719,
      "learning_rate": 5e-05,
      "loss": 0.3117,
      "step": 20648
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6278612017631531,
      "learning_rate": 5e-05,
      "loss": 0.3028,
      "step": 20656
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6593726873397827,
      "learning_rate": 5e-05,
      "loss": 0.3272,
      "step": 20664
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.5686805844306946,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 20672
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6533591747283936,
      "learning_rate": 5e-05,
      "loss": 0.3222,
      "step": 20680
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6811342239379883,
      "learning_rate": 5e-05,
      "loss": 0.3202,
      "step": 20688
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.5811325311660767,
      "learning_rate": 5e-05,
      "loss": 0.3272,
      "step": 20696
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.565848708152771,
      "learning_rate": 5e-05,
      "loss": 0.3203,
      "step": 20704
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6126629114151001,
      "learning_rate": 5e-05,
      "loss": 0.3263,
      "step": 20712
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6462237238883972,
      "learning_rate": 5e-05,
      "loss": 0.3016,
      "step": 20720
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6688641309738159,
      "learning_rate": 5e-05,
      "loss": 0.3444,
      "step": 20728
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6889590620994568,
      "learning_rate": 5e-05,
      "loss": 0.3312,
      "step": 20736
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.659498929977417,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 20744
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6525030136108398,
      "learning_rate": 5e-05,
      "loss": 0.3072,
      "step": 20752
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.6409339904785156,
      "learning_rate": 5e-05,
      "loss": 0.3272,
      "step": 20760
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.7588107585906982,
      "learning_rate": 5e-05,
      "loss": 0.3204,
      "step": 20768
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.592979907989502,
      "learning_rate": 5e-05,
      "loss": 0.3154,
      "step": 20776
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.7808722257614136,
      "learning_rate": 5e-05,
      "loss": 0.3332,
      "step": 20784
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.6098606586456299,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 20792
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.5885589718818665,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 20800
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.6428384780883789,
      "learning_rate": 5e-05,
      "loss": 0.3257,
      "step": 20808
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.5296218395233154,
      "learning_rate": 5e-05,
      "loss": 0.3398,
      "step": 20816
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.5381354689598083,
      "learning_rate": 5e-05,
      "loss": 0.3131,
      "step": 20824
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.6739082336425781,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 20832
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.6867343783378601,
      "learning_rate": 5e-05,
      "loss": 0.3245,
      "step": 20840
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.5555276274681091,
      "learning_rate": 5e-05,
      "loss": 0.3218,
      "step": 20848
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.7276697158813477,
      "learning_rate": 5e-05,
      "loss": 0.3291,
      "step": 20856
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.6661296486854553,
      "learning_rate": 5e-05,
      "loss": 0.339,
      "step": 20864
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.6374983191490173,
      "learning_rate": 5e-05,
      "loss": 0.3361,
      "step": 20872
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.6154367327690125,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 20880
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.7617831230163574,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 20888
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.7358705997467041,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 20896
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.7078589797019958,
      "learning_rate": 5e-05,
      "loss": 0.3295,
      "step": 20904
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.7328445315361023,
      "learning_rate": 5e-05,
      "loss": 0.318,
      "step": 20912
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.8287369012832642,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 20920
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.7030404210090637,
      "learning_rate": 5e-05,
      "loss": 0.3385,
      "step": 20928
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.6262354850769043,
      "learning_rate": 5e-05,
      "loss": 0.3238,
      "step": 20936
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.6628296375274658,
      "learning_rate": 5e-05,
      "loss": 0.3226,
      "step": 20944
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.6579812169075012,
      "learning_rate": 5e-05,
      "loss": 0.3244,
      "step": 20952
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.6635438799858093,
      "learning_rate": 5e-05,
      "loss": 0.3029,
      "step": 20960
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.7220459580421448,
      "learning_rate": 5e-05,
      "loss": 0.3291,
      "step": 20968
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.8098961114883423,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 20976
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.6596884727478027,
      "learning_rate": 5e-05,
      "loss": 0.3129,
      "step": 20984
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.7357888221740723,
      "learning_rate": 5e-05,
      "loss": 0.3166,
      "step": 20992
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.6249331831932068,
      "learning_rate": 5e-05,
      "loss": 0.3297,
      "step": 21000
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.6134795546531677,
      "learning_rate": 5e-05,
      "loss": 0.3057,
      "step": 21008
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.605971097946167,
      "learning_rate": 5e-05,
      "loss": 0.3115,
      "step": 21016
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.9316456913948059,
      "learning_rate": 5e-05,
      "loss": 0.3146,
      "step": 21024
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.645142674446106,
      "learning_rate": 5e-05,
      "loss": 0.3472,
      "step": 21032
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.5415735244750977,
      "learning_rate": 5e-05,
      "loss": 0.3209,
      "step": 21040
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.5921574831008911,
      "learning_rate": 5e-05,
      "loss": 0.3064,
      "step": 21048
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.6452810168266296,
      "learning_rate": 5e-05,
      "loss": 0.3187,
      "step": 21056
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.6269567608833313,
      "learning_rate": 5e-05,
      "loss": 0.3166,
      "step": 21064
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.6319130063056946,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 21072
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.5890977382659912,
      "learning_rate": 5e-05,
      "loss": 0.3362,
      "step": 21080
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.5887786149978638,
      "learning_rate": 5e-05,
      "loss": 0.2935,
      "step": 21088
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.5671348571777344,
      "learning_rate": 5e-05,
      "loss": 0.3079,
      "step": 21096
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.6101347208023071,
      "learning_rate": 5e-05,
      "loss": 0.3494,
      "step": 21104
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.6037946343421936,
      "learning_rate": 5e-05,
      "loss": 0.2846,
      "step": 21112
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.5596304535865784,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 21120
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.6695153713226318,
      "learning_rate": 5e-05,
      "loss": 0.3695,
      "step": 21128
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.7589991092681885,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 21136
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.5870840549468994,
      "learning_rate": 5e-05,
      "loss": 0.3091,
      "step": 21144
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.5871627926826477,
      "learning_rate": 5e-05,
      "loss": 0.3082,
      "step": 21152
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.6190699934959412,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 21160
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.6607969999313354,
      "learning_rate": 5e-05,
      "loss": 0.3344,
      "step": 21168
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.6121357083320618,
      "learning_rate": 5e-05,
      "loss": 0.3217,
      "step": 21176
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.5936025381088257,
      "learning_rate": 5e-05,
      "loss": 0.3278,
      "step": 21184
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.5990511178970337,
      "learning_rate": 5e-05,
      "loss": 0.3225,
      "step": 21192
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.6845062971115112,
      "learning_rate": 5e-05,
      "loss": 0.3262,
      "step": 21200
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.6208195090293884,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 21208
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.578899621963501,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 21216
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.6381663680076599,
      "learning_rate": 5e-05,
      "loss": 0.3107,
      "step": 21224
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.7344636917114258,
      "learning_rate": 5e-05,
      "loss": 0.3269,
      "step": 21232
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.7536100149154663,
      "learning_rate": 5e-05,
      "loss": 0.315,
      "step": 21240
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.5593284368515015,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 21248
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.65500807762146,
      "learning_rate": 5e-05,
      "loss": 0.3181,
      "step": 21256
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.6863778829574585,
      "learning_rate": 5e-05,
      "loss": 0.3066,
      "step": 21264
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.6931648254394531,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 21272
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.6374684572219849,
      "learning_rate": 5e-05,
      "loss": 0.3295,
      "step": 21280
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.6298669576644897,
      "learning_rate": 5e-05,
      "loss": 0.3236,
      "step": 21288
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.5838171243667603,
      "learning_rate": 5e-05,
      "loss": 0.3391,
      "step": 21296
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.6171368360519409,
      "learning_rate": 5e-05,
      "loss": 0.3296,
      "step": 21304
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.6578250527381897,
      "learning_rate": 5e-05,
      "loss": 0.3178,
      "step": 21312
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.6974683403968811,
      "learning_rate": 5e-05,
      "loss": 0.317,
      "step": 21320
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.676364004611969,
      "learning_rate": 5e-05,
      "loss": 0.2949,
      "step": 21328
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.6613803505897522,
      "learning_rate": 5e-05,
      "loss": 0.2985,
      "step": 21336
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.6775720715522766,
      "learning_rate": 5e-05,
      "loss": 0.3376,
      "step": 21344
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.5913087725639343,
      "learning_rate": 5e-05,
      "loss": 0.3097,
      "step": 21352
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.6588908433914185,
      "learning_rate": 5e-05,
      "loss": 0.319,
      "step": 21360
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.7396550178527832,
      "learning_rate": 5e-05,
      "loss": 0.3039,
      "step": 21368
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.6884387135505676,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 21376
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.5867770314216614,
      "learning_rate": 5e-05,
      "loss": 0.3256,
      "step": 21384
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.589379072189331,
      "learning_rate": 5e-05,
      "loss": 0.3535,
      "step": 21392
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.5971572399139404,
      "learning_rate": 5e-05,
      "loss": 0.3193,
      "step": 21400
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.7047766447067261,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 21408
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.7434762120246887,
      "learning_rate": 5e-05,
      "loss": 0.3279,
      "step": 21416
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6559281349182129,
      "learning_rate": 5e-05,
      "loss": 0.3208,
      "step": 21424
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6683840155601501,
      "learning_rate": 5e-05,
      "loss": 0.3053,
      "step": 21432
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.7007954120635986,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 21440
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6908700466156006,
      "learning_rate": 5e-05,
      "loss": 0.3197,
      "step": 21448
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6006715297698975,
      "learning_rate": 5e-05,
      "loss": 0.3303,
      "step": 21456
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.7166298627853394,
      "learning_rate": 5e-05,
      "loss": 0.3254,
      "step": 21464
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6949629187583923,
      "learning_rate": 5e-05,
      "loss": 0.3053,
      "step": 21472
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.7636529803276062,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 21480
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.5486504435539246,
      "learning_rate": 5e-05,
      "loss": 0.3106,
      "step": 21488
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.0072453022003174,
      "learning_rate": 5e-05,
      "loss": 0.3157,
      "step": 21496
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6194190979003906,
      "learning_rate": 5e-05,
      "loss": 0.3025,
      "step": 21504
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6074922680854797,
      "learning_rate": 5e-05,
      "loss": 0.3156,
      "step": 21512
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.5527270436286926,
      "learning_rate": 5e-05,
      "loss": 0.3121,
      "step": 21520
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.62619948387146,
      "learning_rate": 5e-05,
      "loss": 0.3119,
      "step": 21528
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6143770813941956,
      "learning_rate": 5e-05,
      "loss": 0.3529,
      "step": 21536
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6575799584388733,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 21544
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6652283072471619,
      "learning_rate": 5e-05,
      "loss": 0.3635,
      "step": 21552
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6165801286697388,
      "learning_rate": 5e-05,
      "loss": 0.3398,
      "step": 21560
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6785294413566589,
      "learning_rate": 5e-05,
      "loss": 0.3243,
      "step": 21568
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6136937737464905,
      "learning_rate": 5e-05,
      "loss": 0.3259,
      "step": 21576
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6514565348625183,
      "learning_rate": 5e-05,
      "loss": 0.3453,
      "step": 21584
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.677035391330719,
      "learning_rate": 5e-05,
      "loss": 0.2806,
      "step": 21592
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.5898067355155945,
      "learning_rate": 5e-05,
      "loss": 0.3142,
      "step": 21600
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.6565223336219788,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 21608
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.7333663105964661,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 21616
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.6574890613555908,
      "learning_rate": 5e-05,
      "loss": 0.2964,
      "step": 21624
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.7080481648445129,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 21632
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.6854305267333984,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 21640
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.639947235584259,
      "learning_rate": 5e-05,
      "loss": 0.3496,
      "step": 21648
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.5927286744117737,
      "learning_rate": 5e-05,
      "loss": 0.3363,
      "step": 21656
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.657770574092865,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 21664
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.7479998469352722,
      "learning_rate": 5e-05,
      "loss": 0.3161,
      "step": 21672
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.6103571057319641,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 21680
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.5851911306381226,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 21688
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.5630197525024414,
      "learning_rate": 5e-05,
      "loss": 0.3089,
      "step": 21696
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.5916439890861511,
      "learning_rate": 5e-05,
      "loss": 0.3145,
      "step": 21704
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.7659642100334167,
      "learning_rate": 5e-05,
      "loss": 0.3107,
      "step": 21712
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.6053308248519897,
      "learning_rate": 5e-05,
      "loss": 0.3096,
      "step": 21720
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.6827038526535034,
      "learning_rate": 5e-05,
      "loss": 0.3166,
      "step": 21728
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.663213849067688,
      "learning_rate": 5e-05,
      "loss": 0.3123,
      "step": 21736
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.6589397192001343,
      "learning_rate": 5e-05,
      "loss": 0.3102,
      "step": 21744
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.6810632348060608,
      "learning_rate": 5e-05,
      "loss": 0.3247,
      "step": 21752
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.6648986339569092,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 21760
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.6484274864196777,
      "learning_rate": 5e-05,
      "loss": 0.3024,
      "step": 21768
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.803596556186676,
      "learning_rate": 5e-05,
      "loss": 0.3329,
      "step": 21776
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.628787100315094,
      "learning_rate": 5e-05,
      "loss": 0.2934,
      "step": 21784
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.5692775249481201,
      "learning_rate": 5e-05,
      "loss": 0.3238,
      "step": 21792
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.5376395583152771,
      "learning_rate": 5e-05,
      "loss": 0.333,
      "step": 21800
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.7141189575195312,
      "learning_rate": 5e-05,
      "loss": 0.302,
      "step": 21808
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.7096359729766846,
      "learning_rate": 5e-05,
      "loss": 0.2988,
      "step": 21816
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.6420385241508484,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 21824
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.6209710240364075,
      "learning_rate": 5e-05,
      "loss": 0.3012,
      "step": 21832
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.7350357174873352,
      "learning_rate": 5e-05,
      "loss": 0.3612,
      "step": 21840
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.6091372966766357,
      "learning_rate": 5e-05,
      "loss": 0.3169,
      "step": 21848
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.6768810153007507,
      "learning_rate": 5e-05,
      "loss": 0.3293,
      "step": 21856
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.6936633586883545,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 21864
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.6148762106895447,
      "learning_rate": 5e-05,
      "loss": 0.34,
      "step": 21872
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.6685354113578796,
      "learning_rate": 5e-05,
      "loss": 0.3197,
      "step": 21880
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.5899186134338379,
      "learning_rate": 5e-05,
      "loss": 0.3103,
      "step": 21888
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.5887206792831421,
      "learning_rate": 5e-05,
      "loss": 0.3132,
      "step": 21896
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.6170096397399902,
      "learning_rate": 5e-05,
      "loss": 0.3145,
      "step": 21904
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.5758364200592041,
      "learning_rate": 5e-05,
      "loss": 0.3334,
      "step": 21912
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.5408173203468323,
      "learning_rate": 5e-05,
      "loss": 0.3158,
      "step": 21920
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.5552964806556702,
      "learning_rate": 5e-05,
      "loss": 0.3285,
      "step": 21928
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.7382126450538635,
      "learning_rate": 5e-05,
      "loss": 0.3416,
      "step": 21936
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.697753369808197,
      "learning_rate": 5e-05,
      "loss": 0.3115,
      "step": 21944
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.7957051992416382,
      "learning_rate": 5e-05,
      "loss": 0.3432,
      "step": 21952
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6579912900924683,
      "learning_rate": 5e-05,
      "loss": 0.3,
      "step": 21960
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6313967108726501,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 21968
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6529839634895325,
      "learning_rate": 5e-05,
      "loss": 0.3286,
      "step": 21976
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6126450300216675,
      "learning_rate": 5e-05,
      "loss": 0.3331,
      "step": 21984
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.8236079812049866,
      "learning_rate": 5e-05,
      "loss": 0.313,
      "step": 21992
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6344186067581177,
      "learning_rate": 5e-05,
      "loss": 0.3219,
      "step": 22000
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.8474650979042053,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 22008
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6750346422195435,
      "learning_rate": 5e-05,
      "loss": 0.3596,
      "step": 22016
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.5876197218894958,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 22024
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6439518332481384,
      "learning_rate": 5e-05,
      "loss": 0.31,
      "step": 22032
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.7061499357223511,
      "learning_rate": 5e-05,
      "loss": 0.3456,
      "step": 22040
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6823337078094482,
      "learning_rate": 5e-05,
      "loss": 0.3341,
      "step": 22048
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6524416208267212,
      "learning_rate": 5e-05,
      "loss": 0.3306,
      "step": 22056
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.7388827800750732,
      "learning_rate": 5e-05,
      "loss": 0.3237,
      "step": 22064
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.8403537273406982,
      "learning_rate": 5e-05,
      "loss": 0.33,
      "step": 22072
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6468569040298462,
      "learning_rate": 5e-05,
      "loss": 0.3465,
      "step": 22080
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6068201661109924,
      "learning_rate": 5e-05,
      "loss": 0.3064,
      "step": 22088
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.5915194153785706,
      "learning_rate": 5e-05,
      "loss": 0.332,
      "step": 22096
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.5754731893539429,
      "learning_rate": 5e-05,
      "loss": 0.287,
      "step": 22104
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.5605071783065796,
      "learning_rate": 5e-05,
      "loss": 0.3242,
      "step": 22112
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6435921788215637,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 22120
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.7896111011505127,
      "learning_rate": 5e-05,
      "loss": 0.3184,
      "step": 22128
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6340556144714355,
      "learning_rate": 5e-05,
      "loss": 0.3086,
      "step": 22136
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6895516514778137,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 22144
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.5245746374130249,
      "learning_rate": 5e-05,
      "loss": 0.3053,
      "step": 22152
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6615462899208069,
      "learning_rate": 5e-05,
      "loss": 0.2929,
      "step": 22160
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6707968711853027,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 22168
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.7092056274414062,
      "learning_rate": 5e-05,
      "loss": 0.3367,
      "step": 22176
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6561962962150574,
      "learning_rate": 5e-05,
      "loss": 0.3226,
      "step": 22184
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6783233284950256,
      "learning_rate": 5e-05,
      "loss": 0.3416,
      "step": 22192
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.63751620054245,
      "learning_rate": 5e-05,
      "loss": 0.3169,
      "step": 22200
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6415934562683105,
      "learning_rate": 5e-05,
      "loss": 0.3338,
      "step": 22208
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6237562298774719,
      "learning_rate": 5e-05,
      "loss": 0.3117,
      "step": 22216
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6461364030838013,
      "learning_rate": 5e-05,
      "loss": 0.3142,
      "step": 22224
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.5814961194992065,
      "learning_rate": 5e-05,
      "loss": 0.3065,
      "step": 22232
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6443243026733398,
      "learning_rate": 5e-05,
      "loss": 0.3011,
      "step": 22240
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.6181046366691589,
      "learning_rate": 5e-05,
      "loss": 0.2864,
      "step": 22248
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.6012999415397644,
      "learning_rate": 5e-05,
      "loss": 0.3154,
      "step": 22256
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.6103346943855286,
      "learning_rate": 5e-05,
      "loss": 0.3187,
      "step": 22264
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.8695791959762573,
      "learning_rate": 5e-05,
      "loss": 0.2828,
      "step": 22272
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.6150580048561096,
      "learning_rate": 5e-05,
      "loss": 0.3003,
      "step": 22280
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.7100949287414551,
      "learning_rate": 5e-05,
      "loss": 0.3375,
      "step": 22288
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.6680924892425537,
      "learning_rate": 5e-05,
      "loss": 0.2816,
      "step": 22296
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.5971691012382507,
      "learning_rate": 5e-05,
      "loss": 0.3119,
      "step": 22304
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.7830367684364319,
      "learning_rate": 5e-05,
      "loss": 0.3331,
      "step": 22312
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.6725717186927795,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 22320
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.690729558467865,
      "learning_rate": 5e-05,
      "loss": 0.3302,
      "step": 22328
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.7347077131271362,
      "learning_rate": 5e-05,
      "loss": 0.2918,
      "step": 22336
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.4969513714313507,
      "learning_rate": 5e-05,
      "loss": 0.3482,
      "step": 22344
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.5617637634277344,
      "learning_rate": 5e-05,
      "loss": 0.3347,
      "step": 22352
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.7372196316719055,
      "learning_rate": 5e-05,
      "loss": 0.3257,
      "step": 22360
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.61445552110672,
      "learning_rate": 5e-05,
      "loss": 0.2896,
      "step": 22368
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.6012542247772217,
      "learning_rate": 5e-05,
      "loss": 0.3099,
      "step": 22376
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.6693452596664429,
      "learning_rate": 5e-05,
      "loss": 0.331,
      "step": 22384
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.6469360589981079,
      "learning_rate": 5e-05,
      "loss": 0.3292,
      "step": 22392
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.7631157040596008,
      "learning_rate": 5e-05,
      "loss": 0.3273,
      "step": 22400
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.5965183973312378,
      "learning_rate": 5e-05,
      "loss": 0.3105,
      "step": 22408
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.7130091786384583,
      "learning_rate": 5e-05,
      "loss": 0.3398,
      "step": 22416
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.6888017654418945,
      "learning_rate": 5e-05,
      "loss": 0.3105,
      "step": 22424
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.5770869851112366,
      "learning_rate": 5e-05,
      "loss": 0.3284,
      "step": 22432
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.5739288330078125,
      "learning_rate": 5e-05,
      "loss": 0.3056,
      "step": 22440
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.5851131081581116,
      "learning_rate": 5e-05,
      "loss": 0.3238,
      "step": 22448
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.5805842280387878,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 22456
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.6541123986244202,
      "learning_rate": 5e-05,
      "loss": 0.3347,
      "step": 22464
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.6085630655288696,
      "learning_rate": 5e-05,
      "loss": 0.3132,
      "step": 22472
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.6713164448738098,
      "learning_rate": 5e-05,
      "loss": 0.3028,
      "step": 22480
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.617083728313446,
      "learning_rate": 5e-05,
      "loss": 0.307,
      "step": 22488
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.7302610278129578,
      "learning_rate": 5e-05,
      "loss": 0.3297,
      "step": 22496
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.700302243232727,
      "learning_rate": 5e-05,
      "loss": 0.3211,
      "step": 22504
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.707853376865387,
      "learning_rate": 5e-05,
      "loss": 0.3318,
      "step": 22512
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.6583138704299927,
      "learning_rate": 5e-05,
      "loss": 0.3003,
      "step": 22520
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.570414125919342,
      "learning_rate": 5e-05,
      "loss": 0.326,
      "step": 22528
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.6556376218795776,
      "learning_rate": 5e-05,
      "loss": 0.3288,
      "step": 22536
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.6333758234977722,
      "learning_rate": 5e-05,
      "loss": 0.296,
      "step": 22544
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.6507143378257751,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 22552
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.5607871413230896,
      "learning_rate": 5e-05,
      "loss": 0.2804,
      "step": 22560
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.6792399883270264,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 22568
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.4966874420642853,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 22576
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.7183791995048523,
      "learning_rate": 5e-05,
      "loss": 0.3469,
      "step": 22584
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.6136258244514465,
      "learning_rate": 5e-05,
      "loss": 0.2873,
      "step": 22592
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.6794764995574951,
      "learning_rate": 5e-05,
      "loss": 0.2925,
      "step": 22600
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.5745469331741333,
      "learning_rate": 5e-05,
      "loss": 0.326,
      "step": 22608
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.6782281994819641,
      "learning_rate": 5e-05,
      "loss": 0.3083,
      "step": 22616
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.6215945482254028,
      "learning_rate": 5e-05,
      "loss": 0.3552,
      "step": 22624
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.5892948508262634,
      "learning_rate": 5e-05,
      "loss": 0.3022,
      "step": 22632
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.6387922167778015,
      "learning_rate": 5e-05,
      "loss": 0.3134,
      "step": 22640
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.7338014841079712,
      "learning_rate": 5e-05,
      "loss": 0.2978,
      "step": 22648
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.6059242486953735,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 22656
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.6062275767326355,
      "learning_rate": 5e-05,
      "loss": 0.31,
      "step": 22664
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.6139938831329346,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 22672
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.46907883882522583,
      "learning_rate": 5e-05,
      "loss": 0.3008,
      "step": 22680
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.6295758485794067,
      "learning_rate": 5e-05,
      "loss": 0.2983,
      "step": 22688
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.6604342460632324,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 22696
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.657747745513916,
      "learning_rate": 5e-05,
      "loss": 0.3057,
      "step": 22704
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.5876911878585815,
      "learning_rate": 5e-05,
      "loss": 0.3411,
      "step": 22712
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.6279443502426147,
      "learning_rate": 5e-05,
      "loss": 0.3065,
      "step": 22720
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.6106207966804504,
      "learning_rate": 5e-05,
      "loss": 0.3243,
      "step": 22728
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.6605018973350525,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 22736
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.625317394733429,
      "learning_rate": 5e-05,
      "loss": 0.306,
      "step": 22744
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.7325884699821472,
      "learning_rate": 5e-05,
      "loss": 0.304,
      "step": 22752
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6913152933120728,
      "learning_rate": 5e-05,
      "loss": 0.3539,
      "step": 22760
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6554676294326782,
      "learning_rate": 5e-05,
      "loss": 0.3382,
      "step": 22768
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6388727426528931,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 22776
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.5989078879356384,
      "learning_rate": 5e-05,
      "loss": 0.3172,
      "step": 22784
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.851751446723938,
      "learning_rate": 5e-05,
      "loss": 0.3207,
      "step": 22792
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.695107102394104,
      "learning_rate": 5e-05,
      "loss": 0.3158,
      "step": 22800
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6004822254180908,
      "learning_rate": 5e-05,
      "loss": 0.3066,
      "step": 22808
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.7875281572341919,
      "learning_rate": 5e-05,
      "loss": 0.3355,
      "step": 22816
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.708808183670044,
      "learning_rate": 5e-05,
      "loss": 0.3274,
      "step": 22824
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.7025084495544434,
      "learning_rate": 5e-05,
      "loss": 0.3018,
      "step": 22832
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6266522407531738,
      "learning_rate": 5e-05,
      "loss": 0.3285,
      "step": 22840
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6626603007316589,
      "learning_rate": 5e-05,
      "loss": 0.319,
      "step": 22848
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6625916957855225,
      "learning_rate": 5e-05,
      "loss": 0.3079,
      "step": 22856
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.7205774188041687,
      "learning_rate": 5e-05,
      "loss": 0.3244,
      "step": 22864
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6629717946052551,
      "learning_rate": 5e-05,
      "loss": 0.3214,
      "step": 22872
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.742660641670227,
      "learning_rate": 5e-05,
      "loss": 0.3095,
      "step": 22880
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6642327904701233,
      "learning_rate": 5e-05,
      "loss": 0.3231,
      "step": 22888
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6049604415893555,
      "learning_rate": 5e-05,
      "loss": 0.3053,
      "step": 22896
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6090755462646484,
      "learning_rate": 5e-05,
      "loss": 0.3067,
      "step": 22904
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6135750412940979,
      "learning_rate": 5e-05,
      "loss": 0.3038,
      "step": 22912
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.6405408382415771,
      "learning_rate": 5e-05,
      "loss": 0.2918,
      "step": 22920
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.717458188533783,
      "learning_rate": 5e-05,
      "loss": 0.292,
      "step": 22928
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.7141277194023132,
      "learning_rate": 5e-05,
      "loss": 0.3293,
      "step": 22936
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.5918455719947815,
      "learning_rate": 5e-05,
      "loss": 0.3147,
      "step": 22944
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.7763273119926453,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 22952
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.6247264742851257,
      "learning_rate": 5e-05,
      "loss": 0.2788,
      "step": 22960
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.6723113059997559,
      "learning_rate": 5e-05,
      "loss": 0.326,
      "step": 22968
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.6934292912483215,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 22976
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.6469433903694153,
      "learning_rate": 5e-05,
      "loss": 0.2906,
      "step": 22984
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.7020212411880493,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 22992
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.6203349232673645,
      "learning_rate": 5e-05,
      "loss": 0.3075,
      "step": 23000
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.7269706130027771,
      "learning_rate": 5e-05,
      "loss": 0.3427,
      "step": 23008
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.6251019239425659,
      "learning_rate": 5e-05,
      "loss": 0.3424,
      "step": 23016
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.5468248724937439,
      "learning_rate": 5e-05,
      "loss": 0.3081,
      "step": 23024
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.6409258246421814,
      "learning_rate": 5e-05,
      "loss": 0.3193,
      "step": 23032
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.661153256893158,
      "learning_rate": 5e-05,
      "loss": 0.3165,
      "step": 23040
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.7189329266548157,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 23048
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.7526359558105469,
      "learning_rate": 5e-05,
      "loss": 0.3131,
      "step": 23056
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.8211129903793335,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 23064
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.6650316715240479,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 23072
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.6175466775894165,
      "learning_rate": 5e-05,
      "loss": 0.3113,
      "step": 23080
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.5988613963127136,
      "learning_rate": 5e-05,
      "loss": 0.3366,
      "step": 23088
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.6027694344520569,
      "learning_rate": 5e-05,
      "loss": 0.34,
      "step": 23096
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.7517765760421753,
      "learning_rate": 5e-05,
      "loss": 0.3149,
      "step": 23104
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.6129991412162781,
      "learning_rate": 5e-05,
      "loss": 0.309,
      "step": 23112
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.7221934795379639,
      "learning_rate": 5e-05,
      "loss": 0.3296,
      "step": 23120
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.7779537439346313,
      "learning_rate": 5e-05,
      "loss": 0.3421,
      "step": 23128
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.7466399669647217,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 23136
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.6814014911651611,
      "learning_rate": 5e-05,
      "loss": 0.3181,
      "step": 23144
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.5361847877502441,
      "learning_rate": 5e-05,
      "loss": 0.3303,
      "step": 23152
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.5421867370605469,
      "learning_rate": 5e-05,
      "loss": 0.333,
      "step": 23160
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.5809336304664612,
      "learning_rate": 5e-05,
      "loss": 0.3302,
      "step": 23168
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.8062338829040527,
      "learning_rate": 5e-05,
      "loss": 0.318,
      "step": 23176
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.6220899224281311,
      "learning_rate": 5e-05,
      "loss": 0.3368,
      "step": 23184
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.6422003507614136,
      "learning_rate": 5e-05,
      "loss": 0.3148,
      "step": 23192
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.6182599067687988,
      "learning_rate": 5e-05,
      "loss": 0.3383,
      "step": 23200
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.6265121698379517,
      "learning_rate": 5e-05,
      "loss": 0.2966,
      "step": 23208
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.7189270853996277,
      "learning_rate": 5e-05,
      "loss": 0.3219,
      "step": 23216
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.6598518490791321,
      "learning_rate": 5e-05,
      "loss": 0.3185,
      "step": 23224
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.6912491321563721,
      "learning_rate": 5e-05,
      "loss": 0.3115,
      "step": 23232
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.5932443141937256,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 23240
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.6614652872085571,
      "learning_rate": 5e-05,
      "loss": 0.3205,
      "step": 23248
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.6409099698066711,
      "learning_rate": 5e-05,
      "loss": 0.2929,
      "step": 23256
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5483651161193848,
      "learning_rate": 5e-05,
      "loss": 0.3184,
      "step": 23264
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.7299491763114929,
      "learning_rate": 5e-05,
      "loss": 0.3104,
      "step": 23272
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.6389077305793762,
      "learning_rate": 5e-05,
      "loss": 0.3358,
      "step": 23280
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.6050347089767456,
      "learning_rate": 5e-05,
      "loss": 0.307,
      "step": 23288
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.6982671618461609,
      "learning_rate": 5e-05,
      "loss": 0.291,
      "step": 23296
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.7717244029045105,
      "learning_rate": 5e-05,
      "loss": 0.3325,
      "step": 23304
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.7299581170082092,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 23312
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.6039471626281738,
      "learning_rate": 5e-05,
      "loss": 0.2938,
      "step": 23320
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5782449245452881,
      "learning_rate": 5e-05,
      "loss": 0.3257,
      "step": 23328
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5740692019462585,
      "learning_rate": 5e-05,
      "loss": 0.3165,
      "step": 23336
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.6710213422775269,
      "learning_rate": 5e-05,
      "loss": 0.3156,
      "step": 23344
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.8082370758056641,
      "learning_rate": 5e-05,
      "loss": 0.3129,
      "step": 23352
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.7340795397758484,
      "learning_rate": 5e-05,
      "loss": 0.3074,
      "step": 23360
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5923791527748108,
      "learning_rate": 5e-05,
      "loss": 0.2857,
      "step": 23368
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.6220213770866394,
      "learning_rate": 5e-05,
      "loss": 0.2901,
      "step": 23376
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.7401078343391418,
      "learning_rate": 5e-05,
      "loss": 0.3186,
      "step": 23384
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5181377530097961,
      "learning_rate": 5e-05,
      "loss": 0.3066,
      "step": 23392
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.6676180362701416,
      "learning_rate": 5e-05,
      "loss": 0.2928,
      "step": 23400
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.59534752368927,
      "learning_rate": 5e-05,
      "loss": 0.2942,
      "step": 23408
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.6631363034248352,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 23416
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6556286215782166,
      "learning_rate": 5e-05,
      "loss": 0.3094,
      "step": 23424
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.5747007727622986,
      "learning_rate": 5e-05,
      "loss": 0.2917,
      "step": 23432
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6843661665916443,
      "learning_rate": 5e-05,
      "loss": 0.2876,
      "step": 23440
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6813629269599915,
      "learning_rate": 5e-05,
      "loss": 0.3284,
      "step": 23448
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.679312527179718,
      "learning_rate": 5e-05,
      "loss": 0.3243,
      "step": 23456
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.5345783829689026,
      "learning_rate": 5e-05,
      "loss": 0.3278,
      "step": 23464
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6790640354156494,
      "learning_rate": 5e-05,
      "loss": 0.3287,
      "step": 23472
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6416150331497192,
      "learning_rate": 5e-05,
      "loss": 0.3233,
      "step": 23480
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6338496208190918,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 23488
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6864448189735413,
      "learning_rate": 5e-05,
      "loss": 0.3028,
      "step": 23496
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.7428629994392395,
      "learning_rate": 5e-05,
      "loss": 0.3268,
      "step": 23504
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6463288068771362,
      "learning_rate": 5e-05,
      "loss": 0.2978,
      "step": 23512
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6548149585723877,
      "learning_rate": 5e-05,
      "loss": 0.3408,
      "step": 23520
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6809650659561157,
      "learning_rate": 5e-05,
      "loss": 0.3313,
      "step": 23528
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6490358114242554,
      "learning_rate": 5e-05,
      "loss": 0.3218,
      "step": 23536
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.7466077208518982,
      "learning_rate": 5e-05,
      "loss": 0.3348,
      "step": 23544
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6964378952980042,
      "learning_rate": 5e-05,
      "loss": 0.3023,
      "step": 23552
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6206692457199097,
      "learning_rate": 5e-05,
      "loss": 0.3209,
      "step": 23560
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.5767272114753723,
      "learning_rate": 5e-05,
      "loss": 0.3193,
      "step": 23568
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6622503399848938,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 23576
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.6653673648834229,
      "learning_rate": 5e-05,
      "loss": 0.3314,
      "step": 23584
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.6471879482269287,
      "learning_rate": 5e-05,
      "loss": 0.3165,
      "step": 23592
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.7047211527824402,
      "learning_rate": 5e-05,
      "loss": 0.3319,
      "step": 23600
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.6453916430473328,
      "learning_rate": 5e-05,
      "loss": 0.3075,
      "step": 23608
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.6292461156845093,
      "learning_rate": 5e-05,
      "loss": 0.3016,
      "step": 23616
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.5707600116729736,
      "learning_rate": 5e-05,
      "loss": 0.3154,
      "step": 23624
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.6014758348464966,
      "learning_rate": 5e-05,
      "loss": 0.3018,
      "step": 23632
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.5470262169837952,
      "learning_rate": 5e-05,
      "loss": 0.2827,
      "step": 23640
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.7758357524871826,
      "learning_rate": 5e-05,
      "loss": 0.3339,
      "step": 23648
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.5839191675186157,
      "learning_rate": 5e-05,
      "loss": 0.2999,
      "step": 23656
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.7262893319129944,
      "learning_rate": 5e-05,
      "loss": 0.3231,
      "step": 23664
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.5126082897186279,
      "learning_rate": 5e-05,
      "loss": 0.2852,
      "step": 23672
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.6435227990150452,
      "learning_rate": 5e-05,
      "loss": 0.3303,
      "step": 23680
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.6636707782745361,
      "learning_rate": 5e-05,
      "loss": 0.3121,
      "step": 23688
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.9825278520584106,
      "learning_rate": 5e-05,
      "loss": 0.3204,
      "step": 23696
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.7749020457267761,
      "learning_rate": 5e-05,
      "loss": 0.3038,
      "step": 23704
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.6856971383094788,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 23712
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.7819997072219849,
      "learning_rate": 5e-05,
      "loss": 0.3233,
      "step": 23720
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.5728104710578918,
      "learning_rate": 5e-05,
      "loss": 0.3015,
      "step": 23728
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.7206695675849915,
      "learning_rate": 5e-05,
      "loss": 0.3448,
      "step": 23736
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.7732957601547241,
      "learning_rate": 5e-05,
      "loss": 0.3146,
      "step": 23744
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.7350946664810181,
      "learning_rate": 5e-05,
      "loss": 0.2997,
      "step": 23752
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6412501931190491,
      "learning_rate": 5e-05,
      "loss": 0.3218,
      "step": 23760
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6747321486473083,
      "learning_rate": 5e-05,
      "loss": 0.3247,
      "step": 23768
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6204986572265625,
      "learning_rate": 5e-05,
      "loss": 0.3315,
      "step": 23776
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6047306060791016,
      "learning_rate": 5e-05,
      "loss": 0.3764,
      "step": 23784
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.5683130025863647,
      "learning_rate": 5e-05,
      "loss": 0.3087,
      "step": 23792
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.5624969005584717,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 23800
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.538097083568573,
      "learning_rate": 5e-05,
      "loss": 0.3182,
      "step": 23808
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.2440425157546997,
      "learning_rate": 5e-05,
      "loss": 0.3196,
      "step": 23816
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6083279848098755,
      "learning_rate": 5e-05,
      "loss": 0.3333,
      "step": 23824
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.606069803237915,
      "learning_rate": 5e-05,
      "loss": 0.3075,
      "step": 23832
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6229044198989868,
      "learning_rate": 5e-05,
      "loss": 0.3272,
      "step": 23840
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6276721358299255,
      "learning_rate": 5e-05,
      "loss": 0.3012,
      "step": 23848
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6962409019470215,
      "learning_rate": 5e-05,
      "loss": 0.3396,
      "step": 23856
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6462481617927551,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 23864
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.5212982892990112,
      "learning_rate": 5e-05,
      "loss": 0.3286,
      "step": 23872
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6232880353927612,
      "learning_rate": 5e-05,
      "loss": 0.2866,
      "step": 23880
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6291355490684509,
      "learning_rate": 5e-05,
      "loss": 0.3425,
      "step": 23888
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6846427321434021,
      "learning_rate": 5e-05,
      "loss": 0.3288,
      "step": 23896
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6390888690948486,
      "learning_rate": 5e-05,
      "loss": 0.3007,
      "step": 23904
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6428018808364868,
      "learning_rate": 5e-05,
      "loss": 0.302,
      "step": 23912
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6559668183326721,
      "learning_rate": 5e-05,
      "loss": 0.3471,
      "step": 23920
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6838673949241638,
      "learning_rate": 5e-05,
      "loss": 0.3026,
      "step": 23928
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6036014556884766,
      "learning_rate": 5e-05,
      "loss": 0.3288,
      "step": 23936
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.7606208324432373,
      "learning_rate": 5e-05,
      "loss": 0.322,
      "step": 23944
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6520844101905823,
      "learning_rate": 5e-05,
      "loss": 0.305,
      "step": 23952
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6167389154434204,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 23960
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.7326699495315552,
      "learning_rate": 5e-05,
      "loss": 0.3269,
      "step": 23968
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.5651482939720154,
      "learning_rate": 5e-05,
      "loss": 0.3034,
      "step": 23976
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6700709462165833,
      "learning_rate": 5e-05,
      "loss": 0.3567,
      "step": 23984
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6500439047813416,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 23992
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6438978314399719,
      "learning_rate": 5e-05,
      "loss": 0.3274,
      "step": 24000
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6338285207748413,
      "learning_rate": 5e-05,
      "loss": 0.3205,
      "step": 24008
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.7199686169624329,
      "learning_rate": 5e-05,
      "loss": 0.3172,
      "step": 24016
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.5715189576148987,
      "learning_rate": 5e-05,
      "loss": 0.3057,
      "step": 24024
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.5965979099273682,
      "learning_rate": 5e-05,
      "loss": 0.3184,
      "step": 24032
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.5486901998519897,
      "learning_rate": 5e-05,
      "loss": 0.3072,
      "step": 24040
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6291071176528931,
      "learning_rate": 5e-05,
      "loss": 0.3234,
      "step": 24048
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.5814632177352905,
      "learning_rate": 5e-05,
      "loss": 0.3396,
      "step": 24056
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6498600244522095,
      "learning_rate": 5e-05,
      "loss": 0.3228,
      "step": 24064
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.7767634987831116,
      "learning_rate": 5e-05,
      "loss": 0.2986,
      "step": 24072
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.7111014723777771,
      "learning_rate": 5e-05,
      "loss": 0.3166,
      "step": 24080
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6857471466064453,
      "learning_rate": 5e-05,
      "loss": 0.2933,
      "step": 24088
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.5658106803894043,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 24096
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.5652326941490173,
      "learning_rate": 5e-05,
      "loss": 0.3244,
      "step": 24104
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.6930676102638245,
      "learning_rate": 5e-05,
      "loss": 0.315,
      "step": 24112
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.7258737087249756,
      "learning_rate": 5e-05,
      "loss": 0.329,
      "step": 24120
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.6722644567489624,
      "learning_rate": 5e-05,
      "loss": 0.3093,
      "step": 24128
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.5664290189743042,
      "learning_rate": 5e-05,
      "loss": 0.3164,
      "step": 24136
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.5893818140029907,
      "learning_rate": 5e-05,
      "loss": 0.3333,
      "step": 24144
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.6485434174537659,
      "learning_rate": 5e-05,
      "loss": 0.3021,
      "step": 24152
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.7334458231925964,
      "learning_rate": 5e-05,
      "loss": 0.3447,
      "step": 24160
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.5735777020454407,
      "learning_rate": 5e-05,
      "loss": 0.3058,
      "step": 24168
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.5637019872665405,
      "learning_rate": 5e-05,
      "loss": 0.284,
      "step": 24176
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.6217387318611145,
      "learning_rate": 5e-05,
      "loss": 0.3304,
      "step": 24184
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.5912405252456665,
      "learning_rate": 5e-05,
      "loss": 0.3106,
      "step": 24192
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.7052413821220398,
      "learning_rate": 5e-05,
      "loss": 0.2915,
      "step": 24200
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.5579752326011658,
      "learning_rate": 5e-05,
      "loss": 0.2931,
      "step": 24208
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.6131820678710938,
      "learning_rate": 5e-05,
      "loss": 0.304,
      "step": 24216
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.6828820109367371,
      "learning_rate": 5e-05,
      "loss": 0.3506,
      "step": 24224
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.6526604294776917,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 24232
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.5918784141540527,
      "learning_rate": 5e-05,
      "loss": 0.302,
      "step": 24240
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.6779679656028748,
      "learning_rate": 5e-05,
      "loss": 0.3437,
      "step": 24248
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.5980667471885681,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 24256
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.5172829627990723,
      "learning_rate": 5e-05,
      "loss": 0.2993,
      "step": 24264
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.6302407383918762,
      "learning_rate": 5e-05,
      "loss": 0.3281,
      "step": 24272
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.5668847560882568,
      "learning_rate": 5e-05,
      "loss": 0.2977,
      "step": 24280
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.7367182970046997,
      "learning_rate": 5e-05,
      "loss": 0.3319,
      "step": 24288
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.5943049788475037,
      "learning_rate": 5e-05,
      "loss": 0.3368,
      "step": 24296
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.5704874992370605,
      "learning_rate": 5e-05,
      "loss": 0.3378,
      "step": 24304
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.6254278421401978,
      "learning_rate": 5e-05,
      "loss": 0.3134,
      "step": 24312
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.6488733887672424,
      "learning_rate": 5e-05,
      "loss": 0.3435,
      "step": 24320
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.6500393748283386,
      "learning_rate": 5e-05,
      "loss": 0.3139,
      "step": 24328
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.5880823731422424,
      "learning_rate": 5e-05,
      "loss": 0.3249,
      "step": 24336
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.6747149229049683,
      "learning_rate": 5e-05,
      "loss": 0.3137,
      "step": 24344
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.2857855558395386,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 24352
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.6209638118743896,
      "learning_rate": 5e-05,
      "loss": 0.3448,
      "step": 24360
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.5390931367874146,
      "learning_rate": 5e-05,
      "loss": 0.3029,
      "step": 24368
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.6193819046020508,
      "learning_rate": 5e-05,
      "loss": 0.322,
      "step": 24376
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.5836267471313477,
      "learning_rate": 5e-05,
      "loss": 0.3098,
      "step": 24384
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.6846473217010498,
      "learning_rate": 5e-05,
      "loss": 0.2975,
      "step": 24392
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.8050580620765686,
      "learning_rate": 5e-05,
      "loss": 0.3315,
      "step": 24400
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.6375471949577332,
      "learning_rate": 5e-05,
      "loss": 0.3495,
      "step": 24408
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.6477015614509583,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 24416
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6451197266578674,
      "learning_rate": 5e-05,
      "loss": 0.292,
      "step": 24424
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6204867959022522,
      "learning_rate": 5e-05,
      "loss": 0.3115,
      "step": 24432
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6822680830955505,
      "learning_rate": 5e-05,
      "loss": 0.3145,
      "step": 24440
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6891095638275146,
      "learning_rate": 5e-05,
      "loss": 0.3173,
      "step": 24448
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.7572977542877197,
      "learning_rate": 5e-05,
      "loss": 0.3323,
      "step": 24456
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6264724135398865,
      "learning_rate": 5e-05,
      "loss": 0.3388,
      "step": 24464
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6030546426773071,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 24472
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.5915316343307495,
      "learning_rate": 5e-05,
      "loss": 0.315,
      "step": 24480
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6374817490577698,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 24488
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.7085617780685425,
      "learning_rate": 5e-05,
      "loss": 0.3237,
      "step": 24496
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.649808406829834,
      "learning_rate": 5e-05,
      "loss": 0.3313,
      "step": 24504
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6120245456695557,
      "learning_rate": 5e-05,
      "loss": 0.3316,
      "step": 24512
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6061294674873352,
      "learning_rate": 5e-05,
      "loss": 0.3168,
      "step": 24520
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.7755557894706726,
      "learning_rate": 5e-05,
      "loss": 0.3021,
      "step": 24528
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6865647435188293,
      "learning_rate": 5e-05,
      "loss": 0.3229,
      "step": 24536
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.7815207839012146,
      "learning_rate": 5e-05,
      "loss": 0.3055,
      "step": 24544
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6876839995384216,
      "learning_rate": 5e-05,
      "loss": 0.2994,
      "step": 24552
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6808369755744934,
      "learning_rate": 5e-05,
      "loss": 0.3064,
      "step": 24560
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.7577762603759766,
      "learning_rate": 5e-05,
      "loss": 0.3102,
      "step": 24568
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6299115419387817,
      "learning_rate": 5e-05,
      "loss": 0.3318,
      "step": 24576
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.6528868675231934,
      "learning_rate": 5e-05,
      "loss": 0.3238,
      "step": 24584
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.5759846568107605,
      "learning_rate": 5e-05,
      "loss": 0.2866,
      "step": 24592
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.6388801336288452,
      "learning_rate": 5e-05,
      "loss": 0.3323,
      "step": 24600
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.6496489644050598,
      "learning_rate": 5e-05,
      "loss": 0.2929,
      "step": 24608
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.7531707286834717,
      "learning_rate": 5e-05,
      "loss": 0.2954,
      "step": 24616
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.6260471940040588,
      "learning_rate": 5e-05,
      "loss": 0.2837,
      "step": 24624
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.6109731793403625,
      "learning_rate": 5e-05,
      "loss": 0.3448,
      "step": 24632
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.7522669434547424,
      "learning_rate": 5e-05,
      "loss": 0.3198,
      "step": 24640
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.5748236775398254,
      "learning_rate": 5e-05,
      "loss": 0.3127,
      "step": 24648
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.5824341773986816,
      "learning_rate": 5e-05,
      "loss": 0.3388,
      "step": 24656
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.6485515832901001,
      "learning_rate": 5e-05,
      "loss": 0.3291,
      "step": 24664
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.5897999405860901,
      "learning_rate": 5e-05,
      "loss": 0.3139,
      "step": 24672
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.5754304528236389,
      "learning_rate": 5e-05,
      "loss": 0.3249,
      "step": 24680
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.6934069991111755,
      "learning_rate": 5e-05,
      "loss": 0.3243,
      "step": 24688
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.7731755971908569,
      "learning_rate": 5e-05,
      "loss": 0.2881,
      "step": 24696
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.6727638840675354,
      "learning_rate": 5e-05,
      "loss": 0.3098,
      "step": 24704
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.582137405872345,
      "learning_rate": 5e-05,
      "loss": 0.3064,
      "step": 24712
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.5987858176231384,
      "learning_rate": 5e-05,
      "loss": 0.3232,
      "step": 24720
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.6802597045898438,
      "learning_rate": 5e-05,
      "loss": 0.3022,
      "step": 24728
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.5973870158195496,
      "learning_rate": 5e-05,
      "loss": 0.3249,
      "step": 24736
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.689396321773529,
      "learning_rate": 5e-05,
      "loss": 0.2943,
      "step": 24744
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.5533739328384399,
      "learning_rate": 5e-05,
      "loss": 0.3242,
      "step": 24752
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.5848171710968018,
      "learning_rate": 5e-05,
      "loss": 0.3325,
      "step": 24760
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.5910177826881409,
      "learning_rate": 5e-05,
      "loss": 0.3167,
      "step": 24768
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.5857303738594055,
      "learning_rate": 5e-05,
      "loss": 0.2985,
      "step": 24776
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.6041967868804932,
      "learning_rate": 5e-05,
      "loss": 0.3211,
      "step": 24784
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.7680990099906921,
      "learning_rate": 5e-05,
      "loss": 0.2932,
      "step": 24792
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.6159477233886719,
      "learning_rate": 5e-05,
      "loss": 0.3278,
      "step": 24800
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.5644744038581848,
      "learning_rate": 5e-05,
      "loss": 0.3352,
      "step": 24808
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.7286421060562134,
      "learning_rate": 5e-05,
      "loss": 0.2973,
      "step": 24816
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.605659008026123,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 24824
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.6188720464706421,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 24832
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.6067786812782288,
      "learning_rate": 5e-05,
      "loss": 0.3062,
      "step": 24840
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.5836741924285889,
      "learning_rate": 5e-05,
      "loss": 0.3132,
      "step": 24848
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.6813958287239075,
      "learning_rate": 5e-05,
      "loss": 0.3262,
      "step": 24856
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.6500716805458069,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 24864
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.6341405510902405,
      "learning_rate": 5e-05,
      "loss": 0.3065,
      "step": 24872
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.6529644131660461,
      "learning_rate": 5e-05,
      "loss": 0.3354,
      "step": 24880
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.6315616369247437,
      "learning_rate": 5e-05,
      "loss": 0.317,
      "step": 24888
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.6923650503158569,
      "learning_rate": 5e-05,
      "loss": 0.3315,
      "step": 24896
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.7581763863563538,
      "learning_rate": 5e-05,
      "loss": 0.3134,
      "step": 24904
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.811892032623291,
      "learning_rate": 5e-05,
      "loss": 0.3027,
      "step": 24912
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.6257121562957764,
      "learning_rate": 5e-05,
      "loss": 0.3498,
      "step": 24920
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.5677492022514343,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 24928
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.5564913153648376,
      "learning_rate": 5e-05,
      "loss": 0.3043,
      "step": 24936
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6602280139923096,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 24944
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6046156883239746,
      "learning_rate": 5e-05,
      "loss": 0.3103,
      "step": 24952
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6559615135192871,
      "learning_rate": 5e-05,
      "loss": 0.3301,
      "step": 24960
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.5763014554977417,
      "learning_rate": 5e-05,
      "loss": 0.3137,
      "step": 24968
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6128228902816772,
      "learning_rate": 5e-05,
      "loss": 0.3442,
      "step": 24976
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6483580470085144,
      "learning_rate": 5e-05,
      "loss": 0.3188,
      "step": 24984
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6475834846496582,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 24992
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.7605538368225098,
      "learning_rate": 5e-05,
      "loss": 0.3317,
      "step": 25000
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.712433397769928,
      "learning_rate": 5e-05,
      "loss": 0.312,
      "step": 25008
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6103757619857788,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 25016
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.637534499168396,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 25024
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.7400537729263306,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 25032
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6528500914573669,
      "learning_rate": 5e-05,
      "loss": 0.3248,
      "step": 25040
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.7275430560112,
      "learning_rate": 5e-05,
      "loss": 0.3149,
      "step": 25048
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6907097697257996,
      "learning_rate": 5e-05,
      "loss": 0.3452,
      "step": 25056
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.5619761943817139,
      "learning_rate": 5e-05,
      "loss": 0.3305,
      "step": 25064
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6076115369796753,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 25072
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6440783739089966,
      "learning_rate": 5e-05,
      "loss": 0.3292,
      "step": 25080
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.7166790962219238,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 25088
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.6176221370697021,
      "learning_rate": 5e-05,
      "loss": 0.3254,
      "step": 25096
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.7406349778175354,
      "learning_rate": 5e-05,
      "loss": 0.3292,
      "step": 25104
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.6187884211540222,
      "learning_rate": 5e-05,
      "loss": 0.3187,
      "step": 25112
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.7525786757469177,
      "learning_rate": 5e-05,
      "loss": 0.3034,
      "step": 25120
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.7190542817115784,
      "learning_rate": 5e-05,
      "loss": 0.3118,
      "step": 25128
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.6467105746269226,
      "learning_rate": 5e-05,
      "loss": 0.3205,
      "step": 25136
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.5529299974441528,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 25144
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.7173979878425598,
      "learning_rate": 5e-05,
      "loss": 0.3688,
      "step": 25152
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.5890571475028992,
      "learning_rate": 5e-05,
      "loss": 0.309,
      "step": 25160
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.6313536167144775,
      "learning_rate": 5e-05,
      "loss": 0.3252,
      "step": 25168
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.7024229168891907,
      "learning_rate": 5e-05,
      "loss": 0.284,
      "step": 25176
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.6998124122619629,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 25184
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.5319883823394775,
      "learning_rate": 5e-05,
      "loss": 0.3228,
      "step": 25192
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.6105920672416687,
      "learning_rate": 5e-05,
      "loss": 0.2969,
      "step": 25200
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.6719663143157959,
      "learning_rate": 5e-05,
      "loss": 0.3425,
      "step": 25208
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.6921279430389404,
      "learning_rate": 5e-05,
      "loss": 0.2854,
      "step": 25216
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.5460001230239868,
      "learning_rate": 5e-05,
      "loss": 0.3326,
      "step": 25224
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.567194938659668,
      "learning_rate": 5e-05,
      "loss": 0.306,
      "step": 25232
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.6553734540939331,
      "learning_rate": 5e-05,
      "loss": 0.3098,
      "step": 25240
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.0321539640426636,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 25248
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.633263349533081,
      "learning_rate": 5e-05,
      "loss": 0.3092,
      "step": 25256
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.8018788695335388,
      "learning_rate": 5e-05,
      "loss": 0.3059,
      "step": 25264
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.6466713547706604,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 25272
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.6242023706436157,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 25280
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.69382244348526,
      "learning_rate": 5e-05,
      "loss": 0.3278,
      "step": 25288
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.8578258156776428,
      "learning_rate": 5e-05,
      "loss": 0.3248,
      "step": 25296
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.5814095139503479,
      "learning_rate": 5e-05,
      "loss": 0.3537,
      "step": 25304
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.6939266324043274,
      "learning_rate": 5e-05,
      "loss": 0.3203,
      "step": 25312
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.6503327488899231,
      "learning_rate": 5e-05,
      "loss": 0.3338,
      "step": 25320
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.5883446335792542,
      "learning_rate": 5e-05,
      "loss": 0.3112,
      "step": 25328
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.5698954463005066,
      "learning_rate": 5e-05,
      "loss": 0.3201,
      "step": 25336
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.6777665019035339,
      "learning_rate": 5e-05,
      "loss": 0.2977,
      "step": 25344
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.6349390149116516,
      "learning_rate": 5e-05,
      "loss": 0.3021,
      "step": 25352
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.5697408318519592,
      "learning_rate": 5e-05,
      "loss": 0.2892,
      "step": 25360
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.6444800496101379,
      "learning_rate": 5e-05,
      "loss": 0.36,
      "step": 25368
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.6754322052001953,
      "learning_rate": 5e-05,
      "loss": 0.3204,
      "step": 25376
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.7372296452522278,
      "learning_rate": 5e-05,
      "loss": 0.3143,
      "step": 25384
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.5868456959724426,
      "learning_rate": 5e-05,
      "loss": 0.3366,
      "step": 25392
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.6672802567481995,
      "learning_rate": 5e-05,
      "loss": 0.3325,
      "step": 25400
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.7917467951774597,
      "learning_rate": 5e-05,
      "loss": 0.3418,
      "step": 25408
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.5652112364768982,
      "learning_rate": 5e-05,
      "loss": 0.3213,
      "step": 25416
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.7413793206214905,
      "learning_rate": 5e-05,
      "loss": 0.2949,
      "step": 25424
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.694398820400238,
      "learning_rate": 5e-05,
      "loss": 0.3395,
      "step": 25432
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.6701111793518066,
      "learning_rate": 5e-05,
      "loss": 0.3082,
      "step": 25440
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.791130542755127,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 25448
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.5881869792938232,
      "learning_rate": 5e-05,
      "loss": 0.3141,
      "step": 25456
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.7197648882865906,
      "learning_rate": 5e-05,
      "loss": 0.3257,
      "step": 25464
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.6036100387573242,
      "learning_rate": 5e-05,
      "loss": 0.3323,
      "step": 25472
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.6174517869949341,
      "learning_rate": 5e-05,
      "loss": 0.3248,
      "step": 25480
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.6747581958770752,
      "learning_rate": 5e-05,
      "loss": 0.3015,
      "step": 25488
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.589702308177948,
      "learning_rate": 5e-05,
      "loss": 0.3151,
      "step": 25496
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.8280117511749268,
      "learning_rate": 5e-05,
      "loss": 0.3127,
      "step": 25504
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.5557965636253357,
      "learning_rate": 5e-05,
      "loss": 0.35,
      "step": 25512
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.5606807470321655,
      "learning_rate": 5e-05,
      "loss": 0.3481,
      "step": 25520
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.6092622876167297,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 25528
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.7177866697311401,
      "learning_rate": 5e-05,
      "loss": 0.305,
      "step": 25536
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.6020527482032776,
      "learning_rate": 5e-05,
      "loss": 0.3193,
      "step": 25544
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.5700633525848389,
      "learning_rate": 5e-05,
      "loss": 0.2911,
      "step": 25552
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.8189939260482788,
      "learning_rate": 5e-05,
      "loss": 0.3011,
      "step": 25560
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.6749585866928101,
      "learning_rate": 5e-05,
      "loss": 0.3114,
      "step": 25568
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.7352584004402161,
      "learning_rate": 5e-05,
      "loss": 0.3301,
      "step": 25576
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.6260953545570374,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 25584
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.5878900289535522,
      "learning_rate": 5e-05,
      "loss": 0.3248,
      "step": 25592
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.6098287105560303,
      "learning_rate": 5e-05,
      "loss": 0.3194,
      "step": 25600
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.5806565880775452,
      "learning_rate": 5e-05,
      "loss": 0.303,
      "step": 25608
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.7256919741630554,
      "learning_rate": 5e-05,
      "loss": 0.3192,
      "step": 25616
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.615720272064209,
      "learning_rate": 5e-05,
      "loss": 0.3061,
      "step": 25624
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.6142781376838684,
      "learning_rate": 5e-05,
      "loss": 0.2963,
      "step": 25632
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.6575296521186829,
      "learning_rate": 5e-05,
      "loss": 0.3056,
      "step": 25640
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.6381433010101318,
      "learning_rate": 5e-05,
      "loss": 0.3312,
      "step": 25648
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.601358950138092,
      "learning_rate": 5e-05,
      "loss": 0.3013,
      "step": 25656
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.6085029244422913,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 25664
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.73917555809021,
      "learning_rate": 5e-05,
      "loss": 0.3063,
      "step": 25672
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.7229726314544678,
      "learning_rate": 5e-05,
      "loss": 0.3038,
      "step": 25680
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.5810896158218384,
      "learning_rate": 5e-05,
      "loss": 0.3141,
      "step": 25688
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.5982263088226318,
      "learning_rate": 5e-05,
      "loss": 0.2919,
      "step": 25696
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.5711809396743774,
      "learning_rate": 5e-05,
      "loss": 0.2843,
      "step": 25704
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.5646281838417053,
      "learning_rate": 5e-05,
      "loss": 0.2794,
      "step": 25712
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.6074838638305664,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 25720
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.6317183375358582,
      "learning_rate": 5e-05,
      "loss": 0.35,
      "step": 25728
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.6044291853904724,
      "learning_rate": 5e-05,
      "loss": 0.3363,
      "step": 25736
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.6297601461410522,
      "learning_rate": 5e-05,
      "loss": 0.3246,
      "step": 25744
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.6464189291000366,
      "learning_rate": 5e-05,
      "loss": 0.3395,
      "step": 25752
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6094602346420288,
      "learning_rate": 5e-05,
      "loss": 0.3298,
      "step": 25760
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6111010313034058,
      "learning_rate": 5e-05,
      "loss": 0.3186,
      "step": 25768
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6178836226463318,
      "learning_rate": 5e-05,
      "loss": 0.3231,
      "step": 25776
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6591690182685852,
      "learning_rate": 5e-05,
      "loss": 0.2931,
      "step": 25784
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6690966486930847,
      "learning_rate": 5e-05,
      "loss": 0.322,
      "step": 25792
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6396953463554382,
      "learning_rate": 5e-05,
      "loss": 0.3211,
      "step": 25800
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6835767030715942,
      "learning_rate": 5e-05,
      "loss": 0.3218,
      "step": 25808
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6270939707756042,
      "learning_rate": 5e-05,
      "loss": 0.305,
      "step": 25816
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6560315489768982,
      "learning_rate": 5e-05,
      "loss": 0.3113,
      "step": 25824
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6549620032310486,
      "learning_rate": 5e-05,
      "loss": 0.3245,
      "step": 25832
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6082305908203125,
      "learning_rate": 5e-05,
      "loss": 0.2922,
      "step": 25840
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.602920413017273,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 25848
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6252354979515076,
      "learning_rate": 5e-05,
      "loss": 0.3096,
      "step": 25856
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.5852678418159485,
      "learning_rate": 5e-05,
      "loss": 0.3172,
      "step": 25864
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.5959461331367493,
      "learning_rate": 5e-05,
      "loss": 0.3478,
      "step": 25872
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6128203272819519,
      "learning_rate": 5e-05,
      "loss": 0.3023,
      "step": 25880
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6113787889480591,
      "learning_rate": 5e-05,
      "loss": 0.3056,
      "step": 25888
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6012331247329712,
      "learning_rate": 5e-05,
      "loss": 0.3421,
      "step": 25896
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6818694472312927,
      "learning_rate": 5e-05,
      "loss": 0.3249,
      "step": 25904
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6416240334510803,
      "learning_rate": 5e-05,
      "loss": 0.3001,
      "step": 25912
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.6629180312156677,
      "learning_rate": 5e-05,
      "loss": 0.3158,
      "step": 25920
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.6473401188850403,
      "learning_rate": 5e-05,
      "loss": 0.3081,
      "step": 25928
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.6179255247116089,
      "learning_rate": 5e-05,
      "loss": 0.3269,
      "step": 25936
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.6170387864112854,
      "learning_rate": 5e-05,
      "loss": 0.3099,
      "step": 25944
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.8794932961463928,
      "learning_rate": 5e-05,
      "loss": 0.3639,
      "step": 25952
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.5507493615150452,
      "learning_rate": 5e-05,
      "loss": 0.3414,
      "step": 25960
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.7770687937736511,
      "learning_rate": 5e-05,
      "loss": 0.2575,
      "step": 25968
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.650164008140564,
      "learning_rate": 5e-05,
      "loss": 0.3259,
      "step": 25976
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.5815842151641846,
      "learning_rate": 5e-05,
      "loss": 0.3343,
      "step": 25984
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.6039992570877075,
      "learning_rate": 5e-05,
      "loss": 0.3094,
      "step": 25992
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.5597113370895386,
      "learning_rate": 5e-05,
      "loss": 0.3298,
      "step": 26000
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.6189249753952026,
      "learning_rate": 5e-05,
      "loss": 0.3358,
      "step": 26008
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.6301261782646179,
      "learning_rate": 5e-05,
      "loss": 0.3252,
      "step": 26016
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.6135499477386475,
      "learning_rate": 5e-05,
      "loss": 0.3295,
      "step": 26024
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.7246742844581604,
      "learning_rate": 5e-05,
      "loss": 0.3577,
      "step": 26032
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.7548863887786865,
      "learning_rate": 5e-05,
      "loss": 0.3058,
      "step": 26040
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.6186677813529968,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 26048
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.6639878153800964,
      "learning_rate": 5e-05,
      "loss": 0.3021,
      "step": 26056
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.5810321569442749,
      "learning_rate": 5e-05,
      "loss": 0.317,
      "step": 26064
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.5635711550712585,
      "learning_rate": 5e-05,
      "loss": 0.3226,
      "step": 26072
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.64654541015625,
      "learning_rate": 5e-05,
      "loss": 0.3009,
      "step": 26080
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.5733721256256104,
      "learning_rate": 5e-05,
      "loss": 0.3195,
      "step": 26088
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.7721582055091858,
      "learning_rate": 5e-05,
      "loss": 0.2943,
      "step": 26096
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.7561105489730835,
      "learning_rate": 5e-05,
      "loss": 0.2846,
      "step": 26104
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.6084054112434387,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 26112
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.6070255041122437,
      "learning_rate": 5e-05,
      "loss": 0.2992,
      "step": 26120
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.6201529502868652,
      "learning_rate": 5e-05,
      "loss": 0.298,
      "step": 26128
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.7439223527908325,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 26136
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.5691273808479309,
      "learning_rate": 5e-05,
      "loss": 0.3143,
      "step": 26144
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.5659882426261902,
      "learning_rate": 5e-05,
      "loss": 0.3092,
      "step": 26152
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.7105140686035156,
      "learning_rate": 5e-05,
      "loss": 0.3087,
      "step": 26160
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.6289020776748657,
      "learning_rate": 5e-05,
      "loss": 0.3069,
      "step": 26168
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.6811993718147278,
      "learning_rate": 5e-05,
      "loss": 0.3362,
      "step": 26176
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.7935921549797058,
      "learning_rate": 5e-05,
      "loss": 0.3017,
      "step": 26184
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.6541469693183899,
      "learning_rate": 5e-05,
      "loss": 0.3142,
      "step": 26192
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.6597734093666077,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 26200
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.6298665404319763,
      "learning_rate": 5e-05,
      "loss": 0.3449,
      "step": 26208
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.5878270268440247,
      "learning_rate": 5e-05,
      "loss": 0.3069,
      "step": 26216
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.5417410135269165,
      "learning_rate": 5e-05,
      "loss": 0.3139,
      "step": 26224
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.5914445519447327,
      "learning_rate": 5e-05,
      "loss": 0.3177,
      "step": 26232
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.5604099035263062,
      "learning_rate": 5e-05,
      "loss": 0.3011,
      "step": 26240
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.526957631111145,
      "learning_rate": 5e-05,
      "loss": 0.313,
      "step": 26248
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.6724886298179626,
      "learning_rate": 5e-05,
      "loss": 0.2961,
      "step": 26256
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.648925244808197,
      "learning_rate": 5e-05,
      "loss": 0.3151,
      "step": 26264
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.5938622951507568,
      "learning_rate": 5e-05,
      "loss": 0.2974,
      "step": 26272
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.6185329556465149,
      "learning_rate": 5e-05,
      "loss": 0.3225,
      "step": 26280
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.625770628452301,
      "learning_rate": 5e-05,
      "loss": 0.3064,
      "step": 26288
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.6599960923194885,
      "learning_rate": 5e-05,
      "loss": 0.2872,
      "step": 26296
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.6993292570114136,
      "learning_rate": 5e-05,
      "loss": 0.3174,
      "step": 26304
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.6630242466926575,
      "learning_rate": 5e-05,
      "loss": 0.2868,
      "step": 26312
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.6061259508132935,
      "learning_rate": 5e-05,
      "loss": 0.3002,
      "step": 26320
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.5673655271530151,
      "learning_rate": 5e-05,
      "loss": 0.3026,
      "step": 26328
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.6798611283302307,
      "learning_rate": 5e-05,
      "loss": 0.307,
      "step": 26336
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.6029176712036133,
      "learning_rate": 5e-05,
      "loss": 0.3036,
      "step": 26344
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.6300434470176697,
      "learning_rate": 5e-05,
      "loss": 0.3112,
      "step": 26352
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.6371793150901794,
      "learning_rate": 5e-05,
      "loss": 0.3156,
      "step": 26360
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.5977498888969421,
      "learning_rate": 5e-05,
      "loss": 0.296,
      "step": 26368
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.5991979241371155,
      "learning_rate": 5e-05,
      "loss": 0.3207,
      "step": 26376
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.5667784214019775,
      "learning_rate": 5e-05,
      "loss": 0.3027,
      "step": 26384
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.5530774593353271,
      "learning_rate": 5e-05,
      "loss": 0.3055,
      "step": 26392
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.5445090532302856,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 26400
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.5668367147445679,
      "learning_rate": 5e-05,
      "loss": 0.3026,
      "step": 26408
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.7076097726821899,
      "learning_rate": 5e-05,
      "loss": 0.3046,
      "step": 26416
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.5357525944709778,
      "learning_rate": 5e-05,
      "loss": 0.3054,
      "step": 26424
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.6725683212280273,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 26432
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.5690991282463074,
      "learning_rate": 5e-05,
      "loss": 0.3202,
      "step": 26440
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.5814844369888306,
      "learning_rate": 5e-05,
      "loss": 0.3265,
      "step": 26448
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.5597388744354248,
      "learning_rate": 5e-05,
      "loss": 0.3103,
      "step": 26456
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.7331256866455078,
      "learning_rate": 5e-05,
      "loss": 0.3135,
      "step": 26464
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.6336910128593445,
      "learning_rate": 5e-05,
      "loss": 0.3105,
      "step": 26472
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.49892333149909973,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 26480
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.6013844013214111,
      "learning_rate": 5e-05,
      "loss": 0.2766,
      "step": 26488
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.6914038062095642,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 26496
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.636955738067627,
      "learning_rate": 5e-05,
      "loss": 0.3352,
      "step": 26504
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.6072850823402405,
      "learning_rate": 5e-05,
      "loss": 0.3354,
      "step": 26512
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.6017518639564514,
      "learning_rate": 5e-05,
      "loss": 0.2868,
      "step": 26520
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.6688035130500793,
      "learning_rate": 5e-05,
      "loss": 0.3351,
      "step": 26528
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.6487556099891663,
      "learning_rate": 5e-05,
      "loss": 0.3046,
      "step": 26536
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.7118021845817566,
      "learning_rate": 5e-05,
      "loss": 0.3201,
      "step": 26544
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.6856042146682739,
      "learning_rate": 5e-05,
      "loss": 0.3219,
      "step": 26552
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.5700302124023438,
      "learning_rate": 5e-05,
      "loss": 0.2983,
      "step": 26560
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.5732972621917725,
      "learning_rate": 5e-05,
      "loss": 0.3262,
      "step": 26568
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.6117902398109436,
      "learning_rate": 5e-05,
      "loss": 0.3272,
      "step": 26576
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.680054247379303,
      "learning_rate": 5e-05,
      "loss": 0.2925,
      "step": 26584
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.5396626591682434,
      "learning_rate": 5e-05,
      "loss": 0.3178,
      "step": 26592
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6297827959060669,
      "learning_rate": 5e-05,
      "loss": 0.2835,
      "step": 26600
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.7768752574920654,
      "learning_rate": 5e-05,
      "loss": 0.3155,
      "step": 26608
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.5731855034828186,
      "learning_rate": 5e-05,
      "loss": 0.3025,
      "step": 26616
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.7187254428863525,
      "learning_rate": 5e-05,
      "loss": 0.3018,
      "step": 26624
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.9295083284378052,
      "learning_rate": 5e-05,
      "loss": 0.3056,
      "step": 26632
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.5788768529891968,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 26640
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6363678574562073,
      "learning_rate": 5e-05,
      "loss": 0.3426,
      "step": 26648
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6948202848434448,
      "learning_rate": 5e-05,
      "loss": 0.3078,
      "step": 26656
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6183127760887146,
      "learning_rate": 5e-05,
      "loss": 0.3426,
      "step": 26664
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6638079881668091,
      "learning_rate": 5e-05,
      "loss": 0.3014,
      "step": 26672
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6659684777259827,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 26680
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6714146137237549,
      "learning_rate": 5e-05,
      "loss": 0.3254,
      "step": 26688
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.8434998989105225,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 26696
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.5718343257904053,
      "learning_rate": 5e-05,
      "loss": 0.319,
      "step": 26704
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.5577982664108276,
      "learning_rate": 5e-05,
      "loss": 0.315,
      "step": 26712
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.7135945558547974,
      "learning_rate": 5e-05,
      "loss": 0.3302,
      "step": 26720
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6419031620025635,
      "learning_rate": 5e-05,
      "loss": 0.3317,
      "step": 26728
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6712266206741333,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 26736
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.7477277517318726,
      "learning_rate": 5e-05,
      "loss": 0.2915,
      "step": 26744
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6250712275505066,
      "learning_rate": 5e-05,
      "loss": 0.2882,
      "step": 26752
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.5929536819458008,
      "learning_rate": 5e-05,
      "loss": 0.3016,
      "step": 26760
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6270849108695984,
      "learning_rate": 5e-05,
      "loss": 0.3336,
      "step": 26768
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6106846928596497,
      "learning_rate": 5e-05,
      "loss": 0.319,
      "step": 26776
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6000837683677673,
      "learning_rate": 5e-05,
      "loss": 0.3537,
      "step": 26784
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6116468906402588,
      "learning_rate": 5e-05,
      "loss": 0.332,
      "step": 26792
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6188308000564575,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 26800
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6510278582572937,
      "learning_rate": 5e-05,
      "loss": 0.2998,
      "step": 26808
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6034080982208252,
      "learning_rate": 5e-05,
      "loss": 0.3271,
      "step": 26816
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6998815536499023,
      "learning_rate": 5e-05,
      "loss": 0.3073,
      "step": 26824
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6779308915138245,
      "learning_rate": 5e-05,
      "loss": 0.3129,
      "step": 26832
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6385970115661621,
      "learning_rate": 5e-05,
      "loss": 0.3298,
      "step": 26840
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.7986817359924316,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 26848
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.5741000175476074,
      "learning_rate": 5e-05,
      "loss": 0.3134,
      "step": 26856
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6279051899909973,
      "learning_rate": 5e-05,
      "loss": 0.3561,
      "step": 26864
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6079882979393005,
      "learning_rate": 5e-05,
      "loss": 0.3093,
      "step": 26872
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.5940911173820496,
      "learning_rate": 5e-05,
      "loss": 0.3027,
      "step": 26880
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6477941870689392,
      "learning_rate": 5e-05,
      "loss": 0.3034,
      "step": 26888
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6606571078300476,
      "learning_rate": 5e-05,
      "loss": 0.3028,
      "step": 26896
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.6252696514129639,
      "learning_rate": 5e-05,
      "loss": 0.2972,
      "step": 26904
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.5725738406181335,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 26912
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.5135425329208374,
      "learning_rate": 5e-05,
      "loss": 0.2996,
      "step": 26920
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.7748581767082214,
      "learning_rate": 5e-05,
      "loss": 0.3079,
      "step": 26928
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.6451119780540466,
      "learning_rate": 5e-05,
      "loss": 0.2944,
      "step": 26936
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.5886919498443604,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 26944
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.6367959976196289,
      "learning_rate": 5e-05,
      "loss": 0.3154,
      "step": 26952
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.6864711046218872,
      "learning_rate": 5e-05,
      "loss": 0.2948,
      "step": 26960
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.8280400037765503,
      "learning_rate": 5e-05,
      "loss": 0.2827,
      "step": 26968
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.6812787055969238,
      "learning_rate": 5e-05,
      "loss": 0.3082,
      "step": 26976
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.7793423533439636,
      "learning_rate": 5e-05,
      "loss": 0.2992,
      "step": 26984
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.6729627251625061,
      "learning_rate": 5e-05,
      "loss": 0.3444,
      "step": 26992
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.8527328968048096,
      "learning_rate": 5e-05,
      "loss": 0.3371,
      "step": 27000
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.5883289575576782,
      "learning_rate": 5e-05,
      "loss": 0.3297,
      "step": 27008
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.7372667789459229,
      "learning_rate": 5e-05,
      "loss": 0.3259,
      "step": 27016
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.5767961740493774,
      "learning_rate": 5e-05,
      "loss": 0.3256,
      "step": 27024
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.5691516995429993,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 27032
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.6375085711479187,
      "learning_rate": 5e-05,
      "loss": 0.3158,
      "step": 27040
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.6437914371490479,
      "learning_rate": 5e-05,
      "loss": 0.3144,
      "step": 27048
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.031503438949585,
      "learning_rate": 5e-05,
      "loss": 0.3415,
      "step": 27056
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.6868962645530701,
      "learning_rate": 5e-05,
      "loss": 0.3105,
      "step": 27064
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.5653349757194519,
      "learning_rate": 5e-05,
      "loss": 0.2957,
      "step": 27072
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.9408223628997803,
      "learning_rate": 5e-05,
      "loss": 0.3596,
      "step": 27080
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.6456188559532166,
      "learning_rate": 5e-05,
      "loss": 0.2943,
      "step": 27088
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.628518283367157,
      "learning_rate": 5e-05,
      "loss": 0.2901,
      "step": 27096
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.5565946102142334,
      "learning_rate": 5e-05,
      "loss": 0.3184,
      "step": 27104
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.6722931265830994,
      "learning_rate": 5e-05,
      "loss": 0.3127,
      "step": 27112
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.588043212890625,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 27120
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.5946363806724548,
      "learning_rate": 5e-05,
      "loss": 0.3407,
      "step": 27128
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.6031844019889832,
      "learning_rate": 5e-05,
      "loss": 0.2851,
      "step": 27136
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.61905837059021,
      "learning_rate": 5e-05,
      "loss": 0.3112,
      "step": 27144
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.7015725374221802,
      "learning_rate": 5e-05,
      "loss": 0.3134,
      "step": 27152
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.5840235352516174,
      "learning_rate": 5e-05,
      "loss": 0.3299,
      "step": 27160
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.5944421887397766,
      "learning_rate": 5e-05,
      "loss": 0.3113,
      "step": 27168
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.5731068253517151,
      "learning_rate": 5e-05,
      "loss": 0.2904,
      "step": 27176
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.5874670743942261,
      "learning_rate": 5e-05,
      "loss": 0.3149,
      "step": 27184
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.6408411264419556,
      "learning_rate": 5e-05,
      "loss": 0.3003,
      "step": 27192
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.7206549644470215,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 27200
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.6527189612388611,
      "learning_rate": 5e-05,
      "loss": 0.3249,
      "step": 27208
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.6009557247161865,
      "learning_rate": 5e-05,
      "loss": 0.3025,
      "step": 27216
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.6878330707550049,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 27224
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.6476351022720337,
      "learning_rate": 5e-05,
      "loss": 0.3203,
      "step": 27232
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.6860812306404114,
      "learning_rate": 5e-05,
      "loss": 0.3392,
      "step": 27240
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.5366201400756836,
      "learning_rate": 5e-05,
      "loss": 0.3276,
      "step": 27248
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.5862113237380981,
      "learning_rate": 5e-05,
      "loss": 0.2987,
      "step": 27256
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.6355146765708923,
      "learning_rate": 5e-05,
      "loss": 0.3254,
      "step": 27264
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.6646900177001953,
      "learning_rate": 5e-05,
      "loss": 0.3286,
      "step": 27272
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.6358533501625061,
      "learning_rate": 5e-05,
      "loss": 0.3408,
      "step": 27280
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.6279218196868896,
      "learning_rate": 5e-05,
      "loss": 0.2983,
      "step": 27288
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.615812361240387,
      "learning_rate": 5e-05,
      "loss": 0.3141,
      "step": 27296
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.6992418766021729,
      "learning_rate": 5e-05,
      "loss": 0.2979,
      "step": 27304
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.7679601311683655,
      "learning_rate": 5e-05,
      "loss": 0.3246,
      "step": 27312
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.5825555920600891,
      "learning_rate": 5e-05,
      "loss": 0.289,
      "step": 27320
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.663042426109314,
      "learning_rate": 5e-05,
      "loss": 0.3305,
      "step": 27328
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.6535875201225281,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 27336
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.6372026205062866,
      "learning_rate": 5e-05,
      "loss": 0.3235,
      "step": 27344
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.6223599910736084,
      "learning_rate": 5e-05,
      "loss": 0.313,
      "step": 27352
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.6686467528343201,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 27360
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.6195822954177856,
      "learning_rate": 5e-05,
      "loss": 0.3146,
      "step": 27368
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.6145183444023132,
      "learning_rate": 5e-05,
      "loss": 0.2895,
      "step": 27376
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.5951083302497864,
      "learning_rate": 5e-05,
      "loss": 0.2931,
      "step": 27384
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.6955678462982178,
      "learning_rate": 5e-05,
      "loss": 0.3271,
      "step": 27392
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.5331243872642517,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 27400
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.775313138961792,
      "learning_rate": 5e-05,
      "loss": 0.2968,
      "step": 27408
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.5848724246025085,
      "learning_rate": 5e-05,
      "loss": 0.3161,
      "step": 27416
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6732968091964722,
      "learning_rate": 5e-05,
      "loss": 0.3006,
      "step": 27424
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6522772312164307,
      "learning_rate": 5e-05,
      "loss": 0.3001,
      "step": 27432
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6131724715232849,
      "learning_rate": 5e-05,
      "loss": 0.3451,
      "step": 27440
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.5491039752960205,
      "learning_rate": 5e-05,
      "loss": 0.3257,
      "step": 27448
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6769136190414429,
      "learning_rate": 5e-05,
      "loss": 0.3226,
      "step": 27456
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.5486021041870117,
      "learning_rate": 5e-05,
      "loss": 0.3119,
      "step": 27464
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.7044582366943359,
      "learning_rate": 5e-05,
      "loss": 0.3192,
      "step": 27472
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6090224981307983,
      "learning_rate": 5e-05,
      "loss": 0.2884,
      "step": 27480
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6594741940498352,
      "learning_rate": 5e-05,
      "loss": 0.3062,
      "step": 27488
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6175256371498108,
      "learning_rate": 5e-05,
      "loss": 0.3086,
      "step": 27496
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.5988039970397949,
      "learning_rate": 5e-05,
      "loss": 0.2811,
      "step": 27504
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6518938541412354,
      "learning_rate": 5e-05,
      "loss": 0.3331,
      "step": 27512
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6108670234680176,
      "learning_rate": 5e-05,
      "loss": 0.3226,
      "step": 27520
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6096616983413696,
      "learning_rate": 5e-05,
      "loss": 0.2947,
      "step": 27528
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6564627885818481,
      "learning_rate": 5e-05,
      "loss": 0.3294,
      "step": 27536
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.67153400182724,
      "learning_rate": 5e-05,
      "loss": 0.3368,
      "step": 27544
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6988822221755981,
      "learning_rate": 5e-05,
      "loss": 0.3069,
      "step": 27552
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.5872198343276978,
      "learning_rate": 5e-05,
      "loss": 0.3386,
      "step": 27560
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6661990880966187,
      "learning_rate": 5e-05,
      "loss": 0.3353,
      "step": 27568
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6534371376037598,
      "learning_rate": 5e-05,
      "loss": 0.3249,
      "step": 27576
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.7826158404350281,
      "learning_rate": 5e-05,
      "loss": 0.3037,
      "step": 27584
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.574924647808075,
      "learning_rate": 5e-05,
      "loss": 0.3341,
      "step": 27592
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.8443357944488525,
      "learning_rate": 5e-05,
      "loss": 0.3188,
      "step": 27600
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.635148286819458,
      "learning_rate": 5e-05,
      "loss": 0.3217,
      "step": 27608
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.7471671104431152,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 27616
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.6282055974006653,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 27624
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.7445107698440552,
      "learning_rate": 5e-05,
      "loss": 0.3438,
      "step": 27632
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.7365455031394958,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 27640
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.5597612261772156,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 27648
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.6184085607528687,
      "learning_rate": 5e-05,
      "loss": 0.3303,
      "step": 27656
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.662408709526062,
      "learning_rate": 5e-05,
      "loss": 0.2909,
      "step": 27664
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.6277411580085754,
      "learning_rate": 5e-05,
      "loss": 0.3021,
      "step": 27672
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.6549043655395508,
      "learning_rate": 5e-05,
      "loss": 0.3305,
      "step": 27680
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.5284518599510193,
      "learning_rate": 5e-05,
      "loss": 0.2992,
      "step": 27688
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.6269926428794861,
      "learning_rate": 5e-05,
      "loss": 0.3188,
      "step": 27696
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.5269540548324585,
      "learning_rate": 5e-05,
      "loss": 0.3324,
      "step": 27704
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.5919078588485718,
      "learning_rate": 5e-05,
      "loss": 0.3065,
      "step": 27712
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.7476324439048767,
      "learning_rate": 5e-05,
      "loss": 0.3102,
      "step": 27720
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.5580466985702515,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 27728
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.5834406614303589,
      "learning_rate": 5e-05,
      "loss": 0.3234,
      "step": 27736
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.7367151379585266,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 27744
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.8047782182693481,
      "learning_rate": 5e-05,
      "loss": 0.305,
      "step": 27752
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.5701693892478943,
      "learning_rate": 5e-05,
      "loss": 0.3181,
      "step": 27760
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6565514802932739,
      "learning_rate": 5e-05,
      "loss": 0.2925,
      "step": 27768
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.5738652348518372,
      "learning_rate": 5e-05,
      "loss": 0.3127,
      "step": 27776
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6641528606414795,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 27784
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6144148111343384,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 27792
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6817612051963806,
      "learning_rate": 5e-05,
      "loss": 0.3392,
      "step": 27800
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6260988712310791,
      "learning_rate": 5e-05,
      "loss": 0.3426,
      "step": 27808
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.7017664313316345,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 27816
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6395590901374817,
      "learning_rate": 5e-05,
      "loss": 0.3367,
      "step": 27824
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6883029341697693,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 27832
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6830323934555054,
      "learning_rate": 5e-05,
      "loss": 0.3185,
      "step": 27840
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.7417519688606262,
      "learning_rate": 5e-05,
      "loss": 0.3082,
      "step": 27848
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.55925053358078,
      "learning_rate": 5e-05,
      "loss": 0.3182,
      "step": 27856
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6159367561340332,
      "learning_rate": 5e-05,
      "loss": 0.2703,
      "step": 27864
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.5784006118774414,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 27872
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6154285073280334,
      "learning_rate": 5e-05,
      "loss": 0.3345,
      "step": 27880
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.7728115320205688,
      "learning_rate": 5e-05,
      "loss": 0.3148,
      "step": 27888
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6419273614883423,
      "learning_rate": 5e-05,
      "loss": 0.3535,
      "step": 27896
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6209288835525513,
      "learning_rate": 5e-05,
      "loss": 0.3018,
      "step": 27904
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6557580232620239,
      "learning_rate": 5e-05,
      "loss": 0.3037,
      "step": 27912
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.6299932599067688,
      "learning_rate": 5e-05,
      "loss": 0.3184,
      "step": 27920
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.49127086997032166,
      "learning_rate": 5e-05,
      "loss": 0.2907,
      "step": 27928
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.6345114707946777,
      "learning_rate": 5e-05,
      "loss": 0.308,
      "step": 27936
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.6239076852798462,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 27944
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.630705714225769,
      "learning_rate": 5e-05,
      "loss": 0.3114,
      "step": 27952
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.6366379857063293,
      "learning_rate": 5e-05,
      "loss": 0.2868,
      "step": 27960
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.617895245552063,
      "learning_rate": 5e-05,
      "loss": 0.2713,
      "step": 27968
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.6430030465126038,
      "learning_rate": 5e-05,
      "loss": 0.3015,
      "step": 27976
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.6809647083282471,
      "learning_rate": 5e-05,
      "loss": 0.3011,
      "step": 27984
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.6497918367385864,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 27992
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.6217653751373291,
      "learning_rate": 5e-05,
      "loss": 0.3416,
      "step": 28000
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.7092654705047607,
      "learning_rate": 5e-05,
      "loss": 0.3104,
      "step": 28008
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.7252718210220337,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 28016
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.6388052701950073,
      "learning_rate": 5e-05,
      "loss": 0.2876,
      "step": 28024
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.6388800740242004,
      "learning_rate": 5e-05,
      "loss": 0.3324,
      "step": 28032
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.5536336898803711,
      "learning_rate": 5e-05,
      "loss": 0.2981,
      "step": 28040
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.7698363065719604,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 28048
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.688959002494812,
      "learning_rate": 5e-05,
      "loss": 0.3145,
      "step": 28056
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.7656956315040588,
      "learning_rate": 5e-05,
      "loss": 0.3201,
      "step": 28064
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.6216738820075989,
      "learning_rate": 5e-05,
      "loss": 0.3166,
      "step": 28072
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.5405669212341309,
      "learning_rate": 5e-05,
      "loss": 0.3116,
      "step": 28080
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.7516199946403503,
      "learning_rate": 5e-05,
      "loss": 0.3328,
      "step": 28088
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6296257376670837,
      "learning_rate": 5e-05,
      "loss": 0.297,
      "step": 28096
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6652750372886658,
      "learning_rate": 5e-05,
      "loss": 0.3063,
      "step": 28104
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.5836007595062256,
      "learning_rate": 5e-05,
      "loss": 0.2987,
      "step": 28112
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6342441439628601,
      "learning_rate": 5e-05,
      "loss": 0.303,
      "step": 28120
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.567289412021637,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 28128
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.5878049731254578,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 28136
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.7038331031799316,
      "learning_rate": 5e-05,
      "loss": 0.2802,
      "step": 28144
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6230785846710205,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 28152
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6503322124481201,
      "learning_rate": 5e-05,
      "loss": 0.3377,
      "step": 28160
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6216621398925781,
      "learning_rate": 5e-05,
      "loss": 0.291,
      "step": 28168
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6021580100059509,
      "learning_rate": 5e-05,
      "loss": 0.2886,
      "step": 28176
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6127462387084961,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 28184
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6112726330757141,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 28192
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.8285074830055237,
      "learning_rate": 5e-05,
      "loss": 0.2993,
      "step": 28200
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6346246600151062,
      "learning_rate": 5e-05,
      "loss": 0.3211,
      "step": 28208
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.5591272115707397,
      "learning_rate": 5e-05,
      "loss": 0.312,
      "step": 28216
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.5669580101966858,
      "learning_rate": 5e-05,
      "loss": 0.3456,
      "step": 28224
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.5770649313926697,
      "learning_rate": 5e-05,
      "loss": 0.2989,
      "step": 28232
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6362344622612,
      "learning_rate": 5e-05,
      "loss": 0.3377,
      "step": 28240
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.6749422550201416,
      "learning_rate": 5e-05,
      "loss": 0.2916,
      "step": 28248
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6553279161453247,
      "learning_rate": 5e-05,
      "loss": 0.3355,
      "step": 28256
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.5418240427970886,
      "learning_rate": 5e-05,
      "loss": 0.3221,
      "step": 28264
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6336144208908081,
      "learning_rate": 5e-05,
      "loss": 0.3193,
      "step": 28272
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.7876344919204712,
      "learning_rate": 5e-05,
      "loss": 0.3057,
      "step": 28280
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6224931478500366,
      "learning_rate": 5e-05,
      "loss": 0.3296,
      "step": 28288
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.5905778408050537,
      "learning_rate": 5e-05,
      "loss": 0.3154,
      "step": 28296
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6211386322975159,
      "learning_rate": 5e-05,
      "loss": 0.3343,
      "step": 28304
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6601009368896484,
      "learning_rate": 5e-05,
      "loss": 0.3239,
      "step": 28312
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6335617303848267,
      "learning_rate": 5e-05,
      "loss": 0.3199,
      "step": 28320
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.5808601379394531,
      "learning_rate": 5e-05,
      "loss": 0.2872,
      "step": 28328
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.4609406888484955,
      "learning_rate": 5e-05,
      "loss": 0.2911,
      "step": 28336
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.5975990295410156,
      "learning_rate": 5e-05,
      "loss": 0.3208,
      "step": 28344
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6927841305732727,
      "learning_rate": 5e-05,
      "loss": 0.322,
      "step": 28352
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6552805304527283,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 28360
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.5841063857078552,
      "learning_rate": 5e-05,
      "loss": 0.317,
      "step": 28368
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.5971115827560425,
      "learning_rate": 5e-05,
      "loss": 0.3046,
      "step": 28376
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6669016480445862,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 28384
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.5748865008354187,
      "learning_rate": 5e-05,
      "loss": 0.3343,
      "step": 28392
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6889132261276245,
      "learning_rate": 5e-05,
      "loss": 0.3271,
      "step": 28400
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.5401296615600586,
      "learning_rate": 5e-05,
      "loss": 0.3156,
      "step": 28408
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6503990292549133,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 28416
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.6368858218193054,
      "learning_rate": 5e-05,
      "loss": 0.3199,
      "step": 28424
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.6804004311561584,
      "learning_rate": 5e-05,
      "loss": 0.3284,
      "step": 28432
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.6338416337966919,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 28440
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.5913519263267517,
      "learning_rate": 5e-05,
      "loss": 0.2982,
      "step": 28448
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.5590261220932007,
      "learning_rate": 5e-05,
      "loss": 0.2934,
      "step": 28456
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.6533753871917725,
      "learning_rate": 5e-05,
      "loss": 0.323,
      "step": 28464
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.6270752549171448,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 28472
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.6294371485710144,
      "learning_rate": 5e-05,
      "loss": 0.3143,
      "step": 28480
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.5536907315254211,
      "learning_rate": 5e-05,
      "loss": 0.2864,
      "step": 28488
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.6092153787612915,
      "learning_rate": 5e-05,
      "loss": 0.3268,
      "step": 28496
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.5567396879196167,
      "learning_rate": 5e-05,
      "loss": 0.3104,
      "step": 28504
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.7379806041717529,
      "learning_rate": 5e-05,
      "loss": 0.2948,
      "step": 28512
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.6987545490264893,
      "learning_rate": 5e-05,
      "loss": 0.2863,
      "step": 28520
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.6468415856361389,
      "learning_rate": 5e-05,
      "loss": 0.3131,
      "step": 28528
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.6616789102554321,
      "learning_rate": 5e-05,
      "loss": 0.3058,
      "step": 28536
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.6077442765235901,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 28544
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.5611588358879089,
      "learning_rate": 5e-05,
      "loss": 0.3202,
      "step": 28552
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.5650714635848999,
      "learning_rate": 5e-05,
      "loss": 0.3053,
      "step": 28560
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.6987924575805664,
      "learning_rate": 5e-05,
      "loss": 0.3003,
      "step": 28568
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.6928979754447937,
      "learning_rate": 5e-05,
      "loss": 0.2989,
      "step": 28576
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.5628269910812378,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 28584
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6621958613395691,
      "learning_rate": 5e-05,
      "loss": 0.3182,
      "step": 28592
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6448886394500732,
      "learning_rate": 5e-05,
      "loss": 0.2956,
      "step": 28600
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.5981877446174622,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 28608
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.668883740901947,
      "learning_rate": 5e-05,
      "loss": 0.311,
      "step": 28616
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.588508665561676,
      "learning_rate": 5e-05,
      "loss": 0.3064,
      "step": 28624
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6063372492790222,
      "learning_rate": 5e-05,
      "loss": 0.3106,
      "step": 28632
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6213997006416321,
      "learning_rate": 5e-05,
      "loss": 0.3176,
      "step": 28640
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6326330900192261,
      "learning_rate": 5e-05,
      "loss": 0.3022,
      "step": 28648
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6551628708839417,
      "learning_rate": 5e-05,
      "loss": 0.3384,
      "step": 28656
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.5676387548446655,
      "learning_rate": 5e-05,
      "loss": 0.3173,
      "step": 28664
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.7237719297409058,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 28672
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.633155345916748,
      "learning_rate": 5e-05,
      "loss": 0.3188,
      "step": 28680
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6262993812561035,
      "learning_rate": 5e-05,
      "loss": 0.3095,
      "step": 28688
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6358724236488342,
      "learning_rate": 5e-05,
      "loss": 0.2992,
      "step": 28696
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6463870406150818,
      "learning_rate": 5e-05,
      "loss": 0.3063,
      "step": 28704
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.7325605154037476,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 28712
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6257985234260559,
      "learning_rate": 5e-05,
      "loss": 0.3377,
      "step": 28720
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6407337784767151,
      "learning_rate": 5e-05,
      "loss": 0.287,
      "step": 28728
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.7175294756889343,
      "learning_rate": 5e-05,
      "loss": 0.312,
      "step": 28736
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6203475594520569,
      "learning_rate": 5e-05,
      "loss": 0.2972,
      "step": 28744
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6250215172767639,
      "learning_rate": 5e-05,
      "loss": 0.3139,
      "step": 28752
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.5987932682037354,
      "learning_rate": 5e-05,
      "loss": 0.3355,
      "step": 28760
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.7627456188201904,
      "learning_rate": 5e-05,
      "loss": 0.3086,
      "step": 28768
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.6009374856948853,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 28776
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.6191672682762146,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 28784
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.7344827055931091,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 28792
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.709381639957428,
      "learning_rate": 5e-05,
      "loss": 0.2838,
      "step": 28800
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.5961574912071228,
      "learning_rate": 5e-05,
      "loss": 0.309,
      "step": 28808
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.6062580347061157,
      "learning_rate": 5e-05,
      "loss": 0.3122,
      "step": 28816
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.6851287484169006,
      "learning_rate": 5e-05,
      "loss": 0.3222,
      "step": 28824
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.6741114258766174,
      "learning_rate": 5e-05,
      "loss": 0.2955,
      "step": 28832
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.6582099199295044,
      "learning_rate": 5e-05,
      "loss": 0.2939,
      "step": 28840
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.7350422143936157,
      "learning_rate": 5e-05,
      "loss": 0.3276,
      "step": 28848
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.618635892868042,
      "learning_rate": 5e-05,
      "loss": 0.292,
      "step": 28856
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.5630340576171875,
      "learning_rate": 5e-05,
      "loss": 0.3026,
      "step": 28864
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.615310549736023,
      "learning_rate": 5e-05,
      "loss": 0.3034,
      "step": 28872
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.602219820022583,
      "learning_rate": 5e-05,
      "loss": 0.3081,
      "step": 28880
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.705569326877594,
      "learning_rate": 5e-05,
      "loss": 0.2994,
      "step": 28888
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.5705958604812622,
      "learning_rate": 5e-05,
      "loss": 0.3129,
      "step": 28896
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.5991335511207581,
      "learning_rate": 5e-05,
      "loss": 0.3087,
      "step": 28904
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.6937937140464783,
      "learning_rate": 5e-05,
      "loss": 0.3012,
      "step": 28912
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.5883764624595642,
      "learning_rate": 5e-05,
      "loss": 0.2958,
      "step": 28920
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.6814033389091492,
      "learning_rate": 5e-05,
      "loss": 0.3131,
      "step": 28928
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.7746747732162476,
      "learning_rate": 5e-05,
      "loss": 0.312,
      "step": 28936
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.6809284687042236,
      "learning_rate": 5e-05,
      "loss": 0.2977,
      "step": 28944
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.6782969832420349,
      "learning_rate": 5e-05,
      "loss": 0.3034,
      "step": 28952
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.8555514216423035,
      "learning_rate": 5e-05,
      "loss": 0.3442,
      "step": 28960
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.5731621980667114,
      "learning_rate": 5e-05,
      "loss": 0.2893,
      "step": 28968
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.586968719959259,
      "learning_rate": 5e-05,
      "loss": 0.3411,
      "step": 28976
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.6080338358879089,
      "learning_rate": 5e-05,
      "loss": 0.3032,
      "step": 28984
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.591724693775177,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 28992
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.6331624984741211,
      "learning_rate": 5e-05,
      "loss": 0.3188,
      "step": 29000
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.7274227738380432,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 29008
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.5792494416236877,
      "learning_rate": 5e-05,
      "loss": 0.3021,
      "step": 29016
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.6329753398895264,
      "learning_rate": 5e-05,
      "loss": 0.3067,
      "step": 29024
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.7193862795829773,
      "learning_rate": 5e-05,
      "loss": 0.3236,
      "step": 29032
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.574487030506134,
      "learning_rate": 5e-05,
      "loss": 0.2947,
      "step": 29040
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.7611784338951111,
      "learning_rate": 5e-05,
      "loss": 0.3118,
      "step": 29048
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.7323119640350342,
      "learning_rate": 5e-05,
      "loss": 0.3322,
      "step": 29056
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.6649459600448608,
      "learning_rate": 5e-05,
      "loss": 0.3128,
      "step": 29064
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.5899064540863037,
      "learning_rate": 5e-05,
      "loss": 0.3054,
      "step": 29072
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.6087162494659424,
      "learning_rate": 5e-05,
      "loss": 0.2863,
      "step": 29080
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.6741177439689636,
      "learning_rate": 5e-05,
      "loss": 0.3165,
      "step": 29088
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.5853276252746582,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 29096
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.5909819602966309,
      "learning_rate": 5e-05,
      "loss": 0.3126,
      "step": 29104
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.6336734890937805,
      "learning_rate": 5e-05,
      "loss": 0.3165,
      "step": 29112
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.7063974142074585,
      "learning_rate": 5e-05,
      "loss": 0.3214,
      "step": 29120
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.6193971037864685,
      "learning_rate": 5e-05,
      "loss": 0.3108,
      "step": 29128
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.592770516872406,
      "learning_rate": 5e-05,
      "loss": 0.2982,
      "step": 29136
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.5505443811416626,
      "learning_rate": 5e-05,
      "loss": 0.3207,
      "step": 29144
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.6463755965232849,
      "learning_rate": 5e-05,
      "loss": 0.3032,
      "step": 29152
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.6628407835960388,
      "learning_rate": 5e-05,
      "loss": 0.308,
      "step": 29160
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.6351190805435181,
      "learning_rate": 5e-05,
      "loss": 0.3286,
      "step": 29168
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.5307358503341675,
      "learning_rate": 5e-05,
      "loss": 0.29,
      "step": 29176
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.6019631028175354,
      "learning_rate": 5e-05,
      "loss": 0.3354,
      "step": 29184
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.6324132680892944,
      "learning_rate": 5e-05,
      "loss": 0.2812,
      "step": 29192
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.7585196495056152,
      "learning_rate": 5e-05,
      "loss": 0.2834,
      "step": 29200
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.5842944383621216,
      "learning_rate": 5e-05,
      "loss": 0.3043,
      "step": 29208
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.5679641366004944,
      "learning_rate": 5e-05,
      "loss": 0.3259,
      "step": 29216
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.6880465149879456,
      "learning_rate": 5e-05,
      "loss": 0.3027,
      "step": 29224
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.627098560333252,
      "learning_rate": 5e-05,
      "loss": 0.3338,
      "step": 29232
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.6184667348861694,
      "learning_rate": 5e-05,
      "loss": 0.2919,
      "step": 29240
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.5821947455406189,
      "learning_rate": 5e-05,
      "loss": 0.3017,
      "step": 29248
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.6686131954193115,
      "learning_rate": 5e-05,
      "loss": 0.3217,
      "step": 29256
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.6440817713737488,
      "learning_rate": 5e-05,
      "loss": 0.3046,
      "step": 29264
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5945618748664856,
      "learning_rate": 5e-05,
      "loss": 0.3013,
      "step": 29272
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.7740666270256042,
      "learning_rate": 5e-05,
      "loss": 0.3109,
      "step": 29280
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5246570110321045,
      "learning_rate": 5e-05,
      "loss": 0.3332,
      "step": 29288
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5604767203330994,
      "learning_rate": 5e-05,
      "loss": 0.3064,
      "step": 29296
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5723415613174438,
      "learning_rate": 5e-05,
      "loss": 0.3001,
      "step": 29304
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.6303398013114929,
      "learning_rate": 5e-05,
      "loss": 0.3067,
      "step": 29312
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.6664979457855225,
      "learning_rate": 5e-05,
      "loss": 0.3248,
      "step": 29320
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.6916213631629944,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 29328
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.6169893741607666,
      "learning_rate": 5e-05,
      "loss": 0.3235,
      "step": 29336
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5984712839126587,
      "learning_rate": 5e-05,
      "loss": 0.3301,
      "step": 29344
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.7130077481269836,
      "learning_rate": 5e-05,
      "loss": 0.2924,
      "step": 29352
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.7225434184074402,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 29360
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.7044827342033386,
      "learning_rate": 5e-05,
      "loss": 0.2975,
      "step": 29368
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5696516633033752,
      "learning_rate": 5e-05,
      "loss": 0.3079,
      "step": 29376
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.648396372795105,
      "learning_rate": 5e-05,
      "loss": 0.3188,
      "step": 29384
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.8614370822906494,
      "learning_rate": 5e-05,
      "loss": 0.2895,
      "step": 29392
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5562511682510376,
      "learning_rate": 5e-05,
      "loss": 0.3471,
      "step": 29400
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5523645877838135,
      "learning_rate": 5e-05,
      "loss": 0.3096,
      "step": 29408
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.6678026914596558,
      "learning_rate": 5e-05,
      "loss": 0.2994,
      "step": 29416
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.5982593297958374,
      "learning_rate": 5e-05,
      "loss": 0.3112,
      "step": 29424
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.525446891784668,
      "learning_rate": 5e-05,
      "loss": 0.3068,
      "step": 29432
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.5755887627601624,
      "learning_rate": 5e-05,
      "loss": 0.3293,
      "step": 29440
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.6977494955062866,
      "learning_rate": 5e-05,
      "loss": 0.318,
      "step": 29448
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.6929371953010559,
      "learning_rate": 5e-05,
      "loss": 0.357,
      "step": 29456
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.5514217615127563,
      "learning_rate": 5e-05,
      "loss": 0.2841,
      "step": 29464
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.5852166414260864,
      "learning_rate": 5e-05,
      "loss": 0.3253,
      "step": 29472
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.6409909129142761,
      "learning_rate": 5e-05,
      "loss": 0.3118,
      "step": 29480
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.6016031503677368,
      "learning_rate": 5e-05,
      "loss": 0.3277,
      "step": 29488
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.6462852954864502,
      "learning_rate": 5e-05,
      "loss": 0.3103,
      "step": 29496
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.58951336145401,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 29504
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.6526276469230652,
      "learning_rate": 5e-05,
      "loss": 0.3209,
      "step": 29512
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.7224532961845398,
      "learning_rate": 5e-05,
      "loss": 0.3024,
      "step": 29520
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.8036263585090637,
      "learning_rate": 5e-05,
      "loss": 0.306,
      "step": 29528
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.624326229095459,
      "learning_rate": 5e-05,
      "loss": 0.2925,
      "step": 29536
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.7434486746788025,
      "learning_rate": 5e-05,
      "loss": 0.2919,
      "step": 29544
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.6540607810020447,
      "learning_rate": 5e-05,
      "loss": 0.3086,
      "step": 29552
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.7004483342170715,
      "learning_rate": 5e-05,
      "loss": 0.2966,
      "step": 29560
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.5854389667510986,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 29568
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.6156473159790039,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 29576
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.6475402116775513,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 29584
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.648041307926178,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 29592
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.5139162540435791,
      "learning_rate": 5e-05,
      "loss": 0.2986,
      "step": 29600
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.688862681388855,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 29608
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.6799488663673401,
      "learning_rate": 5e-05,
      "loss": 0.3229,
      "step": 29616
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.7485535144805908,
      "learning_rate": 5e-05,
      "loss": 0.3042,
      "step": 29624
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.5776035189628601,
      "learning_rate": 5e-05,
      "loss": 0.3269,
      "step": 29632
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.6834486722946167,
      "learning_rate": 5e-05,
      "loss": 0.2904,
      "step": 29640
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.5662033557891846,
      "learning_rate": 5e-05,
      "loss": 0.2954,
      "step": 29648
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.7355706691741943,
      "learning_rate": 5e-05,
      "loss": 0.3065,
      "step": 29656
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.6109201908111572,
      "learning_rate": 5e-05,
      "loss": 0.2922,
      "step": 29664
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.6378633379936218,
      "learning_rate": 5e-05,
      "loss": 0.297,
      "step": 29672
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.6714115142822266,
      "learning_rate": 5e-05,
      "loss": 0.292,
      "step": 29680
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.6052992939949036,
      "learning_rate": 5e-05,
      "loss": 0.3022,
      "step": 29688
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.6288949251174927,
      "learning_rate": 5e-05,
      "loss": 0.3281,
      "step": 29696
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.6838340163230896,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 29704
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.5898675322532654,
      "learning_rate": 5e-05,
      "loss": 0.3235,
      "step": 29712
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.6824325919151306,
      "learning_rate": 5e-05,
      "loss": 0.2941,
      "step": 29720
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.5589860081672668,
      "learning_rate": 5e-05,
      "loss": 0.3095,
      "step": 29728
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.6062714457511902,
      "learning_rate": 5e-05,
      "loss": 0.2949,
      "step": 29736
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.7762296795845032,
      "learning_rate": 5e-05,
      "loss": 0.3259,
      "step": 29744
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.7021486163139343,
      "learning_rate": 5e-05,
      "loss": 0.3353,
      "step": 29752
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.5311042070388794,
      "learning_rate": 5e-05,
      "loss": 0.3089,
      "step": 29760
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.5710002183914185,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 29768
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.7271977663040161,
      "learning_rate": 5e-05,
      "loss": 0.3526,
      "step": 29776
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.5960873961448669,
      "learning_rate": 5e-05,
      "loss": 0.2854,
      "step": 29784
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.5636471509933472,
      "learning_rate": 5e-05,
      "loss": 0.3114,
      "step": 29792
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.6770808696746826,
      "learning_rate": 5e-05,
      "loss": 0.2874,
      "step": 29800
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.7995772361755371,
      "learning_rate": 5e-05,
      "loss": 0.2816,
      "step": 29808
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.6770672798156738,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 29816
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.7457632422447205,
      "learning_rate": 5e-05,
      "loss": 0.3048,
      "step": 29824
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.6679396629333496,
      "learning_rate": 5e-05,
      "loss": 0.3033,
      "step": 29832
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.6573621034622192,
      "learning_rate": 5e-05,
      "loss": 0.3176,
      "step": 29840
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.7103090286254883,
      "learning_rate": 5e-05,
      "loss": 0.3181,
      "step": 29848
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.5944163799285889,
      "learning_rate": 5e-05,
      "loss": 0.3272,
      "step": 29856
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.7628254294395447,
      "learning_rate": 5e-05,
      "loss": 0.3204,
      "step": 29864
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.5680580735206604,
      "learning_rate": 5e-05,
      "loss": 0.3011,
      "step": 29872
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.5932881832122803,
      "learning_rate": 5e-05,
      "loss": 0.2764,
      "step": 29880
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.5459921956062317,
      "learning_rate": 5e-05,
      "loss": 0.3079,
      "step": 29888
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.6246938705444336,
      "learning_rate": 5e-05,
      "loss": 0.3083,
      "step": 29896
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.6298112273216248,
      "learning_rate": 5e-05,
      "loss": 0.3165,
      "step": 29904
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.6381619572639465,
      "learning_rate": 5e-05,
      "loss": 0.3085,
      "step": 29912
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.632054328918457,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 29920
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6221348643302917,
      "learning_rate": 5e-05,
      "loss": 0.3123,
      "step": 29928
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6750137805938721,
      "learning_rate": 5e-05,
      "loss": 0.3389,
      "step": 29936
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6855314373970032,
      "learning_rate": 5e-05,
      "loss": 0.3212,
      "step": 29944
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6178973913192749,
      "learning_rate": 5e-05,
      "loss": 0.3143,
      "step": 29952
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6182717680931091,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 29960
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.524341881275177,
      "learning_rate": 5e-05,
      "loss": 0.2866,
      "step": 29968
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5878478288650513,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 29976
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5834081172943115,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 29984
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.7598550915718079,
      "learning_rate": 5e-05,
      "loss": 0.3244,
      "step": 29992
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5867394208908081,
      "learning_rate": 5e-05,
      "loss": 0.2957,
      "step": 30000
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5829765796661377,
      "learning_rate": 5e-05,
      "loss": 0.3476,
      "step": 30008
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5354150533676147,
      "learning_rate": 5e-05,
      "loss": 0.2865,
      "step": 30016
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5639106631278992,
      "learning_rate": 5e-05,
      "loss": 0.3263,
      "step": 30024
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.618776261806488,
      "learning_rate": 5e-05,
      "loss": 0.2834,
      "step": 30032
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6975213885307312,
      "learning_rate": 5e-05,
      "loss": 0.3324,
      "step": 30040
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.7238051295280457,
      "learning_rate": 5e-05,
      "loss": 0.2941,
      "step": 30048
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6210888028144836,
      "learning_rate": 5e-05,
      "loss": 0.2905,
      "step": 30056
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5918704867362976,
      "learning_rate": 5e-05,
      "loss": 0.305,
      "step": 30064
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6768348217010498,
      "learning_rate": 5e-05,
      "loss": 0.2903,
      "step": 30072
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.8107029795646667,
      "learning_rate": 5e-05,
      "loss": 0.2939,
      "step": 30080
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6485828757286072,
      "learning_rate": 5e-05,
      "loss": 0.3047,
      "step": 30088
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.7089055776596069,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 30096
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6669833064079285,
      "learning_rate": 5e-05,
      "loss": 0.3135,
      "step": 30104
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6474027633666992,
      "learning_rate": 5e-05,
      "loss": 0.2906,
      "step": 30112
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6310362815856934,
      "learning_rate": 5e-05,
      "loss": 0.3256,
      "step": 30120
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6734411716461182,
      "learning_rate": 5e-05,
      "loss": 0.3134,
      "step": 30128
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6379101276397705,
      "learning_rate": 5e-05,
      "loss": 0.3197,
      "step": 30136
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6453533172607422,
      "learning_rate": 5e-05,
      "loss": 0.3389,
      "step": 30144
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6161579489707947,
      "learning_rate": 5e-05,
      "loss": 0.2755,
      "step": 30152
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6625792384147644,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 30160
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6201679110527039,
      "learning_rate": 5e-05,
      "loss": 0.3066,
      "step": 30168
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.5943549275398254,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 30176
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.622613251209259,
      "learning_rate": 5e-05,
      "loss": 0.3224,
      "step": 30184
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6976863741874695,
      "learning_rate": 5e-05,
      "loss": 0.2916,
      "step": 30192
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6446506381034851,
      "learning_rate": 5e-05,
      "loss": 0.294,
      "step": 30200
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6055974960327148,
      "learning_rate": 5e-05,
      "loss": 0.3463,
      "step": 30208
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.8640863299369812,
      "learning_rate": 5e-05,
      "loss": 0.2995,
      "step": 30216
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.5915018320083618,
      "learning_rate": 5e-05,
      "loss": 0.3313,
      "step": 30224
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.5882315635681152,
      "learning_rate": 5e-05,
      "loss": 0.3053,
      "step": 30232
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6341313123703003,
      "learning_rate": 5e-05,
      "loss": 0.2939,
      "step": 30240
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.6999711990356445,
      "learning_rate": 5e-05,
      "loss": 0.3135,
      "step": 30248
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.5673745274543762,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 30256
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.56720370054245,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 30264
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.6073264479637146,
      "learning_rate": 5e-05,
      "loss": 0.3073,
      "step": 30272
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.608005166053772,
      "learning_rate": 5e-05,
      "loss": 0.3217,
      "step": 30280
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.6860694289207458,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 30288
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.7332276105880737,
      "learning_rate": 5e-05,
      "loss": 0.3055,
      "step": 30296
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.6115840673446655,
      "learning_rate": 5e-05,
      "loss": 0.2884,
      "step": 30304
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.5977525115013123,
      "learning_rate": 5e-05,
      "loss": 0.3156,
      "step": 30312
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.7079819440841675,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 30320
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.6360523700714111,
      "learning_rate": 5e-05,
      "loss": 0.3001,
      "step": 30328
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.6245200037956238,
      "learning_rate": 5e-05,
      "loss": 0.3112,
      "step": 30336
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.7292278409004211,
      "learning_rate": 5e-05,
      "loss": 0.2872,
      "step": 30344
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.6859259605407715,
      "learning_rate": 5e-05,
      "loss": 0.2883,
      "step": 30352
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.6636802554130554,
      "learning_rate": 5e-05,
      "loss": 0.3217,
      "step": 30360
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.6157942414283752,
      "learning_rate": 5e-05,
      "loss": 0.3221,
      "step": 30368
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.5914809107780457,
      "learning_rate": 5e-05,
      "loss": 0.3237,
      "step": 30376
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.8288015723228455,
      "learning_rate": 5e-05,
      "loss": 0.3273,
      "step": 30384
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.6346219182014465,
      "learning_rate": 5e-05,
      "loss": 0.3439,
      "step": 30392
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.5784359574317932,
      "learning_rate": 5e-05,
      "loss": 0.2965,
      "step": 30400
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.5451241135597229,
      "learning_rate": 5e-05,
      "loss": 0.3258,
      "step": 30408
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.6791300177574158,
      "learning_rate": 5e-05,
      "loss": 0.3117,
      "step": 30416
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.6130491495132446,
      "learning_rate": 5e-05,
      "loss": 0.3238,
      "step": 30424
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.6990482807159424,
      "learning_rate": 5e-05,
      "loss": 0.3126,
      "step": 30432
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.5717158913612366,
      "learning_rate": 5e-05,
      "loss": 0.326,
      "step": 30440
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.7270014882087708,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 30448
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.7370187640190125,
      "learning_rate": 5e-05,
      "loss": 0.292,
      "step": 30456
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.644904613494873,
      "learning_rate": 5e-05,
      "loss": 0.3335,
      "step": 30464
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.648761510848999,
      "learning_rate": 5e-05,
      "loss": 0.3274,
      "step": 30472
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.7743607759475708,
      "learning_rate": 5e-05,
      "loss": 0.3525,
      "step": 30480
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.5628202557563782,
      "learning_rate": 5e-05,
      "loss": 0.2934,
      "step": 30488
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.6596700549125671,
      "learning_rate": 5e-05,
      "loss": 0.3054,
      "step": 30496
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.6589887142181396,
      "learning_rate": 5e-05,
      "loss": 0.3078,
      "step": 30504
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.5872544050216675,
      "learning_rate": 5e-05,
      "loss": 0.3175,
      "step": 30512
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.6117273569107056,
      "learning_rate": 5e-05,
      "loss": 0.3117,
      "step": 30520
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.6100756525993347,
      "learning_rate": 5e-05,
      "loss": 0.2978,
      "step": 30528
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.6014564633369446,
      "learning_rate": 5e-05,
      "loss": 0.3037,
      "step": 30536
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.6106606125831604,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 30544
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.7634928226470947,
      "learning_rate": 5e-05,
      "loss": 0.3457,
      "step": 30552
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.5689392685890198,
      "learning_rate": 5e-05,
      "loss": 0.2962,
      "step": 30560
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.669674277305603,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 30568
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.6976350545883179,
      "learning_rate": 5e-05,
      "loss": 0.3273,
      "step": 30576
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.6162765026092529,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 30584
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.6088101863861084,
      "learning_rate": 5e-05,
      "loss": 0.3023,
      "step": 30592
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.6831998229026794,
      "learning_rate": 5e-05,
      "loss": 0.3292,
      "step": 30600
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.5846155285835266,
      "learning_rate": 5e-05,
      "loss": 0.2966,
      "step": 30608
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.7355927228927612,
      "learning_rate": 5e-05,
      "loss": 0.3044,
      "step": 30616
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.5913294553756714,
      "learning_rate": 5e-05,
      "loss": 0.3405,
      "step": 30624
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.6027213335037231,
      "learning_rate": 5e-05,
      "loss": 0.2968,
      "step": 30632
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.5816945433616638,
      "learning_rate": 5e-05,
      "loss": 0.3377,
      "step": 30640
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.6539317965507507,
      "learning_rate": 5e-05,
      "loss": 0.3031,
      "step": 30648
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.5366959571838379,
      "learning_rate": 5e-05,
      "loss": 0.2973,
      "step": 30656
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.5901751518249512,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 30664
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.5556981563568115,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 30672
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.6008962988853455,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 30680
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.5614323616027832,
      "learning_rate": 5e-05,
      "loss": 0.2989,
      "step": 30688
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.6729497313499451,
      "learning_rate": 5e-05,
      "loss": 0.3057,
      "step": 30696
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.5290465950965881,
      "learning_rate": 5e-05,
      "loss": 0.3056,
      "step": 30704
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.566675066947937,
      "learning_rate": 5e-05,
      "loss": 0.3053,
      "step": 30712
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.5480291247367859,
      "learning_rate": 5e-05,
      "loss": 0.3277,
      "step": 30720
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.5898417234420776,
      "learning_rate": 5e-05,
      "loss": 0.3389,
      "step": 30728
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.6102805733680725,
      "learning_rate": 5e-05,
      "loss": 0.3063,
      "step": 30736
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.5930688381195068,
      "learning_rate": 5e-05,
      "loss": 0.3017,
      "step": 30744
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.5916280746459961,
      "learning_rate": 5e-05,
      "loss": 0.2863,
      "step": 30752
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.7474462985992432,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 30760
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.6961223483085632,
      "learning_rate": 5e-05,
      "loss": 0.3119,
      "step": 30768
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.6171861290931702,
      "learning_rate": 5e-05,
      "loss": 0.3245,
      "step": 30776
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.6014454960823059,
      "learning_rate": 5e-05,
      "loss": 0.3087,
      "step": 30784
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.5669479370117188,
      "learning_rate": 5e-05,
      "loss": 0.2766,
      "step": 30792
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.6590340733528137,
      "learning_rate": 5e-05,
      "loss": 0.2906,
      "step": 30800
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.6112842559814453,
      "learning_rate": 5e-05,
      "loss": 0.3235,
      "step": 30808
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.6401360034942627,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 30816
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.560348391532898,
      "learning_rate": 5e-05,
      "loss": 0.2925,
      "step": 30824
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.5491258502006531,
      "learning_rate": 5e-05,
      "loss": 0.2981,
      "step": 30832
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.6797508001327515,
      "learning_rate": 5e-05,
      "loss": 0.3341,
      "step": 30840
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.6785119771957397,
      "learning_rate": 5e-05,
      "loss": 0.3102,
      "step": 30848
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.6295186877250671,
      "learning_rate": 5e-05,
      "loss": 0.3142,
      "step": 30856
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.5935274958610535,
      "learning_rate": 5e-05,
      "loss": 0.3269,
      "step": 30864
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.7800464034080505,
      "learning_rate": 5e-05,
      "loss": 0.3214,
      "step": 30872
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.6290534734725952,
      "learning_rate": 5e-05,
      "loss": 0.3021,
      "step": 30880
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.686509907245636,
      "learning_rate": 5e-05,
      "loss": 0.3129,
      "step": 30888
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.6631814241409302,
      "learning_rate": 5e-05,
      "loss": 0.2988,
      "step": 30896
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.741328775882721,
      "learning_rate": 5e-05,
      "loss": 0.3252,
      "step": 30904
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.7641541361808777,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 30912
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.7213864326477051,
      "learning_rate": 5e-05,
      "loss": 0.3269,
      "step": 30920
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.5788590312004089,
      "learning_rate": 5e-05,
      "loss": 0.2972,
      "step": 30928
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.80002760887146,
      "learning_rate": 5e-05,
      "loss": 0.2953,
      "step": 30936
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.6436554789543152,
      "learning_rate": 5e-05,
      "loss": 0.3268,
      "step": 30944
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.6555594801902771,
      "learning_rate": 5e-05,
      "loss": 0.3375,
      "step": 30952
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.6642328500747681,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 30960
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.5948976278305054,
      "learning_rate": 5e-05,
      "loss": 0.3254,
      "step": 30968
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.6793298125267029,
      "learning_rate": 5e-05,
      "loss": 0.3208,
      "step": 30976
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.6135452389717102,
      "learning_rate": 5e-05,
      "loss": 0.3069,
      "step": 30984
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.6221051216125488,
      "learning_rate": 5e-05,
      "loss": 0.3078,
      "step": 30992
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.757172703742981,
      "learning_rate": 5e-05,
      "loss": 0.307,
      "step": 31000
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.6666035056114197,
      "learning_rate": 5e-05,
      "loss": 0.3218,
      "step": 31008
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.6179904341697693,
      "learning_rate": 5e-05,
      "loss": 0.3089,
      "step": 31016
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.7270243167877197,
      "learning_rate": 5e-05,
      "loss": 0.358,
      "step": 31024
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.6043400168418884,
      "learning_rate": 5e-05,
      "loss": 0.3012,
      "step": 31032
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.832896888256073,
      "learning_rate": 5e-05,
      "loss": 0.3036,
      "step": 31040
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.5623747110366821,
      "learning_rate": 5e-05,
      "loss": 0.3067,
      "step": 31048
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.6445885300636292,
      "learning_rate": 5e-05,
      "loss": 0.275,
      "step": 31056
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.6014389395713806,
      "learning_rate": 5e-05,
      "loss": 0.3288,
      "step": 31064
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.6142023205757141,
      "learning_rate": 5e-05,
      "loss": 0.2997,
      "step": 31072
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.7197883725166321,
      "learning_rate": 5e-05,
      "loss": 0.2981,
      "step": 31080
    },
    {
      "epoch": 1.86,
      "grad_norm": 0.5844488739967346,
      "learning_rate": 5e-05,
      "loss": 0.3306,
      "step": 31088
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6651983261108398,
      "learning_rate": 5e-05,
      "loss": 0.3089,
      "step": 31096
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.5895575284957886,
      "learning_rate": 5e-05,
      "loss": 0.3001,
      "step": 31104
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6910867094993591,
      "learning_rate": 5e-05,
      "loss": 0.3085,
      "step": 31112
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6196063160896301,
      "learning_rate": 5e-05,
      "loss": 0.3017,
      "step": 31120
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6624923944473267,
      "learning_rate": 5e-05,
      "loss": 0.2843,
      "step": 31128
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.8107796311378479,
      "learning_rate": 5e-05,
      "loss": 0.3242,
      "step": 31136
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.7072283029556274,
      "learning_rate": 5e-05,
      "loss": 0.3271,
      "step": 31144
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6330858469009399,
      "learning_rate": 5e-05,
      "loss": 0.2878,
      "step": 31152
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.8125460147857666,
      "learning_rate": 5e-05,
      "loss": 0.3474,
      "step": 31160
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6233470439910889,
      "learning_rate": 5e-05,
      "loss": 0.3352,
      "step": 31168
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.5342148542404175,
      "learning_rate": 5e-05,
      "loss": 0.3169,
      "step": 31176
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6176401376724243,
      "learning_rate": 5e-05,
      "loss": 0.3117,
      "step": 31184
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6021032929420471,
      "learning_rate": 5e-05,
      "loss": 0.3083,
      "step": 31192
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6275718808174133,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 31200
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6419469118118286,
      "learning_rate": 5e-05,
      "loss": 0.3161,
      "step": 31208
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6718276143074036,
      "learning_rate": 5e-05,
      "loss": 0.3001,
      "step": 31216
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6460340619087219,
      "learning_rate": 5e-05,
      "loss": 0.286,
      "step": 31224
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6355900764465332,
      "learning_rate": 5e-05,
      "loss": 0.3091,
      "step": 31232
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6993380188941956,
      "learning_rate": 5e-05,
      "loss": 0.3087,
      "step": 31240
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.6325088739395142,
      "learning_rate": 5e-05,
      "loss": 0.3257,
      "step": 31248
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.5960962772369385,
      "learning_rate": 5e-05,
      "loss": 0.3047,
      "step": 31256
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6914092898368835,
      "learning_rate": 5e-05,
      "loss": 0.3176,
      "step": 31264
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.7591651678085327,
      "learning_rate": 5e-05,
      "loss": 0.3066,
      "step": 31272
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6917913556098938,
      "learning_rate": 5e-05,
      "loss": 0.3003,
      "step": 31280
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.7110518217086792,
      "learning_rate": 5e-05,
      "loss": 0.3085,
      "step": 31288
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.5430155396461487,
      "learning_rate": 5e-05,
      "loss": 0.3047,
      "step": 31296
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6830516457557678,
      "learning_rate": 5e-05,
      "loss": 0.2894,
      "step": 31304
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6693932414054871,
      "learning_rate": 5e-05,
      "loss": 0.3302,
      "step": 31312
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.5976032018661499,
      "learning_rate": 5e-05,
      "loss": 0.3113,
      "step": 31320
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.7265273332595825,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 31328
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6486349701881409,
      "learning_rate": 5e-05,
      "loss": 0.3285,
      "step": 31336
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6927607655525208,
      "learning_rate": 5e-05,
      "loss": 0.3075,
      "step": 31344
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.656411349773407,
      "learning_rate": 5e-05,
      "loss": 0.3198,
      "step": 31352
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6817666888237,
      "learning_rate": 5e-05,
      "loss": 0.2899,
      "step": 31360
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6930018663406372,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 31368
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.596368670463562,
      "learning_rate": 5e-05,
      "loss": 0.3392,
      "step": 31376
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6489575505256653,
      "learning_rate": 5e-05,
      "loss": 0.2946,
      "step": 31384
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6825384497642517,
      "learning_rate": 5e-05,
      "loss": 0.3082,
      "step": 31392
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6654969453811646,
      "learning_rate": 5e-05,
      "loss": 0.3288,
      "step": 31400
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6247103810310364,
      "learning_rate": 5e-05,
      "loss": 0.3278,
      "step": 31408
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.5945187211036682,
      "learning_rate": 5e-05,
      "loss": 0.3301,
      "step": 31416
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.7157462239265442,
      "learning_rate": 5e-05,
      "loss": 0.3017,
      "step": 31424
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.6249197721481323,
      "learning_rate": 5e-05,
      "loss": 0.3187,
      "step": 31432
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.651177167892456,
      "learning_rate": 5e-05,
      "loss": 0.3486,
      "step": 31440
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.5833050012588501,
      "learning_rate": 5e-05,
      "loss": 0.3192,
      "step": 31448
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.6228010058403015,
      "learning_rate": 5e-05,
      "loss": 0.3079,
      "step": 31456
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.6806962490081787,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 31464
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.6477066278457642,
      "learning_rate": 5e-05,
      "loss": 0.3435,
      "step": 31472
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.6191471219062805,
      "learning_rate": 5e-05,
      "loss": 0.3124,
      "step": 31480
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.6255574822425842,
      "learning_rate": 5e-05,
      "loss": 0.2862,
      "step": 31488
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.6657233834266663,
      "learning_rate": 5e-05,
      "loss": 0.2923,
      "step": 31496
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.5981130599975586,
      "learning_rate": 5e-05,
      "loss": 0.2881,
      "step": 31504
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.643636167049408,
      "learning_rate": 5e-05,
      "loss": 0.3109,
      "step": 31512
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.7121837735176086,
      "learning_rate": 5e-05,
      "loss": 0.3067,
      "step": 31520
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.5800399780273438,
      "learning_rate": 5e-05,
      "loss": 0.3243,
      "step": 31528
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.7564257979393005,
      "learning_rate": 5e-05,
      "loss": 0.2987,
      "step": 31536
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.7364436984062195,
      "learning_rate": 5e-05,
      "loss": 0.2947,
      "step": 31544
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.6887451410293579,
      "learning_rate": 5e-05,
      "loss": 0.2982,
      "step": 31552
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.5433502793312073,
      "learning_rate": 5e-05,
      "loss": 0.3257,
      "step": 31560
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.6867319345474243,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 31568
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.7438684105873108,
      "learning_rate": 5e-05,
      "loss": 0.3214,
      "step": 31576
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.623753547668457,
      "learning_rate": 5e-05,
      "loss": 0.29,
      "step": 31584
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.5380845665931702,
      "learning_rate": 5e-05,
      "loss": 0.3103,
      "step": 31592
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.5745688676834106,
      "learning_rate": 5e-05,
      "loss": 0.3059,
      "step": 31600
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.6168413758277893,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 31608
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.6045228838920593,
      "learning_rate": 5e-05,
      "loss": 0.2875,
      "step": 31616
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.6863035559654236,
      "learning_rate": 5e-05,
      "loss": 0.3252,
      "step": 31624
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.7238775491714478,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 31632
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.6307774782180786,
      "learning_rate": 5e-05,
      "loss": 0.3111,
      "step": 31640
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.5854976773262024,
      "learning_rate": 5e-05,
      "loss": 0.3256,
      "step": 31648
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.7969406247138977,
      "learning_rate": 5e-05,
      "loss": 0.3033,
      "step": 31656
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.6983139514923096,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 31664
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.6513068079948425,
      "learning_rate": 5e-05,
      "loss": 0.3385,
      "step": 31672
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.9146172404289246,
      "learning_rate": 5e-05,
      "loss": 0.3046,
      "step": 31680
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.5854323506355286,
      "learning_rate": 5e-05,
      "loss": 0.2851,
      "step": 31688
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.5873110890388489,
      "learning_rate": 5e-05,
      "loss": 0.3111,
      "step": 31696
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.572050929069519,
      "learning_rate": 5e-05,
      "loss": 0.308,
      "step": 31704
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.5340429544448853,
      "learning_rate": 5e-05,
      "loss": 0.3106,
      "step": 31712
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.6844916343688965,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 31720
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.7494795322418213,
      "learning_rate": 5e-05,
      "loss": 0.3162,
      "step": 31728
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.6009687185287476,
      "learning_rate": 5e-05,
      "loss": 0.3288,
      "step": 31736
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.6640984416007996,
      "learning_rate": 5e-05,
      "loss": 0.307,
      "step": 31744
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.6103872060775757,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 31752
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.648837149143219,
      "learning_rate": 5e-05,
      "loss": 0.2913,
      "step": 31760
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.5818588137626648,
      "learning_rate": 5e-05,
      "loss": 0.3162,
      "step": 31768
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.6132252216339111,
      "learning_rate": 5e-05,
      "loss": 0.31,
      "step": 31776
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.6975858807563782,
      "learning_rate": 5e-05,
      "loss": 0.3101,
      "step": 31784
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.5746584534645081,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 31792
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.7181492447853088,
      "learning_rate": 5e-05,
      "loss": 0.2941,
      "step": 31800
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.6253989934921265,
      "learning_rate": 5e-05,
      "loss": 0.2962,
      "step": 31808
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.6504414081573486,
      "learning_rate": 5e-05,
      "loss": 0.2922,
      "step": 31816
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.6725410223007202,
      "learning_rate": 5e-05,
      "loss": 0.3011,
      "step": 31824
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.6694739460945129,
      "learning_rate": 5e-05,
      "loss": 0.315,
      "step": 31832
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.675356388092041,
      "learning_rate": 5e-05,
      "loss": 0.2849,
      "step": 31840
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.7500537037849426,
      "learning_rate": 5e-05,
      "loss": 0.3274,
      "step": 31848
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.5689598321914673,
      "learning_rate": 5e-05,
      "loss": 0.3121,
      "step": 31856
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.6149530410766602,
      "learning_rate": 5e-05,
      "loss": 0.3361,
      "step": 31864
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.6217557191848755,
      "learning_rate": 5e-05,
      "loss": 0.3198,
      "step": 31872
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.6196584105491638,
      "learning_rate": 5e-05,
      "loss": 0.3018,
      "step": 31880
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.5923917293548584,
      "learning_rate": 5e-05,
      "loss": 0.3257,
      "step": 31888
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.563947856426239,
      "learning_rate": 5e-05,
      "loss": 0.3167,
      "step": 31896
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.6682574152946472,
      "learning_rate": 5e-05,
      "loss": 0.3353,
      "step": 31904
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.61605304479599,
      "learning_rate": 5e-05,
      "loss": 0.3221,
      "step": 31912
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.6610131859779358,
      "learning_rate": 5e-05,
      "loss": 0.2985,
      "step": 31920
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6609247922897339,
      "learning_rate": 5e-05,
      "loss": 0.3137,
      "step": 31928
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6176847815513611,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 31936
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6814159750938416,
      "learning_rate": 5e-05,
      "loss": 0.3579,
      "step": 31944
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6830172538757324,
      "learning_rate": 5e-05,
      "loss": 0.288,
      "step": 31952
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6749795079231262,
      "learning_rate": 5e-05,
      "loss": 0.2879,
      "step": 31960
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.563729465007782,
      "learning_rate": 5e-05,
      "loss": 0.3117,
      "step": 31968
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.8850962519645691,
      "learning_rate": 5e-05,
      "loss": 0.2811,
      "step": 31976
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6150420308113098,
      "learning_rate": 5e-05,
      "loss": 0.3026,
      "step": 31984
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6943702101707458,
      "learning_rate": 5e-05,
      "loss": 0.3217,
      "step": 31992
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.7136520743370056,
      "learning_rate": 5e-05,
      "loss": 0.3224,
      "step": 32000
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.5876777172088623,
      "learning_rate": 5e-05,
      "loss": 0.3443,
      "step": 32008
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6366122961044312,
      "learning_rate": 5e-05,
      "loss": 0.3047,
      "step": 32016
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6111003160476685,
      "learning_rate": 5e-05,
      "loss": 0.3066,
      "step": 32024
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6473207473754883,
      "learning_rate": 5e-05,
      "loss": 0.2904,
      "step": 32032
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.5707303881645203,
      "learning_rate": 5e-05,
      "loss": 0.3107,
      "step": 32040
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.7353026270866394,
      "learning_rate": 5e-05,
      "loss": 0.3286,
      "step": 32048
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6612818837165833,
      "learning_rate": 5e-05,
      "loss": 0.298,
      "step": 32056
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.7011653184890747,
      "learning_rate": 5e-05,
      "loss": 0.3353,
      "step": 32064
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6273860335350037,
      "learning_rate": 5e-05,
      "loss": 0.2905,
      "step": 32072
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6728717684745789,
      "learning_rate": 5e-05,
      "loss": 0.3405,
      "step": 32080
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.8122560977935791,
      "learning_rate": 5e-05,
      "loss": 0.3101,
      "step": 32088
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.735598087310791,
      "learning_rate": 5e-05,
      "loss": 0.2822,
      "step": 32096
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.6665811538696289,
      "learning_rate": 5e-05,
      "loss": 0.3135,
      "step": 32104
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.5821973085403442,
      "learning_rate": 5e-05,
      "loss": 0.3347,
      "step": 32112
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.6323612928390503,
      "learning_rate": 5e-05,
      "loss": 0.2938,
      "step": 32120
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.5579435229301453,
      "learning_rate": 5e-05,
      "loss": 0.3133,
      "step": 32128
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.7335100769996643,
      "learning_rate": 5e-05,
      "loss": 0.3076,
      "step": 32136
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.648923933506012,
      "learning_rate": 5e-05,
      "loss": 0.2847,
      "step": 32144
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.7149562835693359,
      "learning_rate": 5e-05,
      "loss": 0.3356,
      "step": 32152
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.6580754518508911,
      "learning_rate": 5e-05,
      "loss": 0.3192,
      "step": 32160
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.7057052254676819,
      "learning_rate": 5e-05,
      "loss": 0.3016,
      "step": 32168
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.6227744817733765,
      "learning_rate": 5e-05,
      "loss": 0.3205,
      "step": 32176
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.6269084811210632,
      "learning_rate": 5e-05,
      "loss": 0.3167,
      "step": 32184
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.5998663306236267,
      "learning_rate": 5e-05,
      "loss": 0.3007,
      "step": 32192
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.4828777015209198,
      "learning_rate": 5e-05,
      "loss": 0.3396,
      "step": 32200
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.6632700562477112,
      "learning_rate": 5e-05,
      "loss": 0.3094,
      "step": 32208
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.6077502965927124,
      "learning_rate": 5e-05,
      "loss": 0.3096,
      "step": 32216
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.5722318291664124,
      "learning_rate": 5e-05,
      "loss": 0.319,
      "step": 32224
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.5766587257385254,
      "learning_rate": 5e-05,
      "loss": 0.3217,
      "step": 32232
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.6667450070381165,
      "learning_rate": 5e-05,
      "loss": 0.3041,
      "step": 32240
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.6439690589904785,
      "learning_rate": 5e-05,
      "loss": 0.3082,
      "step": 32248
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.5987229347229004,
      "learning_rate": 5e-05,
      "loss": 0.315,
      "step": 32256
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.5619509220123291,
      "learning_rate": 5e-05,
      "loss": 0.309,
      "step": 32264
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.6446750164031982,
      "learning_rate": 5e-05,
      "loss": 0.2937,
      "step": 32272
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.5805355906486511,
      "learning_rate": 5e-05,
      "loss": 0.3034,
      "step": 32280
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.7271255850791931,
      "learning_rate": 5e-05,
      "loss": 0.2823,
      "step": 32288
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.6968963742256165,
      "learning_rate": 5e-05,
      "loss": 0.3011,
      "step": 32296
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.7747406363487244,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 32304
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.5920242071151733,
      "learning_rate": 5e-05,
      "loss": 0.2925,
      "step": 32312
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.5975022912025452,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 32320
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.6640435457229614,
      "learning_rate": 5e-05,
      "loss": 0.3222,
      "step": 32328
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.7220867276191711,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 32336
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.5386264324188232,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 32344
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.6300426125526428,
      "learning_rate": 5e-05,
      "loss": 0.3181,
      "step": 32352
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.6509326100349426,
      "learning_rate": 5e-05,
      "loss": 0.2894,
      "step": 32360
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.5996094346046448,
      "learning_rate": 5e-05,
      "loss": 0.3209,
      "step": 32368
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.5700196623802185,
      "learning_rate": 5e-05,
      "loss": 0.2882,
      "step": 32376
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.7242935299873352,
      "learning_rate": 5e-05,
      "loss": 0.3624,
      "step": 32384
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.6164452433586121,
      "learning_rate": 5e-05,
      "loss": 0.2856,
      "step": 32392
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.8492934107780457,
      "learning_rate": 5e-05,
      "loss": 0.2714,
      "step": 32400
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.7301872372627258,
      "learning_rate": 5e-05,
      "loss": 0.2867,
      "step": 32408
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.5500131249427795,
      "learning_rate": 5e-05,
      "loss": 0.2871,
      "step": 32416
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.5675833225250244,
      "learning_rate": 5e-05,
      "loss": 0.3056,
      "step": 32424
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.7287071943283081,
      "learning_rate": 5e-05,
      "loss": 0.3135,
      "step": 32432
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.6301977634429932,
      "learning_rate": 5e-05,
      "loss": 0.3128,
      "step": 32440
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.7082334756851196,
      "learning_rate": 5e-05,
      "loss": 0.3092,
      "step": 32448
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.9089124202728271,
      "learning_rate": 5e-05,
      "loss": 0.3494,
      "step": 32456
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.6017834544181824,
      "learning_rate": 5e-05,
      "loss": 0.3168,
      "step": 32464
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.5973587036132812,
      "learning_rate": 5e-05,
      "loss": 0.2821,
      "step": 32472
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.5901118516921997,
      "learning_rate": 5e-05,
      "loss": 0.3447,
      "step": 32480
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.5835073590278625,
      "learning_rate": 5e-05,
      "loss": 0.2843,
      "step": 32488
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.633618175983429,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 32496
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.5889527201652527,
      "learning_rate": 5e-05,
      "loss": 0.3164,
      "step": 32504
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.5998247265815735,
      "learning_rate": 5e-05,
      "loss": 0.3611,
      "step": 32512
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.5949123501777649,
      "learning_rate": 5e-05,
      "loss": 0.3332,
      "step": 32520
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.7019481658935547,
      "learning_rate": 5e-05,
      "loss": 0.2962,
      "step": 32528
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.5527784824371338,
      "learning_rate": 5e-05,
      "loss": 0.2806,
      "step": 32536
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.6618338227272034,
      "learning_rate": 5e-05,
      "loss": 0.3009,
      "step": 32544
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.6419135332107544,
      "learning_rate": 5e-05,
      "loss": 0.3156,
      "step": 32552
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.5631273984909058,
      "learning_rate": 5e-05,
      "loss": 0.3179,
      "step": 32560
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.7307888865470886,
      "learning_rate": 5e-05,
      "loss": 0.3213,
      "step": 32568
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.6530847549438477,
      "learning_rate": 5e-05,
      "loss": 0.3222,
      "step": 32576
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.6253166794776917,
      "learning_rate": 5e-05,
      "loss": 0.2939,
      "step": 32584
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.6521162986755371,
      "learning_rate": 5e-05,
      "loss": 0.3268,
      "step": 32592
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.6892877817153931,
      "learning_rate": 5e-05,
      "loss": 0.3188,
      "step": 32600
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.5644294619560242,
      "learning_rate": 5e-05,
      "loss": 0.3112,
      "step": 32608
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.6476842761039734,
      "learning_rate": 5e-05,
      "loss": 0.3166,
      "step": 32616
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.6583131551742554,
      "learning_rate": 5e-05,
      "loss": 0.3217,
      "step": 32624
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.6282426118850708,
      "learning_rate": 5e-05,
      "loss": 0.2882,
      "step": 32632
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.6445896625518799,
      "learning_rate": 5e-05,
      "loss": 0.3234,
      "step": 32640
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.5505504608154297,
      "learning_rate": 5e-05,
      "loss": 0.2927,
      "step": 32648
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.6142405271530151,
      "learning_rate": 5e-05,
      "loss": 0.3202,
      "step": 32656
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.5838170647621155,
      "learning_rate": 5e-05,
      "loss": 0.3189,
      "step": 32664
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.5918708443641663,
      "learning_rate": 5e-05,
      "loss": 0.2989,
      "step": 32672
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.5843234658241272,
      "learning_rate": 5e-05,
      "loss": 0.2938,
      "step": 32680
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.5706733465194702,
      "learning_rate": 5e-05,
      "loss": 0.3137,
      "step": 32688
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.7143877744674683,
      "learning_rate": 5e-05,
      "loss": 0.3173,
      "step": 32696
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.60317462682724,
      "learning_rate": 5e-05,
      "loss": 0.2838,
      "step": 32704
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.746619701385498,
      "learning_rate": 5e-05,
      "loss": 0.3137,
      "step": 32712
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.6126787066459656,
      "learning_rate": 5e-05,
      "loss": 0.3078,
      "step": 32720
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.6417933702468872,
      "learning_rate": 5e-05,
      "loss": 0.3145,
      "step": 32728
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.5373066067695618,
      "learning_rate": 5e-05,
      "loss": 0.3168,
      "step": 32736
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.6139423251152039,
      "learning_rate": 5e-05,
      "loss": 0.2816,
      "step": 32744
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.564501941204071,
      "learning_rate": 5e-05,
      "loss": 0.3186,
      "step": 32752
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.5944258570671082,
      "learning_rate": 5e-05,
      "loss": 0.3069,
      "step": 32760
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.6170803308486938,
      "learning_rate": 5e-05,
      "loss": 0.2876,
      "step": 32768
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.7815051674842834,
      "learning_rate": 5e-05,
      "loss": 0.3228,
      "step": 32776
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.7608557343482971,
      "learning_rate": 5e-05,
      "loss": 0.3125,
      "step": 32784
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.5309556126594543,
      "learning_rate": 5e-05,
      "loss": 0.2962,
      "step": 32792
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.706580400466919,
      "learning_rate": 5e-05,
      "loss": 0.3077,
      "step": 32800
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.5989744663238525,
      "learning_rate": 5e-05,
      "loss": 0.3199,
      "step": 32808
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.5955254435539246,
      "learning_rate": 5e-05,
      "loss": 0.3055,
      "step": 32816
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.5587544441223145,
      "learning_rate": 5e-05,
      "loss": 0.2887,
      "step": 32824
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.62523353099823,
      "learning_rate": 5e-05,
      "loss": 0.3096,
      "step": 32832
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.6864722371101379,
      "learning_rate": 5e-05,
      "loss": 0.3077,
      "step": 32840
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.6527178287506104,
      "learning_rate": 5e-05,
      "loss": 0.33,
      "step": 32848
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.524978518486023,
      "learning_rate": 5e-05,
      "loss": 0.3056,
      "step": 32856
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.686862051486969,
      "learning_rate": 5e-05,
      "loss": 0.3099,
      "step": 32864
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.665261447429657,
      "learning_rate": 5e-05,
      "loss": 0.3466,
      "step": 32872
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.5709244608879089,
      "learning_rate": 5e-05,
      "loss": 0.2938,
      "step": 32880
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.6079451441764832,
      "learning_rate": 5e-05,
      "loss": 0.3095,
      "step": 32888
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.6634714603424072,
      "learning_rate": 5e-05,
      "loss": 0.2912,
      "step": 32896
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.5830904245376587,
      "learning_rate": 5e-05,
      "loss": 0.3253,
      "step": 32904
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.5639784336090088,
      "learning_rate": 5e-05,
      "loss": 0.3101,
      "step": 32912
    },
    {
      "epoch": 1.97,
      "grad_norm": 0.6861419677734375,
      "learning_rate": 5e-05,
      "loss": 0.3194,
      "step": 32920
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6051053404808044,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 32928
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.7028206586837769,
      "learning_rate": 5e-05,
      "loss": 0.3208,
      "step": 32936
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6387437582015991,
      "learning_rate": 5e-05,
      "loss": 0.3034,
      "step": 32944
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.7274718880653381,
      "learning_rate": 5e-05,
      "loss": 0.3462,
      "step": 32952
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6495692133903503,
      "learning_rate": 5e-05,
      "loss": 0.2897,
      "step": 32960
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6687620878219604,
      "learning_rate": 5e-05,
      "loss": 0.3147,
      "step": 32968
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6742749214172363,
      "learning_rate": 5e-05,
      "loss": 0.2978,
      "step": 32976
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6099817752838135,
      "learning_rate": 5e-05,
      "loss": 0.3151,
      "step": 32984
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.7449592351913452,
      "learning_rate": 5e-05,
      "loss": 0.315,
      "step": 32992
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.5846185684204102,
      "learning_rate": 5e-05,
      "loss": 0.2947,
      "step": 33000
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6211862564086914,
      "learning_rate": 5e-05,
      "loss": 0.3062,
      "step": 33008
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6154668927192688,
      "learning_rate": 5e-05,
      "loss": 0.2804,
      "step": 33016
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.8500945568084717,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 33024
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.5996040105819702,
      "learning_rate": 5e-05,
      "loss": 0.3125,
      "step": 33032
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.5745533108711243,
      "learning_rate": 5e-05,
      "loss": 0.3209,
      "step": 33040
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.566311776638031,
      "learning_rate": 5e-05,
      "loss": 0.2847,
      "step": 33048
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6378558278083801,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 33056
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6354663372039795,
      "learning_rate": 5e-05,
      "loss": 0.3072,
      "step": 33064
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6098843812942505,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 33072
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.5807830691337585,
      "learning_rate": 5e-05,
      "loss": 0.3429,
      "step": 33080
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6334303617477417,
      "learning_rate": 5e-05,
      "loss": 0.3344,
      "step": 33088
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.747146725654602,
      "learning_rate": 5e-05,
      "loss": 0.2968,
      "step": 33096
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.6184208393096924,
      "learning_rate": 5e-05,
      "loss": 0.3154,
      "step": 33104
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.71232670545578,
      "learning_rate": 5e-05,
      "loss": 0.3029,
      "step": 33112
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.6109605431556702,
      "learning_rate": 5e-05,
      "loss": 0.3009,
      "step": 33120
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.6536057591438293,
      "learning_rate": 5e-05,
      "loss": 0.2906,
      "step": 33128
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.6412925720214844,
      "learning_rate": 5e-05,
      "loss": 0.2878,
      "step": 33136
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.6916685700416565,
      "learning_rate": 5e-05,
      "loss": 0.3271,
      "step": 33144
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.6585358381271362,
      "learning_rate": 5e-05,
      "loss": 0.313,
      "step": 33152
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.588081419467926,
      "learning_rate": 5e-05,
      "loss": 0.3262,
      "step": 33160
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.6517595052719116,
      "learning_rate": 5e-05,
      "loss": 0.3248,
      "step": 33168
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.6306047439575195,
      "learning_rate": 5e-05,
      "loss": 0.3175,
      "step": 33176
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.615467369556427,
      "learning_rate": 5e-05,
      "loss": 0.3345,
      "step": 33184
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.5464417338371277,
      "learning_rate": 5e-05,
      "loss": 0.3139,
      "step": 33192
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.6722164154052734,
      "learning_rate": 5e-05,
      "loss": 0.2811,
      "step": 33200
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.8092257976531982,
      "learning_rate": 5e-05,
      "loss": 0.3334,
      "step": 33208
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.5759871602058411,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 33216
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.6497853994369507,
      "learning_rate": 5e-05,
      "loss": 0.3232,
      "step": 33224
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.6428623199462891,
      "learning_rate": 5e-05,
      "loss": 0.3155,
      "step": 33232
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.6872117519378662,
      "learning_rate": 5e-05,
      "loss": 0.2733,
      "step": 33240
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.6737866997718811,
      "learning_rate": 5e-05,
      "loss": 0.3296,
      "step": 33248
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.8386467099189758,
      "learning_rate": 5e-05,
      "loss": 0.2961,
      "step": 33256
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5997326374053955,
      "learning_rate": 5e-05,
      "loss": 0.2978,
      "step": 33264
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.624103307723999,
      "learning_rate": 5e-05,
      "loss": 0.3028,
      "step": 33272
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6209735870361328,
      "learning_rate": 5e-05,
      "loss": 0.3186,
      "step": 33280
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.638688325881958,
      "learning_rate": 5e-05,
      "loss": 0.2852,
      "step": 33288
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5345243811607361,
      "learning_rate": 5e-05,
      "loss": 0.3351,
      "step": 33296
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5883589386940002,
      "learning_rate": 5e-05,
      "loss": 0.2935,
      "step": 33304
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6901320815086365,
      "learning_rate": 5e-05,
      "loss": 0.3112,
      "step": 33312
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6904137134552002,
      "learning_rate": 5e-05,
      "loss": 0.2791,
      "step": 33320
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6908116340637207,
      "learning_rate": 5e-05,
      "loss": 0.3273,
      "step": 33328
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5904136300086975,
      "learning_rate": 5e-05,
      "loss": 0.3035,
      "step": 33336
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6619035005569458,
      "learning_rate": 5e-05,
      "loss": 0.2846,
      "step": 33344
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5777686834335327,
      "learning_rate": 5e-05,
      "loss": 0.3057,
      "step": 33352
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.7335600256919861,
      "learning_rate": 5e-05,
      "loss": 0.3147,
      "step": 33360
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6805065274238586,
      "learning_rate": 5e-05,
      "loss": 0.3022,
      "step": 33368
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.7246279716491699,
      "learning_rate": 5e-05,
      "loss": 0.3117,
      "step": 33376
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6401209235191345,
      "learning_rate": 5e-05,
      "loss": 0.3099,
      "step": 33384
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5961898565292358,
      "learning_rate": 5e-05,
      "loss": 0.3335,
      "step": 33392
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.638683557510376,
      "learning_rate": 5e-05,
      "loss": 0.2736,
      "step": 33400
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6912566423416138,
      "learning_rate": 5e-05,
      "loss": 0.2974,
      "step": 33408
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.614448070526123,
      "learning_rate": 5e-05,
      "loss": 0.2986,
      "step": 33416
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.625190258026123,
      "learning_rate": 5e-05,
      "loss": 0.3093,
      "step": 33424
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.5448132157325745,
      "learning_rate": 5e-05,
      "loss": 0.3097,
      "step": 33432
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.6119120121002197,
      "learning_rate": 5e-05,
      "loss": 0.3162,
      "step": 33440
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.6171241402626038,
      "learning_rate": 5e-05,
      "loss": 0.3027,
      "step": 33448
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.639794111251831,
      "learning_rate": 5e-05,
      "loss": 0.2909,
      "step": 33456
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.7450178861618042,
      "learning_rate": 5e-05,
      "loss": 0.3252,
      "step": 33464
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.62271648645401,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 33472
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.5962290167808533,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 33480
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.6700425148010254,
      "learning_rate": 5e-05,
      "loss": 0.3193,
      "step": 33488
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.6116033792495728,
      "learning_rate": 5e-05,
      "loss": 0.2812,
      "step": 33496
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.5171489119529724,
      "learning_rate": 5e-05,
      "loss": 0.3072,
      "step": 33504
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.5672289133071899,
      "learning_rate": 5e-05,
      "loss": 0.3061,
      "step": 33512
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.6287549734115601,
      "learning_rate": 5e-05,
      "loss": 0.2874,
      "step": 33520
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.6204075217247009,
      "learning_rate": 5e-05,
      "loss": 0.3178,
      "step": 33528
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.8158624768257141,
      "learning_rate": 5e-05,
      "loss": 0.2754,
      "step": 33536
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.6702231764793396,
      "learning_rate": 5e-05,
      "loss": 0.2962,
      "step": 33544
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.6767700910568237,
      "learning_rate": 5e-05,
      "loss": 0.2908,
      "step": 33552
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.7096847295761108,
      "learning_rate": 5e-05,
      "loss": 0.2978,
      "step": 33560
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.6194784045219421,
      "learning_rate": 5e-05,
      "loss": 0.2866,
      "step": 33568
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.7030655145645142,
      "learning_rate": 5e-05,
      "loss": 0.2932,
      "step": 33576
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.5771032571792603,
      "learning_rate": 5e-05,
      "loss": 0.3046,
      "step": 33584
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.6151476502418518,
      "learning_rate": 5e-05,
      "loss": 0.3001,
      "step": 33592
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.7695232629776001,
      "learning_rate": 5e-05,
      "loss": 0.3312,
      "step": 33600
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.6797298789024353,
      "learning_rate": 5e-05,
      "loss": 0.3145,
      "step": 33608
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.6212589740753174,
      "learning_rate": 5e-05,
      "loss": 0.3069,
      "step": 33616
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.7137076258659363,
      "learning_rate": 5e-05,
      "loss": 0.3157,
      "step": 33624
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.6089023947715759,
      "learning_rate": 5e-05,
      "loss": 0.3256,
      "step": 33632
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.6709553599357605,
      "learning_rate": 5e-05,
      "loss": 0.289,
      "step": 33640
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.6483011841773987,
      "learning_rate": 5e-05,
      "loss": 0.3151,
      "step": 33648
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.5868260860443115,
      "learning_rate": 5e-05,
      "loss": 0.3046,
      "step": 33656
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.6997559070587158,
      "learning_rate": 5e-05,
      "loss": 0.3126,
      "step": 33664
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.7916513085365295,
      "learning_rate": 5e-05,
      "loss": 0.2821,
      "step": 33672
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.6089930534362793,
      "learning_rate": 5e-05,
      "loss": 0.3023,
      "step": 33680
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.720319390296936,
      "learning_rate": 5e-05,
      "loss": 0.2987,
      "step": 33688
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.6192718148231506,
      "learning_rate": 5e-05,
      "loss": 0.319,
      "step": 33696
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.6091421842575073,
      "learning_rate": 5e-05,
      "loss": 0.3143,
      "step": 33704
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.7884953022003174,
      "learning_rate": 5e-05,
      "loss": 0.3128,
      "step": 33712
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.672653079032898,
      "learning_rate": 5e-05,
      "loss": 0.2996,
      "step": 33720
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.5946705937385559,
      "learning_rate": 5e-05,
      "loss": 0.2955,
      "step": 33728
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.5251373648643494,
      "learning_rate": 5e-05,
      "loss": 0.3188,
      "step": 33736
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.7212334871292114,
      "learning_rate": 5e-05,
      "loss": 0.2888,
      "step": 33744
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.7030784487724304,
      "learning_rate": 5e-05,
      "loss": 0.2921,
      "step": 33752
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.7178833484649658,
      "learning_rate": 5e-05,
      "loss": 0.2803,
      "step": 33760
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.6616272330284119,
      "learning_rate": 5e-05,
      "loss": 0.2933,
      "step": 33768
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.8464970588684082,
      "learning_rate": 5e-05,
      "loss": 0.3076,
      "step": 33776
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.6940373778343201,
      "learning_rate": 5e-05,
      "loss": 0.3314,
      "step": 33784
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.7718860507011414,
      "learning_rate": 5e-05,
      "loss": 0.3276,
      "step": 33792
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.5690478086471558,
      "learning_rate": 5e-05,
      "loss": 0.2828,
      "step": 33800
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.726161539554596,
      "learning_rate": 5e-05,
      "loss": 0.2996,
      "step": 33808
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.6550145149230957,
      "learning_rate": 5e-05,
      "loss": 0.3116,
      "step": 33816
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.6981202363967896,
      "learning_rate": 5e-05,
      "loss": 0.304,
      "step": 33824
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.6098544597625732,
      "learning_rate": 5e-05,
      "loss": 0.2707,
      "step": 33832
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.7185953855514526,
      "learning_rate": 5e-05,
      "loss": 0.3084,
      "step": 33840
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.6918792724609375,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 33848
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.6833563446998596,
      "learning_rate": 5e-05,
      "loss": 0.2805,
      "step": 33856
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.733079195022583,
      "learning_rate": 5e-05,
      "loss": 0.2998,
      "step": 33864
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.6734565496444702,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 33872
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.6987329721450806,
      "learning_rate": 5e-05,
      "loss": 0.2969,
      "step": 33880
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.6505094170570374,
      "learning_rate": 5e-05,
      "loss": 0.2992,
      "step": 33888
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.6067156791687012,
      "learning_rate": 5e-05,
      "loss": 0.323,
      "step": 33896
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.5868477821350098,
      "learning_rate": 5e-05,
      "loss": 0.3055,
      "step": 33904
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.5934132933616638,
      "learning_rate": 5e-05,
      "loss": 0.292,
      "step": 33912
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.7100042700767517,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 33920
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.7279655933380127,
      "learning_rate": 5e-05,
      "loss": 0.2718,
      "step": 33928
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.6474448442459106,
      "learning_rate": 5e-05,
      "loss": 0.2973,
      "step": 33936
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.6089739799499512,
      "learning_rate": 5e-05,
      "loss": 0.2754,
      "step": 33944
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.6066088080406189,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 33952
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.7409753799438477,
      "learning_rate": 5e-05,
      "loss": 0.2919,
      "step": 33960
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.6584610342979431,
      "learning_rate": 5e-05,
      "loss": 0.2937,
      "step": 33968
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.6644531488418579,
      "learning_rate": 5e-05,
      "loss": 0.2864,
      "step": 33976
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.0370842218399048,
      "learning_rate": 5e-05,
      "loss": 0.3072,
      "step": 33984
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.5442992448806763,
      "learning_rate": 5e-05,
      "loss": 0.3046,
      "step": 33992
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.5708478689193726,
      "learning_rate": 5e-05,
      "loss": 0.2928,
      "step": 34000
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.6279356479644775,
      "learning_rate": 5e-05,
      "loss": 0.2984,
      "step": 34008
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.6324868202209473,
      "learning_rate": 5e-05,
      "loss": 0.2981,
      "step": 34016
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.747248113155365,
      "learning_rate": 5e-05,
      "loss": 0.2879,
      "step": 34024
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.6252973675727844,
      "learning_rate": 5e-05,
      "loss": 0.2907,
      "step": 34032
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.6712028384208679,
      "learning_rate": 5e-05,
      "loss": 0.3141,
      "step": 34040
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.6060068011283875,
      "learning_rate": 5e-05,
      "loss": 0.3004,
      "step": 34048
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.6172537207603455,
      "learning_rate": 5e-05,
      "loss": 0.2878,
      "step": 34056
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.6541433334350586,
      "learning_rate": 5e-05,
      "loss": 0.3125,
      "step": 34064
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.5899397730827332,
      "learning_rate": 5e-05,
      "loss": 0.307,
      "step": 34072
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.7707744836807251,
      "learning_rate": 5e-05,
      "loss": 0.3114,
      "step": 34080
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.7099409103393555,
      "learning_rate": 5e-05,
      "loss": 0.2869,
      "step": 34088
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.5861613750457764,
      "learning_rate": 5e-05,
      "loss": 0.2988,
      "step": 34096
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.5842878818511963,
      "learning_rate": 5e-05,
      "loss": 0.3108,
      "step": 34104
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.6100829243659973,
      "learning_rate": 5e-05,
      "loss": 0.2942,
      "step": 34112
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.5844601988792419,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 34120
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.5795644521713257,
      "learning_rate": 5e-05,
      "loss": 0.3051,
      "step": 34128
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.5727244019508362,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 34136
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.5585731267929077,
      "learning_rate": 5e-05,
      "loss": 0.31,
      "step": 34144
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.5909925103187561,
      "learning_rate": 5e-05,
      "loss": 0.3092,
      "step": 34152
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.742829442024231,
      "learning_rate": 5e-05,
      "loss": 0.3022,
      "step": 34160
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.5852090716362,
      "learning_rate": 5e-05,
      "loss": 0.2947,
      "step": 34168
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.6433042287826538,
      "learning_rate": 5e-05,
      "loss": 0.3096,
      "step": 34176
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.6526032090187073,
      "learning_rate": 5e-05,
      "loss": 0.3209,
      "step": 34184
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.6622459292411804,
      "learning_rate": 5e-05,
      "loss": 0.2748,
      "step": 34192
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.6245546936988831,
      "learning_rate": 5e-05,
      "loss": 0.2917,
      "step": 34200
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.6430239677429199,
      "learning_rate": 5e-05,
      "loss": 0.2927,
      "step": 34208
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.6137323379516602,
      "learning_rate": 5e-05,
      "loss": 0.3281,
      "step": 34216
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.7029209136962891,
      "learning_rate": 5e-05,
      "loss": 0.3464,
      "step": 34224
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.6862034201622009,
      "learning_rate": 5e-05,
      "loss": 0.2848,
      "step": 34232
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.560742199420929,
      "learning_rate": 5e-05,
      "loss": 0.3105,
      "step": 34240
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.5530500411987305,
      "learning_rate": 5e-05,
      "loss": 0.2793,
      "step": 34248
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.7057939767837524,
      "learning_rate": 5e-05,
      "loss": 0.3174,
      "step": 34256
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.6111828088760376,
      "learning_rate": 5e-05,
      "loss": 0.3027,
      "step": 34264
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.6827762126922607,
      "learning_rate": 5e-05,
      "loss": 0.2939,
      "step": 34272
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.6691879034042358,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 34280
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.5267210006713867,
      "learning_rate": 5e-05,
      "loss": 0.2839,
      "step": 34288
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.6400812864303589,
      "learning_rate": 5e-05,
      "loss": 0.302,
      "step": 34296
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.5773761868476868,
      "learning_rate": 5e-05,
      "loss": 0.3167,
      "step": 34304
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.6979631781578064,
      "learning_rate": 5e-05,
      "loss": 0.3069,
      "step": 34312
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.5852716565132141,
      "learning_rate": 5e-05,
      "loss": 0.3091,
      "step": 34320
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.702029824256897,
      "learning_rate": 5e-05,
      "loss": 0.3141,
      "step": 34328
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.6693731546401978,
      "learning_rate": 5e-05,
      "loss": 0.3039,
      "step": 34336
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.6765850782394409,
      "learning_rate": 5e-05,
      "loss": 0.2878,
      "step": 34344
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.7969835996627808,
      "learning_rate": 5e-05,
      "loss": 0.3199,
      "step": 34352
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.5765413641929626,
      "learning_rate": 5e-05,
      "loss": 0.3038,
      "step": 34360
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.597046434879303,
      "learning_rate": 5e-05,
      "loss": 0.3335,
      "step": 34368
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.5966150760650635,
      "learning_rate": 5e-05,
      "loss": 0.2925,
      "step": 34376
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.6825137734413147,
      "learning_rate": 5e-05,
      "loss": 0.2865,
      "step": 34384
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.5998504161834717,
      "learning_rate": 5e-05,
      "loss": 0.2856,
      "step": 34392
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.6495363116264343,
      "learning_rate": 5e-05,
      "loss": 0.305,
      "step": 34400
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.9537689089775085,
      "learning_rate": 5e-05,
      "loss": 0.3198,
      "step": 34408
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.7256841659545898,
      "learning_rate": 5e-05,
      "loss": 0.3044,
      "step": 34416
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.5560559630393982,
      "learning_rate": 5e-05,
      "loss": 0.3273,
      "step": 34424
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.6606001257896423,
      "learning_rate": 5e-05,
      "loss": 0.3128,
      "step": 34432
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.6448153853416443,
      "learning_rate": 5e-05,
      "loss": 0.33,
      "step": 34440
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.5925772190093994,
      "learning_rate": 5e-05,
      "loss": 0.3141,
      "step": 34448
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.6628158688545227,
      "learning_rate": 5e-05,
      "loss": 0.3305,
      "step": 34456
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.701058566570282,
      "learning_rate": 5e-05,
      "loss": 0.2855,
      "step": 34464
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.6719143986701965,
      "learning_rate": 5e-05,
      "loss": 0.2741,
      "step": 34472
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.626054584980011,
      "learning_rate": 5e-05,
      "loss": 0.322,
      "step": 34480
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.6555227637290955,
      "learning_rate": 5e-05,
      "loss": 0.2757,
      "step": 34488
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.5896575450897217,
      "learning_rate": 5e-05,
      "loss": 0.2764,
      "step": 34496
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.6840566396713257,
      "learning_rate": 5e-05,
      "loss": 0.2861,
      "step": 34504
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.6307763457298279,
      "learning_rate": 5e-05,
      "loss": 0.29,
      "step": 34512
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.5685730576515198,
      "learning_rate": 5e-05,
      "loss": 0.2993,
      "step": 34520
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.6667895317077637,
      "learning_rate": 5e-05,
      "loss": 0.2982,
      "step": 34528
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.6509942412376404,
      "learning_rate": 5e-05,
      "loss": 0.3099,
      "step": 34536
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.664341926574707,
      "learning_rate": 5e-05,
      "loss": 0.2918,
      "step": 34544
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.665938138961792,
      "learning_rate": 5e-05,
      "loss": 0.2968,
      "step": 34552
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.6010467410087585,
      "learning_rate": 5e-05,
      "loss": 0.2894,
      "step": 34560
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.5640990138053894,
      "learning_rate": 5e-05,
      "loss": 0.2821,
      "step": 34568
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.6076362133026123,
      "learning_rate": 5e-05,
      "loss": 0.304,
      "step": 34576
    },
    {
      "epoch": 2.07,
      "grad_norm": 0.6330999732017517,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 34584
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.6572679877281189,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 34592
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.756077766418457,
      "learning_rate": 5e-05,
      "loss": 0.3229,
      "step": 34600
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.599209189414978,
      "learning_rate": 5e-05,
      "loss": 0.3193,
      "step": 34608
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.6513254642486572,
      "learning_rate": 5e-05,
      "loss": 0.3035,
      "step": 34616
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.674548327922821,
      "learning_rate": 5e-05,
      "loss": 0.2868,
      "step": 34624
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.7440518736839294,
      "learning_rate": 5e-05,
      "loss": 0.2785,
      "step": 34632
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.6529659628868103,
      "learning_rate": 5e-05,
      "loss": 0.2805,
      "step": 34640
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.7448461055755615,
      "learning_rate": 5e-05,
      "loss": 0.2819,
      "step": 34648
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.6379222869873047,
      "learning_rate": 5e-05,
      "loss": 0.3467,
      "step": 34656
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.677553117275238,
      "learning_rate": 5e-05,
      "loss": 0.3279,
      "step": 34664
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.5731014609336853,
      "learning_rate": 5e-05,
      "loss": 0.3217,
      "step": 34672
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.6303700804710388,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 34680
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.6213603019714355,
      "learning_rate": 5e-05,
      "loss": 0.3265,
      "step": 34688
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.730735182762146,
      "learning_rate": 5e-05,
      "loss": 0.3347,
      "step": 34696
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.6127389669418335,
      "learning_rate": 5e-05,
      "loss": 0.2943,
      "step": 34704
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.6549146175384521,
      "learning_rate": 5e-05,
      "loss": 0.2754,
      "step": 34712
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.5970664024353027,
      "learning_rate": 5e-05,
      "loss": 0.2949,
      "step": 34720
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.9083128571510315,
      "learning_rate": 5e-05,
      "loss": 0.2921,
      "step": 34728
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.5974630117416382,
      "learning_rate": 5e-05,
      "loss": 0.3344,
      "step": 34736
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.6037518382072449,
      "learning_rate": 5e-05,
      "loss": 0.2737,
      "step": 34744
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.6406481266021729,
      "learning_rate": 5e-05,
      "loss": 0.2862,
      "step": 34752
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.6036675572395325,
      "learning_rate": 5e-05,
      "loss": 0.293,
      "step": 34760
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.7967725396156311,
      "learning_rate": 5e-05,
      "loss": 0.3464,
      "step": 34768
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.6855705380439758,
      "learning_rate": 5e-05,
      "loss": 0.335,
      "step": 34776
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.5681902766227722,
      "learning_rate": 5e-05,
      "loss": 0.3164,
      "step": 34784
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.7049034237861633,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 34792
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.6581477522850037,
      "learning_rate": 5e-05,
      "loss": 0.3025,
      "step": 34800
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.6439927816390991,
      "learning_rate": 5e-05,
      "loss": 0.2912,
      "step": 34808
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.6605757474899292,
      "learning_rate": 5e-05,
      "loss": 0.3256,
      "step": 34816
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.5664170980453491,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 34824
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.7798860669136047,
      "learning_rate": 5e-05,
      "loss": 0.3157,
      "step": 34832
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.6012139916419983,
      "learning_rate": 5e-05,
      "loss": 0.2954,
      "step": 34840
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.621802806854248,
      "learning_rate": 5e-05,
      "loss": 0.2877,
      "step": 34848
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.5794371366500854,
      "learning_rate": 5e-05,
      "loss": 0.3195,
      "step": 34856
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.6351625323295593,
      "learning_rate": 5e-05,
      "loss": 0.3255,
      "step": 34864
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.5443511605262756,
      "learning_rate": 5e-05,
      "loss": 0.2961,
      "step": 34872
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.6854121685028076,
      "learning_rate": 5e-05,
      "loss": 0.2913,
      "step": 34880
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.6780358552932739,
      "learning_rate": 5e-05,
      "loss": 0.3115,
      "step": 34888
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.8292726278305054,
      "learning_rate": 5e-05,
      "loss": 0.2969,
      "step": 34896
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.6861085891723633,
      "learning_rate": 5e-05,
      "loss": 0.3053,
      "step": 34904
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.6821884512901306,
      "learning_rate": 5e-05,
      "loss": 0.2885,
      "step": 34912
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.7392433285713196,
      "learning_rate": 5e-05,
      "loss": 0.2993,
      "step": 34920
    },
    {
      "epoch": 2.1,
      "grad_norm": 1.0883781909942627,
      "learning_rate": 5e-05,
      "loss": 0.3469,
      "step": 34928
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.5960548520088196,
      "learning_rate": 5e-05,
      "loss": 0.2936,
      "step": 34936
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6657291650772095,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 34944
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6449301838874817,
      "learning_rate": 5e-05,
      "loss": 0.3388,
      "step": 34952
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.676032543182373,
      "learning_rate": 5e-05,
      "loss": 0.3249,
      "step": 34960
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6126992106437683,
      "learning_rate": 5e-05,
      "loss": 0.3184,
      "step": 34968
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6443915367126465,
      "learning_rate": 5e-05,
      "loss": 0.3381,
      "step": 34976
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6650373935699463,
      "learning_rate": 5e-05,
      "loss": 0.2601,
      "step": 34984
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6513965725898743,
      "learning_rate": 5e-05,
      "loss": 0.3361,
      "step": 34992
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6869868040084839,
      "learning_rate": 5e-05,
      "loss": 0.3312,
      "step": 35000
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6907528042793274,
      "learning_rate": 5e-05,
      "loss": 0.3082,
      "step": 35008
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6381804347038269,
      "learning_rate": 5e-05,
      "loss": 0.301,
      "step": 35016
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6628227829933167,
      "learning_rate": 5e-05,
      "loss": 0.3204,
      "step": 35024
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6549062728881836,
      "learning_rate": 5e-05,
      "loss": 0.2814,
      "step": 35032
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6663211584091187,
      "learning_rate": 5e-05,
      "loss": 0.2759,
      "step": 35040
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.7172627449035645,
      "learning_rate": 5e-05,
      "loss": 0.3322,
      "step": 35048
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.7100133895874023,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 35056
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6595279574394226,
      "learning_rate": 5e-05,
      "loss": 0.3465,
      "step": 35064
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6271347999572754,
      "learning_rate": 5e-05,
      "loss": 0.3488,
      "step": 35072
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6016432046890259,
      "learning_rate": 5e-05,
      "loss": 0.3175,
      "step": 35080
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.7087594270706177,
      "learning_rate": 5e-05,
      "loss": 0.309,
      "step": 35088
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.8141419887542725,
      "learning_rate": 5e-05,
      "loss": 0.3038,
      "step": 35096
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.6641805768013,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 35104
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.6915740966796875,
      "learning_rate": 5e-05,
      "loss": 0.2751,
      "step": 35112
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.5974162220954895,
      "learning_rate": 5e-05,
      "loss": 0.2938,
      "step": 35120
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.5725933313369751,
      "learning_rate": 5e-05,
      "loss": 0.3008,
      "step": 35128
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.622442901134491,
      "learning_rate": 5e-05,
      "loss": 0.2924,
      "step": 35136
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.7744374871253967,
      "learning_rate": 5e-05,
      "loss": 0.2929,
      "step": 35144
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.5459948778152466,
      "learning_rate": 5e-05,
      "loss": 0.3111,
      "step": 35152
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.6685261130332947,
      "learning_rate": 5e-05,
      "loss": 0.3178,
      "step": 35160
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.6181161999702454,
      "learning_rate": 5e-05,
      "loss": 0.2921,
      "step": 35168
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.7693824768066406,
      "learning_rate": 5e-05,
      "loss": 0.2918,
      "step": 35176
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.6236696839332581,
      "learning_rate": 5e-05,
      "loss": 0.3291,
      "step": 35184
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.6445077061653137,
      "learning_rate": 5e-05,
      "loss": 0.3044,
      "step": 35192
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.6266863942146301,
      "learning_rate": 5e-05,
      "loss": 0.3359,
      "step": 35200
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.6312506198883057,
      "learning_rate": 5e-05,
      "loss": 0.2936,
      "step": 35208
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.7694696187973022,
      "learning_rate": 5e-05,
      "loss": 0.2955,
      "step": 35216
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.5763203501701355,
      "learning_rate": 5e-05,
      "loss": 0.303,
      "step": 35224
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.6253882646560669,
      "learning_rate": 5e-05,
      "loss": 0.3103,
      "step": 35232
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.6531057357788086,
      "learning_rate": 5e-05,
      "loss": 0.3053,
      "step": 35240
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.5977917909622192,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 35248
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.5486586689949036,
      "learning_rate": 5e-05,
      "loss": 0.2697,
      "step": 35256
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6674996614456177,
      "learning_rate": 5e-05,
      "loss": 0.3147,
      "step": 35264
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6355878710746765,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 35272
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.7426425814628601,
      "learning_rate": 5e-05,
      "loss": 0.3062,
      "step": 35280
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6188018321990967,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 35288
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6852284073829651,
      "learning_rate": 5e-05,
      "loss": 0.3162,
      "step": 35296
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6057936549186707,
      "learning_rate": 5e-05,
      "loss": 0.3228,
      "step": 35304
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.7311452627182007,
      "learning_rate": 5e-05,
      "loss": 0.3021,
      "step": 35312
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6523762941360474,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 35320
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.5935900211334229,
      "learning_rate": 5e-05,
      "loss": 0.3142,
      "step": 35328
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6524955630302429,
      "learning_rate": 5e-05,
      "loss": 0.2985,
      "step": 35336
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6457385420799255,
      "learning_rate": 5e-05,
      "loss": 0.2995,
      "step": 35344
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6796466112136841,
      "learning_rate": 5e-05,
      "loss": 0.31,
      "step": 35352
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.5378486514091492,
      "learning_rate": 5e-05,
      "loss": 0.3409,
      "step": 35360
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.5896328091621399,
      "learning_rate": 5e-05,
      "loss": 0.3065,
      "step": 35368
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.767059862613678,
      "learning_rate": 5e-05,
      "loss": 0.3042,
      "step": 35376
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6486144661903381,
      "learning_rate": 5e-05,
      "loss": 0.293,
      "step": 35384
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.7340750694274902,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 35392
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6097944974899292,
      "learning_rate": 5e-05,
      "loss": 0.3082,
      "step": 35400
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.5839712023735046,
      "learning_rate": 5e-05,
      "loss": 0.3002,
      "step": 35408
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.7175628542900085,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 35416
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.5823338627815247,
      "learning_rate": 5e-05,
      "loss": 0.2952,
      "step": 35424
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.7152981758117676,
      "learning_rate": 5e-05,
      "loss": 0.2847,
      "step": 35432
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.6628528237342834,
      "learning_rate": 5e-05,
      "loss": 0.3098,
      "step": 35440
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.5436513423919678,
      "learning_rate": 5e-05,
      "loss": 0.2834,
      "step": 35448
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.6288996934890747,
      "learning_rate": 5e-05,
      "loss": 0.3005,
      "step": 35456
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.6267344951629639,
      "learning_rate": 5e-05,
      "loss": 0.3156,
      "step": 35464
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.5837810635566711,
      "learning_rate": 5e-05,
      "loss": 0.3055,
      "step": 35472
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.5730274319648743,
      "learning_rate": 5e-05,
      "loss": 0.3056,
      "step": 35480
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.7064734697341919,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 35488
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.6013670563697815,
      "learning_rate": 5e-05,
      "loss": 0.3023,
      "step": 35496
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.6408689022064209,
      "learning_rate": 5e-05,
      "loss": 0.2972,
      "step": 35504
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.6689296364784241,
      "learning_rate": 5e-05,
      "loss": 0.3078,
      "step": 35512
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.7959592938423157,
      "learning_rate": 5e-05,
      "loss": 0.304,
      "step": 35520
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.7165562510490417,
      "learning_rate": 5e-05,
      "loss": 0.3267,
      "step": 35528
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.578465461730957,
      "learning_rate": 5e-05,
      "loss": 0.2943,
      "step": 35536
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.7475336194038391,
      "learning_rate": 5e-05,
      "loss": 0.2924,
      "step": 35544
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.535692572593689,
      "learning_rate": 5e-05,
      "loss": 0.2845,
      "step": 35552
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.5952641367912292,
      "learning_rate": 5e-05,
      "loss": 0.2817,
      "step": 35560
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.7175966501235962,
      "learning_rate": 5e-05,
      "loss": 0.2752,
      "step": 35568
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.6104902029037476,
      "learning_rate": 5e-05,
      "loss": 0.2859,
      "step": 35576
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.8362898826599121,
      "learning_rate": 5e-05,
      "loss": 0.3121,
      "step": 35584
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.6079635620117188,
      "learning_rate": 5e-05,
      "loss": 0.2838,
      "step": 35592
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.6556209325790405,
      "learning_rate": 5e-05,
      "loss": 0.3073,
      "step": 35600
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.7367397546768188,
      "learning_rate": 5e-05,
      "loss": 0.312,
      "step": 35608
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.542290985584259,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 35616
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.6999648809432983,
      "learning_rate": 5e-05,
      "loss": 0.2937,
      "step": 35624
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.7182803153991699,
      "learning_rate": 5e-05,
      "loss": 0.2993,
      "step": 35632
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.7122557759284973,
      "learning_rate": 5e-05,
      "loss": 0.2884,
      "step": 35640
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.5871837735176086,
      "learning_rate": 5e-05,
      "loss": 0.2906,
      "step": 35648
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.6398831009864807,
      "learning_rate": 5e-05,
      "loss": 0.2962,
      "step": 35656
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.5147978663444519,
      "learning_rate": 5e-05,
      "loss": 0.3029,
      "step": 35664
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.6116809248924255,
      "learning_rate": 5e-05,
      "loss": 0.3115,
      "step": 35672
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.645084798336029,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 35680
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.5751439929008484,
      "learning_rate": 5e-05,
      "loss": 0.2922,
      "step": 35688
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.7213622331619263,
      "learning_rate": 5e-05,
      "loss": 0.2901,
      "step": 35696
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.7081734538078308,
      "learning_rate": 5e-05,
      "loss": 0.3007,
      "step": 35704
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.5811432600021362,
      "learning_rate": 5e-05,
      "loss": 0.2963,
      "step": 35712
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.6066139340400696,
      "learning_rate": 5e-05,
      "loss": 0.3053,
      "step": 35720
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.848027765750885,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 35728
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.5863878130912781,
      "learning_rate": 5e-05,
      "loss": 0.3202,
      "step": 35736
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.6409555077552795,
      "learning_rate": 5e-05,
      "loss": 0.3068,
      "step": 35744
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.7733837962150574,
      "learning_rate": 5e-05,
      "loss": 0.2864,
      "step": 35752
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.6737145781517029,
      "learning_rate": 5e-05,
      "loss": 0.267,
      "step": 35760
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.6194553375244141,
      "learning_rate": 5e-05,
      "loss": 0.3003,
      "step": 35768
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.6868892908096313,
      "learning_rate": 5e-05,
      "loss": 0.2779,
      "step": 35776
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.5064069628715515,
      "learning_rate": 5e-05,
      "loss": 0.279,
      "step": 35784
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.5821382999420166,
      "learning_rate": 5e-05,
      "loss": 0.2859,
      "step": 35792
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.6568815112113953,
      "learning_rate": 5e-05,
      "loss": 0.3085,
      "step": 35800
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.6781518459320068,
      "learning_rate": 5e-05,
      "loss": 0.2968,
      "step": 35808
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.6481092572212219,
      "learning_rate": 5e-05,
      "loss": 0.2932,
      "step": 35816
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.5989778637886047,
      "learning_rate": 5e-05,
      "loss": 0.3013,
      "step": 35824
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.6787755489349365,
      "learning_rate": 5e-05,
      "loss": 0.3025,
      "step": 35832
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.5951597094535828,
      "learning_rate": 5e-05,
      "loss": 0.3246,
      "step": 35840
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.6521567106246948,
      "learning_rate": 5e-05,
      "loss": 0.3225,
      "step": 35848
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.6048348546028137,
      "learning_rate": 5e-05,
      "loss": 0.3075,
      "step": 35856
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.6591664552688599,
      "learning_rate": 5e-05,
      "loss": 0.2828,
      "step": 35864
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.765644907951355,
      "learning_rate": 5e-05,
      "loss": 0.3039,
      "step": 35872
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.6605204343795776,
      "learning_rate": 5e-05,
      "loss": 0.2622,
      "step": 35880
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.6520184278488159,
      "learning_rate": 5e-05,
      "loss": 0.2895,
      "step": 35888
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.630866527557373,
      "learning_rate": 5e-05,
      "loss": 0.3146,
      "step": 35896
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.5999286770820618,
      "learning_rate": 5e-05,
      "loss": 0.2981,
      "step": 35904
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.7604940533638,
      "learning_rate": 5e-05,
      "loss": 0.3164,
      "step": 35912
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.6128004789352417,
      "learning_rate": 5e-05,
      "loss": 0.277,
      "step": 35920
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6877193450927734,
      "learning_rate": 5e-05,
      "loss": 0.3022,
      "step": 35928
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.5837545394897461,
      "learning_rate": 5e-05,
      "loss": 0.2933,
      "step": 35936
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6405025124549866,
      "learning_rate": 5e-05,
      "loss": 0.3342,
      "step": 35944
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6713099479675293,
      "learning_rate": 5e-05,
      "loss": 0.3186,
      "step": 35952
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.7177920341491699,
      "learning_rate": 5e-05,
      "loss": 0.2996,
      "step": 35960
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.5844731330871582,
      "learning_rate": 5e-05,
      "loss": 0.3025,
      "step": 35968
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.5180978178977966,
      "learning_rate": 5e-05,
      "loss": 0.2943,
      "step": 35976
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.5863854885101318,
      "learning_rate": 5e-05,
      "loss": 0.3041,
      "step": 35984
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.869338870048523,
      "learning_rate": 5e-05,
      "loss": 0.3106,
      "step": 35992
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.7229228019714355,
      "learning_rate": 5e-05,
      "loss": 0.3254,
      "step": 36000
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6602419018745422,
      "learning_rate": 5e-05,
      "loss": 0.2994,
      "step": 36008
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6921038031578064,
      "learning_rate": 5e-05,
      "loss": 0.3207,
      "step": 36016
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6026105880737305,
      "learning_rate": 5e-05,
      "loss": 0.297,
      "step": 36024
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6494675278663635,
      "learning_rate": 5e-05,
      "loss": 0.3162,
      "step": 36032
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.571330189704895,
      "learning_rate": 5e-05,
      "loss": 0.3148,
      "step": 36040
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6477966904640198,
      "learning_rate": 5e-05,
      "loss": 0.3125,
      "step": 36048
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6427239775657654,
      "learning_rate": 5e-05,
      "loss": 0.2941,
      "step": 36056
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6109798550605774,
      "learning_rate": 5e-05,
      "loss": 0.308,
      "step": 36064
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6167916655540466,
      "learning_rate": 5e-05,
      "loss": 0.305,
      "step": 36072
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6329794526100159,
      "learning_rate": 5e-05,
      "loss": 0.2998,
      "step": 36080
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.7988921999931335,
      "learning_rate": 5e-05,
      "loss": 0.3199,
      "step": 36088
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.6414626240730286,
      "learning_rate": 5e-05,
      "loss": 0.2909,
      "step": 36096
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.6331444382667542,
      "learning_rate": 5e-05,
      "loss": 0.3135,
      "step": 36104
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.6388993263244629,
      "learning_rate": 5e-05,
      "loss": 0.3387,
      "step": 36112
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.6552901268005371,
      "learning_rate": 5e-05,
      "loss": 0.3104,
      "step": 36120
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.5995283126831055,
      "learning_rate": 5e-05,
      "loss": 0.3234,
      "step": 36128
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.6615859866142273,
      "learning_rate": 5e-05,
      "loss": 0.3107,
      "step": 36136
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.7124428153038025,
      "learning_rate": 5e-05,
      "loss": 0.3106,
      "step": 36144
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.5738118290901184,
      "learning_rate": 5e-05,
      "loss": 0.281,
      "step": 36152
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.6199686527252197,
      "learning_rate": 5e-05,
      "loss": 0.294,
      "step": 36160
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.6547948718070984,
      "learning_rate": 5e-05,
      "loss": 0.31,
      "step": 36168
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.6711854338645935,
      "learning_rate": 5e-05,
      "loss": 0.2903,
      "step": 36176
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.6233702301979065,
      "learning_rate": 5e-05,
      "loss": 0.3272,
      "step": 36184
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.6276831030845642,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 36192
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.8155984282493591,
      "learning_rate": 5e-05,
      "loss": 0.3214,
      "step": 36200
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.6640543341636658,
      "learning_rate": 5e-05,
      "loss": 0.276,
      "step": 36208
    },
    {
      "epoch": 2.17,
      "grad_norm": 1.0402753353118896,
      "learning_rate": 5e-05,
      "loss": 0.2935,
      "step": 36216
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.6416748762130737,
      "learning_rate": 5e-05,
      "loss": 0.3096,
      "step": 36224
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.5862978100776672,
      "learning_rate": 5e-05,
      "loss": 0.3244,
      "step": 36232
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.6471049189567566,
      "learning_rate": 5e-05,
      "loss": 0.3039,
      "step": 36240
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.5183459520339966,
      "learning_rate": 5e-05,
      "loss": 0.3029,
      "step": 36248
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.7360484004020691,
      "learning_rate": 5e-05,
      "loss": 0.3185,
      "step": 36256
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.6492211818695068,
      "learning_rate": 5e-05,
      "loss": 0.3009,
      "step": 36264
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.6416705250740051,
      "learning_rate": 5e-05,
      "loss": 0.2997,
      "step": 36272
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.6329964995384216,
      "learning_rate": 5e-05,
      "loss": 0.2923,
      "step": 36280
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.6580834984779358,
      "learning_rate": 5e-05,
      "loss": 0.3041,
      "step": 36288
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.7489390969276428,
      "learning_rate": 5e-05,
      "loss": 0.2831,
      "step": 36296
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.6011687517166138,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 36304
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.6361316442489624,
      "learning_rate": 5e-05,
      "loss": 0.2749,
      "step": 36312
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.5619696974754333,
      "learning_rate": 5e-05,
      "loss": 0.2949,
      "step": 36320
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.5708250999450684,
      "learning_rate": 5e-05,
      "loss": 0.325,
      "step": 36328
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.6866110563278198,
      "learning_rate": 5e-05,
      "loss": 0.3048,
      "step": 36336
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.6400188207626343,
      "learning_rate": 5e-05,
      "loss": 0.3069,
      "step": 36344
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.6543012857437134,
      "learning_rate": 5e-05,
      "loss": 0.3115,
      "step": 36352
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.5690435171127319,
      "learning_rate": 5e-05,
      "loss": 0.2884,
      "step": 36360
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.6821727752685547,
      "learning_rate": 5e-05,
      "loss": 0.2936,
      "step": 36368
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.6605945229530334,
      "learning_rate": 5e-05,
      "loss": 0.3023,
      "step": 36376
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.5915712714195251,
      "learning_rate": 5e-05,
      "loss": 0.3167,
      "step": 36384
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.5511715412139893,
      "learning_rate": 5e-05,
      "loss": 0.2779,
      "step": 36392
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.606895387172699,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 36400
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.649661660194397,
      "learning_rate": 5e-05,
      "loss": 0.2932,
      "step": 36408
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.675151526927948,
      "learning_rate": 5e-05,
      "loss": 0.2947,
      "step": 36416
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.592121422290802,
      "learning_rate": 5e-05,
      "loss": 0.3203,
      "step": 36424
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.5714045763015747,
      "learning_rate": 5e-05,
      "loss": 0.2959,
      "step": 36432
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.6446013450622559,
      "learning_rate": 5e-05,
      "loss": 0.3155,
      "step": 36440
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.5687974095344543,
      "learning_rate": 5e-05,
      "loss": 0.2771,
      "step": 36448
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.7733731865882874,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 36456
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.6504940986633301,
      "learning_rate": 5e-05,
      "loss": 0.2987,
      "step": 36464
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.6619157195091248,
      "learning_rate": 5e-05,
      "loss": 0.302,
      "step": 36472
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.7350807785987854,
      "learning_rate": 5e-05,
      "loss": 0.2862,
      "step": 36480
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.6002051830291748,
      "learning_rate": 5e-05,
      "loss": 0.2941,
      "step": 36488
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.6646071076393127,
      "learning_rate": 5e-05,
      "loss": 0.3123,
      "step": 36496
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.7062788009643555,
      "learning_rate": 5e-05,
      "loss": 0.3011,
      "step": 36504
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.6372076272964478,
      "learning_rate": 5e-05,
      "loss": 0.2606,
      "step": 36512
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.6926888823509216,
      "learning_rate": 5e-05,
      "loss": 0.3001,
      "step": 36520
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.6507269144058228,
      "learning_rate": 5e-05,
      "loss": 0.3137,
      "step": 36528
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.6669273972511292,
      "learning_rate": 5e-05,
      "loss": 0.3219,
      "step": 36536
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.580556333065033,
      "learning_rate": 5e-05,
      "loss": 0.3006,
      "step": 36544
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.6498199701309204,
      "learning_rate": 5e-05,
      "loss": 0.2735,
      "step": 36552
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.6825718283653259,
      "learning_rate": 5e-05,
      "loss": 0.3352,
      "step": 36560
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.5762564539909363,
      "learning_rate": 5e-05,
      "loss": 0.3133,
      "step": 36568
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.6229619979858398,
      "learning_rate": 5e-05,
      "loss": 0.2867,
      "step": 36576
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.5978147387504578,
      "learning_rate": 5e-05,
      "loss": 0.2958,
      "step": 36584
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.5443116426467896,
      "learning_rate": 5e-05,
      "loss": 0.2838,
      "step": 36592
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.6572114825248718,
      "learning_rate": 5e-05,
      "loss": 0.3254,
      "step": 36600
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.5623133182525635,
      "learning_rate": 5e-05,
      "loss": 0.2619,
      "step": 36608
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.7928017377853394,
      "learning_rate": 5e-05,
      "loss": 0.2884,
      "step": 36616
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.615080714225769,
      "learning_rate": 5e-05,
      "loss": 0.2802,
      "step": 36624
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.6429153084754944,
      "learning_rate": 5e-05,
      "loss": 0.3029,
      "step": 36632
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.6817951202392578,
      "learning_rate": 5e-05,
      "loss": 0.3277,
      "step": 36640
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.5972500443458557,
      "learning_rate": 5e-05,
      "loss": 0.2881,
      "step": 36648
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.5751915574073792,
      "learning_rate": 5e-05,
      "loss": 0.2869,
      "step": 36656
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.668362557888031,
      "learning_rate": 5e-05,
      "loss": 0.301,
      "step": 36664
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.673183262348175,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 36672
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.6035158038139343,
      "learning_rate": 5e-05,
      "loss": 0.3054,
      "step": 36680
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.5934281945228577,
      "learning_rate": 5e-05,
      "loss": 0.2936,
      "step": 36688
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.6734592318534851,
      "learning_rate": 5e-05,
      "loss": 0.2872,
      "step": 36696
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.6827147006988525,
      "learning_rate": 5e-05,
      "loss": 0.3155,
      "step": 36704
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.6352676153182983,
      "learning_rate": 5e-05,
      "loss": 0.2924,
      "step": 36712
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.6058768630027771,
      "learning_rate": 5e-05,
      "loss": 0.3076,
      "step": 36720
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.9701887965202332,
      "learning_rate": 5e-05,
      "loss": 0.2912,
      "step": 36728
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.5943170785903931,
      "learning_rate": 5e-05,
      "loss": 0.295,
      "step": 36736
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.5929518938064575,
      "learning_rate": 5e-05,
      "loss": 0.2901,
      "step": 36744
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.5840986371040344,
      "learning_rate": 5e-05,
      "loss": 0.2868,
      "step": 36752
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.7452068328857422,
      "learning_rate": 5e-05,
      "loss": 0.2817,
      "step": 36760
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.6725845336914062,
      "learning_rate": 5e-05,
      "loss": 0.2945,
      "step": 36768
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.6371427774429321,
      "learning_rate": 5e-05,
      "loss": 0.3076,
      "step": 36776
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.636585533618927,
      "learning_rate": 5e-05,
      "loss": 0.3125,
      "step": 36784
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.6048322916030884,
      "learning_rate": 5e-05,
      "loss": 0.2964,
      "step": 36792
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.6434220671653748,
      "learning_rate": 5e-05,
      "loss": 0.3292,
      "step": 36800
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.5993325114250183,
      "learning_rate": 5e-05,
      "loss": 0.2553,
      "step": 36808
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.6218364238739014,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 36816
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.805234432220459,
      "learning_rate": 5e-05,
      "loss": 0.2911,
      "step": 36824
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.6788920164108276,
      "learning_rate": 5e-05,
      "loss": 0.2928,
      "step": 36832
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.5948334336280823,
      "learning_rate": 5e-05,
      "loss": 0.3106,
      "step": 36840
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.5703798532485962,
      "learning_rate": 5e-05,
      "loss": 0.3056,
      "step": 36848
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.5591609477996826,
      "learning_rate": 5e-05,
      "loss": 0.323,
      "step": 36856
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.6247930526733398,
      "learning_rate": 5e-05,
      "loss": 0.3168,
      "step": 36864
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.5701536536216736,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 36872
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.5963343381881714,
      "learning_rate": 5e-05,
      "loss": 0.3078,
      "step": 36880
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.6934441328048706,
      "learning_rate": 5e-05,
      "loss": 0.3195,
      "step": 36888
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.6890296936035156,
      "learning_rate": 5e-05,
      "loss": 0.2907,
      "step": 36896
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.6311459541320801,
      "learning_rate": 5e-05,
      "loss": 0.291,
      "step": 36904
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.6376655101776123,
      "learning_rate": 5e-05,
      "loss": 0.3076,
      "step": 36912
    },
    {
      "epoch": 2.21,
      "grad_norm": 0.601832389831543,
      "learning_rate": 5e-05,
      "loss": 0.3201,
      "step": 36920
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.51823890209198,
      "learning_rate": 5e-05,
      "loss": 0.3014,
      "step": 36928
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.6639682054519653,
      "learning_rate": 5e-05,
      "loss": 0.3079,
      "step": 36936
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.6201941967010498,
      "learning_rate": 5e-05,
      "loss": 0.293,
      "step": 36944
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.6443345546722412,
      "learning_rate": 5e-05,
      "loss": 0.2545,
      "step": 36952
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.6350558400154114,
      "learning_rate": 5e-05,
      "loss": 0.2741,
      "step": 36960
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.7044084072113037,
      "learning_rate": 5e-05,
      "loss": 0.3302,
      "step": 36968
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.7037064433097839,
      "learning_rate": 5e-05,
      "loss": 0.2994,
      "step": 36976
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.8831542730331421,
      "learning_rate": 5e-05,
      "loss": 0.2652,
      "step": 36984
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.6058118343353271,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 36992
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.7092124223709106,
      "learning_rate": 5e-05,
      "loss": 0.3545,
      "step": 37000
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.5824806690216064,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 37008
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.7678686380386353,
      "learning_rate": 5e-05,
      "loss": 0.2992,
      "step": 37016
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.6538434624671936,
      "learning_rate": 5e-05,
      "loss": 0.2895,
      "step": 37024
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.697677731513977,
      "learning_rate": 5e-05,
      "loss": 0.2714,
      "step": 37032
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.603809654712677,
      "learning_rate": 5e-05,
      "loss": 0.3403,
      "step": 37040
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.6369549036026001,
      "learning_rate": 5e-05,
      "loss": 0.3041,
      "step": 37048
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.5746632218360901,
      "learning_rate": 5e-05,
      "loss": 0.3128,
      "step": 37056
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.6254834532737732,
      "learning_rate": 5e-05,
      "loss": 0.3253,
      "step": 37064
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.6702522039413452,
      "learning_rate": 5e-05,
      "loss": 0.3106,
      "step": 37072
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.6639187335968018,
      "learning_rate": 5e-05,
      "loss": 0.3184,
      "step": 37080
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.6009498834609985,
      "learning_rate": 5e-05,
      "loss": 0.3169,
      "step": 37088
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.767894983291626,
      "learning_rate": 5e-05,
      "loss": 0.2888,
      "step": 37096
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6578256487846375,
      "learning_rate": 5e-05,
      "loss": 0.3075,
      "step": 37104
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6798973679542542,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 37112
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.5932669639587402,
      "learning_rate": 5e-05,
      "loss": 0.2984,
      "step": 37120
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6434343457221985,
      "learning_rate": 5e-05,
      "loss": 0.3284,
      "step": 37128
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6296672224998474,
      "learning_rate": 5e-05,
      "loss": 0.2737,
      "step": 37136
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6128408908843994,
      "learning_rate": 5e-05,
      "loss": 0.3176,
      "step": 37144
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.5466231107711792,
      "learning_rate": 5e-05,
      "loss": 0.2797,
      "step": 37152
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.5941513776779175,
      "learning_rate": 5e-05,
      "loss": 0.2765,
      "step": 37160
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.7488420009613037,
      "learning_rate": 5e-05,
      "loss": 0.3012,
      "step": 37168
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6419106125831604,
      "learning_rate": 5e-05,
      "loss": 0.3242,
      "step": 37176
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.7095956206321716,
      "learning_rate": 5e-05,
      "loss": 0.281,
      "step": 37184
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6238973140716553,
      "learning_rate": 5e-05,
      "loss": 0.2757,
      "step": 37192
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6558756232261658,
      "learning_rate": 5e-05,
      "loss": 0.2955,
      "step": 37200
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6065971851348877,
      "learning_rate": 5e-05,
      "loss": 0.3013,
      "step": 37208
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6325486302375793,
      "learning_rate": 5e-05,
      "loss": 0.3016,
      "step": 37216
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6270400881767273,
      "learning_rate": 5e-05,
      "loss": 0.2938,
      "step": 37224
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.7032979130744934,
      "learning_rate": 5e-05,
      "loss": 0.2942,
      "step": 37232
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6917093396186829,
      "learning_rate": 5e-05,
      "loss": 0.2944,
      "step": 37240
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6195617914199829,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 37248
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.6298293471336365,
      "learning_rate": 5e-05,
      "loss": 0.311,
      "step": 37256
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.6215317845344543,
      "learning_rate": 5e-05,
      "loss": 0.2941,
      "step": 37264
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.7102223038673401,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 37272
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.7045803070068359,
      "learning_rate": 5e-05,
      "loss": 0.2865,
      "step": 37280
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.6367424130439758,
      "learning_rate": 5e-05,
      "loss": 0.2906,
      "step": 37288
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.5721836090087891,
      "learning_rate": 5e-05,
      "loss": 0.3134,
      "step": 37296
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.6475995779037476,
      "learning_rate": 5e-05,
      "loss": 0.2954,
      "step": 37304
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.6648690700531006,
      "learning_rate": 5e-05,
      "loss": 0.3348,
      "step": 37312
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.632014274597168,
      "learning_rate": 5e-05,
      "loss": 0.3158,
      "step": 37320
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.5545000433921814,
      "learning_rate": 5e-05,
      "loss": 0.3271,
      "step": 37328
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.5390459895133972,
      "learning_rate": 5e-05,
      "loss": 0.3131,
      "step": 37336
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.0811257362365723,
      "learning_rate": 5e-05,
      "loss": 0.3161,
      "step": 37344
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.626251220703125,
      "learning_rate": 5e-05,
      "loss": 0.2774,
      "step": 37352
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.5763014554977417,
      "learning_rate": 5e-05,
      "loss": 0.2653,
      "step": 37360
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.6665917038917542,
      "learning_rate": 5e-05,
      "loss": 0.3089,
      "step": 37368
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.6239259243011475,
      "learning_rate": 5e-05,
      "loss": 0.2969,
      "step": 37376
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.6337071657180786,
      "learning_rate": 5e-05,
      "loss": 0.3073,
      "step": 37384
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.5695187449455261,
      "learning_rate": 5e-05,
      "loss": 0.3229,
      "step": 37392
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.9356067776679993,
      "learning_rate": 5e-05,
      "loss": 0.3221,
      "step": 37400
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.6032189726829529,
      "learning_rate": 5e-05,
      "loss": 0.2936,
      "step": 37408
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.6228855848312378,
      "learning_rate": 5e-05,
      "loss": 0.3076,
      "step": 37416
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.6601117849349976,
      "learning_rate": 5e-05,
      "loss": 0.2981,
      "step": 37424
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.6407434940338135,
      "learning_rate": 5e-05,
      "loss": 0.2999,
      "step": 37432
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.6071450710296631,
      "learning_rate": 5e-05,
      "loss": 0.2739,
      "step": 37440
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.6395639777183533,
      "learning_rate": 5e-05,
      "loss": 0.2829,
      "step": 37448
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.5996021628379822,
      "learning_rate": 5e-05,
      "loss": 0.304,
      "step": 37456
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.591543436050415,
      "learning_rate": 5e-05,
      "loss": 0.3033,
      "step": 37464
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.6968957185745239,
      "learning_rate": 5e-05,
      "loss": 0.3336,
      "step": 37472
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.6018269658088684,
      "learning_rate": 5e-05,
      "loss": 0.2854,
      "step": 37480
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.5727865099906921,
      "learning_rate": 5e-05,
      "loss": 0.3109,
      "step": 37488
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.6840901374816895,
      "learning_rate": 5e-05,
      "loss": 0.3353,
      "step": 37496
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.7259852886199951,
      "learning_rate": 5e-05,
      "loss": 0.2915,
      "step": 37504
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.6973645091056824,
      "learning_rate": 5e-05,
      "loss": 0.2997,
      "step": 37512
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.6102367639541626,
      "learning_rate": 5e-05,
      "loss": 0.3008,
      "step": 37520
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.7072415351867676,
      "learning_rate": 5e-05,
      "loss": 0.2959,
      "step": 37528
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.5736578106880188,
      "learning_rate": 5e-05,
      "loss": 0.302,
      "step": 37536
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.665707528591156,
      "learning_rate": 5e-05,
      "loss": 0.2896,
      "step": 37544
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.672812819480896,
      "learning_rate": 5e-05,
      "loss": 0.2918,
      "step": 37552
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.6195520162582397,
      "learning_rate": 5e-05,
      "loss": 0.3003,
      "step": 37560
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.6691482067108154,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 37568
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.654005229473114,
      "learning_rate": 5e-05,
      "loss": 0.3116,
      "step": 37576
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.7131357192993164,
      "learning_rate": 5e-05,
      "loss": 0.3096,
      "step": 37584
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.6419332027435303,
      "learning_rate": 5e-05,
      "loss": 0.3033,
      "step": 37592
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.5349123477935791,
      "learning_rate": 5e-05,
      "loss": 0.3045,
      "step": 37600
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.7164207100868225,
      "learning_rate": 5e-05,
      "loss": 0.2881,
      "step": 37608
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.6647745370864868,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 37616
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.6049548387527466,
      "learning_rate": 5e-05,
      "loss": 0.2952,
      "step": 37624
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.8890900611877441,
      "learning_rate": 5e-05,
      "loss": 0.2786,
      "step": 37632
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.5999674201011658,
      "learning_rate": 5e-05,
      "loss": 0.3017,
      "step": 37640
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.6872461438179016,
      "learning_rate": 5e-05,
      "loss": 0.3236,
      "step": 37648
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.7345826029777527,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 37656
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.6100128889083862,
      "learning_rate": 5e-05,
      "loss": 0.3124,
      "step": 37664
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.7125124335289001,
      "learning_rate": 5e-05,
      "loss": 0.3348,
      "step": 37672
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.568688690662384,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 37680
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.6751551628112793,
      "learning_rate": 5e-05,
      "loss": 0.2939,
      "step": 37688
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.6173245310783386,
      "learning_rate": 5e-05,
      "loss": 0.2943,
      "step": 37696
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.5619290471076965,
      "learning_rate": 5e-05,
      "loss": 0.3209,
      "step": 37704
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.5667942762374878,
      "learning_rate": 5e-05,
      "loss": 0.3316,
      "step": 37712
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.5969864726066589,
      "learning_rate": 5e-05,
      "loss": 0.3403,
      "step": 37720
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.65639328956604,
      "learning_rate": 5e-05,
      "loss": 0.3313,
      "step": 37728
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.6060450673103333,
      "learning_rate": 5e-05,
      "loss": 0.3008,
      "step": 37736
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.5877370834350586,
      "learning_rate": 5e-05,
      "loss": 0.3335,
      "step": 37744
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.5415775775909424,
      "learning_rate": 5e-05,
      "loss": 0.3109,
      "step": 37752
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.5940651297569275,
      "learning_rate": 5e-05,
      "loss": 0.2832,
      "step": 37760
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.6090815663337708,
      "learning_rate": 5e-05,
      "loss": 0.3139,
      "step": 37768
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.7181258797645569,
      "learning_rate": 5e-05,
      "loss": 0.2832,
      "step": 37776
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.6226044297218323,
      "learning_rate": 5e-05,
      "loss": 0.3065,
      "step": 37784
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.6659483909606934,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 37792
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.5925809144973755,
      "learning_rate": 5e-05,
      "loss": 0.3151,
      "step": 37800
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.7722280025482178,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 37808
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.5793076753616333,
      "learning_rate": 5e-05,
      "loss": 0.3226,
      "step": 37816
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.5952423810958862,
      "learning_rate": 5e-05,
      "loss": 0.3035,
      "step": 37824
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.6048140525817871,
      "learning_rate": 5e-05,
      "loss": 0.2828,
      "step": 37832
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.5968583226203918,
      "learning_rate": 5e-05,
      "loss": 0.2831,
      "step": 37840
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.8620508909225464,
      "learning_rate": 5e-05,
      "loss": 0.3187,
      "step": 37848
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.6623535752296448,
      "learning_rate": 5e-05,
      "loss": 0.3011,
      "step": 37856
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.5874025225639343,
      "learning_rate": 5e-05,
      "loss": 0.2981,
      "step": 37864
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.6014924645423889,
      "learning_rate": 5e-05,
      "loss": 0.3005,
      "step": 37872
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.5988545417785645,
      "learning_rate": 5e-05,
      "loss": 0.2978,
      "step": 37880
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.6225984692573547,
      "learning_rate": 5e-05,
      "loss": 0.3012,
      "step": 37888
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.6618686318397522,
      "learning_rate": 5e-05,
      "loss": 0.3008,
      "step": 37896
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.6414555907249451,
      "learning_rate": 5e-05,
      "loss": 0.3064,
      "step": 37904
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.8806869983673096,
      "learning_rate": 5e-05,
      "loss": 0.2969,
      "step": 37912
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.825934886932373,
      "learning_rate": 5e-05,
      "loss": 0.3116,
      "step": 37920
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.8842064142227173,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 37928
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.5507120490074158,
      "learning_rate": 5e-05,
      "loss": 0.2988,
      "step": 37936
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.6305776834487915,
      "learning_rate": 5e-05,
      "loss": 0.3118,
      "step": 37944
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.7027621865272522,
      "learning_rate": 5e-05,
      "loss": 0.3133,
      "step": 37952
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.6666671633720398,
      "learning_rate": 5e-05,
      "loss": 0.2655,
      "step": 37960
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.582660973072052,
      "learning_rate": 5e-05,
      "loss": 0.2975,
      "step": 37968
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.5677427053451538,
      "learning_rate": 5e-05,
      "loss": 0.2943,
      "step": 37976
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.5992266535758972,
      "learning_rate": 5e-05,
      "loss": 0.2994,
      "step": 37984
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.6102533936500549,
      "learning_rate": 5e-05,
      "loss": 0.2843,
      "step": 37992
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.6920566558837891,
      "learning_rate": 5e-05,
      "loss": 0.3222,
      "step": 38000
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.7182636857032776,
      "learning_rate": 5e-05,
      "loss": 0.3079,
      "step": 38008
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.725227952003479,
      "learning_rate": 5e-05,
      "loss": 0.3053,
      "step": 38016
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.7275867462158203,
      "learning_rate": 5e-05,
      "loss": 0.2809,
      "step": 38024
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.6904053688049316,
      "learning_rate": 5e-05,
      "loss": 0.3113,
      "step": 38032
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.7198679447174072,
      "learning_rate": 5e-05,
      "loss": 0.3077,
      "step": 38040
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.6101671457290649,
      "learning_rate": 5e-05,
      "loss": 0.2934,
      "step": 38048
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.5977408289909363,
      "learning_rate": 5e-05,
      "loss": 0.2975,
      "step": 38056
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.5896178483963013,
      "learning_rate": 5e-05,
      "loss": 0.3097,
      "step": 38064
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.6798603534698486,
      "learning_rate": 5e-05,
      "loss": 0.2853,
      "step": 38072
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.638174295425415,
      "learning_rate": 5e-05,
      "loss": 0.2955,
      "step": 38080
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.6764083504676819,
      "learning_rate": 5e-05,
      "loss": 0.2949,
      "step": 38088
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.6038593053817749,
      "learning_rate": 5e-05,
      "loss": 0.293,
      "step": 38096
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.7122688889503479,
      "learning_rate": 5e-05,
      "loss": 0.3209,
      "step": 38104
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.5856938362121582,
      "learning_rate": 5e-05,
      "loss": 0.3129,
      "step": 38112
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.8337886333465576,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 38120
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.6271276473999023,
      "learning_rate": 5e-05,
      "loss": 0.2896,
      "step": 38128
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.7241807579994202,
      "learning_rate": 5e-05,
      "loss": 0.297,
      "step": 38136
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.6761457324028015,
      "learning_rate": 5e-05,
      "loss": 0.311,
      "step": 38144
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.7312541007995605,
      "learning_rate": 5e-05,
      "loss": 0.2875,
      "step": 38152
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.6207431554794312,
      "learning_rate": 5e-05,
      "loss": 0.3205,
      "step": 38160
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.620068371295929,
      "learning_rate": 5e-05,
      "loss": 0.3108,
      "step": 38168
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.6931141018867493,
      "learning_rate": 5e-05,
      "loss": 0.2994,
      "step": 38176
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.6717990636825562,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 38184
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.5722033381462097,
      "learning_rate": 5e-05,
      "loss": 0.3,
      "step": 38192
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.6998304724693298,
      "learning_rate": 5e-05,
      "loss": 0.3011,
      "step": 38200
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.6486895084381104,
      "learning_rate": 5e-05,
      "loss": 0.3164,
      "step": 38208
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.628426194190979,
      "learning_rate": 5e-05,
      "loss": 0.3122,
      "step": 38216
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.7465749382972717,
      "learning_rate": 5e-05,
      "loss": 0.2839,
      "step": 38224
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.5935664772987366,
      "learning_rate": 5e-05,
      "loss": 0.2868,
      "step": 38232
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.6068112254142761,
      "learning_rate": 5e-05,
      "loss": 0.2803,
      "step": 38240
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.6619434952735901,
      "learning_rate": 5e-05,
      "loss": 0.3102,
      "step": 38248
    },
    {
      "epoch": 2.29,
      "grad_norm": 0.553705096244812,
      "learning_rate": 5e-05,
      "loss": 0.3156,
      "step": 38256
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6309133172035217,
      "learning_rate": 5e-05,
      "loss": 0.322,
      "step": 38264
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6722850799560547,
      "learning_rate": 5e-05,
      "loss": 0.3354,
      "step": 38272
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.593849778175354,
      "learning_rate": 5e-05,
      "loss": 0.3154,
      "step": 38280
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.7579895853996277,
      "learning_rate": 5e-05,
      "loss": 0.3003,
      "step": 38288
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.615243673324585,
      "learning_rate": 5e-05,
      "loss": 0.3048,
      "step": 38296
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.626573920249939,
      "learning_rate": 5e-05,
      "loss": 0.2806,
      "step": 38304
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6306657791137695,
      "learning_rate": 5e-05,
      "loss": 0.2748,
      "step": 38312
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.620042085647583,
      "learning_rate": 5e-05,
      "loss": 0.303,
      "step": 38320
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6806206703186035,
      "learning_rate": 5e-05,
      "loss": 0.3158,
      "step": 38328
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.5799930691719055,
      "learning_rate": 5e-05,
      "loss": 0.2864,
      "step": 38336
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6595515012741089,
      "learning_rate": 5e-05,
      "loss": 0.2738,
      "step": 38344
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6296976208686829,
      "learning_rate": 5e-05,
      "loss": 0.3141,
      "step": 38352
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6960392594337463,
      "learning_rate": 5e-05,
      "loss": 0.3332,
      "step": 38360
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.5870879292488098,
      "learning_rate": 5e-05,
      "loss": 0.2899,
      "step": 38368
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6047790050506592,
      "learning_rate": 5e-05,
      "loss": 0.3015,
      "step": 38376
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6738334894180298,
      "learning_rate": 5e-05,
      "loss": 0.3125,
      "step": 38384
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.5993374586105347,
      "learning_rate": 5e-05,
      "loss": 0.3062,
      "step": 38392
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6050729155540466,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 38400
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6676298975944519,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 38408
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6457134485244751,
      "learning_rate": 5e-05,
      "loss": 0.2789,
      "step": 38416
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6710975766181946,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 38424
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.6140446066856384,
      "learning_rate": 5e-05,
      "loss": 0.3044,
      "step": 38432
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.7010836601257324,
      "learning_rate": 5e-05,
      "loss": 0.3166,
      "step": 38440
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.6236830353736877,
      "learning_rate": 5e-05,
      "loss": 0.2905,
      "step": 38448
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.5548558831214905,
      "learning_rate": 5e-05,
      "loss": 0.3029,
      "step": 38456
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.6812734603881836,
      "learning_rate": 5e-05,
      "loss": 0.3345,
      "step": 38464
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.7783026695251465,
      "learning_rate": 5e-05,
      "loss": 0.3018,
      "step": 38472
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.6403953433036804,
      "learning_rate": 5e-05,
      "loss": 0.3484,
      "step": 38480
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.5561527013778687,
      "learning_rate": 5e-05,
      "loss": 0.3031,
      "step": 38488
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.5599604845046997,
      "learning_rate": 5e-05,
      "loss": 0.2964,
      "step": 38496
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.5921189785003662,
      "learning_rate": 5e-05,
      "loss": 0.3382,
      "step": 38504
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.6342953443527222,
      "learning_rate": 5e-05,
      "loss": 0.3129,
      "step": 38512
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.7284941673278809,
      "learning_rate": 5e-05,
      "loss": 0.269,
      "step": 38520
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.5714460015296936,
      "learning_rate": 5e-05,
      "loss": 0.3294,
      "step": 38528
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.671179473400116,
      "learning_rate": 5e-05,
      "loss": 0.3054,
      "step": 38536
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.5186465382575989,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 38544
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.6793424487113953,
      "learning_rate": 5e-05,
      "loss": 0.3072,
      "step": 38552
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.5749802589416504,
      "learning_rate": 5e-05,
      "loss": 0.3164,
      "step": 38560
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.5586917400360107,
      "learning_rate": 5e-05,
      "loss": 0.3297,
      "step": 38568
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.7100748419761658,
      "learning_rate": 5e-05,
      "loss": 0.3081,
      "step": 38576
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.6091243028640747,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 38584
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.6428732872009277,
      "learning_rate": 5e-05,
      "loss": 0.3119,
      "step": 38592
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.8957899808883667,
      "learning_rate": 5e-05,
      "loss": 0.2853,
      "step": 38600
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.6830476522445679,
      "learning_rate": 5e-05,
      "loss": 0.3078,
      "step": 38608
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.608779788017273,
      "learning_rate": 5e-05,
      "loss": 0.2967,
      "step": 38616
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.6268143057823181,
      "learning_rate": 5e-05,
      "loss": 0.3225,
      "step": 38624
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.597396969795227,
      "learning_rate": 5e-05,
      "loss": 0.3225,
      "step": 38632
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.6015199422836304,
      "learning_rate": 5e-05,
      "loss": 0.2861,
      "step": 38640
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.5399584174156189,
      "learning_rate": 5e-05,
      "loss": 0.2905,
      "step": 38648
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.7615042924880981,
      "learning_rate": 5e-05,
      "loss": 0.319,
      "step": 38656
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.5147743225097656,
      "learning_rate": 5e-05,
      "loss": 0.2797,
      "step": 38664
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.6731091737747192,
      "learning_rate": 5e-05,
      "loss": 0.2913,
      "step": 38672
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.6929093599319458,
      "learning_rate": 5e-05,
      "loss": 0.2905,
      "step": 38680
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.5894959568977356,
      "learning_rate": 5e-05,
      "loss": 0.3013,
      "step": 38688
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.5742965340614319,
      "learning_rate": 5e-05,
      "loss": 0.2885,
      "step": 38696
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.6627801060676575,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 38704
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.5480667352676392,
      "learning_rate": 5e-05,
      "loss": 0.3257,
      "step": 38712
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.6453568339347839,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 38720
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.6295587420463562,
      "learning_rate": 5e-05,
      "loss": 0.2891,
      "step": 38728
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.6452600359916687,
      "learning_rate": 5e-05,
      "loss": 0.2809,
      "step": 38736
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.6803199648857117,
      "learning_rate": 5e-05,
      "loss": 0.2834,
      "step": 38744
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.6281214356422424,
      "learning_rate": 5e-05,
      "loss": 0.3325,
      "step": 38752
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.6381117701530457,
      "learning_rate": 5e-05,
      "loss": 0.2908,
      "step": 38760
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.571891725063324,
      "learning_rate": 5e-05,
      "loss": 0.3036,
      "step": 38768
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.6563186049461365,
      "learning_rate": 5e-05,
      "loss": 0.3106,
      "step": 38776
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.6723490357398987,
      "learning_rate": 5e-05,
      "loss": 0.3207,
      "step": 38784
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.6210009455680847,
      "learning_rate": 5e-05,
      "loss": 0.2588,
      "step": 38792
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.6585608124732971,
      "learning_rate": 5e-05,
      "loss": 0.3473,
      "step": 38800
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.6903204917907715,
      "learning_rate": 5e-05,
      "loss": 0.3045,
      "step": 38808
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.7779436707496643,
      "learning_rate": 5e-05,
      "loss": 0.3288,
      "step": 38816
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.5705909729003906,
      "learning_rate": 5e-05,
      "loss": 0.3126,
      "step": 38824
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.6027182936668396,
      "learning_rate": 5e-05,
      "loss": 0.3114,
      "step": 38832
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.6393328309059143,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 38840
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.5775308012962341,
      "learning_rate": 5e-05,
      "loss": 0.2907,
      "step": 38848
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.708985447883606,
      "learning_rate": 5e-05,
      "loss": 0.3041,
      "step": 38856
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.6738452911376953,
      "learning_rate": 5e-05,
      "loss": 0.2905,
      "step": 38864
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.5714019536972046,
      "learning_rate": 5e-05,
      "loss": 0.3489,
      "step": 38872
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.6533613801002502,
      "learning_rate": 5e-05,
      "loss": 0.2772,
      "step": 38880
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.6517078280448914,
      "learning_rate": 5e-05,
      "loss": 0.3046,
      "step": 38888
    },
    {
      "epoch": 2.33,
      "grad_norm": 1.0752484798431396,
      "learning_rate": 5e-05,
      "loss": 0.2742,
      "step": 38896
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.6682561635971069,
      "learning_rate": 5e-05,
      "loss": 0.3133,
      "step": 38904
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.5477322936058044,
      "learning_rate": 5e-05,
      "loss": 0.3111,
      "step": 38912
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.6984851956367493,
      "learning_rate": 5e-05,
      "loss": 0.2879,
      "step": 38920
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.7032469511032104,
      "learning_rate": 5e-05,
      "loss": 0.301,
      "step": 38928
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.6278706789016724,
      "learning_rate": 5e-05,
      "loss": 0.3238,
      "step": 38936
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.6453021168708801,
      "learning_rate": 5e-05,
      "loss": 0.3072,
      "step": 38944
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.7128610014915466,
      "learning_rate": 5e-05,
      "loss": 0.2898,
      "step": 38952
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.642673909664154,
      "learning_rate": 5e-05,
      "loss": 0.291,
      "step": 38960
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.6340959072113037,
      "learning_rate": 5e-05,
      "loss": 0.3114,
      "step": 38968
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.6102405786514282,
      "learning_rate": 5e-05,
      "loss": 0.3077,
      "step": 38976
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.7362223267555237,
      "learning_rate": 5e-05,
      "loss": 0.3257,
      "step": 38984
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.6402443647384644,
      "learning_rate": 5e-05,
      "loss": 0.2891,
      "step": 38992
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.6240305304527283,
      "learning_rate": 5e-05,
      "loss": 0.2924,
      "step": 39000
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.829791784286499,
      "learning_rate": 5e-05,
      "loss": 0.2851,
      "step": 39008
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.5568175911903381,
      "learning_rate": 5e-05,
      "loss": 0.3268,
      "step": 39016
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.6560308933258057,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 39024
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.6035974025726318,
      "learning_rate": 5e-05,
      "loss": 0.3054,
      "step": 39032
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.585109293460846,
      "learning_rate": 5e-05,
      "loss": 0.2976,
      "step": 39040
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.5724161863327026,
      "learning_rate": 5e-05,
      "loss": 0.3028,
      "step": 39048
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.7190741896629333,
      "learning_rate": 5e-05,
      "loss": 0.3207,
      "step": 39056
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.5369797348976135,
      "learning_rate": 5e-05,
      "loss": 0.3047,
      "step": 39064
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.639708399772644,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 39072
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.585068941116333,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 39080
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.770267128944397,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 39088
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.6562260389328003,
      "learning_rate": 5e-05,
      "loss": 0.2923,
      "step": 39096
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.7404466271400452,
      "learning_rate": 5e-05,
      "loss": 0.3099,
      "step": 39104
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.6235634684562683,
      "learning_rate": 5e-05,
      "loss": 0.2986,
      "step": 39112
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.6007343530654907,
      "learning_rate": 5e-05,
      "loss": 0.2996,
      "step": 39120
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.6609393358230591,
      "learning_rate": 5e-05,
      "loss": 0.2829,
      "step": 39128
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.5788972973823547,
      "learning_rate": 5e-05,
      "loss": 0.2981,
      "step": 39136
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.5924269556999207,
      "learning_rate": 5e-05,
      "loss": 0.317,
      "step": 39144
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.7585251331329346,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 39152
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.5997482538223267,
      "learning_rate": 5e-05,
      "loss": 0.2937,
      "step": 39160
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.6251158118247986,
      "learning_rate": 5e-05,
      "loss": 0.332,
      "step": 39168
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.6827536821365356,
      "learning_rate": 5e-05,
      "loss": 0.2974,
      "step": 39176
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.5719953179359436,
      "learning_rate": 5e-05,
      "loss": 0.2985,
      "step": 39184
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.6790882349014282,
      "learning_rate": 5e-05,
      "loss": 0.3117,
      "step": 39192
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.679449737071991,
      "learning_rate": 5e-05,
      "loss": 0.3094,
      "step": 39200
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.5925180315971375,
      "learning_rate": 5e-05,
      "loss": 0.2888,
      "step": 39208
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.6733051538467407,
      "learning_rate": 5e-05,
      "loss": 0.3073,
      "step": 39216
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.8532371520996094,
      "learning_rate": 5e-05,
      "loss": 0.2977,
      "step": 39224
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.6469686031341553,
      "learning_rate": 5e-05,
      "loss": 0.2529,
      "step": 39232
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.5774940848350525,
      "learning_rate": 5e-05,
      "loss": 0.3155,
      "step": 39240
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.6459593176841736,
      "learning_rate": 5e-05,
      "loss": 0.3047,
      "step": 39248
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.7063837647438049,
      "learning_rate": 5e-05,
      "loss": 0.3022,
      "step": 39256
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.7486778497695923,
      "learning_rate": 5e-05,
      "loss": 0.2984,
      "step": 39264
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.6718953847885132,
      "learning_rate": 5e-05,
      "loss": 0.2924,
      "step": 39272
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.6082789301872253,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 39280
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.6519330739974976,
      "learning_rate": 5e-05,
      "loss": 0.3211,
      "step": 39288
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.6777807474136353,
      "learning_rate": 5e-05,
      "loss": 0.2985,
      "step": 39296
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.5478048920631409,
      "learning_rate": 5e-05,
      "loss": 0.3021,
      "step": 39304
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.790157675743103,
      "learning_rate": 5e-05,
      "loss": 0.3087,
      "step": 39312
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.5503950715065002,
      "learning_rate": 5e-05,
      "loss": 0.2867,
      "step": 39320
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.6626725792884827,
      "learning_rate": 5e-05,
      "loss": 0.2894,
      "step": 39328
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.7251765131950378,
      "learning_rate": 5e-05,
      "loss": 0.2965,
      "step": 39336
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.6375664472579956,
      "learning_rate": 5e-05,
      "loss": 0.2855,
      "step": 39344
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.7227822542190552,
      "learning_rate": 5e-05,
      "loss": 0.3081,
      "step": 39352
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.6668559908866882,
      "learning_rate": 5e-05,
      "loss": 0.2844,
      "step": 39360
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.5607507228851318,
      "learning_rate": 5e-05,
      "loss": 0.2665,
      "step": 39368
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.6410043239593506,
      "learning_rate": 5e-05,
      "loss": 0.3426,
      "step": 39376
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.5905064344406128,
      "learning_rate": 5e-05,
      "loss": 0.2929,
      "step": 39384
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.6198177933692932,
      "learning_rate": 5e-05,
      "loss": 0.3134,
      "step": 39392
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.7068271636962891,
      "learning_rate": 5e-05,
      "loss": 0.302,
      "step": 39400
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.5555166006088257,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 39408
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.5839041471481323,
      "learning_rate": 5e-05,
      "loss": 0.3057,
      "step": 39416
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.648324728012085,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 39424
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.6679414510726929,
      "learning_rate": 5e-05,
      "loss": 0.2813,
      "step": 39432
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.694647490978241,
      "learning_rate": 5e-05,
      "loss": 0.2934,
      "step": 39440
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.6226367354393005,
      "learning_rate": 5e-05,
      "loss": 0.3134,
      "step": 39448
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.5989338755607605,
      "learning_rate": 5e-05,
      "loss": 0.283,
      "step": 39456
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.6056287288665771,
      "learning_rate": 5e-05,
      "loss": 0.2982,
      "step": 39464
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.6420210003852844,
      "learning_rate": 5e-05,
      "loss": 0.289,
      "step": 39472
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.7629812359809875,
      "learning_rate": 5e-05,
      "loss": 0.3198,
      "step": 39480
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.7629595994949341,
      "learning_rate": 5e-05,
      "loss": 0.2764,
      "step": 39488
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.7295454740524292,
      "learning_rate": 5e-05,
      "loss": 0.3219,
      "step": 39496
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.7168627977371216,
      "learning_rate": 5e-05,
      "loss": 0.3581,
      "step": 39504
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.6827220916748047,
      "learning_rate": 5e-05,
      "loss": 0.2923,
      "step": 39512
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.6014231443405151,
      "learning_rate": 5e-05,
      "loss": 0.2898,
      "step": 39520
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.5812781453132629,
      "learning_rate": 5e-05,
      "loss": 0.2997,
      "step": 39528
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.5525895357131958,
      "learning_rate": 5e-05,
      "loss": 0.2946,
      "step": 39536
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.6569519639015198,
      "learning_rate": 5e-05,
      "loss": 0.3192,
      "step": 39544
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.5972513556480408,
      "learning_rate": 5e-05,
      "loss": 0.2976,
      "step": 39552
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.6411344408988953,
      "learning_rate": 5e-05,
      "loss": 0.2965,
      "step": 39560
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.7397971749305725,
      "learning_rate": 5e-05,
      "loss": 0.2799,
      "step": 39568
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.603234589099884,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 39576
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.6248476505279541,
      "learning_rate": 5e-05,
      "loss": 0.3148,
      "step": 39584
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.736970067024231,
      "learning_rate": 5e-05,
      "loss": 0.3073,
      "step": 39592
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.6947547793388367,
      "learning_rate": 5e-05,
      "loss": 0.3217,
      "step": 39600
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.6493974328041077,
      "learning_rate": 5e-05,
      "loss": 0.3125,
      "step": 39608
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.566202700138092,
      "learning_rate": 5e-05,
      "loss": 0.2945,
      "step": 39616
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.6923043131828308,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 39624
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.6410439610481262,
      "learning_rate": 5e-05,
      "loss": 0.2852,
      "step": 39632
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.6848100423812866,
      "learning_rate": 5e-05,
      "loss": 0.3085,
      "step": 39640
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.607154369354248,
      "learning_rate": 5e-05,
      "loss": 0.3517,
      "step": 39648
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.6734180450439453,
      "learning_rate": 5e-05,
      "loss": 0.3091,
      "step": 39656
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.588089644908905,
      "learning_rate": 5e-05,
      "loss": 0.3061,
      "step": 39664
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.7001164555549622,
      "learning_rate": 5e-05,
      "loss": 0.2876,
      "step": 39672
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.7164114713668823,
      "learning_rate": 5e-05,
      "loss": 0.3123,
      "step": 39680
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.6474814414978027,
      "learning_rate": 5e-05,
      "loss": 0.3195,
      "step": 39688
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.6500856280326843,
      "learning_rate": 5e-05,
      "loss": 0.3527,
      "step": 39696
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.6536779999732971,
      "learning_rate": 5e-05,
      "loss": 0.3255,
      "step": 39704
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.5871610641479492,
      "learning_rate": 5e-05,
      "loss": 0.3543,
      "step": 39712
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.6177217364311218,
      "learning_rate": 5e-05,
      "loss": 0.3344,
      "step": 39720
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.5673894286155701,
      "learning_rate": 5e-05,
      "loss": 0.3061,
      "step": 39728
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.8196367621421814,
      "learning_rate": 5e-05,
      "loss": 0.3101,
      "step": 39736
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.5973244905471802,
      "learning_rate": 5e-05,
      "loss": 0.3168,
      "step": 39744
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.6386091709136963,
      "learning_rate": 5e-05,
      "loss": 0.3066,
      "step": 39752
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.5658184289932251,
      "learning_rate": 5e-05,
      "loss": 0.3042,
      "step": 39760
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.5908626914024353,
      "learning_rate": 5e-05,
      "loss": 0.3089,
      "step": 39768
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.7421798706054688,
      "learning_rate": 5e-05,
      "loss": 0.3279,
      "step": 39776
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.5348920226097107,
      "learning_rate": 5e-05,
      "loss": 0.2975,
      "step": 39784
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.5969269871711731,
      "learning_rate": 5e-05,
      "loss": 0.2927,
      "step": 39792
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.6290650367736816,
      "learning_rate": 5e-05,
      "loss": 0.2984,
      "step": 39800
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.6536175012588501,
      "learning_rate": 5e-05,
      "loss": 0.2952,
      "step": 39808
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.7342120409011841,
      "learning_rate": 5e-05,
      "loss": 0.3207,
      "step": 39816
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.6607552170753479,
      "learning_rate": 5e-05,
      "loss": 0.3256,
      "step": 39824
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.5732713341712952,
      "learning_rate": 5e-05,
      "loss": 0.2998,
      "step": 39832
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.7962527275085449,
      "learning_rate": 5e-05,
      "loss": 0.3116,
      "step": 39840
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.6476691365242004,
      "learning_rate": 5e-05,
      "loss": 0.3093,
      "step": 39848
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.6642870903015137,
      "learning_rate": 5e-05,
      "loss": 0.2873,
      "step": 39856
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.6546688079833984,
      "learning_rate": 5e-05,
      "loss": 0.2883,
      "step": 39864
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.6804309487342834,
      "learning_rate": 5e-05,
      "loss": 0.2789,
      "step": 39872
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.5915132761001587,
      "learning_rate": 5e-05,
      "loss": 0.3174,
      "step": 39880
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.6646320223808289,
      "learning_rate": 5e-05,
      "loss": 0.3056,
      "step": 39888
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.5808599591255188,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 39896
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.6956605315208435,
      "learning_rate": 5e-05,
      "loss": 0.3111,
      "step": 39904
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.6645084619522095,
      "learning_rate": 5e-05,
      "loss": 0.2867,
      "step": 39912
    },
    {
      "epoch": 2.39,
      "grad_norm": 0.7163470387458801,
      "learning_rate": 5e-05,
      "loss": 0.2963,
      "step": 39920
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.7772453427314758,
      "learning_rate": 5e-05,
      "loss": 0.3166,
      "step": 39928
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.7229870557785034,
      "learning_rate": 5e-05,
      "loss": 0.2903,
      "step": 39936
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6107905507087708,
      "learning_rate": 5e-05,
      "loss": 0.2729,
      "step": 39944
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6256915926933289,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 39952
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.5379796624183655,
      "learning_rate": 5e-05,
      "loss": 0.2921,
      "step": 39960
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.5199184417724609,
      "learning_rate": 5e-05,
      "loss": 0.2814,
      "step": 39968
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6737632751464844,
      "learning_rate": 5e-05,
      "loss": 0.3169,
      "step": 39976
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.5737455487251282,
      "learning_rate": 5e-05,
      "loss": 0.3237,
      "step": 39984
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6025679111480713,
      "learning_rate": 5e-05,
      "loss": 0.3117,
      "step": 39992
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.7435866594314575,
      "learning_rate": 5e-05,
      "loss": 0.2894,
      "step": 40000
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.664766252040863,
      "learning_rate": 5e-05,
      "loss": 0.3022,
      "step": 40008
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.8677249550819397,
      "learning_rate": 5e-05,
      "loss": 0.3248,
      "step": 40016
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6232808828353882,
      "learning_rate": 5e-05,
      "loss": 0.2939,
      "step": 40024
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.5387217998504639,
      "learning_rate": 5e-05,
      "loss": 0.2883,
      "step": 40032
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.5969482660293579,
      "learning_rate": 5e-05,
      "loss": 0.2996,
      "step": 40040
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.516686201095581,
      "learning_rate": 5e-05,
      "loss": 0.3453,
      "step": 40048
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.5948514938354492,
      "learning_rate": 5e-05,
      "loss": 0.3377,
      "step": 40056
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.5878745913505554,
      "learning_rate": 5e-05,
      "loss": 0.2756,
      "step": 40064
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.7126731276512146,
      "learning_rate": 5e-05,
      "loss": 0.2639,
      "step": 40072
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6098885536193848,
      "learning_rate": 5e-05,
      "loss": 0.3285,
      "step": 40080
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6155340075492859,
      "learning_rate": 5e-05,
      "loss": 0.2732,
      "step": 40088
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.7572523951530457,
      "learning_rate": 5e-05,
      "loss": 0.2933,
      "step": 40096
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.6675192713737488,
      "learning_rate": 5e-05,
      "loss": 0.3068,
      "step": 40104
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.6008213758468628,
      "learning_rate": 5e-05,
      "loss": 0.3017,
      "step": 40112
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.5596103072166443,
      "learning_rate": 5e-05,
      "loss": 0.2831,
      "step": 40120
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.5848262906074524,
      "learning_rate": 5e-05,
      "loss": 0.2989,
      "step": 40128
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.5472460389137268,
      "learning_rate": 5e-05,
      "loss": 0.3103,
      "step": 40136
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.659122884273529,
      "learning_rate": 5e-05,
      "loss": 0.2992,
      "step": 40144
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.5888992547988892,
      "learning_rate": 5e-05,
      "loss": 0.3238,
      "step": 40152
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.6510236263275146,
      "learning_rate": 5e-05,
      "loss": 0.2876,
      "step": 40160
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.5932167172431946,
      "learning_rate": 5e-05,
      "loss": 0.306,
      "step": 40168
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.6228008270263672,
      "learning_rate": 5e-05,
      "loss": 0.3189,
      "step": 40176
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.6276249885559082,
      "learning_rate": 5e-05,
      "loss": 0.3001,
      "step": 40184
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.6535806059837341,
      "learning_rate": 5e-05,
      "loss": 0.3267,
      "step": 40192
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.7551069259643555,
      "learning_rate": 5e-05,
      "loss": 0.3099,
      "step": 40200
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.6390423774719238,
      "learning_rate": 5e-05,
      "loss": 0.2965,
      "step": 40208
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.5948089361190796,
      "learning_rate": 5e-05,
      "loss": 0.3084,
      "step": 40216
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.7382300496101379,
      "learning_rate": 5e-05,
      "loss": 0.2808,
      "step": 40224
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.7567991018295288,
      "learning_rate": 5e-05,
      "loss": 0.2813,
      "step": 40232
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.6652088761329651,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 40240
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.6528613567352295,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 40248
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.6986161470413208,
      "learning_rate": 5e-05,
      "loss": 0.2967,
      "step": 40256
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.6650104522705078,
      "learning_rate": 5e-05,
      "loss": 0.2788,
      "step": 40264
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.6333812475204468,
      "learning_rate": 5e-05,
      "loss": 0.2816,
      "step": 40272
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.5500295162200928,
      "learning_rate": 5e-05,
      "loss": 0.2926,
      "step": 40280
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.6532941460609436,
      "learning_rate": 5e-05,
      "loss": 0.2834,
      "step": 40288
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.5837734341621399,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 40296
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.603937566280365,
      "learning_rate": 5e-05,
      "loss": 0.3172,
      "step": 40304
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.6364027857780457,
      "learning_rate": 5e-05,
      "loss": 0.3149,
      "step": 40312
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.5963456034660339,
      "learning_rate": 5e-05,
      "loss": 0.2903,
      "step": 40320
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.7473012208938599,
      "learning_rate": 5e-05,
      "loss": 0.3141,
      "step": 40328
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.5886682271957397,
      "learning_rate": 5e-05,
      "loss": 0.2743,
      "step": 40336
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.6915072798728943,
      "learning_rate": 5e-05,
      "loss": 0.2907,
      "step": 40344
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.6817536354064941,
      "learning_rate": 5e-05,
      "loss": 0.3122,
      "step": 40352
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.6596297025680542,
      "learning_rate": 5e-05,
      "loss": 0.305,
      "step": 40360
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.687968373298645,
      "learning_rate": 5e-05,
      "loss": 0.3115,
      "step": 40368
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.7359049916267395,
      "learning_rate": 5e-05,
      "loss": 0.3017,
      "step": 40376
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.7480942606925964,
      "learning_rate": 5e-05,
      "loss": 0.248,
      "step": 40384
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.6999598145484924,
      "learning_rate": 5e-05,
      "loss": 0.2889,
      "step": 40392
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.6630874872207642,
      "learning_rate": 5e-05,
      "loss": 0.2967,
      "step": 40400
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.6149833798408508,
      "learning_rate": 5e-05,
      "loss": 0.3236,
      "step": 40408
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.5997551083564758,
      "learning_rate": 5e-05,
      "loss": 0.3083,
      "step": 40416
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.6041567921638489,
      "learning_rate": 5e-05,
      "loss": 0.3064,
      "step": 40424
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.5916931629180908,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 40432
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.5560636520385742,
      "learning_rate": 5e-05,
      "loss": 0.308,
      "step": 40440
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.6694087982177734,
      "learning_rate": 5e-05,
      "loss": 0.2985,
      "step": 40448
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.6651255488395691,
      "learning_rate": 5e-05,
      "loss": 0.2977,
      "step": 40456
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.5878409743309021,
      "learning_rate": 5e-05,
      "loss": 0.303,
      "step": 40464
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.6693480610847473,
      "learning_rate": 5e-05,
      "loss": 0.3106,
      "step": 40472
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.6483968496322632,
      "learning_rate": 5e-05,
      "loss": 0.3266,
      "step": 40480
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.5857736468315125,
      "learning_rate": 5e-05,
      "loss": 0.3188,
      "step": 40488
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.6481632590293884,
      "learning_rate": 5e-05,
      "loss": 0.3006,
      "step": 40496
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.5678340196609497,
      "learning_rate": 5e-05,
      "loss": 0.2866,
      "step": 40504
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.7340509295463562,
      "learning_rate": 5e-05,
      "loss": 0.3053,
      "step": 40512
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.605035662651062,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 40520
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.7723595499992371,
      "learning_rate": 5e-05,
      "loss": 0.2942,
      "step": 40528
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.5724252462387085,
      "learning_rate": 5e-05,
      "loss": 0.3221,
      "step": 40536
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.7172582149505615,
      "learning_rate": 5e-05,
      "loss": 0.2925,
      "step": 40544
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.6228265762329102,
      "learning_rate": 5e-05,
      "loss": 0.3196,
      "step": 40552
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.685594916343689,
      "learning_rate": 5e-05,
      "loss": 0.2941,
      "step": 40560
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.7665099501609802,
      "learning_rate": 5e-05,
      "loss": 0.2878,
      "step": 40568
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.6913102269172668,
      "learning_rate": 5e-05,
      "loss": 0.2691,
      "step": 40576
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.6365355849266052,
      "learning_rate": 5e-05,
      "loss": 0.282,
      "step": 40584
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.6481989026069641,
      "learning_rate": 5e-05,
      "loss": 0.2834,
      "step": 40592
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.6812267899513245,
      "learning_rate": 5e-05,
      "loss": 0.3074,
      "step": 40600
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.5969778299331665,
      "learning_rate": 5e-05,
      "loss": 0.2924,
      "step": 40608
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.5858957171440125,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 40616
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.7226760983467102,
      "learning_rate": 5e-05,
      "loss": 0.3166,
      "step": 40624
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.6648269891738892,
      "learning_rate": 5e-05,
      "loss": 0.332,
      "step": 40632
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.6209232211112976,
      "learning_rate": 5e-05,
      "loss": 0.3235,
      "step": 40640
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.5854129791259766,
      "learning_rate": 5e-05,
      "loss": 0.3104,
      "step": 40648
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.6632853746414185,
      "learning_rate": 5e-05,
      "loss": 0.3045,
      "step": 40656
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.6821274757385254,
      "learning_rate": 5e-05,
      "loss": 0.2955,
      "step": 40664
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.7589138150215149,
      "learning_rate": 5e-05,
      "loss": 0.2943,
      "step": 40672
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.8054712414741516,
      "learning_rate": 5e-05,
      "loss": 0.3009,
      "step": 40680
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.7028850317001343,
      "learning_rate": 5e-05,
      "loss": 0.3035,
      "step": 40688
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.6453988552093506,
      "learning_rate": 5e-05,
      "loss": 0.2877,
      "step": 40696
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.6637486219406128,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 40704
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.6054717302322388,
      "learning_rate": 5e-05,
      "loss": 0.3007,
      "step": 40712
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.5489179491996765,
      "learning_rate": 5e-05,
      "loss": 0.2885,
      "step": 40720
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.6636810302734375,
      "learning_rate": 5e-05,
      "loss": 0.3148,
      "step": 40728
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.7767845988273621,
      "learning_rate": 5e-05,
      "loss": 0.26,
      "step": 40736
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.6648324131965637,
      "learning_rate": 5e-05,
      "loss": 0.3193,
      "step": 40744
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.6004325747489929,
      "learning_rate": 5e-05,
      "loss": 0.3188,
      "step": 40752
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.7949836850166321,
      "learning_rate": 5e-05,
      "loss": 0.3266,
      "step": 40760
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6689242720603943,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 40768
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6812804341316223,
      "learning_rate": 5e-05,
      "loss": 0.295,
      "step": 40776
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.9411259293556213,
      "learning_rate": 5e-05,
      "loss": 0.3224,
      "step": 40784
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.7370694279670715,
      "learning_rate": 5e-05,
      "loss": 0.2901,
      "step": 40792
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6649524569511414,
      "learning_rate": 5e-05,
      "loss": 0.2761,
      "step": 40800
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.5181682109832764,
      "learning_rate": 5e-05,
      "loss": 0.2748,
      "step": 40808
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6523007750511169,
      "learning_rate": 5e-05,
      "loss": 0.2923,
      "step": 40816
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6608277559280396,
      "learning_rate": 5e-05,
      "loss": 0.3118,
      "step": 40824
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6516743302345276,
      "learning_rate": 5e-05,
      "loss": 0.2883,
      "step": 40832
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6340296864509583,
      "learning_rate": 5e-05,
      "loss": 0.2969,
      "step": 40840
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6056206822395325,
      "learning_rate": 5e-05,
      "loss": 0.2768,
      "step": 40848
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.5833117961883545,
      "learning_rate": 5e-05,
      "loss": 0.2844,
      "step": 40856
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6714105606079102,
      "learning_rate": 5e-05,
      "loss": 0.294,
      "step": 40864
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.7573038935661316,
      "learning_rate": 5e-05,
      "loss": 0.3164,
      "step": 40872
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.5963425636291504,
      "learning_rate": 5e-05,
      "loss": 0.2889,
      "step": 40880
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6248946785926819,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 40888
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6597451567649841,
      "learning_rate": 5e-05,
      "loss": 0.2962,
      "step": 40896
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6772807240486145,
      "learning_rate": 5e-05,
      "loss": 0.2839,
      "step": 40904
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.5841982960700989,
      "learning_rate": 5e-05,
      "loss": 0.3085,
      "step": 40912
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.5217612385749817,
      "learning_rate": 5e-05,
      "loss": 0.2954,
      "step": 40920
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.5863867998123169,
      "learning_rate": 5e-05,
      "loss": 0.2755,
      "step": 40928
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.643606424331665,
      "learning_rate": 5e-05,
      "loss": 0.3257,
      "step": 40936
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.6454321146011353,
      "learning_rate": 5e-05,
      "loss": 0.2996,
      "step": 40944
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.6065958142280579,
      "learning_rate": 5e-05,
      "loss": 0.3047,
      "step": 40952
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.6760237812995911,
      "learning_rate": 5e-05,
      "loss": 0.3297,
      "step": 40960
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.6196637749671936,
      "learning_rate": 5e-05,
      "loss": 0.3095,
      "step": 40968
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.606059730052948,
      "learning_rate": 5e-05,
      "loss": 0.3266,
      "step": 40976
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.6052684187889099,
      "learning_rate": 5e-05,
      "loss": 0.3066,
      "step": 40984
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.7076948881149292,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 40992
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.5399879813194275,
      "learning_rate": 5e-05,
      "loss": 0.3192,
      "step": 41000
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.7474480271339417,
      "learning_rate": 5e-05,
      "loss": 0.2852,
      "step": 41008
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.7189234495162964,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 41016
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.6479636430740356,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 41024
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.5828351378440857,
      "learning_rate": 5e-05,
      "loss": 0.2774,
      "step": 41032
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.6216056942939758,
      "learning_rate": 5e-05,
      "loss": 0.282,
      "step": 41040
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.6216005086898804,
      "learning_rate": 5e-05,
      "loss": 0.2901,
      "step": 41048
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.7699791789054871,
      "learning_rate": 5e-05,
      "loss": 0.2966,
      "step": 41056
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.5351660251617432,
      "learning_rate": 5e-05,
      "loss": 0.2918,
      "step": 41064
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.6201372146606445,
      "learning_rate": 5e-05,
      "loss": 0.2909,
      "step": 41072
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.6043215990066528,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 41080
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.5500293374061584,
      "learning_rate": 5e-05,
      "loss": 0.2953,
      "step": 41088
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.7515226006507874,
      "learning_rate": 5e-05,
      "loss": 0.3262,
      "step": 41096
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.5611081123352051,
      "learning_rate": 5e-05,
      "loss": 0.2601,
      "step": 41104
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.6043957471847534,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 41112
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.5335047245025635,
      "learning_rate": 5e-05,
      "loss": 0.2847,
      "step": 41120
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.6916287541389465,
      "learning_rate": 5e-05,
      "loss": 0.2886,
      "step": 41128
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.6827853918075562,
      "learning_rate": 5e-05,
      "loss": 0.2958,
      "step": 41136
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.7283211946487427,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 41144
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.6678784489631653,
      "learning_rate": 5e-05,
      "loss": 0.3146,
      "step": 41152
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.6541714072227478,
      "learning_rate": 5e-05,
      "loss": 0.329,
      "step": 41160
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.6567519307136536,
      "learning_rate": 5e-05,
      "loss": 0.2873,
      "step": 41168
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.565330982208252,
      "learning_rate": 5e-05,
      "loss": 0.2717,
      "step": 41176
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.5949271321296692,
      "learning_rate": 5e-05,
      "loss": 0.2909,
      "step": 41184
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.5535311698913574,
      "learning_rate": 5e-05,
      "loss": 0.3141,
      "step": 41192
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.6690227389335632,
      "learning_rate": 5e-05,
      "loss": 0.2745,
      "step": 41200
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.6599024534225464,
      "learning_rate": 5e-05,
      "loss": 0.3299,
      "step": 41208
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.6991164088249207,
      "learning_rate": 5e-05,
      "loss": 0.2957,
      "step": 41216
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.7624493837356567,
      "learning_rate": 5e-05,
      "loss": 0.2793,
      "step": 41224
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.6447016596794128,
      "learning_rate": 5e-05,
      "loss": 0.2675,
      "step": 41232
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.64013671875,
      "learning_rate": 5e-05,
      "loss": 0.287,
      "step": 41240
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.6583411693572998,
      "learning_rate": 5e-05,
      "loss": 0.3129,
      "step": 41248
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.6177353262901306,
      "learning_rate": 5e-05,
      "loss": 0.3184,
      "step": 41256
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.5793857574462891,
      "learning_rate": 5e-05,
      "loss": 0.3162,
      "step": 41264
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.614406943321228,
      "learning_rate": 5e-05,
      "loss": 0.2981,
      "step": 41272
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.7289506793022156,
      "learning_rate": 5e-05,
      "loss": 0.3116,
      "step": 41280
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.5549356937408447,
      "learning_rate": 5e-05,
      "loss": 0.3044,
      "step": 41288
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.5885474681854248,
      "learning_rate": 5e-05,
      "loss": 0.2897,
      "step": 41296
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.6884485483169556,
      "learning_rate": 5e-05,
      "loss": 0.3285,
      "step": 41304
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.7044220566749573,
      "learning_rate": 5e-05,
      "loss": 0.2848,
      "step": 41312
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.6093472838401794,
      "learning_rate": 5e-05,
      "loss": 0.3098,
      "step": 41320
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.6050266623497009,
      "learning_rate": 5e-05,
      "loss": 0.2953,
      "step": 41328
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.6073393821716309,
      "learning_rate": 5e-05,
      "loss": 0.3055,
      "step": 41336
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.6413955092430115,
      "learning_rate": 5e-05,
      "loss": 0.3072,
      "step": 41344
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.544404149055481,
      "learning_rate": 5e-05,
      "loss": 0.2797,
      "step": 41352
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.5990931391716003,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 41360
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.7089073061943054,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 41368
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.6734262108802795,
      "learning_rate": 5e-05,
      "loss": 0.2841,
      "step": 41376
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.7058226466178894,
      "learning_rate": 5e-05,
      "loss": 0.2998,
      "step": 41384
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.6440843939781189,
      "learning_rate": 5e-05,
      "loss": 0.3098,
      "step": 41392
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.6988478899002075,
      "learning_rate": 5e-05,
      "loss": 0.3036,
      "step": 41400
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.7263687252998352,
      "learning_rate": 5e-05,
      "loss": 0.3022,
      "step": 41408
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.69175785779953,
      "learning_rate": 5e-05,
      "loss": 0.3099,
      "step": 41416
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.5404467582702637,
      "learning_rate": 5e-05,
      "loss": 0.2928,
      "step": 41424
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.635549783706665,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 41432
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.6730602383613586,
      "learning_rate": 5e-05,
      "loss": 0.2909,
      "step": 41440
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.6542193293571472,
      "learning_rate": 5e-05,
      "loss": 0.3027,
      "step": 41448
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.7035797834396362,
      "learning_rate": 5e-05,
      "loss": 0.309,
      "step": 41456
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.6261968612670898,
      "learning_rate": 5e-05,
      "loss": 0.2838,
      "step": 41464
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.6101805567741394,
      "learning_rate": 5e-05,
      "loss": 0.302,
      "step": 41472
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.6766106486320496,
      "learning_rate": 5e-05,
      "loss": 0.3042,
      "step": 41480
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.6229290962219238,
      "learning_rate": 5e-05,
      "loss": 0.3113,
      "step": 41488
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.6839847564697266,
      "learning_rate": 5e-05,
      "loss": 0.2992,
      "step": 41496
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.6132160425186157,
      "learning_rate": 5e-05,
      "loss": 0.3083,
      "step": 41504
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.7500802874565125,
      "learning_rate": 5e-05,
      "loss": 0.2972,
      "step": 41512
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.599768877029419,
      "learning_rate": 5e-05,
      "loss": 0.2968,
      "step": 41520
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.5357787609100342,
      "learning_rate": 5e-05,
      "loss": 0.2936,
      "step": 41528
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.607850193977356,
      "learning_rate": 5e-05,
      "loss": 0.2889,
      "step": 41536
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.772201657295227,
      "learning_rate": 5e-05,
      "loss": 0.3037,
      "step": 41544
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.6267467141151428,
      "learning_rate": 5e-05,
      "loss": 0.3226,
      "step": 41552
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.6349508762359619,
      "learning_rate": 5e-05,
      "loss": 0.3106,
      "step": 41560
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.7476595640182495,
      "learning_rate": 5e-05,
      "loss": 0.3046,
      "step": 41568
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.6109424829483032,
      "learning_rate": 5e-05,
      "loss": 0.2911,
      "step": 41576
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.5915241837501526,
      "learning_rate": 5e-05,
      "loss": 0.2764,
      "step": 41584
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.5496276617050171,
      "learning_rate": 5e-05,
      "loss": 0.3262,
      "step": 41592
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.569719135761261,
      "learning_rate": 5e-05,
      "loss": 0.2777,
      "step": 41600
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.74895179271698,
      "learning_rate": 5e-05,
      "loss": 0.2911,
      "step": 41608
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.5299206972122192,
      "learning_rate": 5e-05,
      "loss": 0.297,
      "step": 41616
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6693989634513855,
      "learning_rate": 5e-05,
      "loss": 0.2943,
      "step": 41624
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6282646059989929,
      "learning_rate": 5e-05,
      "loss": 0.2902,
      "step": 41632
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6600635647773743,
      "learning_rate": 5e-05,
      "loss": 0.3111,
      "step": 41640
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6842719912528992,
      "learning_rate": 5e-05,
      "loss": 0.2979,
      "step": 41648
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.7022441029548645,
      "learning_rate": 5e-05,
      "loss": 0.2984,
      "step": 41656
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6902121901512146,
      "learning_rate": 5e-05,
      "loss": 0.3057,
      "step": 41664
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6779572367668152,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 41672
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6392619013786316,
      "learning_rate": 5e-05,
      "loss": 0.2993,
      "step": 41680
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6116772294044495,
      "learning_rate": 5e-05,
      "loss": 0.2956,
      "step": 41688
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6354489922523499,
      "learning_rate": 5e-05,
      "loss": 0.2897,
      "step": 41696
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.5698193907737732,
      "learning_rate": 5e-05,
      "loss": 0.3389,
      "step": 41704
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.5716139078140259,
      "learning_rate": 5e-05,
      "loss": 0.2938,
      "step": 41712
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6254584789276123,
      "learning_rate": 5e-05,
      "loss": 0.2901,
      "step": 41720
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.716270923614502,
      "learning_rate": 5e-05,
      "loss": 0.3397,
      "step": 41728
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6277835965156555,
      "learning_rate": 5e-05,
      "loss": 0.2731,
      "step": 41736
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6017786264419556,
      "learning_rate": 5e-05,
      "loss": 0.3279,
      "step": 41744
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.759894847869873,
      "learning_rate": 5e-05,
      "loss": 0.3245,
      "step": 41752
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.6472707390785217,
      "learning_rate": 5e-05,
      "loss": 0.3212,
      "step": 41760
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.5905184149742126,
      "learning_rate": 5e-05,
      "loss": 0.2979,
      "step": 41768
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.6444873213768005,
      "learning_rate": 5e-05,
      "loss": 0.2966,
      "step": 41776
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.6674420237541199,
      "learning_rate": 5e-05,
      "loss": 0.3129,
      "step": 41784
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.6524333953857422,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 41792
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.6353583335876465,
      "learning_rate": 5e-05,
      "loss": 0.2995,
      "step": 41800
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.6584296822547913,
      "learning_rate": 5e-05,
      "loss": 0.3031,
      "step": 41808
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.6740649938583374,
      "learning_rate": 5e-05,
      "loss": 0.3197,
      "step": 41816
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.6107770204544067,
      "learning_rate": 5e-05,
      "loss": 0.3169,
      "step": 41824
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.6051254272460938,
      "learning_rate": 5e-05,
      "loss": 0.3198,
      "step": 41832
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.9687848687171936,
      "learning_rate": 5e-05,
      "loss": 0.2909,
      "step": 41840
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.7220578193664551,
      "learning_rate": 5e-05,
      "loss": 0.3069,
      "step": 41848
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.6757155656814575,
      "learning_rate": 5e-05,
      "loss": 0.2947,
      "step": 41856
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.8425447344779968,
      "learning_rate": 5e-05,
      "loss": 0.3018,
      "step": 41864
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.7236946821212769,
      "learning_rate": 5e-05,
      "loss": 0.3182,
      "step": 41872
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.5741114616394043,
      "learning_rate": 5e-05,
      "loss": 0.3054,
      "step": 41880
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.6198058724403381,
      "learning_rate": 5e-05,
      "loss": 0.273,
      "step": 41888
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.5854181051254272,
      "learning_rate": 5e-05,
      "loss": 0.3133,
      "step": 41896
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.4917004108428955,
      "learning_rate": 5e-05,
      "loss": 0.2767,
      "step": 41904
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.60142982006073,
      "learning_rate": 5e-05,
      "loss": 0.2984,
      "step": 41912
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.6415871977806091,
      "learning_rate": 5e-05,
      "loss": 0.3341,
      "step": 41920
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.5700823664665222,
      "learning_rate": 5e-05,
      "loss": 0.2921,
      "step": 41928
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.8009951114654541,
      "learning_rate": 5e-05,
      "loss": 0.2862,
      "step": 41936
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.7412938475608826,
      "learning_rate": 5e-05,
      "loss": 0.2725,
      "step": 41944
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.6792343854904175,
      "learning_rate": 5e-05,
      "loss": 0.2959,
      "step": 41952
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.5643225312232971,
      "learning_rate": 5e-05,
      "loss": 0.3103,
      "step": 41960
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.6639535427093506,
      "learning_rate": 5e-05,
      "loss": 0.2988,
      "step": 41968
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.627422571182251,
      "learning_rate": 5e-05,
      "loss": 0.3048,
      "step": 41976
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.7760323286056519,
      "learning_rate": 5e-05,
      "loss": 0.2809,
      "step": 41984
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.5550137162208557,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 41992
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.6789913177490234,
      "learning_rate": 5e-05,
      "loss": 0.3124,
      "step": 42000
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.6383979320526123,
      "learning_rate": 5e-05,
      "loss": 0.2783,
      "step": 42008
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.6507329344749451,
      "learning_rate": 5e-05,
      "loss": 0.2836,
      "step": 42016
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.709577202796936,
      "learning_rate": 5e-05,
      "loss": 0.3366,
      "step": 42024
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.5554131865501404,
      "learning_rate": 5e-05,
      "loss": 0.3129,
      "step": 42032
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.7762128114700317,
      "learning_rate": 5e-05,
      "loss": 0.28,
      "step": 42040
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.5615707039833069,
      "learning_rate": 5e-05,
      "loss": 0.3108,
      "step": 42048
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.6218012571334839,
      "learning_rate": 5e-05,
      "loss": 0.3077,
      "step": 42056
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.6363071203231812,
      "learning_rate": 5e-05,
      "loss": 0.303,
      "step": 42064
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.5617914795875549,
      "learning_rate": 5e-05,
      "loss": 0.2971,
      "step": 42072
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.6020826697349548,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 42080
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.6297128796577454,
      "learning_rate": 5e-05,
      "loss": 0.2891,
      "step": 42088
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.6232288479804993,
      "learning_rate": 5e-05,
      "loss": 0.2852,
      "step": 42096
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.6189300417900085,
      "learning_rate": 5e-05,
      "loss": 0.3056,
      "step": 42104
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.5925434231758118,
      "learning_rate": 5e-05,
      "loss": 0.3,
      "step": 42112
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.6548433303833008,
      "learning_rate": 5e-05,
      "loss": 0.2979,
      "step": 42120
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.7664344906806946,
      "learning_rate": 5e-05,
      "loss": 0.2772,
      "step": 42128
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.6799829006195068,
      "learning_rate": 5e-05,
      "loss": 0.3008,
      "step": 42136
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.5557929277420044,
      "learning_rate": 5e-05,
      "loss": 0.2993,
      "step": 42144
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.6533363461494446,
      "learning_rate": 5e-05,
      "loss": 0.3306,
      "step": 42152
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.5907695293426514,
      "learning_rate": 5e-05,
      "loss": 0.2802,
      "step": 42160
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.5936056971549988,
      "learning_rate": 5e-05,
      "loss": 0.2927,
      "step": 42168
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.6795068979263306,
      "learning_rate": 5e-05,
      "loss": 0.3279,
      "step": 42176
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.7105458974838257,
      "learning_rate": 5e-05,
      "loss": 0.3316,
      "step": 42184
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.6773089170455933,
      "learning_rate": 5e-05,
      "loss": 0.317,
      "step": 42192
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.6154956817626953,
      "learning_rate": 5e-05,
      "loss": 0.3112,
      "step": 42200
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.6059722304344177,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 42208
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.60365229845047,
      "learning_rate": 5e-05,
      "loss": 0.3126,
      "step": 42216
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.6008744239807129,
      "learning_rate": 5e-05,
      "loss": 0.2916,
      "step": 42224
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.677692711353302,
      "learning_rate": 5e-05,
      "loss": 0.2992,
      "step": 42232
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.540529191493988,
      "learning_rate": 5e-05,
      "loss": 0.2936,
      "step": 42240
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.7514981627464294,
      "learning_rate": 5e-05,
      "loss": 0.2811,
      "step": 42248
    },
    {
      "epoch": 2.53,
      "grad_norm": 0.6184205412864685,
      "learning_rate": 5e-05,
      "loss": 0.2942,
      "step": 42256
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.549405038356781,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 42264
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.6037447452545166,
      "learning_rate": 5e-05,
      "loss": 0.2823,
      "step": 42272
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.5766615271568298,
      "learning_rate": 5e-05,
      "loss": 0.2825,
      "step": 42280
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.6599771976470947,
      "learning_rate": 5e-05,
      "loss": 0.2912,
      "step": 42288
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.5782356858253479,
      "learning_rate": 5e-05,
      "loss": 0.3217,
      "step": 42296
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.6222048401832581,
      "learning_rate": 5e-05,
      "loss": 0.2782,
      "step": 42304
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.5813248753547668,
      "learning_rate": 5e-05,
      "loss": 0.2502,
      "step": 42312
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.7782464027404785,
      "learning_rate": 5e-05,
      "loss": 0.3147,
      "step": 42320
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.6867289543151855,
      "learning_rate": 5e-05,
      "loss": 0.323,
      "step": 42328
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.7814149260520935,
      "learning_rate": 5e-05,
      "loss": 0.2945,
      "step": 42336
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.6594758629798889,
      "learning_rate": 5e-05,
      "loss": 0.297,
      "step": 42344
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.6560435891151428,
      "learning_rate": 5e-05,
      "loss": 0.2721,
      "step": 42352
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.6224526762962341,
      "learning_rate": 5e-05,
      "loss": 0.3113,
      "step": 42360
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.5614458322525024,
      "learning_rate": 5e-05,
      "loss": 0.3003,
      "step": 42368
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.7222800254821777,
      "learning_rate": 5e-05,
      "loss": 0.3208,
      "step": 42376
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.5971099734306335,
      "learning_rate": 5e-05,
      "loss": 0.3273,
      "step": 42384
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.6286357641220093,
      "learning_rate": 5e-05,
      "loss": 0.3131,
      "step": 42392
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.7015527486801147,
      "learning_rate": 5e-05,
      "loss": 0.2936,
      "step": 42400
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.6639447212219238,
      "learning_rate": 5e-05,
      "loss": 0.3041,
      "step": 42408
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.6756492257118225,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 42416
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.8122789859771729,
      "learning_rate": 5e-05,
      "loss": 0.3033,
      "step": 42424
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.6036916375160217,
      "learning_rate": 5e-05,
      "loss": 0.2964,
      "step": 42432
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.5815976858139038,
      "learning_rate": 5e-05,
      "loss": 0.2733,
      "step": 42440
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.6676626801490784,
      "learning_rate": 5e-05,
      "loss": 0.3027,
      "step": 42448
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.5979791879653931,
      "learning_rate": 5e-05,
      "loss": 0.2902,
      "step": 42456
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.7888495922088623,
      "learning_rate": 5e-05,
      "loss": 0.3147,
      "step": 42464
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.6226103901863098,
      "learning_rate": 5e-05,
      "loss": 0.2688,
      "step": 42472
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.7300316095352173,
      "learning_rate": 5e-05,
      "loss": 0.2897,
      "step": 42480
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.6403544545173645,
      "learning_rate": 5e-05,
      "loss": 0.28,
      "step": 42488
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.6648208498954773,
      "learning_rate": 5e-05,
      "loss": 0.2894,
      "step": 42496
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.5982799530029297,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 42504
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.5617195963859558,
      "learning_rate": 5e-05,
      "loss": 0.2943,
      "step": 42512
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.75260329246521,
      "learning_rate": 5e-05,
      "loss": 0.3249,
      "step": 42520
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.6047691702842712,
      "learning_rate": 5e-05,
      "loss": 0.3202,
      "step": 42528
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.6447746753692627,
      "learning_rate": 5e-05,
      "loss": 0.2854,
      "step": 42536
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.6431092619895935,
      "learning_rate": 5e-05,
      "loss": 0.3007,
      "step": 42544
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.5862928628921509,
      "learning_rate": 5e-05,
      "loss": 0.3254,
      "step": 42552
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.7869302034378052,
      "learning_rate": 5e-05,
      "loss": 0.297,
      "step": 42560
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.6176860928535461,
      "learning_rate": 5e-05,
      "loss": 0.3064,
      "step": 42568
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.585548996925354,
      "learning_rate": 5e-05,
      "loss": 0.3187,
      "step": 42576
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.6568413972854614,
      "learning_rate": 5e-05,
      "loss": 0.2915,
      "step": 42584
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6210300922393799,
      "learning_rate": 5e-05,
      "loss": 0.3082,
      "step": 42592
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6176884770393372,
      "learning_rate": 5e-05,
      "loss": 0.2965,
      "step": 42600
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.7363962531089783,
      "learning_rate": 5e-05,
      "loss": 0.3134,
      "step": 42608
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.5653038620948792,
      "learning_rate": 5e-05,
      "loss": 0.2898,
      "step": 42616
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6307886242866516,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 42624
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.612727165222168,
      "learning_rate": 5e-05,
      "loss": 0.3067,
      "step": 42632
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.5752308964729309,
      "learning_rate": 5e-05,
      "loss": 0.2934,
      "step": 42640
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.7902550101280212,
      "learning_rate": 5e-05,
      "loss": 0.3319,
      "step": 42648
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6188510656356812,
      "learning_rate": 5e-05,
      "loss": 0.2691,
      "step": 42656
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6324818730354309,
      "learning_rate": 5e-05,
      "loss": 0.3037,
      "step": 42664
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.8131102919578552,
      "learning_rate": 5e-05,
      "loss": 0.3065,
      "step": 42672
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.573371171951294,
      "learning_rate": 5e-05,
      "loss": 0.2883,
      "step": 42680
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.8317430019378662,
      "learning_rate": 5e-05,
      "loss": 0.2989,
      "step": 42688
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6885577440261841,
      "learning_rate": 5e-05,
      "loss": 0.3093,
      "step": 42696
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.5578675270080566,
      "learning_rate": 5e-05,
      "loss": 0.2884,
      "step": 42704
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6295762062072754,
      "learning_rate": 5e-05,
      "loss": 0.3154,
      "step": 42712
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.7316493988037109,
      "learning_rate": 5e-05,
      "loss": 0.2802,
      "step": 42720
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6650760769844055,
      "learning_rate": 5e-05,
      "loss": 0.2985,
      "step": 42728
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6515300273895264,
      "learning_rate": 5e-05,
      "loss": 0.2817,
      "step": 42736
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.7877790331840515,
      "learning_rate": 5e-05,
      "loss": 0.3098,
      "step": 42744
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6398194432258606,
      "learning_rate": 5e-05,
      "loss": 0.2952,
      "step": 42752
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.6383711695671082,
      "learning_rate": 5e-05,
      "loss": 0.2895,
      "step": 42760
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.585820734500885,
      "learning_rate": 5e-05,
      "loss": 0.3091,
      "step": 42768
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.6737381815910339,
      "learning_rate": 5e-05,
      "loss": 0.2827,
      "step": 42776
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.721365213394165,
      "learning_rate": 5e-05,
      "loss": 0.3225,
      "step": 42784
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.631328821182251,
      "learning_rate": 5e-05,
      "loss": 0.3128,
      "step": 42792
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.6679280400276184,
      "learning_rate": 5e-05,
      "loss": 0.2925,
      "step": 42800
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.6400592923164368,
      "learning_rate": 5e-05,
      "loss": 0.291,
      "step": 42808
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.5918914675712585,
      "learning_rate": 5e-05,
      "loss": 0.2881,
      "step": 42816
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.7478594183921814,
      "learning_rate": 5e-05,
      "loss": 0.3149,
      "step": 42824
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.5919943451881409,
      "learning_rate": 5e-05,
      "loss": 0.3252,
      "step": 42832
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.7582948803901672,
      "learning_rate": 5e-05,
      "loss": 0.2849,
      "step": 42840
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.6803013682365417,
      "learning_rate": 5e-05,
      "loss": 0.309,
      "step": 42848
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.5705994367599487,
      "learning_rate": 5e-05,
      "loss": 0.3017,
      "step": 42856
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.8274264335632324,
      "learning_rate": 5e-05,
      "loss": 0.2926,
      "step": 42864
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.7135179042816162,
      "learning_rate": 5e-05,
      "loss": 0.3127,
      "step": 42872
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.6795179843902588,
      "learning_rate": 5e-05,
      "loss": 0.3132,
      "step": 42880
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.6206592321395874,
      "learning_rate": 5e-05,
      "loss": 0.2817,
      "step": 42888
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.5942262411117554,
      "learning_rate": 5e-05,
      "loss": 0.2884,
      "step": 42896
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.5798564553260803,
      "learning_rate": 5e-05,
      "loss": 0.2812,
      "step": 42904
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.6987192630767822,
      "learning_rate": 5e-05,
      "loss": 0.3032,
      "step": 42912
    },
    {
      "epoch": 2.57,
      "grad_norm": 0.5661432147026062,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 42920
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.53423672914505,
      "learning_rate": 5e-05,
      "loss": 0.2839,
      "step": 42928
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.6787099242210388,
      "learning_rate": 5e-05,
      "loss": 0.3314,
      "step": 42936
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.5827888250350952,
      "learning_rate": 5e-05,
      "loss": 0.2518,
      "step": 42944
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.6848878264427185,
      "learning_rate": 5e-05,
      "loss": 0.2819,
      "step": 42952
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.7146557569503784,
      "learning_rate": 5e-05,
      "loss": 0.3125,
      "step": 42960
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.6702262759208679,
      "learning_rate": 5e-05,
      "loss": 0.2926,
      "step": 42968
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.6397412419319153,
      "learning_rate": 5e-05,
      "loss": 0.294,
      "step": 42976
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.6209767460823059,
      "learning_rate": 5e-05,
      "loss": 0.2904,
      "step": 42984
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.5695132613182068,
      "learning_rate": 5e-05,
      "loss": 0.2977,
      "step": 42992
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.6152318120002747,
      "learning_rate": 5e-05,
      "loss": 0.2839,
      "step": 43000
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.6257559061050415,
      "learning_rate": 5e-05,
      "loss": 0.2882,
      "step": 43008
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.7121198177337646,
      "learning_rate": 5e-05,
      "loss": 0.2972,
      "step": 43016
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.639157772064209,
      "learning_rate": 5e-05,
      "loss": 0.31,
      "step": 43024
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.6360350251197815,
      "learning_rate": 5e-05,
      "loss": 0.3021,
      "step": 43032
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.5937222838401794,
      "learning_rate": 5e-05,
      "loss": 0.2917,
      "step": 43040
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.6912404298782349,
      "learning_rate": 5e-05,
      "loss": 0.3029,
      "step": 43048
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.5451474189758301,
      "learning_rate": 5e-05,
      "loss": 0.2974,
      "step": 43056
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.6469051241874695,
      "learning_rate": 5e-05,
      "loss": 0.2966,
      "step": 43064
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.6273193955421448,
      "learning_rate": 5e-05,
      "loss": 0.2963,
      "step": 43072
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.6584316492080688,
      "learning_rate": 5e-05,
      "loss": 0.293,
      "step": 43080
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.817858099937439,
      "learning_rate": 5e-05,
      "loss": 0.3361,
      "step": 43088
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.6836028099060059,
      "learning_rate": 5e-05,
      "loss": 0.3057,
      "step": 43096
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.5623923540115356,
      "learning_rate": 5e-05,
      "loss": 0.3034,
      "step": 43104
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.5804985165596008,
      "learning_rate": 5e-05,
      "loss": 0.2877,
      "step": 43112
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.6621010899543762,
      "learning_rate": 5e-05,
      "loss": 0.2918,
      "step": 43120
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.6415408849716187,
      "learning_rate": 5e-05,
      "loss": 0.3042,
      "step": 43128
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.727406919002533,
      "learning_rate": 5e-05,
      "loss": 0.3231,
      "step": 43136
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.5654085874557495,
      "learning_rate": 5e-05,
      "loss": 0.2858,
      "step": 43144
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.5608276128768921,
      "learning_rate": 5e-05,
      "loss": 0.3008,
      "step": 43152
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.5841701626777649,
      "learning_rate": 5e-05,
      "loss": 0.3148,
      "step": 43160
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.6005547642707825,
      "learning_rate": 5e-05,
      "loss": 0.3231,
      "step": 43168
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.5867676734924316,
      "learning_rate": 5e-05,
      "loss": 0.3288,
      "step": 43176
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.7068361639976501,
      "learning_rate": 5e-05,
      "loss": 0.3005,
      "step": 43184
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.6154447197914124,
      "learning_rate": 5e-05,
      "loss": 0.3076,
      "step": 43192
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.6373676657676697,
      "learning_rate": 5e-05,
      "loss": 0.2973,
      "step": 43200
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.7550925016403198,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 43208
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.5789016485214233,
      "learning_rate": 5e-05,
      "loss": 0.3146,
      "step": 43216
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.7273593544960022,
      "learning_rate": 5e-05,
      "loss": 0.3024,
      "step": 43224
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.6067187190055847,
      "learning_rate": 5e-05,
      "loss": 0.3029,
      "step": 43232
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.6225293874740601,
      "learning_rate": 5e-05,
      "loss": 0.3118,
      "step": 43240
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.5647129416465759,
      "learning_rate": 5e-05,
      "loss": 0.3145,
      "step": 43248
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.7170272469520569,
      "learning_rate": 5e-05,
      "loss": 0.2969,
      "step": 43256
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.6187757849693298,
      "learning_rate": 5e-05,
      "loss": 0.2865,
      "step": 43264
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.6114077568054199,
      "learning_rate": 5e-05,
      "loss": 0.2819,
      "step": 43272
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.6338999271392822,
      "learning_rate": 5e-05,
      "loss": 0.3036,
      "step": 43280
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.691807746887207,
      "learning_rate": 5e-05,
      "loss": 0.3026,
      "step": 43288
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5792515873908997,
      "learning_rate": 5e-05,
      "loss": 0.2933,
      "step": 43296
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5890458822250366,
      "learning_rate": 5e-05,
      "loss": 0.2767,
      "step": 43304
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5624036192893982,
      "learning_rate": 5e-05,
      "loss": 0.2763,
      "step": 43312
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.6105789542198181,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 43320
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.7075651288032532,
      "learning_rate": 5e-05,
      "loss": 0.301,
      "step": 43328
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5371295809745789,
      "learning_rate": 5e-05,
      "loss": 0.2938,
      "step": 43336
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.738827645778656,
      "learning_rate": 5e-05,
      "loss": 0.3132,
      "step": 43344
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.7439411878585815,
      "learning_rate": 5e-05,
      "loss": 0.2988,
      "step": 43352
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.6623951196670532,
      "learning_rate": 5e-05,
      "loss": 0.312,
      "step": 43360
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.748301088809967,
      "learning_rate": 5e-05,
      "loss": 0.2848,
      "step": 43368
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.6425691246986389,
      "learning_rate": 5e-05,
      "loss": 0.3003,
      "step": 43376
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5689449310302734,
      "learning_rate": 5e-05,
      "loss": 0.2754,
      "step": 43384
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.8847485184669495,
      "learning_rate": 5e-05,
      "loss": 0.2857,
      "step": 43392
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.6934236288070679,
      "learning_rate": 5e-05,
      "loss": 0.3029,
      "step": 43400
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.6586219072341919,
      "learning_rate": 5e-05,
      "loss": 0.302,
      "step": 43408
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.7630059719085693,
      "learning_rate": 5e-05,
      "loss": 0.3335,
      "step": 43416
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.6354655623435974,
      "learning_rate": 5e-05,
      "loss": 0.3093,
      "step": 43424
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.5264362096786499,
      "learning_rate": 5e-05,
      "loss": 0.3025,
      "step": 43432
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.635709285736084,
      "learning_rate": 5e-05,
      "loss": 0.3099,
      "step": 43440
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.6152222156524658,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 43448
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.7630343437194824,
      "learning_rate": 5e-05,
      "loss": 0.3118,
      "step": 43456
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.6185798645019531,
      "learning_rate": 5e-05,
      "loss": 0.2909,
      "step": 43464
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.6625975370407104,
      "learning_rate": 5e-05,
      "loss": 0.2838,
      "step": 43472
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.5595309734344482,
      "learning_rate": 5e-05,
      "loss": 0.2936,
      "step": 43480
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.6695166826248169,
      "learning_rate": 5e-05,
      "loss": 0.2927,
      "step": 43488
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.5587595105171204,
      "learning_rate": 5e-05,
      "loss": 0.2896,
      "step": 43496
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.5632269382476807,
      "learning_rate": 5e-05,
      "loss": 0.3108,
      "step": 43504
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.7183549404144287,
      "learning_rate": 5e-05,
      "loss": 0.2903,
      "step": 43512
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.5137784481048584,
      "learning_rate": 5e-05,
      "loss": 0.2885,
      "step": 43520
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.6010279059410095,
      "learning_rate": 5e-05,
      "loss": 0.2941,
      "step": 43528
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.5823428630828857,
      "learning_rate": 5e-05,
      "loss": 0.2888,
      "step": 43536
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.6780409216880798,
      "learning_rate": 5e-05,
      "loss": 0.2972,
      "step": 43544
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.6870138049125671,
      "learning_rate": 5e-05,
      "loss": 0.3067,
      "step": 43552
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.6289941072463989,
      "learning_rate": 5e-05,
      "loss": 0.2965,
      "step": 43560
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.824263870716095,
      "learning_rate": 5e-05,
      "loss": 0.2929,
      "step": 43568
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.653762698173523,
      "learning_rate": 5e-05,
      "loss": 0.3095,
      "step": 43576
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.6363741159439087,
      "learning_rate": 5e-05,
      "loss": 0.2939,
      "step": 43584
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.6767188906669617,
      "learning_rate": 5e-05,
      "loss": 0.3022,
      "step": 43592
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.794773519039154,
      "learning_rate": 5e-05,
      "loss": 0.3101,
      "step": 43600
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6049134731292725,
      "learning_rate": 5e-05,
      "loss": 0.2995,
      "step": 43608
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6015716195106506,
      "learning_rate": 5e-05,
      "loss": 0.2956,
      "step": 43616
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6505745053291321,
      "learning_rate": 5e-05,
      "loss": 0.2928,
      "step": 43624
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6200616955757141,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 43632
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.7195655107498169,
      "learning_rate": 5e-05,
      "loss": 0.2887,
      "step": 43640
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.5857329964637756,
      "learning_rate": 5e-05,
      "loss": 0.3041,
      "step": 43648
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6304851770401001,
      "learning_rate": 5e-05,
      "loss": 0.304,
      "step": 43656
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6010873913764954,
      "learning_rate": 5e-05,
      "loss": 0.3038,
      "step": 43664
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6399930715560913,
      "learning_rate": 5e-05,
      "loss": 0.318,
      "step": 43672
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6460935473442078,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 43680
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.5792660713195801,
      "learning_rate": 5e-05,
      "loss": 0.3018,
      "step": 43688
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6259061098098755,
      "learning_rate": 5e-05,
      "loss": 0.2848,
      "step": 43696
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6315445899963379,
      "learning_rate": 5e-05,
      "loss": 0.2785,
      "step": 43704
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6866820454597473,
      "learning_rate": 5e-05,
      "loss": 0.322,
      "step": 43712
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.632885754108429,
      "learning_rate": 5e-05,
      "loss": 0.2861,
      "step": 43720
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6544566750526428,
      "learning_rate": 5e-05,
      "loss": 0.304,
      "step": 43728
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.5157155394554138,
      "learning_rate": 5e-05,
      "loss": 0.298,
      "step": 43736
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.5871020555496216,
      "learning_rate": 5e-05,
      "loss": 0.2846,
      "step": 43744
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.7162251472473145,
      "learning_rate": 5e-05,
      "loss": 0.2772,
      "step": 43752
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.7049763202667236,
      "learning_rate": 5e-05,
      "loss": 0.2901,
      "step": 43760
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.6289750933647156,
      "learning_rate": 5e-05,
      "loss": 0.3144,
      "step": 43768
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.6465743184089661,
      "learning_rate": 5e-05,
      "loss": 0.2927,
      "step": 43776
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.5924093723297119,
      "learning_rate": 5e-05,
      "loss": 0.3296,
      "step": 43784
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.6027860045433044,
      "learning_rate": 5e-05,
      "loss": 0.3106,
      "step": 43792
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.6370327472686768,
      "learning_rate": 5e-05,
      "loss": 0.2729,
      "step": 43800
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.6015233993530273,
      "learning_rate": 5e-05,
      "loss": 0.3226,
      "step": 43808
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.6143257021903992,
      "learning_rate": 5e-05,
      "loss": 0.3038,
      "step": 43816
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.660203754901886,
      "learning_rate": 5e-05,
      "loss": 0.2976,
      "step": 43824
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.5602329969406128,
      "learning_rate": 5e-05,
      "loss": 0.2992,
      "step": 43832
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.5437610745429993,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 43840
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.7156984210014343,
      "learning_rate": 5e-05,
      "loss": 0.3133,
      "step": 43848
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.5727522969245911,
      "learning_rate": 5e-05,
      "loss": 0.2951,
      "step": 43856
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.6315353512763977,
      "learning_rate": 5e-05,
      "loss": 0.3103,
      "step": 43864
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.562847375869751,
      "learning_rate": 5e-05,
      "loss": 0.3067,
      "step": 43872
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.5910744667053223,
      "learning_rate": 5e-05,
      "loss": 0.3061,
      "step": 43880
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.8224759697914124,
      "learning_rate": 5e-05,
      "loss": 0.2797,
      "step": 43888
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.6527900099754333,
      "learning_rate": 5e-05,
      "loss": 0.3149,
      "step": 43896
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.6976113319396973,
      "learning_rate": 5e-05,
      "loss": 0.3247,
      "step": 43904
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.6087566018104553,
      "learning_rate": 5e-05,
      "loss": 0.2866,
      "step": 43912
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.6369835734367371,
      "learning_rate": 5e-05,
      "loss": 0.2907,
      "step": 43920
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.6094362735748291,
      "learning_rate": 5e-05,
      "loss": 0.2981,
      "step": 43928
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.703982949256897,
      "learning_rate": 5e-05,
      "loss": 0.2872,
      "step": 43936
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.5736421942710876,
      "learning_rate": 5e-05,
      "loss": 0.2978,
      "step": 43944
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.6314958333969116,
      "learning_rate": 5e-05,
      "loss": 0.317,
      "step": 43952
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.726254940032959,
      "learning_rate": 5e-05,
      "loss": 0.269,
      "step": 43960
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.5809912085533142,
      "learning_rate": 5e-05,
      "loss": 0.3658,
      "step": 43968
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.5694934129714966,
      "learning_rate": 5e-05,
      "loss": 0.2918,
      "step": 43976
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.619846522808075,
      "learning_rate": 5e-05,
      "loss": 0.3354,
      "step": 43984
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.6456940770149231,
      "learning_rate": 5e-05,
      "loss": 0.2881,
      "step": 43992
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.6336761713027954,
      "learning_rate": 5e-05,
      "loss": 0.3178,
      "step": 44000
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.6476974487304688,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 44008
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.5876970887184143,
      "learning_rate": 5e-05,
      "loss": 0.3105,
      "step": 44016
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.5514354109764099,
      "learning_rate": 5e-05,
      "loss": 0.298,
      "step": 44024
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.66862952709198,
      "learning_rate": 5e-05,
      "loss": 0.304,
      "step": 44032
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.635238766670227,
      "learning_rate": 5e-05,
      "loss": 0.3021,
      "step": 44040
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.6012513041496277,
      "learning_rate": 5e-05,
      "loss": 0.3033,
      "step": 44048
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.5767420530319214,
      "learning_rate": 5e-05,
      "loss": 0.2903,
      "step": 44056
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.6438104510307312,
      "learning_rate": 5e-05,
      "loss": 0.3095,
      "step": 44064
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.6302599310874939,
      "learning_rate": 5e-05,
      "loss": 0.3133,
      "step": 44072
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.5815167427062988,
      "learning_rate": 5e-05,
      "loss": 0.3003,
      "step": 44080
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.609773576259613,
      "learning_rate": 5e-05,
      "loss": 0.3061,
      "step": 44088
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.667836606502533,
      "learning_rate": 5e-05,
      "loss": 0.3092,
      "step": 44096
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.724255383014679,
      "learning_rate": 5e-05,
      "loss": 0.2871,
      "step": 44104
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.6697562336921692,
      "learning_rate": 5e-05,
      "loss": 0.3011,
      "step": 44112
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.6118778586387634,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 44120
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.6222423315048218,
      "learning_rate": 5e-05,
      "loss": 0.2832,
      "step": 44128
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.5677543878555298,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 44136
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.6235179305076599,
      "learning_rate": 5e-05,
      "loss": 0.3046,
      "step": 44144
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.510201096534729,
      "learning_rate": 5e-05,
      "loss": 0.2715,
      "step": 44152
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.5985720157623291,
      "learning_rate": 5e-05,
      "loss": 0.3116,
      "step": 44160
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.6734926700592041,
      "learning_rate": 5e-05,
      "loss": 0.2744,
      "step": 44168
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.6170828342437744,
      "learning_rate": 5e-05,
      "loss": 0.2912,
      "step": 44176
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.722148060798645,
      "learning_rate": 5e-05,
      "loss": 0.3202,
      "step": 44184
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.6981833577156067,
      "learning_rate": 5e-05,
      "loss": 0.2915,
      "step": 44192
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.5782923102378845,
      "learning_rate": 5e-05,
      "loss": 0.3128,
      "step": 44200
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.6412497758865356,
      "learning_rate": 5e-05,
      "loss": 0.3009,
      "step": 44208
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.6572463512420654,
      "learning_rate": 5e-05,
      "loss": 0.296,
      "step": 44216
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.685884952545166,
      "learning_rate": 5e-05,
      "loss": 0.3021,
      "step": 44224
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.7168949842453003,
      "learning_rate": 5e-05,
      "loss": 0.2899,
      "step": 44232
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.5247123837471008,
      "learning_rate": 5e-05,
      "loss": 0.3113,
      "step": 44240
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.555127739906311,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 44248
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.5350973606109619,
      "learning_rate": 5e-05,
      "loss": 0.3032,
      "step": 44256
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.5351576805114746,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 44264
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.6597448587417603,
      "learning_rate": 5e-05,
      "loss": 0.3024,
      "step": 44272
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.5977823734283447,
      "learning_rate": 5e-05,
      "loss": 0.3092,
      "step": 44280
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.6298574209213257,
      "learning_rate": 5e-05,
      "loss": 0.2859,
      "step": 44288
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.6094557046890259,
      "learning_rate": 5e-05,
      "loss": 0.3102,
      "step": 44296
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.5892809629440308,
      "learning_rate": 5e-05,
      "loss": 0.3288,
      "step": 44304
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.7221441268920898,
      "learning_rate": 5e-05,
      "loss": 0.3073,
      "step": 44312
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.5987129211425781,
      "learning_rate": 5e-05,
      "loss": 0.277,
      "step": 44320
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.6002534031867981,
      "learning_rate": 5e-05,
      "loss": 0.3118,
      "step": 44328
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.6364060640335083,
      "learning_rate": 5e-05,
      "loss": 0.3228,
      "step": 44336
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.6722704768180847,
      "learning_rate": 5e-05,
      "loss": 0.3058,
      "step": 44344
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.6434255838394165,
      "learning_rate": 5e-05,
      "loss": 0.3017,
      "step": 44352
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.6355435252189636,
      "learning_rate": 5e-05,
      "loss": 0.2777,
      "step": 44360
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.6350008249282837,
      "learning_rate": 5e-05,
      "loss": 0.309,
      "step": 44368
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.6205779314041138,
      "learning_rate": 5e-05,
      "loss": 0.2936,
      "step": 44376
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.5781938433647156,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 44384
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.5678477883338928,
      "learning_rate": 5e-05,
      "loss": 0.2867,
      "step": 44392
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.6029459834098816,
      "learning_rate": 5e-05,
      "loss": 0.2777,
      "step": 44400
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.6608057618141174,
      "learning_rate": 5e-05,
      "loss": 0.2973,
      "step": 44408
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.6068359017372131,
      "learning_rate": 5e-05,
      "loss": 0.2979,
      "step": 44416
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.6318786144256592,
      "learning_rate": 5e-05,
      "loss": 0.3129,
      "step": 44424
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.696842610836029,
      "learning_rate": 5e-05,
      "loss": 0.2687,
      "step": 44432
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.6656370759010315,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 44440
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.6431641578674316,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 44448
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.6578259468078613,
      "learning_rate": 5e-05,
      "loss": 0.2916,
      "step": 44456
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.7085314989089966,
      "learning_rate": 5e-05,
      "loss": 0.303,
      "step": 44464
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.7932847738265991,
      "learning_rate": 5e-05,
      "loss": 0.3204,
      "step": 44472
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.5662952661514282,
      "learning_rate": 5e-05,
      "loss": 0.3104,
      "step": 44480
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.7080447673797607,
      "learning_rate": 5e-05,
      "loss": 0.3176,
      "step": 44488
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.748428463935852,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 44496
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.6398844718933105,
      "learning_rate": 5e-05,
      "loss": 0.3098,
      "step": 44504
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.5762525200843811,
      "learning_rate": 5e-05,
      "loss": 0.2984,
      "step": 44512
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.6132975816726685,
      "learning_rate": 5e-05,
      "loss": 0.3006,
      "step": 44520
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.8096846342086792,
      "learning_rate": 5e-05,
      "loss": 0.2926,
      "step": 44528
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.6144037842750549,
      "learning_rate": 5e-05,
      "loss": 0.2826,
      "step": 44536
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.6673215627670288,
      "learning_rate": 5e-05,
      "loss": 0.2927,
      "step": 44544
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.6244664788246155,
      "learning_rate": 5e-05,
      "loss": 0.3024,
      "step": 44552
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.6317005157470703,
      "learning_rate": 5e-05,
      "loss": 0.28,
      "step": 44560
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.6829986572265625,
      "learning_rate": 5e-05,
      "loss": 0.2897,
      "step": 44568
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.6534754633903503,
      "learning_rate": 5e-05,
      "loss": 0.3001,
      "step": 44576
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.6316825151443481,
      "learning_rate": 5e-05,
      "loss": 0.3149,
      "step": 44584
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.6661637425422668,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 44592
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6683074831962585,
      "learning_rate": 5e-05,
      "loss": 0.3,
      "step": 44600
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6718645691871643,
      "learning_rate": 5e-05,
      "loss": 0.3263,
      "step": 44608
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6207844614982605,
      "learning_rate": 5e-05,
      "loss": 0.3064,
      "step": 44616
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.5353774428367615,
      "learning_rate": 5e-05,
      "loss": 0.2725,
      "step": 44624
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6704735159873962,
      "learning_rate": 5e-05,
      "loss": 0.3154,
      "step": 44632
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.669110894203186,
      "learning_rate": 5e-05,
      "loss": 0.2913,
      "step": 44640
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.5367807149887085,
      "learning_rate": 5e-05,
      "loss": 0.292,
      "step": 44648
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.7338130474090576,
      "learning_rate": 5e-05,
      "loss": 0.285,
      "step": 44656
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.5863490104675293,
      "learning_rate": 5e-05,
      "loss": 0.2787,
      "step": 44664
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.5787959098815918,
      "learning_rate": 5e-05,
      "loss": 0.2953,
      "step": 44672
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6048613786697388,
      "learning_rate": 5e-05,
      "loss": 0.2886,
      "step": 44680
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6040073037147522,
      "learning_rate": 5e-05,
      "loss": 0.2973,
      "step": 44688
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6346316337585449,
      "learning_rate": 5e-05,
      "loss": 0.2846,
      "step": 44696
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6483058333396912,
      "learning_rate": 5e-05,
      "loss": 0.264,
      "step": 44704
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6344823241233826,
      "learning_rate": 5e-05,
      "loss": 0.3093,
      "step": 44712
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.8706260323524475,
      "learning_rate": 5e-05,
      "loss": 0.2997,
      "step": 44720
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6268662810325623,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 44728
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6977227926254272,
      "learning_rate": 5e-05,
      "loss": 0.3083,
      "step": 44736
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.5833721160888672,
      "learning_rate": 5e-05,
      "loss": 0.3009,
      "step": 44744
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.7670886516571045,
      "learning_rate": 5e-05,
      "loss": 0.3292,
      "step": 44752
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.5834766030311584,
      "learning_rate": 5e-05,
      "loss": 0.2762,
      "step": 44760
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6701341271400452,
      "learning_rate": 5e-05,
      "loss": 0.3151,
      "step": 44768
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.5587064027786255,
      "learning_rate": 5e-05,
      "loss": 0.3161,
      "step": 44776
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.5966728925704956,
      "learning_rate": 5e-05,
      "loss": 0.3229,
      "step": 44784
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6146326661109924,
      "learning_rate": 5e-05,
      "loss": 0.3139,
      "step": 44792
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6054702997207642,
      "learning_rate": 5e-05,
      "loss": 0.3005,
      "step": 44800
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.5561925768852234,
      "learning_rate": 5e-05,
      "loss": 0.2896,
      "step": 44808
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6178483963012695,
      "learning_rate": 5e-05,
      "loss": 0.3168,
      "step": 44816
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6241745352745056,
      "learning_rate": 5e-05,
      "loss": 0.3006,
      "step": 44824
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6166187524795532,
      "learning_rate": 5e-05,
      "loss": 0.2962,
      "step": 44832
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.5632051825523376,
      "learning_rate": 5e-05,
      "loss": 0.3188,
      "step": 44840
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.5654194355010986,
      "learning_rate": 5e-05,
      "loss": 0.2729,
      "step": 44848
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6102780699729919,
      "learning_rate": 5e-05,
      "loss": 0.3001,
      "step": 44856
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6112004518508911,
      "learning_rate": 5e-05,
      "loss": 0.3062,
      "step": 44864
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.671977162361145,
      "learning_rate": 5e-05,
      "loss": 0.3032,
      "step": 44872
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.617451548576355,
      "learning_rate": 5e-05,
      "loss": 0.3146,
      "step": 44880
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6294134259223938,
      "learning_rate": 5e-05,
      "loss": 0.3258,
      "step": 44888
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6478877067565918,
      "learning_rate": 5e-05,
      "loss": 0.3135,
      "step": 44896
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6113740801811218,
      "learning_rate": 5e-05,
      "loss": 0.3016,
      "step": 44904
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6462671756744385,
      "learning_rate": 5e-05,
      "loss": 0.2935,
      "step": 44912
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.6269077062606812,
      "learning_rate": 5e-05,
      "loss": 0.3043,
      "step": 44920
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.5491786003112793,
      "learning_rate": 5e-05,
      "loss": 0.2921,
      "step": 44928
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.6176071763038635,
      "learning_rate": 5e-05,
      "loss": 0.2816,
      "step": 44936
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.5817489624023438,
      "learning_rate": 5e-05,
      "loss": 0.3107,
      "step": 44944
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.5639175772666931,
      "learning_rate": 5e-05,
      "loss": 0.2844,
      "step": 44952
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.6666743159294128,
      "learning_rate": 5e-05,
      "loss": 0.2819,
      "step": 44960
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.6138969659805298,
      "learning_rate": 5e-05,
      "loss": 0.3193,
      "step": 44968
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.592947244644165,
      "learning_rate": 5e-05,
      "loss": 0.2757,
      "step": 44976
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.69716477394104,
      "learning_rate": 5e-05,
      "loss": 0.2867,
      "step": 44984
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.7087855339050293,
      "learning_rate": 5e-05,
      "loss": 0.2948,
      "step": 44992
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.5805885195732117,
      "learning_rate": 5e-05,
      "loss": 0.3353,
      "step": 45000
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.5805323123931885,
      "learning_rate": 5e-05,
      "loss": 0.3042,
      "step": 45008
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.5572466254234314,
      "learning_rate": 5e-05,
      "loss": 0.2959,
      "step": 45016
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.6832346320152283,
      "learning_rate": 5e-05,
      "loss": 0.2974,
      "step": 45024
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.6646375060081482,
      "learning_rate": 5e-05,
      "loss": 0.2953,
      "step": 45032
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.6937956809997559,
      "learning_rate": 5e-05,
      "loss": 0.3046,
      "step": 45040
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.6024516820907593,
      "learning_rate": 5e-05,
      "loss": 0.33,
      "step": 45048
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.75958651304245,
      "learning_rate": 5e-05,
      "loss": 0.3453,
      "step": 45056
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.5747031569480896,
      "learning_rate": 5e-05,
      "loss": 0.3226,
      "step": 45064
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.6781009435653687,
      "learning_rate": 5e-05,
      "loss": 0.2984,
      "step": 45072
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.8156101107597351,
      "learning_rate": 5e-05,
      "loss": 0.2957,
      "step": 45080
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.7503845691680908,
      "learning_rate": 5e-05,
      "loss": 0.2644,
      "step": 45088
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.7194620966911316,
      "learning_rate": 5e-05,
      "loss": 0.2926,
      "step": 45096
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.7037612199783325,
      "learning_rate": 5e-05,
      "loss": 0.2979,
      "step": 45104
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.5677711367607117,
      "learning_rate": 5e-05,
      "loss": 0.3079,
      "step": 45112
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.6410704851150513,
      "learning_rate": 5e-05,
      "loss": 0.3037,
      "step": 45120
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.6476199626922607,
      "learning_rate": 5e-05,
      "loss": 0.2964,
      "step": 45128
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.662738561630249,
      "learning_rate": 5e-05,
      "loss": 0.275,
      "step": 45136
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.5657380223274231,
      "learning_rate": 5e-05,
      "loss": 0.2902,
      "step": 45144
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.5997557044029236,
      "learning_rate": 5e-05,
      "loss": 0.3343,
      "step": 45152
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.5432640314102173,
      "learning_rate": 5e-05,
      "loss": 0.3081,
      "step": 45160
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.5826063752174377,
      "learning_rate": 5e-05,
      "loss": 0.3025,
      "step": 45168
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.5720595717430115,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 45176
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.6813570261001587,
      "learning_rate": 5e-05,
      "loss": 0.3032,
      "step": 45184
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.6737726330757141,
      "learning_rate": 5e-05,
      "loss": 0.2944,
      "step": 45192
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.6307549476623535,
      "learning_rate": 5e-05,
      "loss": 0.2798,
      "step": 45200
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.6635366082191467,
      "learning_rate": 5e-05,
      "loss": 0.323,
      "step": 45208
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.5667478442192078,
      "learning_rate": 5e-05,
      "loss": 0.3018,
      "step": 45216
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.6076275706291199,
      "learning_rate": 5e-05,
      "loss": 0.2896,
      "step": 45224
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.6939085125923157,
      "learning_rate": 5e-05,
      "loss": 0.2917,
      "step": 45232
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.6235601305961609,
      "learning_rate": 5e-05,
      "loss": 0.3023,
      "step": 45240
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.5693671703338623,
      "learning_rate": 5e-05,
      "loss": 0.3044,
      "step": 45248
    },
    {
      "epoch": 2.71,
      "grad_norm": 0.6869052052497864,
      "learning_rate": 5e-05,
      "loss": 0.2977,
      "step": 45256
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.5874981880187988,
      "learning_rate": 5e-05,
      "loss": 0.3001,
      "step": 45264
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.7405845522880554,
      "learning_rate": 5e-05,
      "loss": 0.3149,
      "step": 45272
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.5362253785133362,
      "learning_rate": 5e-05,
      "loss": 0.3362,
      "step": 45280
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.5898466110229492,
      "learning_rate": 5e-05,
      "loss": 0.2723,
      "step": 45288
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.6526048183441162,
      "learning_rate": 5e-05,
      "loss": 0.2985,
      "step": 45296
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.6353946924209595,
      "learning_rate": 5e-05,
      "loss": 0.2913,
      "step": 45304
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.6340036988258362,
      "learning_rate": 5e-05,
      "loss": 0.2959,
      "step": 45312
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.6209630966186523,
      "learning_rate": 5e-05,
      "loss": 0.305,
      "step": 45320
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.5839102864265442,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 45328
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.5613468289375305,
      "learning_rate": 5e-05,
      "loss": 0.2984,
      "step": 45336
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.5920791029930115,
      "learning_rate": 5e-05,
      "loss": 0.3108,
      "step": 45344
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.5798993110656738,
      "learning_rate": 5e-05,
      "loss": 0.3078,
      "step": 45352
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.6636402010917664,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 45360
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.7450409531593323,
      "learning_rate": 5e-05,
      "loss": 0.3017,
      "step": 45368
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.6508578062057495,
      "learning_rate": 5e-05,
      "loss": 0.2804,
      "step": 45376
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.8166278004646301,
      "learning_rate": 5e-05,
      "loss": 0.3048,
      "step": 45384
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.8140769004821777,
      "learning_rate": 5e-05,
      "loss": 0.2882,
      "step": 45392
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.6515560150146484,
      "learning_rate": 5e-05,
      "loss": 0.2976,
      "step": 45400
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.5343839526176453,
      "learning_rate": 5e-05,
      "loss": 0.3186,
      "step": 45408
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.5383312106132507,
      "learning_rate": 5e-05,
      "loss": 0.2615,
      "step": 45416
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.5841087698936462,
      "learning_rate": 5e-05,
      "loss": 0.3173,
      "step": 45424
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.6832945942878723,
      "learning_rate": 5e-05,
      "loss": 0.2964,
      "step": 45432
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.7668094635009766,
      "learning_rate": 5e-05,
      "loss": 0.2934,
      "step": 45440
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.656261682510376,
      "learning_rate": 5e-05,
      "loss": 0.3002,
      "step": 45448
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.6722955107688904,
      "learning_rate": 5e-05,
      "loss": 0.3213,
      "step": 45456
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.6724138855934143,
      "learning_rate": 5e-05,
      "loss": 0.3148,
      "step": 45464
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.6798093914985657,
      "learning_rate": 5e-05,
      "loss": 0.2972,
      "step": 45472
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.5677250623703003,
      "learning_rate": 5e-05,
      "loss": 0.2966,
      "step": 45480
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.6221700310707092,
      "learning_rate": 5e-05,
      "loss": 0.315,
      "step": 45488
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.6183597445487976,
      "learning_rate": 5e-05,
      "loss": 0.3069,
      "step": 45496
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.6439735889434814,
      "learning_rate": 5e-05,
      "loss": 0.3247,
      "step": 45504
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.6306720972061157,
      "learning_rate": 5e-05,
      "loss": 0.3075,
      "step": 45512
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.558517336845398,
      "learning_rate": 5e-05,
      "loss": 0.2837,
      "step": 45520
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.6619482040405273,
      "learning_rate": 5e-05,
      "loss": 0.2719,
      "step": 45528
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.6932295560836792,
      "learning_rate": 5e-05,
      "loss": 0.2997,
      "step": 45536
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.6436654925346375,
      "learning_rate": 5e-05,
      "loss": 0.2688,
      "step": 45544
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.799313485622406,
      "learning_rate": 5e-05,
      "loss": 0.2972,
      "step": 45552
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.6387026906013489,
      "learning_rate": 5e-05,
      "loss": 0.3069,
      "step": 45560
    },
    {
      "epoch": 2.73,
      "grad_norm": 1.0576672554016113,
      "learning_rate": 5e-05,
      "loss": 0.2981,
      "step": 45568
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.7659234404563904,
      "learning_rate": 5e-05,
      "loss": 0.2934,
      "step": 45576
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.5225802659988403,
      "learning_rate": 5e-05,
      "loss": 0.2977,
      "step": 45584
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.5645679831504822,
      "learning_rate": 5e-05,
      "loss": 0.2877,
      "step": 45592
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.634194552898407,
      "learning_rate": 5e-05,
      "loss": 0.2974,
      "step": 45600
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.6652652621269226,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 45608
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.596618115901947,
      "learning_rate": 5e-05,
      "loss": 0.2758,
      "step": 45616
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.6171510219573975,
      "learning_rate": 5e-05,
      "loss": 0.3248,
      "step": 45624
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.7312078475952148,
      "learning_rate": 5e-05,
      "loss": 0.2924,
      "step": 45632
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.6100607514381409,
      "learning_rate": 5e-05,
      "loss": 0.296,
      "step": 45640
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.6628344655036926,
      "learning_rate": 5e-05,
      "loss": 0.3306,
      "step": 45648
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.5164755582809448,
      "learning_rate": 5e-05,
      "loss": 0.3172,
      "step": 45656
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.6011092066764832,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 45664
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.6031506061553955,
      "learning_rate": 5e-05,
      "loss": 0.3005,
      "step": 45672
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.6804608702659607,
      "learning_rate": 5e-05,
      "loss": 0.2989,
      "step": 45680
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.6193336248397827,
      "learning_rate": 5e-05,
      "loss": 0.2994,
      "step": 45688
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.5909881591796875,
      "learning_rate": 5e-05,
      "loss": 0.2802,
      "step": 45696
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.5952807664871216,
      "learning_rate": 5e-05,
      "loss": 0.3193,
      "step": 45704
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.5881304144859314,
      "learning_rate": 5e-05,
      "loss": 0.3325,
      "step": 45712
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.6700215339660645,
      "learning_rate": 5e-05,
      "loss": 0.3015,
      "step": 45720
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.7023828625679016,
      "learning_rate": 5e-05,
      "loss": 0.2637,
      "step": 45728
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.6203307509422302,
      "learning_rate": 5e-05,
      "loss": 0.2875,
      "step": 45736
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.6577408909797668,
      "learning_rate": 5e-05,
      "loss": 0.2851,
      "step": 45744
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.5997927188873291,
      "learning_rate": 5e-05,
      "loss": 0.2735,
      "step": 45752
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.6572352051734924,
      "learning_rate": 5e-05,
      "loss": 0.3016,
      "step": 45760
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.9481663107872009,
      "learning_rate": 5e-05,
      "loss": 0.2894,
      "step": 45768
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.6362681984901428,
      "learning_rate": 5e-05,
      "loss": 0.306,
      "step": 45776
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.7463296055793762,
      "learning_rate": 5e-05,
      "loss": 0.3006,
      "step": 45784
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.7000741362571716,
      "learning_rate": 5e-05,
      "loss": 0.2995,
      "step": 45792
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.5972601175308228,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 45800
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.6099475622177124,
      "learning_rate": 5e-05,
      "loss": 0.3047,
      "step": 45808
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.6126229166984558,
      "learning_rate": 5e-05,
      "loss": 0.3164,
      "step": 45816
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.5503207445144653,
      "learning_rate": 5e-05,
      "loss": 0.3168,
      "step": 45824
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.5743644833564758,
      "learning_rate": 5e-05,
      "loss": 0.2786,
      "step": 45832
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.6821293234825134,
      "learning_rate": 5e-05,
      "loss": 0.3043,
      "step": 45840
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.6066232323646545,
      "learning_rate": 5e-05,
      "loss": 0.322,
      "step": 45848
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.5996542572975159,
      "learning_rate": 5e-05,
      "loss": 0.2916,
      "step": 45856
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.6228063702583313,
      "learning_rate": 5e-05,
      "loss": 0.2987,
      "step": 45864
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.6459088921546936,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 45872
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.5944981575012207,
      "learning_rate": 5e-05,
      "loss": 0.2981,
      "step": 45880
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.6459100246429443,
      "learning_rate": 5e-05,
      "loss": 0.2954,
      "step": 45888
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.5772096514701843,
      "learning_rate": 5e-05,
      "loss": 0.3257,
      "step": 45896
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.6870209574699402,
      "learning_rate": 5e-05,
      "loss": 0.275,
      "step": 45904
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.6161807775497437,
      "learning_rate": 5e-05,
      "loss": 0.2932,
      "step": 45912
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.6534063220024109,
      "learning_rate": 5e-05,
      "loss": 0.2918,
      "step": 45920
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.6122350692749023,
      "learning_rate": 5e-05,
      "loss": 0.2998,
      "step": 45928
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.5836241245269775,
      "learning_rate": 5e-05,
      "loss": 0.3085,
      "step": 45936
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.7314164042472839,
      "learning_rate": 5e-05,
      "loss": 0.3047,
      "step": 45944
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.6126130223274231,
      "learning_rate": 5e-05,
      "loss": 0.3036,
      "step": 45952
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.5938711166381836,
      "learning_rate": 5e-05,
      "loss": 0.2964,
      "step": 45960
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.6605126261711121,
      "learning_rate": 5e-05,
      "loss": 0.3115,
      "step": 45968
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.6032730340957642,
      "learning_rate": 5e-05,
      "loss": 0.3137,
      "step": 45976
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.5897210836410522,
      "learning_rate": 5e-05,
      "loss": 0.2967,
      "step": 45984
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.6903715133666992,
      "learning_rate": 5e-05,
      "loss": 0.288,
      "step": 45992
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.530341625213623,
      "learning_rate": 5e-05,
      "loss": 0.3137,
      "step": 46000
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.6340727210044861,
      "learning_rate": 5e-05,
      "loss": 0.3323,
      "step": 46008
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.6191062331199646,
      "learning_rate": 5e-05,
      "loss": 0.3361,
      "step": 46016
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.5688819289207458,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 46024
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.6445487141609192,
      "learning_rate": 5e-05,
      "loss": 0.3087,
      "step": 46032
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.5819001793861389,
      "learning_rate": 5e-05,
      "loss": 0.2945,
      "step": 46040
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.6002898216247559,
      "learning_rate": 5e-05,
      "loss": 0.3104,
      "step": 46048
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.6722593307495117,
      "learning_rate": 5e-05,
      "loss": 0.2797,
      "step": 46056
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.5588069558143616,
      "learning_rate": 5e-05,
      "loss": 0.286,
      "step": 46064
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.5636457800865173,
      "learning_rate": 5e-05,
      "loss": 0.3126,
      "step": 46072
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.5094190239906311,
      "learning_rate": 5e-05,
      "loss": 0.31,
      "step": 46080
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.654645562171936,
      "learning_rate": 5e-05,
      "loss": 0.2965,
      "step": 46088
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6517935991287231,
      "learning_rate": 5e-05,
      "loss": 0.2974,
      "step": 46096
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6047048568725586,
      "learning_rate": 5e-05,
      "loss": 0.2974,
      "step": 46104
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.5849935412406921,
      "learning_rate": 5e-05,
      "loss": 0.3083,
      "step": 46112
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6140872240066528,
      "learning_rate": 5e-05,
      "loss": 0.312,
      "step": 46120
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6824328303337097,
      "learning_rate": 5e-05,
      "loss": 0.2841,
      "step": 46128
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.5752183794975281,
      "learning_rate": 5e-05,
      "loss": 0.2784,
      "step": 46136
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.7495229840278625,
      "learning_rate": 5e-05,
      "loss": 0.3168,
      "step": 46144
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6513410806655884,
      "learning_rate": 5e-05,
      "loss": 0.2978,
      "step": 46152
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6575416326522827,
      "learning_rate": 5e-05,
      "loss": 0.3108,
      "step": 46160
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6013052463531494,
      "learning_rate": 5e-05,
      "loss": 0.3033,
      "step": 46168
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.5960243940353394,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 46176
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6878073811531067,
      "learning_rate": 5e-05,
      "loss": 0.3148,
      "step": 46184
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.705902636051178,
      "learning_rate": 5e-05,
      "loss": 0.2952,
      "step": 46192
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.7297022342681885,
      "learning_rate": 5e-05,
      "loss": 0.2977,
      "step": 46200
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6049675345420837,
      "learning_rate": 5e-05,
      "loss": 0.3148,
      "step": 46208
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6104649305343628,
      "learning_rate": 5e-05,
      "loss": 0.2952,
      "step": 46216
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6002334356307983,
      "learning_rate": 5e-05,
      "loss": 0.2805,
      "step": 46224
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6817726492881775,
      "learning_rate": 5e-05,
      "loss": 0.318,
      "step": 46232
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.564816415309906,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 46240
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6072236895561218,
      "learning_rate": 5e-05,
      "loss": 0.2783,
      "step": 46248
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.6797749400138855,
      "learning_rate": 5e-05,
      "loss": 0.3226,
      "step": 46256
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.6260986924171448,
      "learning_rate": 5e-05,
      "loss": 0.2962,
      "step": 46264
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.6279903054237366,
      "learning_rate": 5e-05,
      "loss": 0.2955,
      "step": 46272
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.5902754068374634,
      "learning_rate": 5e-05,
      "loss": 0.2817,
      "step": 46280
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.6494640111923218,
      "learning_rate": 5e-05,
      "loss": 0.2897,
      "step": 46288
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.8734297156333923,
      "learning_rate": 5e-05,
      "loss": 0.3239,
      "step": 46296
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.7121767997741699,
      "learning_rate": 5e-05,
      "loss": 0.3072,
      "step": 46304
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.5538884997367859,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 46312
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.5952711701393127,
      "learning_rate": 5e-05,
      "loss": 0.2861,
      "step": 46320
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.5721651315689087,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 46328
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.5732529759407043,
      "learning_rate": 5e-05,
      "loss": 0.278,
      "step": 46336
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.584101140499115,
      "learning_rate": 5e-05,
      "loss": 0.2765,
      "step": 46344
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.5533275008201599,
      "learning_rate": 5e-05,
      "loss": 0.2758,
      "step": 46352
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.6341989636421204,
      "learning_rate": 5e-05,
      "loss": 0.2858,
      "step": 46360
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.6111471056938171,
      "learning_rate": 5e-05,
      "loss": 0.2957,
      "step": 46368
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.623729407787323,
      "learning_rate": 5e-05,
      "loss": 0.305,
      "step": 46376
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.5712010264396667,
      "learning_rate": 5e-05,
      "loss": 0.2649,
      "step": 46384
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.7100977897644043,
      "learning_rate": 5e-05,
      "loss": 0.2998,
      "step": 46392
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.7732923030853271,
      "learning_rate": 5e-05,
      "loss": 0.3122,
      "step": 46400
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.7939494252204895,
      "learning_rate": 5e-05,
      "loss": 0.3126,
      "step": 46408
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.6019562482833862,
      "learning_rate": 5e-05,
      "loss": 0.3143,
      "step": 46416
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.5722528696060181,
      "learning_rate": 5e-05,
      "loss": 0.2801,
      "step": 46424
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.6259454488754272,
      "learning_rate": 5e-05,
      "loss": 0.3027,
      "step": 46432
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.6829470992088318,
      "learning_rate": 5e-05,
      "loss": 0.2947,
      "step": 46440
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.6972622275352478,
      "learning_rate": 5e-05,
      "loss": 0.2993,
      "step": 46448
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.6276742815971375,
      "learning_rate": 5e-05,
      "loss": 0.289,
      "step": 46456
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.6902586221694946,
      "learning_rate": 5e-05,
      "loss": 0.283,
      "step": 46464
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.6255651712417603,
      "learning_rate": 5e-05,
      "loss": 0.2711,
      "step": 46472
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.608729362487793,
      "learning_rate": 5e-05,
      "loss": 0.2918,
      "step": 46480
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.6285390257835388,
      "learning_rate": 5e-05,
      "loss": 0.3222,
      "step": 46488
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.6147312521934509,
      "learning_rate": 5e-05,
      "loss": 0.3276,
      "step": 46496
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.6112112998962402,
      "learning_rate": 5e-05,
      "loss": 0.289,
      "step": 46504
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.5375611186027527,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 46512
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.574683427810669,
      "learning_rate": 5e-05,
      "loss": 0.2925,
      "step": 46520
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.6166195273399353,
      "learning_rate": 5e-05,
      "loss": 0.287,
      "step": 46528
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.6010944247245789,
      "learning_rate": 5e-05,
      "loss": 0.2915,
      "step": 46536
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.5528489947319031,
      "learning_rate": 5e-05,
      "loss": 0.2673,
      "step": 46544
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.5416778326034546,
      "learning_rate": 5e-05,
      "loss": 0.3055,
      "step": 46552
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.534148097038269,
      "learning_rate": 5e-05,
      "loss": 0.3166,
      "step": 46560
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.5626007318496704,
      "learning_rate": 5e-05,
      "loss": 0.3081,
      "step": 46568
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.7454299926757812,
      "learning_rate": 5e-05,
      "loss": 0.2608,
      "step": 46576
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.7199504375457764,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 46584
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.6544187664985657,
      "learning_rate": 5e-05,
      "loss": 0.2867,
      "step": 46592
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.5746468901634216,
      "learning_rate": 5e-05,
      "loss": 0.3107,
      "step": 46600
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.6423729062080383,
      "learning_rate": 5e-05,
      "loss": 0.2981,
      "step": 46608
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.6588420271873474,
      "learning_rate": 5e-05,
      "loss": 0.2948,
      "step": 46616
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.6555061936378479,
      "learning_rate": 5e-05,
      "loss": 0.2803,
      "step": 46624
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.6360424160957336,
      "learning_rate": 5e-05,
      "loss": 0.3154,
      "step": 46632
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.5934634804725647,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 46640
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.772980272769928,
      "learning_rate": 5e-05,
      "loss": 0.3083,
      "step": 46648
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.5619934797286987,
      "learning_rate": 5e-05,
      "loss": 0.3013,
      "step": 46656
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.5358021855354309,
      "learning_rate": 5e-05,
      "loss": 0.3027,
      "step": 46664
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.5671599507331848,
      "learning_rate": 5e-05,
      "loss": 0.3234,
      "step": 46672
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.6661980152130127,
      "learning_rate": 5e-05,
      "loss": 0.3059,
      "step": 46680
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.6528242230415344,
      "learning_rate": 5e-05,
      "loss": 0.2993,
      "step": 46688
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.5977092981338501,
      "learning_rate": 5e-05,
      "loss": 0.2848,
      "step": 46696
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.799592912197113,
      "learning_rate": 5e-05,
      "loss": 0.3178,
      "step": 46704
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.6402280926704407,
      "learning_rate": 5e-05,
      "loss": 0.3176,
      "step": 46712
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.6348761916160583,
      "learning_rate": 5e-05,
      "loss": 0.3034,
      "step": 46720
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.6875099539756775,
      "learning_rate": 5e-05,
      "loss": 0.3002,
      "step": 46728
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.6555556654930115,
      "learning_rate": 5e-05,
      "loss": 0.3139,
      "step": 46736
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.6633660793304443,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 46744
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.616735577583313,
      "learning_rate": 5e-05,
      "loss": 0.2993,
      "step": 46752
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.5870696902275085,
      "learning_rate": 5e-05,
      "loss": 0.2907,
      "step": 46760
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.7292740941047668,
      "learning_rate": 5e-05,
      "loss": 0.2919,
      "step": 46768
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.7907018065452576,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 46776
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.5954875349998474,
      "learning_rate": 5e-05,
      "loss": 0.2814,
      "step": 46784
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.6620765328407288,
      "learning_rate": 5e-05,
      "loss": 0.3099,
      "step": 46792
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.7367269992828369,
      "learning_rate": 5e-05,
      "loss": 0.2957,
      "step": 46800
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.5485527515411377,
      "learning_rate": 5e-05,
      "loss": 0.3156,
      "step": 46808
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.5822993516921997,
      "learning_rate": 5e-05,
      "loss": 0.3173,
      "step": 46816
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.6854696273803711,
      "learning_rate": 5e-05,
      "loss": 0.2793,
      "step": 46824
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.7442636489868164,
      "learning_rate": 5e-05,
      "loss": 0.282,
      "step": 46832
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.5853539109230042,
      "learning_rate": 5e-05,
      "loss": 0.2866,
      "step": 46840
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.6156332492828369,
      "learning_rate": 5e-05,
      "loss": 0.3131,
      "step": 46848
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.6388475894927979,
      "learning_rate": 5e-05,
      "loss": 0.2701,
      "step": 46856
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.5810498595237732,
      "learning_rate": 5e-05,
      "loss": 0.2939,
      "step": 46864
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.7194507122039795,
      "learning_rate": 5e-05,
      "loss": 0.3126,
      "step": 46872
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.6574190855026245,
      "learning_rate": 5e-05,
      "loss": 0.3119,
      "step": 46880
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.6771230101585388,
      "learning_rate": 5e-05,
      "loss": 0.3266,
      "step": 46888
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.722350537776947,
      "learning_rate": 5e-05,
      "loss": 0.2826,
      "step": 46896
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.7045547366142273,
      "learning_rate": 5e-05,
      "loss": 0.325,
      "step": 46904
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.578342854976654,
      "learning_rate": 5e-05,
      "loss": 0.2848,
      "step": 46912
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.6701444983482361,
      "learning_rate": 5e-05,
      "loss": 0.3115,
      "step": 46920
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.5939541459083557,
      "learning_rate": 5e-05,
      "loss": 0.2771,
      "step": 46928
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.6681787967681885,
      "learning_rate": 5e-05,
      "loss": 0.291,
      "step": 46936
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.587476372718811,
      "learning_rate": 5e-05,
      "loss": 0.3202,
      "step": 46944
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.6183128356933594,
      "learning_rate": 5e-05,
      "loss": 0.3208,
      "step": 46952
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.6416968703269958,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 46960
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.6382582783699036,
      "learning_rate": 5e-05,
      "loss": 0.2944,
      "step": 46968
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.6862849593162537,
      "learning_rate": 5e-05,
      "loss": 0.3035,
      "step": 46976
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.6399480700492859,
      "learning_rate": 5e-05,
      "loss": 0.2775,
      "step": 46984
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.7187553644180298,
      "learning_rate": 5e-05,
      "loss": 0.2848,
      "step": 46992
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.6047887802124023,
      "learning_rate": 5e-05,
      "loss": 0.2768,
      "step": 47000
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.693871259689331,
      "learning_rate": 5e-05,
      "loss": 0.3025,
      "step": 47008
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.7503833770751953,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 47016
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.6537802219390869,
      "learning_rate": 5e-05,
      "loss": 0.297,
      "step": 47024
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.6516287326812744,
      "learning_rate": 5e-05,
      "loss": 0.2978,
      "step": 47032
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.6813344359397888,
      "learning_rate": 5e-05,
      "loss": 0.3,
      "step": 47040
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.7243618965148926,
      "learning_rate": 5e-05,
      "loss": 0.2777,
      "step": 47048
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.5905630588531494,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 47056
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.6778313517570496,
      "learning_rate": 5e-05,
      "loss": 0.3249,
      "step": 47064
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.7070116400718689,
      "learning_rate": 5e-05,
      "loss": 0.2938,
      "step": 47072
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.5655873417854309,
      "learning_rate": 5e-05,
      "loss": 0.2921,
      "step": 47080
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.62380450963974,
      "learning_rate": 5e-05,
      "loss": 0.2982,
      "step": 47088
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.6432580947875977,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 47096
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.5697562098503113,
      "learning_rate": 5e-05,
      "loss": 0.3149,
      "step": 47104
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.6757634282112122,
      "learning_rate": 5e-05,
      "loss": 0.2989,
      "step": 47112
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.5349236130714417,
      "learning_rate": 5e-05,
      "loss": 0.2894,
      "step": 47120
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.676841139793396,
      "learning_rate": 5e-05,
      "loss": 0.2881,
      "step": 47128
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.6401227116584778,
      "learning_rate": 5e-05,
      "loss": 0.2977,
      "step": 47136
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.6379292011260986,
      "learning_rate": 5e-05,
      "loss": 0.304,
      "step": 47144
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.6313698291778564,
      "learning_rate": 5e-05,
      "loss": 0.3123,
      "step": 47152
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.6249613761901855,
      "learning_rate": 5e-05,
      "loss": 0.3202,
      "step": 47160
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.5257179141044617,
      "learning_rate": 5e-05,
      "loss": 0.2971,
      "step": 47168
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.5581419467926025,
      "learning_rate": 5e-05,
      "loss": 0.2818,
      "step": 47176
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.6096402406692505,
      "learning_rate": 5e-05,
      "loss": 0.2819,
      "step": 47184
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.611750066280365,
      "learning_rate": 5e-05,
      "loss": 0.3236,
      "step": 47192
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.6166356205940247,
      "learning_rate": 5e-05,
      "loss": 0.3347,
      "step": 47200
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.6092678904533386,
      "learning_rate": 5e-05,
      "loss": 0.3011,
      "step": 47208
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.7285842895507812,
      "learning_rate": 5e-05,
      "loss": 0.2911,
      "step": 47216
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.5838575959205627,
      "learning_rate": 5e-05,
      "loss": 0.2894,
      "step": 47224
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.5769664645195007,
      "learning_rate": 5e-05,
      "loss": 0.2916,
      "step": 47232
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.7073174715042114,
      "learning_rate": 5e-05,
      "loss": 0.3085,
      "step": 47240
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.5279200077056885,
      "learning_rate": 5e-05,
      "loss": 0.3106,
      "step": 47248
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.7454007267951965,
      "learning_rate": 5e-05,
      "loss": 0.2834,
      "step": 47256
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.596551239490509,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 47264
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6001192331314087,
      "learning_rate": 5e-05,
      "loss": 0.3113,
      "step": 47272
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.613562822341919,
      "learning_rate": 5e-05,
      "loss": 0.3328,
      "step": 47280
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.5785990953445435,
      "learning_rate": 5e-05,
      "loss": 0.3366,
      "step": 47288
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.8819319009780884,
      "learning_rate": 5e-05,
      "loss": 0.3243,
      "step": 47296
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6063988208770752,
      "learning_rate": 5e-05,
      "loss": 0.2917,
      "step": 47304
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6058390736579895,
      "learning_rate": 5e-05,
      "loss": 0.2872,
      "step": 47312
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6428461670875549,
      "learning_rate": 5e-05,
      "loss": 0.3033,
      "step": 47320
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6627182960510254,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 47328
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6526223421096802,
      "learning_rate": 5e-05,
      "loss": 0.2743,
      "step": 47336
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6860144138336182,
      "learning_rate": 5e-05,
      "loss": 0.3065,
      "step": 47344
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6805369257926941,
      "learning_rate": 5e-05,
      "loss": 0.2984,
      "step": 47352
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.8553906679153442,
      "learning_rate": 5e-05,
      "loss": 0.287,
      "step": 47360
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.7434130311012268,
      "learning_rate": 5e-05,
      "loss": 0.3094,
      "step": 47368
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.49756932258605957,
      "learning_rate": 5e-05,
      "loss": 0.2928,
      "step": 47376
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6908404231071472,
      "learning_rate": 5e-05,
      "loss": 0.276,
      "step": 47384
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.5463737845420837,
      "learning_rate": 5e-05,
      "loss": 0.2679,
      "step": 47392
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6028925180435181,
      "learning_rate": 5e-05,
      "loss": 0.331,
      "step": 47400
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.6217557787895203,
      "learning_rate": 5e-05,
      "loss": 0.2783,
      "step": 47408
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.578605055809021,
      "learning_rate": 5e-05,
      "loss": 0.3042,
      "step": 47416
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.5725480318069458,
      "learning_rate": 5e-05,
      "loss": 0.306,
      "step": 47424
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6335573792457581,
      "learning_rate": 5e-05,
      "loss": 0.3063,
      "step": 47432
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6102908253669739,
      "learning_rate": 5e-05,
      "loss": 0.2945,
      "step": 47440
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.7270910143852234,
      "learning_rate": 5e-05,
      "loss": 0.2969,
      "step": 47448
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.5735874772071838,
      "learning_rate": 5e-05,
      "loss": 0.2963,
      "step": 47456
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6660119891166687,
      "learning_rate": 5e-05,
      "loss": 0.3074,
      "step": 47464
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6079747676849365,
      "learning_rate": 5e-05,
      "loss": 0.3095,
      "step": 47472
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6798564791679382,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 47480
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6582822203636169,
      "learning_rate": 5e-05,
      "loss": 0.3254,
      "step": 47488
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.5900227427482605,
      "learning_rate": 5e-05,
      "loss": 0.302,
      "step": 47496
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6238040328025818,
      "learning_rate": 5e-05,
      "loss": 0.3168,
      "step": 47504
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6293094754219055,
      "learning_rate": 5e-05,
      "loss": 0.3067,
      "step": 47512
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.5811108946800232,
      "learning_rate": 5e-05,
      "loss": 0.3108,
      "step": 47520
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6101860404014587,
      "learning_rate": 5e-05,
      "loss": 0.2773,
      "step": 47528
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.5780535340309143,
      "learning_rate": 5e-05,
      "loss": 0.296,
      "step": 47536
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6991830468177795,
      "learning_rate": 5e-05,
      "loss": 0.2961,
      "step": 47544
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6373089551925659,
      "learning_rate": 5e-05,
      "loss": 0.3055,
      "step": 47552
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6217986345291138,
      "learning_rate": 5e-05,
      "loss": 0.2897,
      "step": 47560
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6528640389442444,
      "learning_rate": 5e-05,
      "loss": 0.3011,
      "step": 47568
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.7733114957809448,
      "learning_rate": 5e-05,
      "loss": 0.3023,
      "step": 47576
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6417549252510071,
      "learning_rate": 5e-05,
      "loss": 0.2839,
      "step": 47584
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6739240884780884,
      "learning_rate": 5e-05,
      "loss": 0.3132,
      "step": 47592
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.6078312993049622,
      "learning_rate": 5e-05,
      "loss": 0.307,
      "step": 47600
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.6413484215736389,
      "learning_rate": 5e-05,
      "loss": 0.292,
      "step": 47608
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.5977157354354858,
      "learning_rate": 5e-05,
      "loss": 0.3322,
      "step": 47616
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.6681060194969177,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 47624
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.6419736742973328,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 47632
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.5681930780410767,
      "learning_rate": 5e-05,
      "loss": 0.2856,
      "step": 47640
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.5700884461402893,
      "learning_rate": 5e-05,
      "loss": 0.294,
      "step": 47648
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.7532516717910767,
      "learning_rate": 5e-05,
      "loss": 0.2904,
      "step": 47656
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.630487859249115,
      "learning_rate": 5e-05,
      "loss": 0.2978,
      "step": 47664
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.6144867539405823,
      "learning_rate": 5e-05,
      "loss": 0.2979,
      "step": 47672
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.5522981882095337,
      "learning_rate": 5e-05,
      "loss": 0.2871,
      "step": 47680
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.6582788825035095,
      "learning_rate": 5e-05,
      "loss": 0.3062,
      "step": 47688
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.5938667058944702,
      "learning_rate": 5e-05,
      "loss": 0.2888,
      "step": 47696
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.6306728720664978,
      "learning_rate": 5e-05,
      "loss": 0.3157,
      "step": 47704
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.574978232383728,
      "learning_rate": 5e-05,
      "loss": 0.2857,
      "step": 47712
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.6619949340820312,
      "learning_rate": 5e-05,
      "loss": 0.2646,
      "step": 47720
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.6797588467597961,
      "learning_rate": 5e-05,
      "loss": 0.2987,
      "step": 47728
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.593498706817627,
      "learning_rate": 5e-05,
      "loss": 0.2729,
      "step": 47736
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.6674907207489014,
      "learning_rate": 5e-05,
      "loss": 0.2879,
      "step": 47744
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.7984377145767212,
      "learning_rate": 5e-05,
      "loss": 0.3035,
      "step": 47752
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.5754748582839966,
      "learning_rate": 5e-05,
      "loss": 0.2716,
      "step": 47760
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.7066583037376404,
      "learning_rate": 5e-05,
      "loss": 0.2955,
      "step": 47768
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.6969524621963501,
      "learning_rate": 5e-05,
      "loss": 0.303,
      "step": 47776
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.6129788756370544,
      "learning_rate": 5e-05,
      "loss": 0.3385,
      "step": 47784
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.6034911274909973,
      "learning_rate": 5e-05,
      "loss": 0.3054,
      "step": 47792
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.6090621948242188,
      "learning_rate": 5e-05,
      "loss": 0.2987,
      "step": 47800
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.6128329634666443,
      "learning_rate": 5e-05,
      "loss": 0.2663,
      "step": 47808
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.585139811038971,
      "learning_rate": 5e-05,
      "loss": 0.3007,
      "step": 47816
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.6028509736061096,
      "learning_rate": 5e-05,
      "loss": 0.2933,
      "step": 47824
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.7009786367416382,
      "learning_rate": 5e-05,
      "loss": 0.2777,
      "step": 47832
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.6295748353004456,
      "learning_rate": 5e-05,
      "loss": 0.3076,
      "step": 47840
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.6543133854866028,
      "learning_rate": 5e-05,
      "loss": 0.2966,
      "step": 47848
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.6363328695297241,
      "learning_rate": 5e-05,
      "loss": 0.2993,
      "step": 47856
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.5174146890640259,
      "learning_rate": 5e-05,
      "loss": 0.2999,
      "step": 47864
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.6277289390563965,
      "learning_rate": 5e-05,
      "loss": 0.3128,
      "step": 47872
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.6222671866416931,
      "learning_rate": 5e-05,
      "loss": 0.3151,
      "step": 47880
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.701445460319519,
      "learning_rate": 5e-05,
      "loss": 0.3095,
      "step": 47888
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.5772193670272827,
      "learning_rate": 5e-05,
      "loss": 0.2681,
      "step": 47896
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.606203019618988,
      "learning_rate": 5e-05,
      "loss": 0.3173,
      "step": 47904
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.660791277885437,
      "learning_rate": 5e-05,
      "loss": 0.3011,
      "step": 47912
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.6232360601425171,
      "learning_rate": 5e-05,
      "loss": 0.3213,
      "step": 47920
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.597027063369751,
      "learning_rate": 5e-05,
      "loss": 0.3047,
      "step": 47928
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.6668680906295776,
      "learning_rate": 5e-05,
      "loss": 0.3135,
      "step": 47936
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.7398287057876587,
      "learning_rate": 5e-05,
      "loss": 0.3121,
      "step": 47944
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.5164180397987366,
      "learning_rate": 5e-05,
      "loss": 0.2907,
      "step": 47952
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.5922660827636719,
      "learning_rate": 5e-05,
      "loss": 0.2797,
      "step": 47960
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.5677666664123535,
      "learning_rate": 5e-05,
      "loss": 0.2874,
      "step": 47968
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.627083420753479,
      "learning_rate": 5e-05,
      "loss": 0.3128,
      "step": 47976
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.6641680002212524,
      "learning_rate": 5e-05,
      "loss": 0.3376,
      "step": 47984
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.6869648098945618,
      "learning_rate": 5e-05,
      "loss": 0.2829,
      "step": 47992
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.6251816749572754,
      "learning_rate": 5e-05,
      "loss": 0.3114,
      "step": 48000
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.5858500599861145,
      "learning_rate": 5e-05,
      "loss": 0.3032,
      "step": 48008
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.6423116326332092,
      "learning_rate": 5e-05,
      "loss": 0.2828,
      "step": 48016
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.7554872632026672,
      "learning_rate": 5e-05,
      "loss": 0.3103,
      "step": 48024
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.5792844295501709,
      "learning_rate": 5e-05,
      "loss": 0.2825,
      "step": 48032
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.6363368630409241,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 48040
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.7786049842834473,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 48048
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.6758889555931091,
      "learning_rate": 5e-05,
      "loss": 0.2979,
      "step": 48056
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.5932868719100952,
      "learning_rate": 5e-05,
      "loss": 0.2745,
      "step": 48064
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.7778865694999695,
      "learning_rate": 5e-05,
      "loss": 0.3136,
      "step": 48072
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.6832823157310486,
      "learning_rate": 5e-05,
      "loss": 0.2756,
      "step": 48080
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.6774238348007202,
      "learning_rate": 5e-05,
      "loss": 0.3229,
      "step": 48088
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.6061142086982727,
      "learning_rate": 5e-05,
      "loss": 0.2892,
      "step": 48096
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.6018190979957581,
      "learning_rate": 5e-05,
      "loss": 0.2907,
      "step": 48104
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.6134174466133118,
      "learning_rate": 5e-05,
      "loss": 0.2851,
      "step": 48112
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.5445499420166016,
      "learning_rate": 5e-05,
      "loss": 0.3339,
      "step": 48120
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.656227171421051,
      "learning_rate": 5e-05,
      "loss": 0.2874,
      "step": 48128
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.5834502577781677,
      "learning_rate": 5e-05,
      "loss": 0.2917,
      "step": 48136
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.7440242767333984,
      "learning_rate": 5e-05,
      "loss": 0.2871,
      "step": 48144
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.6681444048881531,
      "learning_rate": 5e-05,
      "loss": 0.2828,
      "step": 48152
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.7143710255622864,
      "learning_rate": 5e-05,
      "loss": 0.2923,
      "step": 48160
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.8747516870498657,
      "learning_rate": 5e-05,
      "loss": 0.2925,
      "step": 48168
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.6664302349090576,
      "learning_rate": 5e-05,
      "loss": 0.2889,
      "step": 48176
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.5976414084434509,
      "learning_rate": 5e-05,
      "loss": 0.283,
      "step": 48184
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.6850353479385376,
      "learning_rate": 5e-05,
      "loss": 0.3014,
      "step": 48192
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.660489022731781,
      "learning_rate": 5e-05,
      "loss": 0.2993,
      "step": 48200
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.7527305483818054,
      "learning_rate": 5e-05,
      "loss": 0.2841,
      "step": 48208
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.6226964592933655,
      "learning_rate": 5e-05,
      "loss": 0.3014,
      "step": 48216
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.6032289862632751,
      "learning_rate": 5e-05,
      "loss": 0.3201,
      "step": 48224
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.6670694351196289,
      "learning_rate": 5e-05,
      "loss": 0.2975,
      "step": 48232
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.7802793979644775,
      "learning_rate": 5e-05,
      "loss": 0.2911,
      "step": 48240
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.6388475894927979,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 48248
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.7068951725959778,
      "learning_rate": 5e-05,
      "loss": 0.2714,
      "step": 48256
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.8028077483177185,
      "learning_rate": 5e-05,
      "loss": 0.3096,
      "step": 48264
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.615735650062561,
      "learning_rate": 5e-05,
      "loss": 0.2971,
      "step": 48272
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.6750596761703491,
      "learning_rate": 5e-05,
      "loss": 0.3233,
      "step": 48280
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.6528306603431702,
      "learning_rate": 5e-05,
      "loss": 0.3006,
      "step": 48288
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.5803462266921997,
      "learning_rate": 5e-05,
      "loss": 0.2961,
      "step": 48296
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.6314976215362549,
      "learning_rate": 5e-05,
      "loss": 0.3058,
      "step": 48304
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.6505764722824097,
      "learning_rate": 5e-05,
      "loss": 0.3066,
      "step": 48312
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.5614486932754517,
      "learning_rate": 5e-05,
      "loss": 0.3207,
      "step": 48320
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.6768513321876526,
      "learning_rate": 5e-05,
      "loss": 0.3033,
      "step": 48328
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.6482447385787964,
      "learning_rate": 5e-05,
      "loss": 0.3111,
      "step": 48336
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.6263796091079712,
      "learning_rate": 5e-05,
      "loss": 0.3082,
      "step": 48344
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.7192526459693909,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 48352
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.5756723880767822,
      "learning_rate": 5e-05,
      "loss": 0.2991,
      "step": 48360
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.588186502456665,
      "learning_rate": 5e-05,
      "loss": 0.3047,
      "step": 48368
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.5827417969703674,
      "learning_rate": 5e-05,
      "loss": 0.2769,
      "step": 48376
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.5096271634101868,
      "learning_rate": 5e-05,
      "loss": 0.2663,
      "step": 48384
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.6532790064811707,
      "learning_rate": 5e-05,
      "loss": 0.3297,
      "step": 48392
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.6070789098739624,
      "learning_rate": 5e-05,
      "loss": 0.2864,
      "step": 48400
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.5813570022583008,
      "learning_rate": 5e-05,
      "loss": 0.3087,
      "step": 48408
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.6539775729179382,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 48416
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.6288134455680847,
      "learning_rate": 5e-05,
      "loss": 0.3295,
      "step": 48424
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.5619117617607117,
      "learning_rate": 5e-05,
      "loss": 0.2986,
      "step": 48432
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.7067954540252686,
      "learning_rate": 5e-05,
      "loss": 0.3087,
      "step": 48440
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.6712599992752075,
      "learning_rate": 5e-05,
      "loss": 0.2935,
      "step": 48448
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.5957054495811462,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 48456
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.6859953999519348,
      "learning_rate": 5e-05,
      "loss": 0.2846,
      "step": 48464
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.6052360534667969,
      "learning_rate": 5e-05,
      "loss": 0.2785,
      "step": 48472
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.6091076731681824,
      "learning_rate": 5e-05,
      "loss": 0.2714,
      "step": 48480
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.6280121207237244,
      "learning_rate": 5e-05,
      "loss": 0.3151,
      "step": 48488
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.5555803775787354,
      "learning_rate": 5e-05,
      "loss": 0.3062,
      "step": 48496
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.740142822265625,
      "learning_rate": 5e-05,
      "loss": 0.3085,
      "step": 48504
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.590804398059845,
      "learning_rate": 5e-05,
      "loss": 0.3323,
      "step": 48512
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.7136174440383911,
      "learning_rate": 5e-05,
      "loss": 0.2791,
      "step": 48520
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.7033610939979553,
      "learning_rate": 5e-05,
      "loss": 0.3018,
      "step": 48528
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.6855792999267578,
      "learning_rate": 5e-05,
      "loss": 0.3066,
      "step": 48536
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.5477354526519775,
      "learning_rate": 5e-05,
      "loss": 0.2985,
      "step": 48544
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.6205393671989441,
      "learning_rate": 5e-05,
      "loss": 0.292,
      "step": 48552
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.6124922633171082,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 48560
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.5475358963012695,
      "learning_rate": 5e-05,
      "loss": 0.2806,
      "step": 48568
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.6566202044487,
      "learning_rate": 5e-05,
      "loss": 0.3124,
      "step": 48576
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.6514317989349365,
      "learning_rate": 5e-05,
      "loss": 0.3239,
      "step": 48584
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.6836796402931213,
      "learning_rate": 5e-05,
      "loss": 0.3187,
      "step": 48592
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.7078777551651001,
      "learning_rate": 5e-05,
      "loss": 0.313,
      "step": 48600
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.5708314180374146,
      "learning_rate": 5e-05,
      "loss": 0.2854,
      "step": 48608
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.5127955079078674,
      "learning_rate": 5e-05,
      "loss": 0.2724,
      "step": 48616
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.5681992173194885,
      "learning_rate": 5e-05,
      "loss": 0.2932,
      "step": 48624
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.5592976808547974,
      "learning_rate": 5e-05,
      "loss": 0.3073,
      "step": 48632
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.550879716873169,
      "learning_rate": 5e-05,
      "loss": 0.3143,
      "step": 48640
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.5599925518035889,
      "learning_rate": 5e-05,
      "loss": 0.3203,
      "step": 48648
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.6683847308158875,
      "learning_rate": 5e-05,
      "loss": 0.3044,
      "step": 48656
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.7247145175933838,
      "learning_rate": 5e-05,
      "loss": 0.3107,
      "step": 48664
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.5679524540901184,
      "learning_rate": 5e-05,
      "loss": 0.2806,
      "step": 48672
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.667100191116333,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 48680
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.754309356212616,
      "learning_rate": 5e-05,
      "loss": 0.2817,
      "step": 48688
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.6901340484619141,
      "learning_rate": 5e-05,
      "loss": 0.3075,
      "step": 48696
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.5560516119003296,
      "learning_rate": 5e-05,
      "loss": 0.2955,
      "step": 48704
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.6836901307106018,
      "learning_rate": 5e-05,
      "loss": 0.2865,
      "step": 48712
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.6405771374702454,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 48720
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.6022176742553711,
      "learning_rate": 5e-05,
      "loss": 0.2875,
      "step": 48728
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.5614262819290161,
      "learning_rate": 5e-05,
      "loss": 0.2862,
      "step": 48736
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.5505275726318359,
      "learning_rate": 5e-05,
      "loss": 0.2744,
      "step": 48744
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.6713039875030518,
      "learning_rate": 5e-05,
      "loss": 0.2911,
      "step": 48752
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.5704814791679382,
      "learning_rate": 5e-05,
      "loss": 0.3075,
      "step": 48760
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.5904073715209961,
      "learning_rate": 5e-05,
      "loss": 0.3181,
      "step": 48768
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.6553964614868164,
      "learning_rate": 5e-05,
      "loss": 0.293,
      "step": 48776
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.5406246781349182,
      "learning_rate": 5e-05,
      "loss": 0.301,
      "step": 48784
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.5144655704498291,
      "learning_rate": 5e-05,
      "loss": 0.3102,
      "step": 48792
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.6257306337356567,
      "learning_rate": 5e-05,
      "loss": 0.2754,
      "step": 48800
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.5925906896591187,
      "learning_rate": 5e-05,
      "loss": 0.2716,
      "step": 48808
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.6468988060951233,
      "learning_rate": 5e-05,
      "loss": 0.2848,
      "step": 48816
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.7761918902397156,
      "learning_rate": 5e-05,
      "loss": 0.2932,
      "step": 48824
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.6231958866119385,
      "learning_rate": 5e-05,
      "loss": 0.2893,
      "step": 48832
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.5301772952079773,
      "learning_rate": 5e-05,
      "loss": 0.2879,
      "step": 48840
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.6108296513557434,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 48848
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.6800258755683899,
      "learning_rate": 5e-05,
      "loss": 0.3036,
      "step": 48856
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.5500138998031616,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 48864
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.5282983779907227,
      "learning_rate": 5e-05,
      "loss": 0.3075,
      "step": 48872
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.6283438205718994,
      "learning_rate": 5e-05,
      "loss": 0.2682,
      "step": 48880
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.5984851121902466,
      "learning_rate": 5e-05,
      "loss": 0.2888,
      "step": 48888
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.7245371341705322,
      "learning_rate": 5e-05,
      "loss": 0.2948,
      "step": 48896
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.620898962020874,
      "learning_rate": 5e-05,
      "loss": 0.2882,
      "step": 48904
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.6275284886360168,
      "learning_rate": 5e-05,
      "loss": 0.2903,
      "step": 48912
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.5028267502784729,
      "learning_rate": 5e-05,
      "loss": 0.2795,
      "step": 48920
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.6597000956535339,
      "learning_rate": 5e-05,
      "loss": 0.2801,
      "step": 48928
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.6143746972084045,
      "learning_rate": 5e-05,
      "loss": 0.2885,
      "step": 48936
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.5970877408981323,
      "learning_rate": 5e-05,
      "loss": 0.3226,
      "step": 48944
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.6731817722320557,
      "learning_rate": 5e-05,
      "loss": 0.3018,
      "step": 48952
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.6002299785614014,
      "learning_rate": 5e-05,
      "loss": 0.2918,
      "step": 48960
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.5522893071174622,
      "learning_rate": 5e-05,
      "loss": 0.2869,
      "step": 48968
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.5518156290054321,
      "learning_rate": 5e-05,
      "loss": 0.295,
      "step": 48976
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.682149350643158,
      "learning_rate": 5e-05,
      "loss": 0.2758,
      "step": 48984
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.5439725518226624,
      "learning_rate": 5e-05,
      "loss": 0.3458,
      "step": 48992
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.7536020278930664,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 49000
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.6832077503204346,
      "learning_rate": 5e-05,
      "loss": 0.3093,
      "step": 49008
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.5575932264328003,
      "learning_rate": 5e-05,
      "loss": 0.294,
      "step": 49016
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.7225978374481201,
      "learning_rate": 5e-05,
      "loss": 0.3115,
      "step": 49024
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.6821931600570679,
      "learning_rate": 5e-05,
      "loss": 0.309,
      "step": 49032
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.7264928221702576,
      "learning_rate": 5e-05,
      "loss": 0.3027,
      "step": 49040
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.8361984491348267,
      "learning_rate": 5e-05,
      "loss": 0.2928,
      "step": 49048
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.6495774984359741,
      "learning_rate": 5e-05,
      "loss": 0.326,
      "step": 49056
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.6741483807563782,
      "learning_rate": 5e-05,
      "loss": 0.2947,
      "step": 49064
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.6595421433448792,
      "learning_rate": 5e-05,
      "loss": 0.2828,
      "step": 49072
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.7214072346687317,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 49080
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.630897045135498,
      "learning_rate": 5e-05,
      "loss": 0.2886,
      "step": 49088
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.8467810750007629,
      "learning_rate": 5e-05,
      "loss": 0.3068,
      "step": 49096
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.6861692667007446,
      "learning_rate": 5e-05,
      "loss": 0.2871,
      "step": 49104
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.5802463293075562,
      "learning_rate": 5e-05,
      "loss": 0.2892,
      "step": 49112
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.5927038788795471,
      "learning_rate": 5e-05,
      "loss": 0.2999,
      "step": 49120
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.5909944176673889,
      "learning_rate": 5e-05,
      "loss": 0.3194,
      "step": 49128
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.593716025352478,
      "learning_rate": 5e-05,
      "loss": 0.3032,
      "step": 49136
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.6630838513374329,
      "learning_rate": 5e-05,
      "loss": 0.3022,
      "step": 49144
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.6573938131332397,
      "learning_rate": 5e-05,
      "loss": 0.3149,
      "step": 49152
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.614891767501831,
      "learning_rate": 5e-05,
      "loss": 0.283,
      "step": 49160
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.6605307459831238,
      "learning_rate": 5e-05,
      "loss": 0.2783,
      "step": 49168
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.5571786761283875,
      "learning_rate": 5e-05,
      "loss": 0.3086,
      "step": 49176
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.7264101505279541,
      "learning_rate": 5e-05,
      "loss": 0.2912,
      "step": 49184
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.883844256401062,
      "learning_rate": 5e-05,
      "loss": 0.3339,
      "step": 49192
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.597547709941864,
      "learning_rate": 5e-05,
      "loss": 0.2881,
      "step": 49200
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.5699580311775208,
      "learning_rate": 5e-05,
      "loss": 0.2985,
      "step": 49208
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.806575357913971,
      "learning_rate": 5e-05,
      "loss": 0.3177,
      "step": 49216
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.6504348516464233,
      "learning_rate": 5e-05,
      "loss": 0.2649,
      "step": 49224
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.6064772009849548,
      "learning_rate": 5e-05,
      "loss": 0.2917,
      "step": 49232
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.6106051802635193,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 49240
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.5702462196350098,
      "learning_rate": 5e-05,
      "loss": 0.2793,
      "step": 49248
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.6096554398536682,
      "learning_rate": 5e-05,
      "loss": 0.3247,
      "step": 49256
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6220273375511169,
      "learning_rate": 5e-05,
      "loss": 0.3098,
      "step": 49264
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.623216450214386,
      "learning_rate": 5e-05,
      "loss": 0.2864,
      "step": 49272
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.5061234831809998,
      "learning_rate": 5e-05,
      "loss": 0.2938,
      "step": 49280
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6715856194496155,
      "learning_rate": 5e-05,
      "loss": 0.3054,
      "step": 49288
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6467166543006897,
      "learning_rate": 5e-05,
      "loss": 0.3046,
      "step": 49296
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6453720331192017,
      "learning_rate": 5e-05,
      "loss": 0.336,
      "step": 49304
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6965961456298828,
      "learning_rate": 5e-05,
      "loss": 0.293,
      "step": 49312
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6406648755073547,
      "learning_rate": 5e-05,
      "loss": 0.2963,
      "step": 49320
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.5873019099235535,
      "learning_rate": 5e-05,
      "loss": 0.2901,
      "step": 49328
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6134396195411682,
      "learning_rate": 5e-05,
      "loss": 0.281,
      "step": 49336
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6349919438362122,
      "learning_rate": 5e-05,
      "loss": 0.3101,
      "step": 49344
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6185488104820251,
      "learning_rate": 5e-05,
      "loss": 0.3197,
      "step": 49352
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.5587440133094788,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 49360
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.5492651462554932,
      "learning_rate": 5e-05,
      "loss": 0.3273,
      "step": 49368
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6871534585952759,
      "learning_rate": 5e-05,
      "loss": 0.2863,
      "step": 49376
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6973853707313538,
      "learning_rate": 5e-05,
      "loss": 0.3024,
      "step": 49384
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.7111796140670776,
      "learning_rate": 5e-05,
      "loss": 0.3443,
      "step": 49392
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.579234778881073,
      "learning_rate": 5e-05,
      "loss": 0.2642,
      "step": 49400
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6310675144195557,
      "learning_rate": 5e-05,
      "loss": 0.3167,
      "step": 49408
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.531233012676239,
      "learning_rate": 5e-05,
      "loss": 0.3231,
      "step": 49416
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6014676094055176,
      "learning_rate": 5e-05,
      "loss": 0.3037,
      "step": 49424
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.7895181179046631,
      "learning_rate": 5e-05,
      "loss": 0.3054,
      "step": 49432
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.7362639904022217,
      "learning_rate": 5e-05,
      "loss": 0.2901,
      "step": 49440
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.5543087720870972,
      "learning_rate": 5e-05,
      "loss": 0.2701,
      "step": 49448
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.712162971496582,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 49456
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.883031964302063,
      "learning_rate": 5e-05,
      "loss": 0.2955,
      "step": 49464
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.7034156918525696,
      "learning_rate": 5e-05,
      "loss": 0.3156,
      "step": 49472
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.7125970125198364,
      "learning_rate": 5e-05,
      "loss": 0.2946,
      "step": 49480
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.629645586013794,
      "learning_rate": 5e-05,
      "loss": 0.3028,
      "step": 49488
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.7050708532333374,
      "learning_rate": 5e-05,
      "loss": 0.2836,
      "step": 49496
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.5892000794410706,
      "learning_rate": 5e-05,
      "loss": 0.319,
      "step": 49504
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.5987075567245483,
      "learning_rate": 5e-05,
      "loss": 0.3255,
      "step": 49512
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.6266989707946777,
      "learning_rate": 5e-05,
      "loss": 0.2789,
      "step": 49520
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.688534677028656,
      "learning_rate": 5e-05,
      "loss": 0.3207,
      "step": 49528
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.6617078185081482,
      "learning_rate": 5e-05,
      "loss": 0.254,
      "step": 49536
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.6329370737075806,
      "learning_rate": 5e-05,
      "loss": 0.2872,
      "step": 49544
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.61250901222229,
      "learning_rate": 5e-05,
      "loss": 0.3,
      "step": 49552
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.6496697068214417,
      "learning_rate": 5e-05,
      "loss": 0.2689,
      "step": 49560
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.683239758014679,
      "learning_rate": 5e-05,
      "loss": 0.3254,
      "step": 49568
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.6269171833992004,
      "learning_rate": 5e-05,
      "loss": 0.3013,
      "step": 49576
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.6245267391204834,
      "learning_rate": 5e-05,
      "loss": 0.2987,
      "step": 49584
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.5759334564208984,
      "learning_rate": 5e-05,
      "loss": 0.3053,
      "step": 49592
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.7054308652877808,
      "learning_rate": 5e-05,
      "loss": 0.2998,
      "step": 49600
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.667462170124054,
      "learning_rate": 5e-05,
      "loss": 0.3231,
      "step": 49608
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.7015975713729858,
      "learning_rate": 5e-05,
      "loss": 0.2963,
      "step": 49616
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.6277377605438232,
      "learning_rate": 5e-05,
      "loss": 0.3256,
      "step": 49624
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.6904175281524658,
      "learning_rate": 5e-05,
      "loss": 0.3148,
      "step": 49632
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.608210563659668,
      "learning_rate": 5e-05,
      "loss": 0.2943,
      "step": 49640
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.6184343099594116,
      "learning_rate": 5e-05,
      "loss": 0.2875,
      "step": 49648
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.6324699521064758,
      "learning_rate": 5e-05,
      "loss": 0.2841,
      "step": 49656
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.6403823494911194,
      "learning_rate": 5e-05,
      "loss": 0.2648,
      "step": 49664
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.6363682150840759,
      "learning_rate": 5e-05,
      "loss": 0.2707,
      "step": 49672
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.5923758745193481,
      "learning_rate": 5e-05,
      "loss": 0.2622,
      "step": 49680
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.5064617991447449,
      "learning_rate": 5e-05,
      "loss": 0.305,
      "step": 49688
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.6919897794723511,
      "learning_rate": 5e-05,
      "loss": 0.2724,
      "step": 49696
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.6292517781257629,
      "learning_rate": 5e-05,
      "loss": 0.3004,
      "step": 49704
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.5404171943664551,
      "learning_rate": 5e-05,
      "loss": 0.2941,
      "step": 49712
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.6712119579315186,
      "learning_rate": 5e-05,
      "loss": 0.3157,
      "step": 49720
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.6509730219841003,
      "learning_rate": 5e-05,
      "loss": 0.2845,
      "step": 49728
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.6753647923469543,
      "learning_rate": 5e-05,
      "loss": 0.2828,
      "step": 49736
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.6155637502670288,
      "learning_rate": 5e-05,
      "loss": 0.2875,
      "step": 49744
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.5871621966362,
      "learning_rate": 5e-05,
      "loss": 0.2968,
      "step": 49752
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6066195368766785,
      "learning_rate": 5e-05,
      "loss": 0.2802,
      "step": 49760
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6030882000923157,
      "learning_rate": 5e-05,
      "loss": 0.251,
      "step": 49768
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6694841384887695,
      "learning_rate": 5e-05,
      "loss": 0.291,
      "step": 49776
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6810145974159241,
      "learning_rate": 5e-05,
      "loss": 0.3092,
      "step": 49784
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6542806029319763,
      "learning_rate": 5e-05,
      "loss": 0.2892,
      "step": 49792
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6004013419151306,
      "learning_rate": 5e-05,
      "loss": 0.3062,
      "step": 49800
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6212916970252991,
      "learning_rate": 5e-05,
      "loss": 0.3067,
      "step": 49808
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6482468843460083,
      "learning_rate": 5e-05,
      "loss": 0.2766,
      "step": 49816
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6689311861991882,
      "learning_rate": 5e-05,
      "loss": 0.3154,
      "step": 49824
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6583773493766785,
      "learning_rate": 5e-05,
      "loss": 0.2986,
      "step": 49832
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6401052474975586,
      "learning_rate": 5e-05,
      "loss": 0.2709,
      "step": 49840
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.5756669044494629,
      "learning_rate": 5e-05,
      "loss": 0.2773,
      "step": 49848
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6542029976844788,
      "learning_rate": 5e-05,
      "loss": 0.2965,
      "step": 49856
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.7654930353164673,
      "learning_rate": 5e-05,
      "loss": 0.2872,
      "step": 49864
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.5261678099632263,
      "learning_rate": 5e-05,
      "loss": 0.2981,
      "step": 49872
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6119492650032043,
      "learning_rate": 5e-05,
      "loss": 0.3032,
      "step": 49880
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6884146928787231,
      "learning_rate": 5e-05,
      "loss": 0.3324,
      "step": 49888
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.701781153678894,
      "learning_rate": 5e-05,
      "loss": 0.2786,
      "step": 49896
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.7014322876930237,
      "learning_rate": 5e-05,
      "loss": 0.2997,
      "step": 49904
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.6424748301506042,
      "learning_rate": 5e-05,
      "loss": 0.3294,
      "step": 49912
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.5833702087402344,
      "learning_rate": 5e-05,
      "loss": 0.3021,
      "step": 49920
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.6244869828224182,
      "learning_rate": 5e-05,
      "loss": 0.3079,
      "step": 49928
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.7169370651245117,
      "learning_rate": 5e-05,
      "loss": 0.3086,
      "step": 49936
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.6539326906204224,
      "learning_rate": 5e-05,
      "loss": 0.2868,
      "step": 49944
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.6026358604431152,
      "learning_rate": 5e-05,
      "loss": 0.312,
      "step": 49952
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.7226690649986267,
      "learning_rate": 5e-05,
      "loss": 0.2919,
      "step": 49960
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.6711050868034363,
      "learning_rate": 5e-05,
      "loss": 0.289,
      "step": 49968
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.8077164888381958,
      "learning_rate": 5e-05,
      "loss": 0.274,
      "step": 49976
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.7838351130485535,
      "learning_rate": 5e-05,
      "loss": 0.2866,
      "step": 49984
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.5857176780700684,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 49992
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.6315209269523621,
      "learning_rate": 5e-05,
      "loss": 0.2732,
      "step": 50000
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.7459800243377686,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 50008
    }
  ],
  "logging_steps": 8,
  "max_steps": 166700,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 3.0837733334397747e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
