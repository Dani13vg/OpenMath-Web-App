{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 16670,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.24143537878990173,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 0.6459,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.2472335696220398,
      "learning_rate": 2.666666666666667e-06,
      "loss": 0.5959,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.2364300936460495,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.6332,
      "step": 24
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.2816077768802643,
      "learning_rate": 5.333333333333334e-06,
      "loss": 0.6172,
      "step": 32
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.29912033677101135,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.6738,
      "step": 40
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.249250590801239,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.6092,
      "step": 48
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.2965880334377289,
      "learning_rate": 9.333333333333334e-06,
      "loss": 0.614,
      "step": 56
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.46303820610046387,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 0.633,
      "step": 64
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.309923380613327,
      "learning_rate": 1.2e-05,
      "loss": 0.6098,
      "step": 72
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.37677791714668274,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.5987,
      "step": 80
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.24933458864688873,
      "learning_rate": 1.4666666666666668e-05,
      "loss": 0.5682,
      "step": 88
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.25531166791915894,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.5711,
      "step": 96
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2667256295681,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 0.5471,
      "step": 104
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2821418046951294,
      "learning_rate": 1.866666666666667e-05,
      "loss": 0.553,
      "step": 112
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2695710062980652,
      "learning_rate": 2e-05,
      "loss": 0.538,
      "step": 120
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2957484722137451,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 0.5135,
      "step": 128
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.42678552865982056,
      "learning_rate": 2.2666666666666668e-05,
      "loss": 0.496,
      "step": 136
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4111417829990387,
      "learning_rate": 2.4e-05,
      "loss": 0.4975,
      "step": 144
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2893507182598114,
      "learning_rate": 2.5333333333333337e-05,
      "loss": 0.4744,
      "step": 152
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.32691410183906555,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.4452,
      "step": 160
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3170139491558075,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.4825,
      "step": 168
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3100413978099823,
      "learning_rate": 2.9333333333333336e-05,
      "loss": 0.4689,
      "step": 176
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3523889183998108,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.4584,
      "step": 184
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3352666199207306,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.458,
      "step": 192
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4200054407119751,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.4468,
      "step": 200
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3382682502269745,
      "learning_rate": 3.466666666666667e-05,
      "loss": 0.4529,
      "step": 208
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3515879213809967,
      "learning_rate": 3.6e-05,
      "loss": 0.4535,
      "step": 216
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4336322844028473,
      "learning_rate": 3.733333333333334e-05,
      "loss": 0.4592,
      "step": 224
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.36572617292404175,
      "learning_rate": 3.866666666666667e-05,
      "loss": 0.4781,
      "step": 232
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.42819225788116455,
      "learning_rate": 4e-05,
      "loss": 0.4778,
      "step": 240
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.43568071722984314,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.4511,
      "step": 248
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5093626976013184,
      "learning_rate": 4.266666666666667e-05,
      "loss": 0.4497,
      "step": 256
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3977808952331543,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.4225,
      "step": 264
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.44592997431755066,
      "learning_rate": 4.5333333333333335e-05,
      "loss": 0.4006,
      "step": 272
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.43540599942207336,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.4229,
      "step": 280
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.38028445839881897,
      "learning_rate": 4.8e-05,
      "loss": 0.4233,
      "step": 288
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4539943039417267,
      "learning_rate": 4.933333333333334e-05,
      "loss": 0.4134,
      "step": 296
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4364908039569855,
      "learning_rate": 5e-05,
      "loss": 0.4487,
      "step": 304
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.42028915882110596,
      "learning_rate": 5e-05,
      "loss": 0.4287,
      "step": 312
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4493330419063568,
      "learning_rate": 5e-05,
      "loss": 0.4202,
      "step": 320
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.39179810881614685,
      "learning_rate": 5e-05,
      "loss": 0.3949,
      "step": 328
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4946478307247162,
      "learning_rate": 5e-05,
      "loss": 0.4229,
      "step": 336
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4921341836452484,
      "learning_rate": 5e-05,
      "loss": 0.4321,
      "step": 344
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.47139596939086914,
      "learning_rate": 5e-05,
      "loss": 0.415,
      "step": 352
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5145672559738159,
      "learning_rate": 5e-05,
      "loss": 0.4042,
      "step": 360
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.48216742277145386,
      "learning_rate": 5e-05,
      "loss": 0.461,
      "step": 368
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.41667380928993225,
      "learning_rate": 5e-05,
      "loss": 0.4255,
      "step": 376
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6124529838562012,
      "learning_rate": 5e-05,
      "loss": 0.4047,
      "step": 384
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.47695767879486084,
      "learning_rate": 5e-05,
      "loss": 0.421,
      "step": 392
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4411948323249817,
      "learning_rate": 5e-05,
      "loss": 0.448,
      "step": 400
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4248618483543396,
      "learning_rate": 5e-05,
      "loss": 0.4159,
      "step": 408
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4173220992088318,
      "learning_rate": 5e-05,
      "loss": 0.4202,
      "step": 416
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5304524302482605,
      "learning_rate": 5e-05,
      "loss": 0.4166,
      "step": 424
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4801962077617645,
      "learning_rate": 5e-05,
      "loss": 0.4064,
      "step": 432
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.44316813349723816,
      "learning_rate": 5e-05,
      "loss": 0.4215,
      "step": 440
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4866090714931488,
      "learning_rate": 5e-05,
      "loss": 0.4199,
      "step": 448
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5606065988540649,
      "learning_rate": 5e-05,
      "loss": 0.411,
      "step": 456
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4673297703266144,
      "learning_rate": 5e-05,
      "loss": 0.4153,
      "step": 464
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.45093387365341187,
      "learning_rate": 5e-05,
      "loss": 0.4095,
      "step": 472
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6274799108505249,
      "learning_rate": 5e-05,
      "loss": 0.4073,
      "step": 480
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5730473399162292,
      "learning_rate": 5e-05,
      "loss": 0.4482,
      "step": 488
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5826826095581055,
      "learning_rate": 5e-05,
      "loss": 0.4058,
      "step": 496
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5925338864326477,
      "learning_rate": 5e-05,
      "loss": 0.4375,
      "step": 504
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4882834851741791,
      "learning_rate": 5e-05,
      "loss": 0.4041,
      "step": 512
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.509181797504425,
      "learning_rate": 5e-05,
      "loss": 0.3925,
      "step": 520
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5000987648963928,
      "learning_rate": 5e-05,
      "loss": 0.445,
      "step": 528
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4371197819709778,
      "learning_rate": 5e-05,
      "loss": 0.406,
      "step": 536
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7119228839874268,
      "learning_rate": 5e-05,
      "loss": 0.4146,
      "step": 544
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5746567845344543,
      "learning_rate": 5e-05,
      "loss": 0.4258,
      "step": 552
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5083961486816406,
      "learning_rate": 5e-05,
      "loss": 0.4091,
      "step": 560
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5534496903419495,
      "learning_rate": 5e-05,
      "loss": 0.4342,
      "step": 568
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5308454036712646,
      "learning_rate": 5e-05,
      "loss": 0.4427,
      "step": 576
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.465870201587677,
      "learning_rate": 5e-05,
      "loss": 0.3777,
      "step": 584
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5409905314445496,
      "learning_rate": 5e-05,
      "loss": 0.3767,
      "step": 592
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4379894733428955,
      "learning_rate": 5e-05,
      "loss": 0.4021,
      "step": 600
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.533363401889801,
      "learning_rate": 5e-05,
      "loss": 0.4289,
      "step": 608
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.653228223323822,
      "learning_rate": 5e-05,
      "loss": 0.3946,
      "step": 616
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5099853277206421,
      "learning_rate": 5e-05,
      "loss": 0.3935,
      "step": 624
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5417746901512146,
      "learning_rate": 5e-05,
      "loss": 0.4203,
      "step": 632
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.546052098274231,
      "learning_rate": 5e-05,
      "loss": 0.4252,
      "step": 640
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4992561638355255,
      "learning_rate": 5e-05,
      "loss": 0.4054,
      "step": 648
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5687839388847351,
      "learning_rate": 5e-05,
      "loss": 0.4011,
      "step": 656
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.47953471541404724,
      "learning_rate": 5e-05,
      "loss": 0.3801,
      "step": 664
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.531091034412384,
      "learning_rate": 5e-05,
      "loss": 0.4169,
      "step": 672
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5083421468734741,
      "learning_rate": 5e-05,
      "loss": 0.4011,
      "step": 680
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.471312552690506,
      "learning_rate": 5e-05,
      "loss": 0.4045,
      "step": 688
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7170818448066711,
      "learning_rate": 5e-05,
      "loss": 0.4041,
      "step": 696
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5586820840835571,
      "learning_rate": 5e-05,
      "loss": 0.3968,
      "step": 704
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5666413903236389,
      "learning_rate": 5e-05,
      "loss": 0.4442,
      "step": 712
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5205560326576233,
      "learning_rate": 5e-05,
      "loss": 0.4097,
      "step": 720
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5761955976486206,
      "learning_rate": 5e-05,
      "loss": 0.394,
      "step": 728
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6032946109771729,
      "learning_rate": 5e-05,
      "loss": 0.3977,
      "step": 736
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5904003977775574,
      "learning_rate": 5e-05,
      "loss": 0.3967,
      "step": 744
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6065666675567627,
      "learning_rate": 5e-05,
      "loss": 0.4355,
      "step": 752
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6280517578125,
      "learning_rate": 5e-05,
      "loss": 0.3915,
      "step": 760
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5013232231140137,
      "learning_rate": 5e-05,
      "loss": 0.4053,
      "step": 768
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6173021793365479,
      "learning_rate": 5e-05,
      "loss": 0.404,
      "step": 776
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5329601168632507,
      "learning_rate": 5e-05,
      "loss": 0.4173,
      "step": 784
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6704656481742859,
      "learning_rate": 5e-05,
      "loss": 0.3774,
      "step": 792
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5940672755241394,
      "learning_rate": 5e-05,
      "loss": 0.4354,
      "step": 800
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4520357847213745,
      "learning_rate": 5e-05,
      "loss": 0.4282,
      "step": 808
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5604348182678223,
      "learning_rate": 5e-05,
      "loss": 0.3937,
      "step": 816
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6334150433540344,
      "learning_rate": 5e-05,
      "loss": 0.3874,
      "step": 824
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6019077897071838,
      "learning_rate": 5e-05,
      "loss": 0.4112,
      "step": 832
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4843190312385559,
      "learning_rate": 5e-05,
      "loss": 0.3934,
      "step": 840
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6495702862739563,
      "learning_rate": 5e-05,
      "loss": 0.4054,
      "step": 848
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.47830939292907715,
      "learning_rate": 5e-05,
      "loss": 0.45,
      "step": 856
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5367005467414856,
      "learning_rate": 5e-05,
      "loss": 0.3917,
      "step": 864
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5625686645507812,
      "learning_rate": 5e-05,
      "loss": 0.3982,
      "step": 872
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5134758949279785,
      "learning_rate": 5e-05,
      "loss": 0.4135,
      "step": 880
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5079184770584106,
      "learning_rate": 5e-05,
      "loss": 0.3742,
      "step": 888
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5753551721572876,
      "learning_rate": 5e-05,
      "loss": 0.4322,
      "step": 896
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5508925914764404,
      "learning_rate": 5e-05,
      "loss": 0.3826,
      "step": 904
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4682897925376892,
      "learning_rate": 5e-05,
      "loss": 0.4115,
      "step": 912
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4519505202770233,
      "learning_rate": 5e-05,
      "loss": 0.4027,
      "step": 920
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5191996097564697,
      "learning_rate": 5e-05,
      "loss": 0.3969,
      "step": 928
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5402015447616577,
      "learning_rate": 5e-05,
      "loss": 0.3829,
      "step": 936
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6117361783981323,
      "learning_rate": 5e-05,
      "loss": 0.401,
      "step": 944
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5983314514160156,
      "learning_rate": 5e-05,
      "loss": 0.3789,
      "step": 952
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5873628258705139,
      "learning_rate": 5e-05,
      "loss": 0.4113,
      "step": 960
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5010546445846558,
      "learning_rate": 5e-05,
      "loss": 0.407,
      "step": 968
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5085048079490662,
      "learning_rate": 5e-05,
      "loss": 0.4267,
      "step": 976
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7057944536209106,
      "learning_rate": 5e-05,
      "loss": 0.3814,
      "step": 984
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5603216290473938,
      "learning_rate": 5e-05,
      "loss": 0.3709,
      "step": 992
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5397158265113831,
      "learning_rate": 5e-05,
      "loss": 0.3918,
      "step": 1000
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.4278487265110016,
      "learning_rate": 5e-05,
      "loss": 0.3857,
      "step": 1008
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7391152381896973,
      "learning_rate": 5e-05,
      "loss": 0.4134,
      "step": 1016
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5431184768676758,
      "learning_rate": 5e-05,
      "loss": 0.3938,
      "step": 1024
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6744566559791565,
      "learning_rate": 5e-05,
      "loss": 0.3984,
      "step": 1032
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5427542328834534,
      "learning_rate": 5e-05,
      "loss": 0.403,
      "step": 1040
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5901840329170227,
      "learning_rate": 5e-05,
      "loss": 0.4128,
      "step": 1048
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5814626216888428,
      "learning_rate": 5e-05,
      "loss": 0.373,
      "step": 1056
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6415109038352966,
      "learning_rate": 5e-05,
      "loss": 0.3656,
      "step": 1064
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6378155946731567,
      "learning_rate": 5e-05,
      "loss": 0.3815,
      "step": 1072
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5991031527519226,
      "learning_rate": 5e-05,
      "loss": 0.4249,
      "step": 1080
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.500542402267456,
      "learning_rate": 5e-05,
      "loss": 0.3872,
      "step": 1088
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5452626347541809,
      "learning_rate": 5e-05,
      "loss": 0.3929,
      "step": 1096
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6464059948921204,
      "learning_rate": 5e-05,
      "loss": 0.4068,
      "step": 1104
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.46498554944992065,
      "learning_rate": 5e-05,
      "loss": 0.3945,
      "step": 1112
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5821170210838318,
      "learning_rate": 5e-05,
      "loss": 0.3957,
      "step": 1120
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5749747157096863,
      "learning_rate": 5e-05,
      "loss": 0.3919,
      "step": 1128
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5607484579086304,
      "learning_rate": 5e-05,
      "loss": 0.3849,
      "step": 1136
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6181458234786987,
      "learning_rate": 5e-05,
      "loss": 0.3776,
      "step": 1144
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5613293051719666,
      "learning_rate": 5e-05,
      "loss": 0.4177,
      "step": 1152
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5554724931716919,
      "learning_rate": 5e-05,
      "loss": 0.4142,
      "step": 1160
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4915931820869446,
      "learning_rate": 5e-05,
      "loss": 0.3529,
      "step": 1168
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4778289496898651,
      "learning_rate": 5e-05,
      "loss": 0.3828,
      "step": 1176
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5697522163391113,
      "learning_rate": 5e-05,
      "loss": 0.3815,
      "step": 1184
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5608448386192322,
      "learning_rate": 5e-05,
      "loss": 0.41,
      "step": 1192
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.465880423784256,
      "learning_rate": 5e-05,
      "loss": 0.3686,
      "step": 1200
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.6057308316230774,
      "learning_rate": 5e-05,
      "loss": 0.4245,
      "step": 1208
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5478179454803467,
      "learning_rate": 5e-05,
      "loss": 0.4123,
      "step": 1216
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5199862122535706,
      "learning_rate": 5e-05,
      "loss": 0.3713,
      "step": 1224
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5230967402458191,
      "learning_rate": 5e-05,
      "loss": 0.406,
      "step": 1232
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5693303942680359,
      "learning_rate": 5e-05,
      "loss": 0.412,
      "step": 1240
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5122774839401245,
      "learning_rate": 5e-05,
      "loss": 0.4241,
      "step": 1248
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5852788090705872,
      "learning_rate": 5e-05,
      "loss": 0.4008,
      "step": 1256
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6500278115272522,
      "learning_rate": 5e-05,
      "loss": 0.3766,
      "step": 1264
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.527764618396759,
      "learning_rate": 5e-05,
      "loss": 0.3961,
      "step": 1272
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6855109333992004,
      "learning_rate": 5e-05,
      "loss": 0.3699,
      "step": 1280
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5719074606895447,
      "learning_rate": 5e-05,
      "loss": 0.4109,
      "step": 1288
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5986074209213257,
      "learning_rate": 5e-05,
      "loss": 0.3924,
      "step": 1296
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.660051703453064,
      "learning_rate": 5e-05,
      "loss": 0.4011,
      "step": 1304
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7998953461647034,
      "learning_rate": 5e-05,
      "loss": 0.4005,
      "step": 1312
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5576145052909851,
      "learning_rate": 5e-05,
      "loss": 0.3697,
      "step": 1320
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5149469971656799,
      "learning_rate": 5e-05,
      "loss": 0.4191,
      "step": 1328
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5616046190261841,
      "learning_rate": 5e-05,
      "loss": 0.3754,
      "step": 1336
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5885199308395386,
      "learning_rate": 5e-05,
      "loss": 0.3858,
      "step": 1344
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5487523078918457,
      "learning_rate": 5e-05,
      "loss": 0.4028,
      "step": 1352
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.516200602054596,
      "learning_rate": 5e-05,
      "loss": 0.3811,
      "step": 1360
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5711460113525391,
      "learning_rate": 5e-05,
      "loss": 0.3986,
      "step": 1368
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5493947267532349,
      "learning_rate": 5e-05,
      "loss": 0.387,
      "step": 1376
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5594437718391418,
      "learning_rate": 5e-05,
      "loss": 0.3699,
      "step": 1384
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5981267690658569,
      "learning_rate": 5e-05,
      "loss": 0.4467,
      "step": 1392
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7665478587150574,
      "learning_rate": 5e-05,
      "loss": 0.3939,
      "step": 1400
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5214836597442627,
      "learning_rate": 5e-05,
      "loss": 0.3752,
      "step": 1408
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7257180213928223,
      "learning_rate": 5e-05,
      "loss": 0.4123,
      "step": 1416
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5002092123031616,
      "learning_rate": 5e-05,
      "loss": 0.3964,
      "step": 1424
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6611246466636658,
      "learning_rate": 5e-05,
      "loss": 0.3998,
      "step": 1432
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.548430860042572,
      "learning_rate": 5e-05,
      "loss": 0.4037,
      "step": 1440
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5451266169548035,
      "learning_rate": 5e-05,
      "loss": 0.3831,
      "step": 1448
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5614047646522522,
      "learning_rate": 5e-05,
      "loss": 0.3838,
      "step": 1456
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5117180943489075,
      "learning_rate": 5e-05,
      "loss": 0.3676,
      "step": 1464
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6426647901535034,
      "learning_rate": 5e-05,
      "loss": 0.404,
      "step": 1472
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5904093384742737,
      "learning_rate": 5e-05,
      "loss": 0.4427,
      "step": 1480
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5427354574203491,
      "learning_rate": 5e-05,
      "loss": 0.3658,
      "step": 1488
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6426519751548767,
      "learning_rate": 5e-05,
      "loss": 0.3764,
      "step": 1496
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5430707335472107,
      "learning_rate": 5e-05,
      "loss": 0.4005,
      "step": 1504
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5247192978858948,
      "learning_rate": 5e-05,
      "loss": 0.4095,
      "step": 1512
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5719732642173767,
      "learning_rate": 5e-05,
      "loss": 0.4022,
      "step": 1520
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.527255654335022,
      "learning_rate": 5e-05,
      "loss": 0.3685,
      "step": 1528
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5916329622268677,
      "learning_rate": 5e-05,
      "loss": 0.3853,
      "step": 1536
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5653153657913208,
      "learning_rate": 5e-05,
      "loss": 0.3994,
      "step": 1544
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6286762952804565,
      "learning_rate": 5e-05,
      "loss": 0.3881,
      "step": 1552
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5679059624671936,
      "learning_rate": 5e-05,
      "loss": 0.3882,
      "step": 1560
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6501833200454712,
      "learning_rate": 5e-05,
      "loss": 0.3685,
      "step": 1568
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5935968160629272,
      "learning_rate": 5e-05,
      "loss": 0.3845,
      "step": 1576
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6241245865821838,
      "learning_rate": 5e-05,
      "loss": 0.3934,
      "step": 1584
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5434229373931885,
      "learning_rate": 5e-05,
      "loss": 0.3778,
      "step": 1592
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5396613478660583,
      "learning_rate": 5e-05,
      "loss": 0.407,
      "step": 1600
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.556045413017273,
      "learning_rate": 5e-05,
      "loss": 0.3577,
      "step": 1608
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6386162042617798,
      "learning_rate": 5e-05,
      "loss": 0.3853,
      "step": 1616
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5276755094528198,
      "learning_rate": 5e-05,
      "loss": 0.4138,
      "step": 1624
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5727963447570801,
      "learning_rate": 5e-05,
      "loss": 0.3582,
      "step": 1632
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6436756253242493,
      "learning_rate": 5e-05,
      "loss": 0.4005,
      "step": 1640
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6801229119300842,
      "learning_rate": 5e-05,
      "loss": 0.4101,
      "step": 1648
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5246322154998779,
      "learning_rate": 5e-05,
      "loss": 0.3915,
      "step": 1656
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6270157098770142,
      "learning_rate": 5e-05,
      "loss": 0.392,
      "step": 1664
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5341548323631287,
      "learning_rate": 5e-05,
      "loss": 0.3599,
      "step": 1672
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6022641658782959,
      "learning_rate": 5e-05,
      "loss": 0.3734,
      "step": 1680
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6603118181228638,
      "learning_rate": 5e-05,
      "loss": 0.3933,
      "step": 1688
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7052502036094666,
      "learning_rate": 5e-05,
      "loss": 0.3399,
      "step": 1696
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.4983758330345154,
      "learning_rate": 5e-05,
      "loss": 0.3948,
      "step": 1704
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7602158188819885,
      "learning_rate": 5e-05,
      "loss": 0.3697,
      "step": 1712
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6058089733123779,
      "learning_rate": 5e-05,
      "loss": 0.3992,
      "step": 1720
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5349518656730652,
      "learning_rate": 5e-05,
      "loss": 0.3849,
      "step": 1728
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5216469764709473,
      "learning_rate": 5e-05,
      "loss": 0.3608,
      "step": 1736
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6780779957771301,
      "learning_rate": 5e-05,
      "loss": 0.3909,
      "step": 1744
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5234096050262451,
      "learning_rate": 5e-05,
      "loss": 0.3504,
      "step": 1752
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5727269053459167,
      "learning_rate": 5e-05,
      "loss": 0.4119,
      "step": 1760
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5616229176521301,
      "learning_rate": 5e-05,
      "loss": 0.3788,
      "step": 1768
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6083842515945435,
      "learning_rate": 5e-05,
      "loss": 0.36,
      "step": 1776
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5594242215156555,
      "learning_rate": 5e-05,
      "loss": 0.3731,
      "step": 1784
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6609058976173401,
      "learning_rate": 5e-05,
      "loss": 0.3676,
      "step": 1792
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5656469464302063,
      "learning_rate": 5e-05,
      "loss": 0.3552,
      "step": 1800
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5179153084754944,
      "learning_rate": 5e-05,
      "loss": 0.3885,
      "step": 1808
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.600010097026825,
      "learning_rate": 5e-05,
      "loss": 0.3761,
      "step": 1816
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6119586229324341,
      "learning_rate": 5e-05,
      "loss": 0.3742,
      "step": 1824
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.549519956111908,
      "learning_rate": 5e-05,
      "loss": 0.3766,
      "step": 1832
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5820218324661255,
      "learning_rate": 5e-05,
      "loss": 0.3711,
      "step": 1840
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.600985050201416,
      "learning_rate": 5e-05,
      "loss": 0.3925,
      "step": 1848
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6206485629081726,
      "learning_rate": 5e-05,
      "loss": 0.4179,
      "step": 1856
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6917864680290222,
      "learning_rate": 5e-05,
      "loss": 0.4125,
      "step": 1864
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7255344986915588,
      "learning_rate": 5e-05,
      "loss": 0.4098,
      "step": 1872
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5712417364120483,
      "learning_rate": 5e-05,
      "loss": 0.4,
      "step": 1880
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.567142903804779,
      "learning_rate": 5e-05,
      "loss": 0.3629,
      "step": 1888
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5125579237937927,
      "learning_rate": 5e-05,
      "loss": 0.4091,
      "step": 1896
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5126217603683472,
      "learning_rate": 5e-05,
      "loss": 0.3672,
      "step": 1904
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5565463900566101,
      "learning_rate": 5e-05,
      "loss": 0.3816,
      "step": 1912
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6486559510231018,
      "learning_rate": 5e-05,
      "loss": 0.3946,
      "step": 1920
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6468684673309326,
      "learning_rate": 5e-05,
      "loss": 0.3588,
      "step": 1928
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5388001203536987,
      "learning_rate": 5e-05,
      "loss": 0.3766,
      "step": 1936
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5922123193740845,
      "learning_rate": 5e-05,
      "loss": 0.3906,
      "step": 1944
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4926656484603882,
      "learning_rate": 5e-05,
      "loss": 0.3669,
      "step": 1952
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5758693218231201,
      "learning_rate": 5e-05,
      "loss": 0.3798,
      "step": 1960
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7154409289360046,
      "learning_rate": 5e-05,
      "loss": 0.3943,
      "step": 1968
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4877222776412964,
      "learning_rate": 5e-05,
      "loss": 0.3733,
      "step": 1976
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6126779913902283,
      "learning_rate": 5e-05,
      "loss": 0.3736,
      "step": 1984
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5798994898796082,
      "learning_rate": 5e-05,
      "loss": 0.389,
      "step": 1992
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5974281430244446,
      "learning_rate": 5e-05,
      "loss": 0.3974,
      "step": 2000
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.758792519569397,
      "learning_rate": 5e-05,
      "loss": 0.3763,
      "step": 2008
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6795257925987244,
      "learning_rate": 5e-05,
      "loss": 0.3587,
      "step": 2016
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5487764477729797,
      "learning_rate": 5e-05,
      "loss": 0.3874,
      "step": 2024
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.736642599105835,
      "learning_rate": 5e-05,
      "loss": 0.3777,
      "step": 2032
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5303991436958313,
      "learning_rate": 5e-05,
      "loss": 0.338,
      "step": 2040
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6177852749824524,
      "learning_rate": 5e-05,
      "loss": 0.3695,
      "step": 2048
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5618902444839478,
      "learning_rate": 5e-05,
      "loss": 0.3768,
      "step": 2056
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7104151844978333,
      "learning_rate": 5e-05,
      "loss": 0.3965,
      "step": 2064
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5704423189163208,
      "learning_rate": 5e-05,
      "loss": 0.3835,
      "step": 2072
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.529854953289032,
      "learning_rate": 5e-05,
      "loss": 0.3546,
      "step": 2080
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5998002290725708,
      "learning_rate": 5e-05,
      "loss": 0.3785,
      "step": 2088
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.479072242975235,
      "learning_rate": 5e-05,
      "loss": 0.3738,
      "step": 2096
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5688881874084473,
      "learning_rate": 5e-05,
      "loss": 0.3813,
      "step": 2104
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.621194064617157,
      "learning_rate": 5e-05,
      "loss": 0.3756,
      "step": 2112
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5653874278068542,
      "learning_rate": 5e-05,
      "loss": 0.383,
      "step": 2120
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5413981676101685,
      "learning_rate": 5e-05,
      "loss": 0.3862,
      "step": 2128
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5866512060165405,
      "learning_rate": 5e-05,
      "loss": 0.4032,
      "step": 2136
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5199511647224426,
      "learning_rate": 5e-05,
      "loss": 0.3738,
      "step": 2144
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5875186920166016,
      "learning_rate": 5e-05,
      "loss": 0.4003,
      "step": 2152
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5867213606834412,
      "learning_rate": 5e-05,
      "loss": 0.3788,
      "step": 2160
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5304619669914246,
      "learning_rate": 5e-05,
      "loss": 0.3573,
      "step": 2168
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6420231461524963,
      "learning_rate": 5e-05,
      "loss": 0.3599,
      "step": 2176
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5786098837852478,
      "learning_rate": 5e-05,
      "loss": 0.4215,
      "step": 2184
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5137288570404053,
      "learning_rate": 5e-05,
      "loss": 0.3647,
      "step": 2192
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6985302567481995,
      "learning_rate": 5e-05,
      "loss": 0.383,
      "step": 2200
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.6880848407745361,
      "learning_rate": 5e-05,
      "loss": 0.3602,
      "step": 2208
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5581952333450317,
      "learning_rate": 5e-05,
      "loss": 0.3607,
      "step": 2216
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.649761438369751,
      "learning_rate": 5e-05,
      "loss": 0.3729,
      "step": 2224
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5252882242202759,
      "learning_rate": 5e-05,
      "loss": 0.3621,
      "step": 2232
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5796079635620117,
      "learning_rate": 5e-05,
      "loss": 0.3834,
      "step": 2240
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5609112977981567,
      "learning_rate": 5e-05,
      "loss": 0.3884,
      "step": 2248
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4302780330181122,
      "learning_rate": 5e-05,
      "loss": 0.3488,
      "step": 2256
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6766378879547119,
      "learning_rate": 5e-05,
      "loss": 0.3585,
      "step": 2264
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6534774303436279,
      "learning_rate": 5e-05,
      "loss": 0.3734,
      "step": 2272
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6187124848365784,
      "learning_rate": 5e-05,
      "loss": 0.3896,
      "step": 2280
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6015236973762512,
      "learning_rate": 5e-05,
      "loss": 0.3819,
      "step": 2288
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6376507878303528,
      "learning_rate": 5e-05,
      "loss": 0.4118,
      "step": 2296
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6800397634506226,
      "learning_rate": 5e-05,
      "loss": 0.4015,
      "step": 2304
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6130414009094238,
      "learning_rate": 5e-05,
      "loss": 0.3862,
      "step": 2312
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4870285093784332,
      "learning_rate": 5e-05,
      "loss": 0.3842,
      "step": 2320
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5562127828598022,
      "learning_rate": 5e-05,
      "loss": 0.3498,
      "step": 2328
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6637508273124695,
      "learning_rate": 5e-05,
      "loss": 0.3694,
      "step": 2336
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5816512703895569,
      "learning_rate": 5e-05,
      "loss": 0.3869,
      "step": 2344
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6156788468360901,
      "learning_rate": 5e-05,
      "loss": 0.3792,
      "step": 2352
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5873692631721497,
      "learning_rate": 5e-05,
      "loss": 0.404,
      "step": 2360
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5839155912399292,
      "learning_rate": 5e-05,
      "loss": 0.3663,
      "step": 2368
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5056508183479309,
      "learning_rate": 5e-05,
      "loss": 0.3848,
      "step": 2376
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5761997103691101,
      "learning_rate": 5e-05,
      "loss": 0.3818,
      "step": 2384
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5598558187484741,
      "learning_rate": 5e-05,
      "loss": 0.3607,
      "step": 2392
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5906513929367065,
      "learning_rate": 5e-05,
      "loss": 0.3891,
      "step": 2400
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6031843423843384,
      "learning_rate": 5e-05,
      "loss": 0.3996,
      "step": 2408
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6188597679138184,
      "learning_rate": 5e-05,
      "loss": 0.3774,
      "step": 2416
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5733513236045837,
      "learning_rate": 5e-05,
      "loss": 0.4015,
      "step": 2424
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6181842088699341,
      "learning_rate": 5e-05,
      "loss": 0.3766,
      "step": 2432
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6390984654426575,
      "learning_rate": 5e-05,
      "loss": 0.3928,
      "step": 2440
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4844450354576111,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 2448
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.622024655342102,
      "learning_rate": 5e-05,
      "loss": 0.3913,
      "step": 2456
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5153866410255432,
      "learning_rate": 5e-05,
      "loss": 0.3943,
      "step": 2464
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5795977115631104,
      "learning_rate": 5e-05,
      "loss": 0.3998,
      "step": 2472
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.645358681678772,
      "learning_rate": 5e-05,
      "loss": 0.37,
      "step": 2480
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5190269947052002,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 2488
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5772053599357605,
      "learning_rate": 5e-05,
      "loss": 0.3673,
      "step": 2496
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6557765603065491,
      "learning_rate": 5e-05,
      "loss": 0.3614,
      "step": 2504
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6292911171913147,
      "learning_rate": 5e-05,
      "loss": 0.388,
      "step": 2512
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5035672783851624,
      "learning_rate": 5e-05,
      "loss": 0.3735,
      "step": 2520
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.520801842212677,
      "learning_rate": 5e-05,
      "loss": 0.3697,
      "step": 2528
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5682325959205627,
      "learning_rate": 5e-05,
      "loss": 0.3851,
      "step": 2536
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6113422513008118,
      "learning_rate": 5e-05,
      "loss": 0.3314,
      "step": 2544
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5739313960075378,
      "learning_rate": 5e-05,
      "loss": 0.3845,
      "step": 2552
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.637407124042511,
      "learning_rate": 5e-05,
      "loss": 0.3678,
      "step": 2560
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6562245488166809,
      "learning_rate": 5e-05,
      "loss": 0.4004,
      "step": 2568
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5265894532203674,
      "learning_rate": 5e-05,
      "loss": 0.3931,
      "step": 2576
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6341988444328308,
      "learning_rate": 5e-05,
      "loss": 0.3643,
      "step": 2584
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.591012179851532,
      "learning_rate": 5e-05,
      "loss": 0.3825,
      "step": 2592
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7030534148216248,
      "learning_rate": 5e-05,
      "loss": 0.3627,
      "step": 2600
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.620255172252655,
      "learning_rate": 5e-05,
      "loss": 0.3618,
      "step": 2608
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.459275484085083,
      "learning_rate": 5e-05,
      "loss": 0.3925,
      "step": 2616
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5745649933815002,
      "learning_rate": 5e-05,
      "loss": 0.3852,
      "step": 2624
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.59456866979599,
      "learning_rate": 5e-05,
      "loss": 0.3972,
      "step": 2632
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5437700748443604,
      "learning_rate": 5e-05,
      "loss": 0.3562,
      "step": 2640
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.784271240234375,
      "learning_rate": 5e-05,
      "loss": 0.3486,
      "step": 2648
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5255110263824463,
      "learning_rate": 5e-05,
      "loss": 0.3778,
      "step": 2656
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7270928621292114,
      "learning_rate": 5e-05,
      "loss": 0.3559,
      "step": 2664
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6065828204154968,
      "learning_rate": 5e-05,
      "loss": 0.4092,
      "step": 2672
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.512862503528595,
      "learning_rate": 5e-05,
      "loss": 0.3777,
      "step": 2680
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.595648467540741,
      "learning_rate": 5e-05,
      "loss": 0.3804,
      "step": 2688
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6055711507797241,
      "learning_rate": 5e-05,
      "loss": 0.3939,
      "step": 2696
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6517634987831116,
      "learning_rate": 5e-05,
      "loss": 0.3495,
      "step": 2704
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5845239162445068,
      "learning_rate": 5e-05,
      "loss": 0.3697,
      "step": 2712
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6512972712516785,
      "learning_rate": 5e-05,
      "loss": 0.3946,
      "step": 2720
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5918008089065552,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 2728
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5442565083503723,
      "learning_rate": 5e-05,
      "loss": 0.366,
      "step": 2736
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6275639533996582,
      "learning_rate": 5e-05,
      "loss": 0.3814,
      "step": 2744
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4831700026988983,
      "learning_rate": 5e-05,
      "loss": 0.3722,
      "step": 2752
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5250324010848999,
      "learning_rate": 5e-05,
      "loss": 0.3774,
      "step": 2760
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5956652760505676,
      "learning_rate": 5e-05,
      "loss": 0.3684,
      "step": 2768
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5964152812957764,
      "learning_rate": 5e-05,
      "loss": 0.3724,
      "step": 2776
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5483466982841492,
      "learning_rate": 5e-05,
      "loss": 0.3883,
      "step": 2784
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6872438192367554,
      "learning_rate": 5e-05,
      "loss": 0.3862,
      "step": 2792
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7109268307685852,
      "learning_rate": 5e-05,
      "loss": 0.3576,
      "step": 2800
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4904407858848572,
      "learning_rate": 5e-05,
      "loss": 0.3912,
      "step": 2808
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6339721083641052,
      "learning_rate": 5e-05,
      "loss": 0.373,
      "step": 2816
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.84218430519104,
      "learning_rate": 5e-05,
      "loss": 0.378,
      "step": 2824
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7349323034286499,
      "learning_rate": 5e-05,
      "loss": 0.3944,
      "step": 2832
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.605637788772583,
      "learning_rate": 5e-05,
      "loss": 0.3506,
      "step": 2840
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7720818519592285,
      "learning_rate": 5e-05,
      "loss": 0.3563,
      "step": 2848
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5383459329605103,
      "learning_rate": 5e-05,
      "loss": 0.3614,
      "step": 2856
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6028696298599243,
      "learning_rate": 5e-05,
      "loss": 0.3978,
      "step": 2864
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5193788409233093,
      "learning_rate": 5e-05,
      "loss": 0.3522,
      "step": 2872
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7402640581130981,
      "learning_rate": 5e-05,
      "loss": 0.3767,
      "step": 2880
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5021522641181946,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 2888
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6210490465164185,
      "learning_rate": 5e-05,
      "loss": 0.3803,
      "step": 2896
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6406670808792114,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 2904
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5688474178314209,
      "learning_rate": 5e-05,
      "loss": 0.3551,
      "step": 2912
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5783625245094299,
      "learning_rate": 5e-05,
      "loss": 0.3891,
      "step": 2920
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7755634784698486,
      "learning_rate": 5e-05,
      "loss": 0.3734,
      "step": 2928
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6137913465499878,
      "learning_rate": 5e-05,
      "loss": 0.3654,
      "step": 2936
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6216821074485779,
      "learning_rate": 5e-05,
      "loss": 0.3866,
      "step": 2944
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.542413592338562,
      "learning_rate": 5e-05,
      "loss": 0.3565,
      "step": 2952
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6382929682731628,
      "learning_rate": 5e-05,
      "loss": 0.3712,
      "step": 2960
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6498731970787048,
      "learning_rate": 5e-05,
      "loss": 0.3497,
      "step": 2968
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5086306929588318,
      "learning_rate": 5e-05,
      "loss": 0.3594,
      "step": 2976
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5820601582527161,
      "learning_rate": 5e-05,
      "loss": 0.3766,
      "step": 2984
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6069422364234924,
      "learning_rate": 5e-05,
      "loss": 0.3523,
      "step": 2992
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.49583250284194946,
      "learning_rate": 5e-05,
      "loss": 0.3878,
      "step": 3000
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6406127214431763,
      "learning_rate": 5e-05,
      "loss": 0.3916,
      "step": 3008
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5835070013999939,
      "learning_rate": 5e-05,
      "loss": 0.3667,
      "step": 3016
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5110674500465393,
      "learning_rate": 5e-05,
      "loss": 0.3829,
      "step": 3024
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6187220811843872,
      "learning_rate": 5e-05,
      "loss": 0.3681,
      "step": 3032
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5111606121063232,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 3040
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.732969343662262,
      "learning_rate": 5e-05,
      "loss": 0.386,
      "step": 3048
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6955947875976562,
      "learning_rate": 5e-05,
      "loss": 0.3777,
      "step": 3056
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5437219738960266,
      "learning_rate": 5e-05,
      "loss": 0.3866,
      "step": 3064
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6390591859817505,
      "learning_rate": 5e-05,
      "loss": 0.3527,
      "step": 3072
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6205664277076721,
      "learning_rate": 5e-05,
      "loss": 0.3605,
      "step": 3080
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.544156014919281,
      "learning_rate": 5e-05,
      "loss": 0.4132,
      "step": 3088
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5916967988014221,
      "learning_rate": 5e-05,
      "loss": 0.3899,
      "step": 3096
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5450756549835205,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 3104
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6259794235229492,
      "learning_rate": 5e-05,
      "loss": 0.3538,
      "step": 3112
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6717710494995117,
      "learning_rate": 5e-05,
      "loss": 0.3502,
      "step": 3120
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5862123966217041,
      "learning_rate": 5e-05,
      "loss": 0.3893,
      "step": 3128
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5562939047813416,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 3136
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5428516864776611,
      "learning_rate": 5e-05,
      "loss": 0.3682,
      "step": 3144
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6708892583847046,
      "learning_rate": 5e-05,
      "loss": 0.4094,
      "step": 3152
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5910276770591736,
      "learning_rate": 5e-05,
      "loss": 0.3658,
      "step": 3160
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.646064281463623,
      "learning_rate": 5e-05,
      "loss": 0.3606,
      "step": 3168
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6046662330627441,
      "learning_rate": 5e-05,
      "loss": 0.3716,
      "step": 3176
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6068945527076721,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 3184
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6746262907981873,
      "learning_rate": 5e-05,
      "loss": 0.3909,
      "step": 3192
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5978808999061584,
      "learning_rate": 5e-05,
      "loss": 0.3957,
      "step": 3200
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6191290616989136,
      "learning_rate": 5e-05,
      "loss": 0.373,
      "step": 3208
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.532682478427887,
      "learning_rate": 5e-05,
      "loss": 0.367,
      "step": 3216
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5923565030097961,
      "learning_rate": 5e-05,
      "loss": 0.3992,
      "step": 3224
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.537261962890625,
      "learning_rate": 5e-05,
      "loss": 0.3545,
      "step": 3232
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.587615966796875,
      "learning_rate": 5e-05,
      "loss": 0.3598,
      "step": 3240
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6204034090042114,
      "learning_rate": 5e-05,
      "loss": 0.3882,
      "step": 3248
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.48009026050567627,
      "learning_rate": 5e-05,
      "loss": 0.3886,
      "step": 3256
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5286311507225037,
      "learning_rate": 5e-05,
      "loss": 0.3795,
      "step": 3264
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.589332640171051,
      "learning_rate": 5e-05,
      "loss": 0.373,
      "step": 3272
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7380439043045044,
      "learning_rate": 5e-05,
      "loss": 0.3777,
      "step": 3280
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5601157546043396,
      "learning_rate": 5e-05,
      "loss": 0.3537,
      "step": 3288
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6216224431991577,
      "learning_rate": 5e-05,
      "loss": 0.377,
      "step": 3296
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5332857370376587,
      "learning_rate": 5e-05,
      "loss": 0.3561,
      "step": 3304
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.555673360824585,
      "learning_rate": 5e-05,
      "loss": 0.3399,
      "step": 3312
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5437247157096863,
      "learning_rate": 5e-05,
      "loss": 0.3924,
      "step": 3320
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5820500254631042,
      "learning_rate": 5e-05,
      "loss": 0.3768,
      "step": 3328
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7405074238777161,
      "learning_rate": 5e-05,
      "loss": 0.3716,
      "step": 3336
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5826177597045898,
      "learning_rate": 5e-05,
      "loss": 0.3726,
      "step": 3344
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5971702933311462,
      "learning_rate": 5e-05,
      "loss": 0.3613,
      "step": 3352
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5798519253730774,
      "learning_rate": 5e-05,
      "loss": 0.3916,
      "step": 3360
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6392762064933777,
      "learning_rate": 5e-05,
      "loss": 0.3582,
      "step": 3368
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6125460267066956,
      "learning_rate": 5e-05,
      "loss": 0.3769,
      "step": 3376
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7877257466316223,
      "learning_rate": 5e-05,
      "loss": 0.3859,
      "step": 3384
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6025648713111877,
      "learning_rate": 5e-05,
      "loss": 0.3647,
      "step": 3392
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6992126703262329,
      "learning_rate": 5e-05,
      "loss": 0.3482,
      "step": 3400
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6048790812492371,
      "learning_rate": 5e-05,
      "loss": 0.3567,
      "step": 3408
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6033861041069031,
      "learning_rate": 5e-05,
      "loss": 0.3728,
      "step": 3416
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.631150484085083,
      "learning_rate": 5e-05,
      "loss": 0.3762,
      "step": 3424
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5445570945739746,
      "learning_rate": 5e-05,
      "loss": 0.3628,
      "step": 3432
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5770473480224609,
      "learning_rate": 5e-05,
      "loss": 0.367,
      "step": 3440
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6046950817108154,
      "learning_rate": 5e-05,
      "loss": 0.3931,
      "step": 3448
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6474387645721436,
      "learning_rate": 5e-05,
      "loss": 0.3647,
      "step": 3456
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.592641294002533,
      "learning_rate": 5e-05,
      "loss": 0.3769,
      "step": 3464
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6064008474349976,
      "learning_rate": 5e-05,
      "loss": 0.371,
      "step": 3472
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6094073057174683,
      "learning_rate": 5e-05,
      "loss": 0.3716,
      "step": 3480
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.561212420463562,
      "learning_rate": 5e-05,
      "loss": 0.3783,
      "step": 3488
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6977812647819519,
      "learning_rate": 5e-05,
      "loss": 0.3832,
      "step": 3496
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.598319947719574,
      "learning_rate": 5e-05,
      "loss": 0.3622,
      "step": 3504
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6150346398353577,
      "learning_rate": 5e-05,
      "loss": 0.3598,
      "step": 3512
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.626431405544281,
      "learning_rate": 5e-05,
      "loss": 0.3816,
      "step": 3520
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5620126724243164,
      "learning_rate": 5e-05,
      "loss": 0.3764,
      "step": 3528
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5329760909080505,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 3536
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6248601675033569,
      "learning_rate": 5e-05,
      "loss": 0.3605,
      "step": 3544
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.617912232875824,
      "learning_rate": 5e-05,
      "loss": 0.3745,
      "step": 3552
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4754418432712555,
      "learning_rate": 5e-05,
      "loss": 0.3657,
      "step": 3560
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5911908745765686,
      "learning_rate": 5e-05,
      "loss": 0.3617,
      "step": 3568
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5107258558273315,
      "learning_rate": 5e-05,
      "loss": 0.3471,
      "step": 3576
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6004649996757507,
      "learning_rate": 5e-05,
      "loss": 0.3906,
      "step": 3584
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5187152028083801,
      "learning_rate": 5e-05,
      "loss": 0.3615,
      "step": 3592
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5438922643661499,
      "learning_rate": 5e-05,
      "loss": 0.3348,
      "step": 3600
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5268060564994812,
      "learning_rate": 5e-05,
      "loss": 0.3672,
      "step": 3608
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6725350618362427,
      "learning_rate": 5e-05,
      "loss": 0.3594,
      "step": 3616
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6217457056045532,
      "learning_rate": 5e-05,
      "loss": 0.3848,
      "step": 3624
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8438531756401062,
      "learning_rate": 5e-05,
      "loss": 0.35,
      "step": 3632
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6210736632347107,
      "learning_rate": 5e-05,
      "loss": 0.363,
      "step": 3640
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.624305009841919,
      "learning_rate": 5e-05,
      "loss": 0.3835,
      "step": 3648
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.526938259601593,
      "learning_rate": 5e-05,
      "loss": 0.3905,
      "step": 3656
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6067880392074585,
      "learning_rate": 5e-05,
      "loss": 0.3389,
      "step": 3664
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7149994373321533,
      "learning_rate": 5e-05,
      "loss": 0.353,
      "step": 3672
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7504158616065979,
      "learning_rate": 5e-05,
      "loss": 0.3618,
      "step": 3680
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6988388299942017,
      "learning_rate": 5e-05,
      "loss": 0.4161,
      "step": 3688
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5817334055900574,
      "learning_rate": 5e-05,
      "loss": 0.3659,
      "step": 3696
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6734567880630493,
      "learning_rate": 5e-05,
      "loss": 0.4098,
      "step": 3704
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5594524145126343,
      "learning_rate": 5e-05,
      "loss": 0.3587,
      "step": 3712
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6046500205993652,
      "learning_rate": 5e-05,
      "loss": 0.3678,
      "step": 3720
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6625332832336426,
      "learning_rate": 5e-05,
      "loss": 0.3879,
      "step": 3728
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7345660924911499,
      "learning_rate": 5e-05,
      "loss": 0.4103,
      "step": 3736
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5997243523597717,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 3744
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5704938769340515,
      "learning_rate": 5e-05,
      "loss": 0.3965,
      "step": 3752
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5932504534721375,
      "learning_rate": 5e-05,
      "loss": 0.3664,
      "step": 3760
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7440085411071777,
      "learning_rate": 5e-05,
      "loss": 0.3744,
      "step": 3768
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7819765210151672,
      "learning_rate": 5e-05,
      "loss": 0.3532,
      "step": 3776
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5796692371368408,
      "learning_rate": 5e-05,
      "loss": 0.3326,
      "step": 3784
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6262866854667664,
      "learning_rate": 5e-05,
      "loss": 0.3589,
      "step": 3792
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.578029215335846,
      "learning_rate": 5e-05,
      "loss": 0.3479,
      "step": 3800
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6334495544433594,
      "learning_rate": 5e-05,
      "loss": 0.3627,
      "step": 3808
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6797861456871033,
      "learning_rate": 5e-05,
      "loss": 0.3489,
      "step": 3816
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7752485275268555,
      "learning_rate": 5e-05,
      "loss": 0.3634,
      "step": 3824
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5845540165901184,
      "learning_rate": 5e-05,
      "loss": 0.378,
      "step": 3832
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5739538669586182,
      "learning_rate": 5e-05,
      "loss": 0.387,
      "step": 3840
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6501076817512512,
      "learning_rate": 5e-05,
      "loss": 0.3579,
      "step": 3848
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5585381984710693,
      "learning_rate": 5e-05,
      "loss": 0.375,
      "step": 3856
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.60853511095047,
      "learning_rate": 5e-05,
      "loss": 0.3673,
      "step": 3864
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5908211469650269,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 3872
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6255670785903931,
      "learning_rate": 5e-05,
      "loss": 0.3429,
      "step": 3880
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6694207787513733,
      "learning_rate": 5e-05,
      "loss": 0.3821,
      "step": 3888
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7013923525810242,
      "learning_rate": 5e-05,
      "loss": 0.3767,
      "step": 3896
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7502742409706116,
      "learning_rate": 5e-05,
      "loss": 0.3755,
      "step": 3904
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5641376972198486,
      "learning_rate": 5e-05,
      "loss": 0.3525,
      "step": 3912
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5676360130310059,
      "learning_rate": 5e-05,
      "loss": 0.3411,
      "step": 3920
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5674182176589966,
      "learning_rate": 5e-05,
      "loss": 0.3701,
      "step": 3928
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5222844481468201,
      "learning_rate": 5e-05,
      "loss": 0.3529,
      "step": 3936
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5447665452957153,
      "learning_rate": 5e-05,
      "loss": 0.3821,
      "step": 3944
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.612508237361908,
      "learning_rate": 5e-05,
      "loss": 0.3627,
      "step": 3952
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5350823402404785,
      "learning_rate": 5e-05,
      "loss": 0.379,
      "step": 3960
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.715728223323822,
      "learning_rate": 5e-05,
      "loss": 0.3516,
      "step": 3968
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5637520551681519,
      "learning_rate": 5e-05,
      "loss": 0.3631,
      "step": 3976
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7447178363800049,
      "learning_rate": 5e-05,
      "loss": 0.3651,
      "step": 3984
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5280184149742126,
      "learning_rate": 5e-05,
      "loss": 0.39,
      "step": 3992
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.496010422706604,
      "learning_rate": 5e-05,
      "loss": 0.3698,
      "step": 4000
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.681063711643219,
      "learning_rate": 5e-05,
      "loss": 0.3652,
      "step": 4008
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.8148801326751709,
      "learning_rate": 5e-05,
      "loss": 0.3685,
      "step": 4016
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5934609174728394,
      "learning_rate": 5e-05,
      "loss": 0.3898,
      "step": 4024
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5636022090911865,
      "learning_rate": 5e-05,
      "loss": 0.3459,
      "step": 4032
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6289224624633789,
      "learning_rate": 5e-05,
      "loss": 0.3883,
      "step": 4040
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5254249572753906,
      "learning_rate": 5e-05,
      "loss": 0.3497,
      "step": 4048
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5793301463127136,
      "learning_rate": 5e-05,
      "loss": 0.3298,
      "step": 4056
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6917692422866821,
      "learning_rate": 5e-05,
      "loss": 0.3751,
      "step": 4064
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5536271333694458,
      "learning_rate": 5e-05,
      "loss": 0.3689,
      "step": 4072
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6953570246696472,
      "learning_rate": 5e-05,
      "loss": 0.3621,
      "step": 4080
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6018871068954468,
      "learning_rate": 5e-05,
      "loss": 0.342,
      "step": 4088
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.569123387336731,
      "learning_rate": 5e-05,
      "loss": 0.3576,
      "step": 4096
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5977156162261963,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 4104
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5691630840301514,
      "learning_rate": 5e-05,
      "loss": 0.3696,
      "step": 4112
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5835095643997192,
      "learning_rate": 5e-05,
      "loss": 0.3835,
      "step": 4120
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5003004670143127,
      "learning_rate": 5e-05,
      "loss": 0.3373,
      "step": 4128
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6183885931968689,
      "learning_rate": 5e-05,
      "loss": 0.3867,
      "step": 4136
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6489753723144531,
      "learning_rate": 5e-05,
      "loss": 0.3833,
      "step": 4144
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6354680061340332,
      "learning_rate": 5e-05,
      "loss": 0.3714,
      "step": 4152
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.626227617263794,
      "learning_rate": 5e-05,
      "loss": 0.3518,
      "step": 4160
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6387676000595093,
      "learning_rate": 5e-05,
      "loss": 0.3463,
      "step": 4168
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5173450112342834,
      "learning_rate": 5e-05,
      "loss": 0.3716,
      "step": 4176
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5576667189598083,
      "learning_rate": 5e-05,
      "loss": 0.3822,
      "step": 4184
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6349327564239502,
      "learning_rate": 5e-05,
      "loss": 0.36,
      "step": 4192
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6602625846862793,
      "learning_rate": 5e-05,
      "loss": 0.3957,
      "step": 4200
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6087417006492615,
      "learning_rate": 5e-05,
      "loss": 0.3682,
      "step": 4208
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6355285048484802,
      "learning_rate": 5e-05,
      "loss": 0.3596,
      "step": 4216
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.700975775718689,
      "learning_rate": 5e-05,
      "loss": 0.37,
      "step": 4224
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6179533004760742,
      "learning_rate": 5e-05,
      "loss": 0.3912,
      "step": 4232
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5765446424484253,
      "learning_rate": 5e-05,
      "loss": 0.3599,
      "step": 4240
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5425381064414978,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 4248
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6093931198120117,
      "learning_rate": 5e-05,
      "loss": 0.3632,
      "step": 4256
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6451171040534973,
      "learning_rate": 5e-05,
      "loss": 0.3709,
      "step": 4264
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5856810212135315,
      "learning_rate": 5e-05,
      "loss": 0.3838,
      "step": 4272
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5591624975204468,
      "learning_rate": 5e-05,
      "loss": 0.3649,
      "step": 4280
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5765906572341919,
      "learning_rate": 5e-05,
      "loss": 0.3551,
      "step": 4288
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5996723175048828,
      "learning_rate": 5e-05,
      "loss": 0.3418,
      "step": 4296
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7033903002738953,
      "learning_rate": 5e-05,
      "loss": 0.3862,
      "step": 4304
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5477246642112732,
      "learning_rate": 5e-05,
      "loss": 0.3659,
      "step": 4312
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6740657091140747,
      "learning_rate": 5e-05,
      "loss": 0.3562,
      "step": 4320
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5353357791900635,
      "learning_rate": 5e-05,
      "loss": 0.3758,
      "step": 4328
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8465714454650879,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 4336
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.659356951713562,
      "learning_rate": 5e-05,
      "loss": 0.3726,
      "step": 4344
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6197179555892944,
      "learning_rate": 5e-05,
      "loss": 0.3824,
      "step": 4352
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5892958641052246,
      "learning_rate": 5e-05,
      "loss": 0.3469,
      "step": 4360
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6582675576210022,
      "learning_rate": 5e-05,
      "loss": 0.352,
      "step": 4368
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5388155579566956,
      "learning_rate": 5e-05,
      "loss": 0.3543,
      "step": 4376
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5954020023345947,
      "learning_rate": 5e-05,
      "loss": 0.3707,
      "step": 4384
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6944409012794495,
      "learning_rate": 5e-05,
      "loss": 0.3862,
      "step": 4392
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5826597809791565,
      "learning_rate": 5e-05,
      "loss": 0.3596,
      "step": 4400
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5372472405433655,
      "learning_rate": 5e-05,
      "loss": 0.3589,
      "step": 4408
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5769539475440979,
      "learning_rate": 5e-05,
      "loss": 0.374,
      "step": 4416
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5628166794776917,
      "learning_rate": 5e-05,
      "loss": 0.352,
      "step": 4424
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6481004357337952,
      "learning_rate": 5e-05,
      "loss": 0.3834,
      "step": 4432
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6103420257568359,
      "learning_rate": 5e-05,
      "loss": 0.3642,
      "step": 4440
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6502674221992493,
      "learning_rate": 5e-05,
      "loss": 0.3715,
      "step": 4448
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5401626825332642,
      "learning_rate": 5e-05,
      "loss": 0.3479,
      "step": 4456
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5532200336456299,
      "learning_rate": 5e-05,
      "loss": 0.3873,
      "step": 4464
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.49590885639190674,
      "learning_rate": 5e-05,
      "loss": 0.371,
      "step": 4472
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5856391787528992,
      "learning_rate": 5e-05,
      "loss": 0.348,
      "step": 4480
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5424610376358032,
      "learning_rate": 5e-05,
      "loss": 0.3608,
      "step": 4488
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7910908460617065,
      "learning_rate": 5e-05,
      "loss": 0.3623,
      "step": 4496
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5697240829467773,
      "learning_rate": 5e-05,
      "loss": 0.3711,
      "step": 4504
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6328216195106506,
      "learning_rate": 5e-05,
      "loss": 0.3613,
      "step": 4512
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6186020970344543,
      "learning_rate": 5e-05,
      "loss": 0.3568,
      "step": 4520
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.668321967124939,
      "learning_rate": 5e-05,
      "loss": 0.3615,
      "step": 4528
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6719413995742798,
      "learning_rate": 5e-05,
      "loss": 0.3809,
      "step": 4536
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5288121104240417,
      "learning_rate": 5e-05,
      "loss": 0.367,
      "step": 4544
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5939645767211914,
      "learning_rate": 5e-05,
      "loss": 0.359,
      "step": 4552
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7219897508621216,
      "learning_rate": 5e-05,
      "loss": 0.3493,
      "step": 4560
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5643470287322998,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 4568
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6158863306045532,
      "learning_rate": 5e-05,
      "loss": 0.3519,
      "step": 4576
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5422260761260986,
      "learning_rate": 5e-05,
      "loss": 0.3551,
      "step": 4584
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6258586049079895,
      "learning_rate": 5e-05,
      "loss": 0.3774,
      "step": 4592
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5193554162979126,
      "learning_rate": 5e-05,
      "loss": 0.3974,
      "step": 4600
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6053996682167053,
      "learning_rate": 5e-05,
      "loss": 0.3754,
      "step": 4608
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5593486428260803,
      "learning_rate": 5e-05,
      "loss": 0.3593,
      "step": 4616
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5403149127960205,
      "learning_rate": 5e-05,
      "loss": 0.3703,
      "step": 4624
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7462954521179199,
      "learning_rate": 5e-05,
      "loss": 0.3633,
      "step": 4632
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.593892514705658,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 4640
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.587394654750824,
      "learning_rate": 5e-05,
      "loss": 0.3481,
      "step": 4648
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6243960857391357,
      "learning_rate": 5e-05,
      "loss": 0.3451,
      "step": 4656
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5046678781509399,
      "learning_rate": 5e-05,
      "loss": 0.3494,
      "step": 4664
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5341074466705322,
      "learning_rate": 5e-05,
      "loss": 0.3659,
      "step": 4672
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6476245522499084,
      "learning_rate": 5e-05,
      "loss": 0.3591,
      "step": 4680
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.49033352732658386,
      "learning_rate": 5e-05,
      "loss": 0.3709,
      "step": 4688
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5814931392669678,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 4696
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5847153067588806,
      "learning_rate": 5e-05,
      "loss": 0.3692,
      "step": 4704
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.47053995728492737,
      "learning_rate": 5e-05,
      "loss": 0.3837,
      "step": 4712
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6946582794189453,
      "learning_rate": 5e-05,
      "loss": 0.3943,
      "step": 4720
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.594685435295105,
      "learning_rate": 5e-05,
      "loss": 0.3732,
      "step": 4728
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6791764497756958,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 4736
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6300022602081299,
      "learning_rate": 5e-05,
      "loss": 0.3281,
      "step": 4744
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6508093476295471,
      "learning_rate": 5e-05,
      "loss": 0.3598,
      "step": 4752
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5523666739463806,
      "learning_rate": 5e-05,
      "loss": 0.3603,
      "step": 4760
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6224042773246765,
      "learning_rate": 5e-05,
      "loss": 0.3785,
      "step": 4768
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8043243885040283,
      "learning_rate": 5e-05,
      "loss": 0.3524,
      "step": 4776
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6268855333328247,
      "learning_rate": 5e-05,
      "loss": 0.3531,
      "step": 4784
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.602414608001709,
      "learning_rate": 5e-05,
      "loss": 0.337,
      "step": 4792
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7838016748428345,
      "learning_rate": 5e-05,
      "loss": 0.3875,
      "step": 4800
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6895694136619568,
      "learning_rate": 5e-05,
      "loss": 0.3642,
      "step": 4808
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6339758634567261,
      "learning_rate": 5e-05,
      "loss": 0.4029,
      "step": 4816
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6325401663780212,
      "learning_rate": 5e-05,
      "loss": 0.3642,
      "step": 4824
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.60548335313797,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 4832
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6281307935714722,
      "learning_rate": 5e-05,
      "loss": 0.3467,
      "step": 4840
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5848056077957153,
      "learning_rate": 5e-05,
      "loss": 0.3481,
      "step": 4848
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6219514608383179,
      "learning_rate": 5e-05,
      "loss": 0.3651,
      "step": 4856
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6804084181785583,
      "learning_rate": 5e-05,
      "loss": 0.3402,
      "step": 4864
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5110087990760803,
      "learning_rate": 5e-05,
      "loss": 0.3557,
      "step": 4872
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5846076607704163,
      "learning_rate": 5e-05,
      "loss": 0.359,
      "step": 4880
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5556555986404419,
      "learning_rate": 5e-05,
      "loss": 0.3456,
      "step": 4888
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6334839463233948,
      "learning_rate": 5e-05,
      "loss": 0.353,
      "step": 4896
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5439375042915344,
      "learning_rate": 5e-05,
      "loss": 0.3674,
      "step": 4904
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.573937714099884,
      "learning_rate": 5e-05,
      "loss": 0.3384,
      "step": 4912
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6489399075508118,
      "learning_rate": 5e-05,
      "loss": 0.355,
      "step": 4920
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6669545769691467,
      "learning_rate": 5e-05,
      "loss": 0.3863,
      "step": 4928
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.48860082030296326,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 4936
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6368935108184814,
      "learning_rate": 5e-05,
      "loss": 0.3637,
      "step": 4944
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6718161106109619,
      "learning_rate": 5e-05,
      "loss": 0.3538,
      "step": 4952
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6308802366256714,
      "learning_rate": 5e-05,
      "loss": 0.3616,
      "step": 4960
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6465697884559631,
      "learning_rate": 5e-05,
      "loss": 0.3704,
      "step": 4968
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5954138040542603,
      "learning_rate": 5e-05,
      "loss": 0.3382,
      "step": 4976
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5879426598548889,
      "learning_rate": 5e-05,
      "loss": 0.3509,
      "step": 4984
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6044078469276428,
      "learning_rate": 5e-05,
      "loss": 0.3558,
      "step": 4992
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6343244910240173,
      "learning_rate": 5e-05,
      "loss": 0.3775,
      "step": 5000
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6933174729347229,
      "learning_rate": 5e-05,
      "loss": 0.3703,
      "step": 5008
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6722953915596008,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 5016
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6266788840293884,
      "learning_rate": 5e-05,
      "loss": 0.3878,
      "step": 5024
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5664046406745911,
      "learning_rate": 5e-05,
      "loss": 0.3763,
      "step": 5032
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6683749556541443,
      "learning_rate": 5e-05,
      "loss": 0.3468,
      "step": 5040
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6518334746360779,
      "learning_rate": 5e-05,
      "loss": 0.3516,
      "step": 5048
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5932533740997314,
      "learning_rate": 5e-05,
      "loss": 0.384,
      "step": 5056
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7625011801719666,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 5064
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6598358154296875,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 5072
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6907387971878052,
      "learning_rate": 5e-05,
      "loss": 0.3658,
      "step": 5080
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6106390953063965,
      "learning_rate": 5e-05,
      "loss": 0.3674,
      "step": 5088
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6598876714706421,
      "learning_rate": 5e-05,
      "loss": 0.3481,
      "step": 5096
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7029162645339966,
      "learning_rate": 5e-05,
      "loss": 0.3599,
      "step": 5104
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5726357102394104,
      "learning_rate": 5e-05,
      "loss": 0.3449,
      "step": 5112
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5939725041389465,
      "learning_rate": 5e-05,
      "loss": 0.381,
      "step": 5120
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5740622878074646,
      "learning_rate": 5e-05,
      "loss": 0.3566,
      "step": 5128
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6265860199928284,
      "learning_rate": 5e-05,
      "loss": 0.3571,
      "step": 5136
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6339547634124756,
      "learning_rate": 5e-05,
      "loss": 0.3851,
      "step": 5144
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6440486311912537,
      "learning_rate": 5e-05,
      "loss": 0.3543,
      "step": 5152
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.670076847076416,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 5160
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5866201519966125,
      "learning_rate": 5e-05,
      "loss": 0.3467,
      "step": 5168
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5064319968223572,
      "learning_rate": 5e-05,
      "loss": 0.3473,
      "step": 5176
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5966705679893494,
      "learning_rate": 5e-05,
      "loss": 0.3738,
      "step": 5184
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6519707441329956,
      "learning_rate": 5e-05,
      "loss": 0.3741,
      "step": 5192
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5459244251251221,
      "learning_rate": 5e-05,
      "loss": 0.3506,
      "step": 5200
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5847277045249939,
      "learning_rate": 5e-05,
      "loss": 0.3665,
      "step": 5208
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6336643099784851,
      "learning_rate": 5e-05,
      "loss": 0.3922,
      "step": 5216
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5543423295021057,
      "learning_rate": 5e-05,
      "loss": 0.3515,
      "step": 5224
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.559566855430603,
      "learning_rate": 5e-05,
      "loss": 0.3577,
      "step": 5232
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5954195261001587,
      "learning_rate": 5e-05,
      "loss": 0.3855,
      "step": 5240
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6118185520172119,
      "learning_rate": 5e-05,
      "loss": 0.3742,
      "step": 5248
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6938015222549438,
      "learning_rate": 5e-05,
      "loss": 0.3474,
      "step": 5256
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6585535407066345,
      "learning_rate": 5e-05,
      "loss": 0.3815,
      "step": 5264
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6644339561462402,
      "learning_rate": 5e-05,
      "loss": 0.3679,
      "step": 5272
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6405429840087891,
      "learning_rate": 5e-05,
      "loss": 0.3538,
      "step": 5280
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6031171083450317,
      "learning_rate": 5e-05,
      "loss": 0.3674,
      "step": 5288
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.557439923286438,
      "learning_rate": 5e-05,
      "loss": 0.3556,
      "step": 5296
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5385639071464539,
      "learning_rate": 5e-05,
      "loss": 0.379,
      "step": 5304
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5778435468673706,
      "learning_rate": 5e-05,
      "loss": 0.3528,
      "step": 5312
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.598552405834198,
      "learning_rate": 5e-05,
      "loss": 0.3559,
      "step": 5320
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5344844460487366,
      "learning_rate": 5e-05,
      "loss": 0.3431,
      "step": 5328
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5855515003204346,
      "learning_rate": 5e-05,
      "loss": 0.3775,
      "step": 5336
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5578524470329285,
      "learning_rate": 5e-05,
      "loss": 0.4022,
      "step": 5344
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.574910581111908,
      "learning_rate": 5e-05,
      "loss": 0.3797,
      "step": 5352
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6020411252975464,
      "learning_rate": 5e-05,
      "loss": 0.3931,
      "step": 5360
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5987209677696228,
      "learning_rate": 5e-05,
      "loss": 0.3588,
      "step": 5368
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6338961124420166,
      "learning_rate": 5e-05,
      "loss": 0.3688,
      "step": 5376
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5801267027854919,
      "learning_rate": 5e-05,
      "loss": 0.3714,
      "step": 5384
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6628265380859375,
      "learning_rate": 5e-05,
      "loss": 0.3491,
      "step": 5392
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6502863764762878,
      "learning_rate": 5e-05,
      "loss": 0.3363,
      "step": 5400
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5543188452720642,
      "learning_rate": 5e-05,
      "loss": 0.3519,
      "step": 5408
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.606001079082489,
      "learning_rate": 5e-05,
      "loss": 0.341,
      "step": 5416
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5632416605949402,
      "learning_rate": 5e-05,
      "loss": 0.3625,
      "step": 5424
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5403155088424683,
      "learning_rate": 5e-05,
      "loss": 0.3642,
      "step": 5432
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6284400224685669,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 5440
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.654181182384491,
      "learning_rate": 5e-05,
      "loss": 0.3465,
      "step": 5448
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5567167401313782,
      "learning_rate": 5e-05,
      "loss": 0.3671,
      "step": 5456
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6209814548492432,
      "learning_rate": 5e-05,
      "loss": 0.3673,
      "step": 5464
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5596505403518677,
      "learning_rate": 5e-05,
      "loss": 0.3362,
      "step": 5472
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6360599398612976,
      "learning_rate": 5e-05,
      "loss": 0.3548,
      "step": 5480
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6070075035095215,
      "learning_rate": 5e-05,
      "loss": 0.3352,
      "step": 5488
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6785553097724915,
      "learning_rate": 5e-05,
      "loss": 0.3285,
      "step": 5496
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5920276045799255,
      "learning_rate": 5e-05,
      "loss": 0.3348,
      "step": 5504
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6288107633590698,
      "learning_rate": 5e-05,
      "loss": 0.3412,
      "step": 5512
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6177977919578552,
      "learning_rate": 5e-05,
      "loss": 0.3419,
      "step": 5520
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6534387469291687,
      "learning_rate": 5e-05,
      "loss": 0.3876,
      "step": 5528
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8152582049369812,
      "learning_rate": 5e-05,
      "loss": 0.4044,
      "step": 5536
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5217374563217163,
      "learning_rate": 5e-05,
      "loss": 0.3374,
      "step": 5544
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6934604048728943,
      "learning_rate": 5e-05,
      "loss": 0.3669,
      "step": 5552
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7119637131690979,
      "learning_rate": 5e-05,
      "loss": 0.375,
      "step": 5560
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5922262072563171,
      "learning_rate": 5e-05,
      "loss": 0.3582,
      "step": 5568
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6170105934143066,
      "learning_rate": 5e-05,
      "loss": 0.3485,
      "step": 5576
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6404053568840027,
      "learning_rate": 5e-05,
      "loss": 0.3601,
      "step": 5584
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5757104158401489,
      "learning_rate": 5e-05,
      "loss": 0.3469,
      "step": 5592
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6085199117660522,
      "learning_rate": 5e-05,
      "loss": 0.3713,
      "step": 5600
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5983723998069763,
      "learning_rate": 5e-05,
      "loss": 0.3588,
      "step": 5608
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5860595107078552,
      "learning_rate": 5e-05,
      "loss": 0.381,
      "step": 5616
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6989970207214355,
      "learning_rate": 5e-05,
      "loss": 0.3429,
      "step": 5624
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5570116639137268,
      "learning_rate": 5e-05,
      "loss": 0.368,
      "step": 5632
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5894924402236938,
      "learning_rate": 5e-05,
      "loss": 0.3409,
      "step": 5640
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5745004415512085,
      "learning_rate": 5e-05,
      "loss": 0.359,
      "step": 5648
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6287571787834167,
      "learning_rate": 5e-05,
      "loss": 0.3727,
      "step": 5656
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6242244839668274,
      "learning_rate": 5e-05,
      "loss": 0.3579,
      "step": 5664
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6111618280410767,
      "learning_rate": 5e-05,
      "loss": 0.3442,
      "step": 5672
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6190316677093506,
      "learning_rate": 5e-05,
      "loss": 0.3529,
      "step": 5680
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6077950596809387,
      "learning_rate": 5e-05,
      "loss": 0.36,
      "step": 5688
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5599620938301086,
      "learning_rate": 5e-05,
      "loss": 0.3607,
      "step": 5696
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5490062236785889,
      "learning_rate": 5e-05,
      "loss": 0.35,
      "step": 5704
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.572725772857666,
      "learning_rate": 5e-05,
      "loss": 0.3511,
      "step": 5712
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5715057253837585,
      "learning_rate": 5e-05,
      "loss": 0.3615,
      "step": 5720
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5513268113136292,
      "learning_rate": 5e-05,
      "loss": 0.3497,
      "step": 5728
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7172395586967468,
      "learning_rate": 5e-05,
      "loss": 0.3526,
      "step": 5736
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5528473258018494,
      "learning_rate": 5e-05,
      "loss": 0.3273,
      "step": 5744
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6507661938667297,
      "learning_rate": 5e-05,
      "loss": 0.3594,
      "step": 5752
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6180864572525024,
      "learning_rate": 5e-05,
      "loss": 0.342,
      "step": 5760
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8701971173286438,
      "learning_rate": 5e-05,
      "loss": 0.3726,
      "step": 5768
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6584043502807617,
      "learning_rate": 5e-05,
      "loss": 0.3406,
      "step": 5776
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6453743577003479,
      "learning_rate": 5e-05,
      "loss": 0.3242,
      "step": 5784
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6983501315116882,
      "learning_rate": 5e-05,
      "loss": 0.3567,
      "step": 5792
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7659922242164612,
      "learning_rate": 5e-05,
      "loss": 0.3489,
      "step": 5800
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.600328803062439,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 5808
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5835305452346802,
      "learning_rate": 5e-05,
      "loss": 0.3515,
      "step": 5816
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5740078091621399,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 5824
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5799431204795837,
      "learning_rate": 5e-05,
      "loss": 0.3569,
      "step": 5832
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5514675378799438,
      "learning_rate": 5e-05,
      "loss": 0.3633,
      "step": 5840
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5408797264099121,
      "learning_rate": 5e-05,
      "loss": 0.3429,
      "step": 5848
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6099961996078491,
      "learning_rate": 5e-05,
      "loss": 0.3523,
      "step": 5856
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6140954494476318,
      "learning_rate": 5e-05,
      "loss": 0.3639,
      "step": 5864
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5708874464035034,
      "learning_rate": 5e-05,
      "loss": 0.3196,
      "step": 5872
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.72857666015625,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 5880
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5372282266616821,
      "learning_rate": 5e-05,
      "loss": 0.346,
      "step": 5888
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5763370394706726,
      "learning_rate": 5e-05,
      "loss": 0.3697,
      "step": 5896
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5797571539878845,
      "learning_rate": 5e-05,
      "loss": 0.3524,
      "step": 5904
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7053424715995789,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 5912
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5278441905975342,
      "learning_rate": 5e-05,
      "loss": 0.3375,
      "step": 5920
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5771918892860413,
      "learning_rate": 5e-05,
      "loss": 0.3863,
      "step": 5928
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5191749334335327,
      "learning_rate": 5e-05,
      "loss": 0.3424,
      "step": 5936
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6407923698425293,
      "learning_rate": 5e-05,
      "loss": 0.3525,
      "step": 5944
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5572529435157776,
      "learning_rate": 5e-05,
      "loss": 0.3422,
      "step": 5952
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6302818059921265,
      "learning_rate": 5e-05,
      "loss": 0.3676,
      "step": 5960
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6769126057624817,
      "learning_rate": 5e-05,
      "loss": 0.3462,
      "step": 5968
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5630389451980591,
      "learning_rate": 5e-05,
      "loss": 0.394,
      "step": 5976
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6010197997093201,
      "learning_rate": 5e-05,
      "loss": 0.3555,
      "step": 5984
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5520468950271606,
      "learning_rate": 5e-05,
      "loss": 0.3336,
      "step": 5992
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5351448655128479,
      "learning_rate": 5e-05,
      "loss": 0.3659,
      "step": 6000
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5210369229316711,
      "learning_rate": 5e-05,
      "loss": 0.3296,
      "step": 6008
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7123698592185974,
      "learning_rate": 5e-05,
      "loss": 0.3497,
      "step": 6016
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.561368465423584,
      "learning_rate": 5e-05,
      "loss": 0.3654,
      "step": 6024
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7848602533340454,
      "learning_rate": 5e-05,
      "loss": 0.3546,
      "step": 6032
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5996608138084412,
      "learning_rate": 5e-05,
      "loss": 0.3653,
      "step": 6040
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6210663318634033,
      "learning_rate": 5e-05,
      "loss": 0.3444,
      "step": 6048
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5748615860939026,
      "learning_rate": 5e-05,
      "loss": 0.3465,
      "step": 6056
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5750020146369934,
      "learning_rate": 5e-05,
      "loss": 0.3841,
      "step": 6064
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6624456644058228,
      "learning_rate": 5e-05,
      "loss": 0.3468,
      "step": 6072
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6409837007522583,
      "learning_rate": 5e-05,
      "loss": 0.3537,
      "step": 6080
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6411604285240173,
      "learning_rate": 5e-05,
      "loss": 0.3455,
      "step": 6088
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.570838212966919,
      "learning_rate": 5e-05,
      "loss": 0.3521,
      "step": 6096
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6419001817703247,
      "learning_rate": 5e-05,
      "loss": 0.3627,
      "step": 6104
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6823618412017822,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 6112
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5863112807273865,
      "learning_rate": 5e-05,
      "loss": 0.3402,
      "step": 6120
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7078675627708435,
      "learning_rate": 5e-05,
      "loss": 0.3553,
      "step": 6128
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7732614874839783,
      "learning_rate": 5e-05,
      "loss": 0.388,
      "step": 6136
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5900639295578003,
      "learning_rate": 5e-05,
      "loss": 0.3597,
      "step": 6144
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7023693919181824,
      "learning_rate": 5e-05,
      "loss": 0.3328,
      "step": 6152
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6209189891815186,
      "learning_rate": 5e-05,
      "loss": 0.3586,
      "step": 6160
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7013123035430908,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 6168
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7470307946205139,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 6176
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5452154278755188,
      "learning_rate": 5e-05,
      "loss": 0.3457,
      "step": 6184
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5055367946624756,
      "learning_rate": 5e-05,
      "loss": 0.3564,
      "step": 6192
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6416140198707581,
      "learning_rate": 5e-05,
      "loss": 0.3724,
      "step": 6200
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6052671670913696,
      "learning_rate": 5e-05,
      "loss": 0.3644,
      "step": 6208
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7494964599609375,
      "learning_rate": 5e-05,
      "loss": 0.3387,
      "step": 6216
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7010308504104614,
      "learning_rate": 5e-05,
      "loss": 0.3602,
      "step": 6224
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5866555571556091,
      "learning_rate": 5e-05,
      "loss": 0.3745,
      "step": 6232
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.668093204498291,
      "learning_rate": 5e-05,
      "loss": 0.3727,
      "step": 6240
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5539557933807373,
      "learning_rate": 5e-05,
      "loss": 0.3694,
      "step": 6248
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.711258053779602,
      "learning_rate": 5e-05,
      "loss": 0.3609,
      "step": 6256
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6690407395362854,
      "learning_rate": 5e-05,
      "loss": 0.3291,
      "step": 6264
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5393860340118408,
      "learning_rate": 5e-05,
      "loss": 0.368,
      "step": 6272
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7008528113365173,
      "learning_rate": 5e-05,
      "loss": 0.3552,
      "step": 6280
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.541908860206604,
      "learning_rate": 5e-05,
      "loss": 0.3466,
      "step": 6288
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5263568162918091,
      "learning_rate": 5e-05,
      "loss": 0.3386,
      "step": 6296
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5984251499176025,
      "learning_rate": 5e-05,
      "loss": 0.3675,
      "step": 6304
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6556429266929626,
      "learning_rate": 5e-05,
      "loss": 0.3682,
      "step": 6312
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5526572465896606,
      "learning_rate": 5e-05,
      "loss": 0.3533,
      "step": 6320
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.601842999458313,
      "learning_rate": 5e-05,
      "loss": 0.3616,
      "step": 6328
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7034745216369629,
      "learning_rate": 5e-05,
      "loss": 0.3394,
      "step": 6336
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6059306859970093,
      "learning_rate": 5e-05,
      "loss": 0.3788,
      "step": 6344
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6593411564826965,
      "learning_rate": 5e-05,
      "loss": 0.3551,
      "step": 6352
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7152368426322937,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 6360
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.584262490272522,
      "learning_rate": 5e-05,
      "loss": 0.388,
      "step": 6368
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6130170226097107,
      "learning_rate": 5e-05,
      "loss": 0.3438,
      "step": 6376
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.66304612159729,
      "learning_rate": 5e-05,
      "loss": 0.3688,
      "step": 6384
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.868206262588501,
      "learning_rate": 5e-05,
      "loss": 0.3696,
      "step": 6392
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6213858127593994,
      "learning_rate": 5e-05,
      "loss": 0.3729,
      "step": 6400
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7415663003921509,
      "learning_rate": 5e-05,
      "loss": 0.3561,
      "step": 6408
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6048742532730103,
      "learning_rate": 5e-05,
      "loss": 0.3931,
      "step": 6416
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.596523642539978,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 6424
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6243599653244019,
      "learning_rate": 5e-05,
      "loss": 0.3692,
      "step": 6432
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6253889799118042,
      "learning_rate": 5e-05,
      "loss": 0.3749,
      "step": 6440
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6568957567214966,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 6448
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6138812303543091,
      "learning_rate": 5e-05,
      "loss": 0.3682,
      "step": 6456
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5102739930152893,
      "learning_rate": 5e-05,
      "loss": 0.3822,
      "step": 6464
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5828747749328613,
      "learning_rate": 5e-05,
      "loss": 0.3456,
      "step": 6472
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5488832592964172,
      "learning_rate": 5e-05,
      "loss": 0.3689,
      "step": 6480
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6685381531715393,
      "learning_rate": 5e-05,
      "loss": 0.3495,
      "step": 6488
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5547995567321777,
      "learning_rate": 5e-05,
      "loss": 0.3409,
      "step": 6496
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6326066255569458,
      "learning_rate": 5e-05,
      "loss": 0.3612,
      "step": 6504
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6222307682037354,
      "learning_rate": 5e-05,
      "loss": 0.3256,
      "step": 6512
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6293895840644836,
      "learning_rate": 5e-05,
      "loss": 0.3402,
      "step": 6520
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5700721740722656,
      "learning_rate": 5e-05,
      "loss": 0.341,
      "step": 6528
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6425430178642273,
      "learning_rate": 5e-05,
      "loss": 0.3671,
      "step": 6536
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6327005624771118,
      "learning_rate": 5e-05,
      "loss": 0.3821,
      "step": 6544
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5904926657676697,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 6552
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6158030033111572,
      "learning_rate": 5e-05,
      "loss": 0.3531,
      "step": 6560
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5695927739143372,
      "learning_rate": 5e-05,
      "loss": 0.3604,
      "step": 6568
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6373934745788574,
      "learning_rate": 5e-05,
      "loss": 0.3476,
      "step": 6576
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7011004090309143,
      "learning_rate": 5e-05,
      "loss": 0.351,
      "step": 6584
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.602225661277771,
      "learning_rate": 5e-05,
      "loss": 0.3758,
      "step": 6592
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6868135929107666,
      "learning_rate": 5e-05,
      "loss": 0.3549,
      "step": 6600
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5941131114959717,
      "learning_rate": 5e-05,
      "loss": 0.3276,
      "step": 6608
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7466349601745605,
      "learning_rate": 5e-05,
      "loss": 0.3989,
      "step": 6616
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5245662927627563,
      "learning_rate": 5e-05,
      "loss": 0.3421,
      "step": 6624
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7494786977767944,
      "learning_rate": 5e-05,
      "loss": 0.3546,
      "step": 6632
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6232408285140991,
      "learning_rate": 5e-05,
      "loss": 0.3566,
      "step": 6640
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.569436252117157,
      "learning_rate": 5e-05,
      "loss": 0.3453,
      "step": 6648
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6287713050842285,
      "learning_rate": 5e-05,
      "loss": 0.372,
      "step": 6656
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6652557849884033,
      "learning_rate": 5e-05,
      "loss": 0.3694,
      "step": 6664
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7804819345474243,
      "learning_rate": 5e-05,
      "loss": 0.3664,
      "step": 6672
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5826248526573181,
      "learning_rate": 5e-05,
      "loss": 0.3774,
      "step": 6680
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6282849311828613,
      "learning_rate": 5e-05,
      "loss": 0.3688,
      "step": 6688
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4883749485015869,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 6696
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5250711441040039,
      "learning_rate": 5e-05,
      "loss": 0.3381,
      "step": 6704
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6777974963188171,
      "learning_rate": 5e-05,
      "loss": 0.3457,
      "step": 6712
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6012282967567444,
      "learning_rate": 5e-05,
      "loss": 0.3632,
      "step": 6720
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5453338623046875,
      "learning_rate": 5e-05,
      "loss": 0.3511,
      "step": 6728
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6007276773452759,
      "learning_rate": 5e-05,
      "loss": 0.3693,
      "step": 6736
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5461999773979187,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 6744
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.567751407623291,
      "learning_rate": 5e-05,
      "loss": 0.3449,
      "step": 6752
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6049940586090088,
      "learning_rate": 5e-05,
      "loss": 0.364,
      "step": 6760
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6169165372848511,
      "learning_rate": 5e-05,
      "loss": 0.3746,
      "step": 6768
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.624072253704071,
      "learning_rate": 5e-05,
      "loss": 0.3606,
      "step": 6776
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6352782249450684,
      "learning_rate": 5e-05,
      "loss": 0.381,
      "step": 6784
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7292031049728394,
      "learning_rate": 5e-05,
      "loss": 0.3694,
      "step": 6792
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6273316144943237,
      "learning_rate": 5e-05,
      "loss": 0.3451,
      "step": 6800
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.557575523853302,
      "learning_rate": 5e-05,
      "loss": 0.3778,
      "step": 6808
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5688517689704895,
      "learning_rate": 5e-05,
      "loss": 0.3595,
      "step": 6816
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6336917877197266,
      "learning_rate": 5e-05,
      "loss": 0.3247,
      "step": 6824
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6194690465927124,
      "learning_rate": 5e-05,
      "loss": 0.352,
      "step": 6832
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5887450575828552,
      "learning_rate": 5e-05,
      "loss": 0.3357,
      "step": 6840
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6544482707977295,
      "learning_rate": 5e-05,
      "loss": 0.3561,
      "step": 6848
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6526637673377991,
      "learning_rate": 5e-05,
      "loss": 0.3565,
      "step": 6856
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.891618549823761,
      "learning_rate": 5e-05,
      "loss": 0.3329,
      "step": 6864
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5822259187698364,
      "learning_rate": 5e-05,
      "loss": 0.3653,
      "step": 6872
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6897250413894653,
      "learning_rate": 5e-05,
      "loss": 0.3239,
      "step": 6880
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5891435742378235,
      "learning_rate": 5e-05,
      "loss": 0.3728,
      "step": 6888
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5777029395103455,
      "learning_rate": 5e-05,
      "loss": 0.3608,
      "step": 6896
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.553629457950592,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 6904
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5325490236282349,
      "learning_rate": 5e-05,
      "loss": 0.3416,
      "step": 6912
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6086377501487732,
      "learning_rate": 5e-05,
      "loss": 0.3324,
      "step": 6920
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6219669580459595,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 6928
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.542865514755249,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 6936
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.594450056552887,
      "learning_rate": 5e-05,
      "loss": 0.3536,
      "step": 6944
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6255719065666199,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 6952
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5688394904136658,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 6960
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5831891298294067,
      "learning_rate": 5e-05,
      "loss": 0.3337,
      "step": 6968
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7512842416763306,
      "learning_rate": 5e-05,
      "loss": 0.3562,
      "step": 6976
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5885868668556213,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 6984
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6957432627677917,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 6992
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5821425318717957,
      "learning_rate": 5e-05,
      "loss": 0.3387,
      "step": 7000
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7242659330368042,
      "learning_rate": 5e-05,
      "loss": 0.3414,
      "step": 7008
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7569436430931091,
      "learning_rate": 5e-05,
      "loss": 0.3692,
      "step": 7016
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6930930614471436,
      "learning_rate": 5e-05,
      "loss": 0.335,
      "step": 7024
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6011356711387634,
      "learning_rate": 5e-05,
      "loss": 0.3775,
      "step": 7032
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6574671864509583,
      "learning_rate": 5e-05,
      "loss": 0.3516,
      "step": 7040
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6840088367462158,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 7048
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7356491684913635,
      "learning_rate": 5e-05,
      "loss": 0.3565,
      "step": 7056
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5695561170578003,
      "learning_rate": 5e-05,
      "loss": 0.3419,
      "step": 7064
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6669720411300659,
      "learning_rate": 5e-05,
      "loss": 0.3595,
      "step": 7072
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5124131441116333,
      "learning_rate": 5e-05,
      "loss": 0.3668,
      "step": 7080
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5204052329063416,
      "learning_rate": 5e-05,
      "loss": 0.3407,
      "step": 7088
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.662809431552887,
      "learning_rate": 5e-05,
      "loss": 0.3451,
      "step": 7096
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5884864330291748,
      "learning_rate": 5e-05,
      "loss": 0.3284,
      "step": 7104
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6299489736557007,
      "learning_rate": 5e-05,
      "loss": 0.3731,
      "step": 7112
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6530448794364929,
      "learning_rate": 5e-05,
      "loss": 0.378,
      "step": 7120
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5637719631195068,
      "learning_rate": 5e-05,
      "loss": 0.3433,
      "step": 7128
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6477360129356384,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 7136
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6362443566322327,
      "learning_rate": 5e-05,
      "loss": 0.3351,
      "step": 7144
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5921796560287476,
      "learning_rate": 5e-05,
      "loss": 0.3459,
      "step": 7152
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0410271883010864,
      "learning_rate": 5e-05,
      "loss": 0.3432,
      "step": 7160
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6236830949783325,
      "learning_rate": 5e-05,
      "loss": 0.339,
      "step": 7168
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8012858033180237,
      "learning_rate": 5e-05,
      "loss": 0.3556,
      "step": 7176
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5903409123420715,
      "learning_rate": 5e-05,
      "loss": 0.3444,
      "step": 7184
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6022192239761353,
      "learning_rate": 5e-05,
      "loss": 0.3613,
      "step": 7192
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6217748522758484,
      "learning_rate": 5e-05,
      "loss": 0.347,
      "step": 7200
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6185138821601868,
      "learning_rate": 5e-05,
      "loss": 0.3741,
      "step": 7208
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5401825308799744,
      "learning_rate": 5e-05,
      "loss": 0.3463,
      "step": 7216
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6466178894042969,
      "learning_rate": 5e-05,
      "loss": 0.3529,
      "step": 7224
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5977393984794617,
      "learning_rate": 5e-05,
      "loss": 0.3672,
      "step": 7232
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5838562250137329,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 7240
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5590260028839111,
      "learning_rate": 5e-05,
      "loss": 0.3626,
      "step": 7248
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.601106584072113,
      "learning_rate": 5e-05,
      "loss": 0.3463,
      "step": 7256
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6098788380622864,
      "learning_rate": 5e-05,
      "loss": 0.3387,
      "step": 7264
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4962191879749298,
      "learning_rate": 5e-05,
      "loss": 0.3759,
      "step": 7272
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6601049900054932,
      "learning_rate": 5e-05,
      "loss": 0.3356,
      "step": 7280
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6261628270149231,
      "learning_rate": 5e-05,
      "loss": 0.3687,
      "step": 7288
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6546595692634583,
      "learning_rate": 5e-05,
      "loss": 0.3498,
      "step": 7296
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6441331505775452,
      "learning_rate": 5e-05,
      "loss": 0.3645,
      "step": 7304
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6424397826194763,
      "learning_rate": 5e-05,
      "loss": 0.346,
      "step": 7312
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6707794666290283,
      "learning_rate": 5e-05,
      "loss": 0.3479,
      "step": 7320
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5831230282783508,
      "learning_rate": 5e-05,
      "loss": 0.3412,
      "step": 7328
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5564189553260803,
      "learning_rate": 5e-05,
      "loss": 0.3408,
      "step": 7336
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.54982590675354,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 7344
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6322117447853088,
      "learning_rate": 5e-05,
      "loss": 0.3471,
      "step": 7352
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6549745798110962,
      "learning_rate": 5e-05,
      "loss": 0.3334,
      "step": 7360
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6492270827293396,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 7368
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6040534377098083,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 7376
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.4976804554462433,
      "learning_rate": 5e-05,
      "loss": 0.3575,
      "step": 7384
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6672009825706482,
      "learning_rate": 5e-05,
      "loss": 0.3604,
      "step": 7392
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6064351201057434,
      "learning_rate": 5e-05,
      "loss": 0.3581,
      "step": 7400
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5703521370887756,
      "learning_rate": 5e-05,
      "loss": 0.3723,
      "step": 7408
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6185021996498108,
      "learning_rate": 5e-05,
      "loss": 0.3424,
      "step": 7416
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6735872626304626,
      "learning_rate": 5e-05,
      "loss": 0.341,
      "step": 7424
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6495489478111267,
      "learning_rate": 5e-05,
      "loss": 0.3652,
      "step": 7432
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6465815305709839,
      "learning_rate": 5e-05,
      "loss": 0.3519,
      "step": 7440
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6248384714126587,
      "learning_rate": 5e-05,
      "loss": 0.3436,
      "step": 7448
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.690941333770752,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 7456
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6432768702507019,
      "learning_rate": 5e-05,
      "loss": 0.3601,
      "step": 7464
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5738213658332825,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 7472
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6164145469665527,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 7480
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5354952216148376,
      "learning_rate": 5e-05,
      "loss": 0.3286,
      "step": 7488
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5957325100898743,
      "learning_rate": 5e-05,
      "loss": 0.3734,
      "step": 7496
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5275541543960571,
      "learning_rate": 5e-05,
      "loss": 0.3385,
      "step": 7504
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5589298009872437,
      "learning_rate": 5e-05,
      "loss": 0.3745,
      "step": 7512
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5141000151634216,
      "learning_rate": 5e-05,
      "loss": 0.3534,
      "step": 7520
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.647366464138031,
      "learning_rate": 5e-05,
      "loss": 0.3709,
      "step": 7528
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5387702584266663,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 7536
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6217681765556335,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 7544
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.62913578748703,
      "learning_rate": 5e-05,
      "loss": 0.3599,
      "step": 7552
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5133370757102966,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 7560
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6101593971252441,
      "learning_rate": 5e-05,
      "loss": 0.3513,
      "step": 7568
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6290757060050964,
      "learning_rate": 5e-05,
      "loss": 0.3324,
      "step": 7576
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6897355318069458,
      "learning_rate": 5e-05,
      "loss": 0.3097,
      "step": 7584
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6404970288276672,
      "learning_rate": 5e-05,
      "loss": 0.3268,
      "step": 7592
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6246362924575806,
      "learning_rate": 5e-05,
      "loss": 0.3747,
      "step": 7600
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5835902690887451,
      "learning_rate": 5e-05,
      "loss": 0.3493,
      "step": 7608
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6250380873680115,
      "learning_rate": 5e-05,
      "loss": 0.3118,
      "step": 7616
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.687962532043457,
      "learning_rate": 5e-05,
      "loss": 0.3604,
      "step": 7624
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.607012152671814,
      "learning_rate": 5e-05,
      "loss": 0.3517,
      "step": 7632
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7046197056770325,
      "learning_rate": 5e-05,
      "loss": 0.386,
      "step": 7640
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6579168438911438,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 7648
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6439909338951111,
      "learning_rate": 5e-05,
      "loss": 0.3384,
      "step": 7656
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.575372040271759,
      "learning_rate": 5e-05,
      "loss": 0.3389,
      "step": 7664
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1167999505996704,
      "learning_rate": 5e-05,
      "loss": 0.3357,
      "step": 7672
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6073970794677734,
      "learning_rate": 5e-05,
      "loss": 0.3632,
      "step": 7680
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6421475410461426,
      "learning_rate": 5e-05,
      "loss": 0.3419,
      "step": 7688
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6857643127441406,
      "learning_rate": 5e-05,
      "loss": 0.3553,
      "step": 7696
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7015168070793152,
      "learning_rate": 5e-05,
      "loss": 0.3919,
      "step": 7704
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7489351630210876,
      "learning_rate": 5e-05,
      "loss": 0.3436,
      "step": 7712
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5720611810684204,
      "learning_rate": 5e-05,
      "loss": 0.36,
      "step": 7720
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5933656096458435,
      "learning_rate": 5e-05,
      "loss": 0.3076,
      "step": 7728
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6454412341117859,
      "learning_rate": 5e-05,
      "loss": 0.4018,
      "step": 7736
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5726249814033508,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 7744
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5995859503746033,
      "learning_rate": 5e-05,
      "loss": 0.335,
      "step": 7752
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6971457004547119,
      "learning_rate": 5e-05,
      "loss": 0.3819,
      "step": 7760
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7940343618392944,
      "learning_rate": 5e-05,
      "loss": 0.3345,
      "step": 7768
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7511868476867676,
      "learning_rate": 5e-05,
      "loss": 0.3919,
      "step": 7776
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6825281381607056,
      "learning_rate": 5e-05,
      "loss": 0.3618,
      "step": 7784
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.577135443687439,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 7792
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5510308742523193,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 7800
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6098339557647705,
      "learning_rate": 5e-05,
      "loss": 0.3427,
      "step": 7808
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6129526495933533,
      "learning_rate": 5e-05,
      "loss": 0.3314,
      "step": 7816
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6180107593536377,
      "learning_rate": 5e-05,
      "loss": 0.3473,
      "step": 7824
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6397267580032349,
      "learning_rate": 5e-05,
      "loss": 0.3601,
      "step": 7832
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.631585419178009,
      "learning_rate": 5e-05,
      "loss": 0.3765,
      "step": 7840
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6268865466117859,
      "learning_rate": 5e-05,
      "loss": 0.3402,
      "step": 7848
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5828505754470825,
      "learning_rate": 5e-05,
      "loss": 0.3587,
      "step": 7856
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7241054773330688,
      "learning_rate": 5e-05,
      "loss": 0.3328,
      "step": 7864
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.687592089176178,
      "learning_rate": 5e-05,
      "loss": 0.3196,
      "step": 7872
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5485118627548218,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 7880
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6260198354721069,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 7888
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5646809935569763,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 7896
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5792361497879028,
      "learning_rate": 5e-05,
      "loss": 0.3448,
      "step": 7904
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6003931760787964,
      "learning_rate": 5e-05,
      "loss": 0.3613,
      "step": 7912
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5830269455909729,
      "learning_rate": 5e-05,
      "loss": 0.3518,
      "step": 7920
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.776450514793396,
      "learning_rate": 5e-05,
      "loss": 0.3498,
      "step": 7928
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7129718661308289,
      "learning_rate": 5e-05,
      "loss": 0.3731,
      "step": 7936
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6080146431922913,
      "learning_rate": 5e-05,
      "loss": 0.3396,
      "step": 7944
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6765956878662109,
      "learning_rate": 5e-05,
      "loss": 0.3236,
      "step": 7952
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6827810406684875,
      "learning_rate": 5e-05,
      "loss": 0.3583,
      "step": 7960
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6447938084602356,
      "learning_rate": 5e-05,
      "loss": 0.3716,
      "step": 7968
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5314803123474121,
      "learning_rate": 5e-05,
      "loss": 0.3467,
      "step": 7976
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6975467801094055,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 7984
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5331715941429138,
      "learning_rate": 5e-05,
      "loss": 0.3177,
      "step": 7992
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6285995244979858,
      "learning_rate": 5e-05,
      "loss": 0.3612,
      "step": 8000
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.8536523580551147,
      "learning_rate": 5e-05,
      "loss": 0.3397,
      "step": 8008
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7172076106071472,
      "learning_rate": 5e-05,
      "loss": 0.3376,
      "step": 8016
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5653433203697205,
      "learning_rate": 5e-05,
      "loss": 0.3763,
      "step": 8024
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5719582438468933,
      "learning_rate": 5e-05,
      "loss": 0.3315,
      "step": 8032
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7055224776268005,
      "learning_rate": 5e-05,
      "loss": 0.3469,
      "step": 8040
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5202829837799072,
      "learning_rate": 5e-05,
      "loss": 0.3333,
      "step": 8048
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5130680799484253,
      "learning_rate": 5e-05,
      "loss": 0.3449,
      "step": 8056
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6137490272521973,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 8064
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6417834758758545,
      "learning_rate": 5e-05,
      "loss": 0.3467,
      "step": 8072
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6430174708366394,
      "learning_rate": 5e-05,
      "loss": 0.3744,
      "step": 8080
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6228025555610657,
      "learning_rate": 5e-05,
      "loss": 0.3306,
      "step": 8088
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7760663032531738,
      "learning_rate": 5e-05,
      "loss": 0.3547,
      "step": 8096
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6061572432518005,
      "learning_rate": 5e-05,
      "loss": 0.3186,
      "step": 8104
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6070271730422974,
      "learning_rate": 5e-05,
      "loss": 0.3187,
      "step": 8112
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6116273999214172,
      "learning_rate": 5e-05,
      "loss": 0.3743,
      "step": 8120
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.630460262298584,
      "learning_rate": 5e-05,
      "loss": 0.3363,
      "step": 8128
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5059425234794617,
      "learning_rate": 5e-05,
      "loss": 0.3416,
      "step": 8136
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7060939073562622,
      "learning_rate": 5e-05,
      "loss": 0.3564,
      "step": 8144
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6360746622085571,
      "learning_rate": 5e-05,
      "loss": 0.336,
      "step": 8152
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7389026284217834,
      "learning_rate": 5e-05,
      "loss": 0.3741,
      "step": 8160
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5956030488014221,
      "learning_rate": 5e-05,
      "loss": 0.3649,
      "step": 8168
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6247546076774597,
      "learning_rate": 5e-05,
      "loss": 0.377,
      "step": 8176
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5925621390342712,
      "learning_rate": 5e-05,
      "loss": 0.3193,
      "step": 8184
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6367142796516418,
      "learning_rate": 5e-05,
      "loss": 0.3641,
      "step": 8192
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.632428765296936,
      "learning_rate": 5e-05,
      "loss": 0.3383,
      "step": 8200
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6842299699783325,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 8208
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6488126516342163,
      "learning_rate": 5e-05,
      "loss": 0.3756,
      "step": 8216
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5833509564399719,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 8224
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5657253265380859,
      "learning_rate": 5e-05,
      "loss": 0.3276,
      "step": 8232
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6554439067840576,
      "learning_rate": 5e-05,
      "loss": 0.359,
      "step": 8240
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8739708662033081,
      "learning_rate": 5e-05,
      "loss": 0.3611,
      "step": 8248
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6545332074165344,
      "learning_rate": 5e-05,
      "loss": 0.3554,
      "step": 8256
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6704609990119934,
      "learning_rate": 5e-05,
      "loss": 0.3889,
      "step": 8264
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5814836621284485,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 8272
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7314685583114624,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 8280
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6730906367301941,
      "learning_rate": 5e-05,
      "loss": 0.3295,
      "step": 8288
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5814905166625977,
      "learning_rate": 5e-05,
      "loss": 0.3523,
      "step": 8296
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5757113695144653,
      "learning_rate": 5e-05,
      "loss": 0.3636,
      "step": 8304
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7516657114028931,
      "learning_rate": 5e-05,
      "loss": 0.3334,
      "step": 8312
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5586227774620056,
      "learning_rate": 5e-05,
      "loss": 0.3572,
      "step": 8320
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5889323949813843,
      "learning_rate": 5e-05,
      "loss": 0.3673,
      "step": 8328
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5509456396102905,
      "learning_rate": 5e-05,
      "loss": 0.3195,
      "step": 8336
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6345747709274292,
      "learning_rate": 5e-05,
      "loss": 0.3438,
      "step": 8344
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5767418742179871,
      "learning_rate": 5e-05,
      "loss": 0.3568,
      "step": 8352
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5474343299865723,
      "learning_rate": 5e-05,
      "loss": 0.3554,
      "step": 8360
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6386330723762512,
      "learning_rate": 5e-05,
      "loss": 0.3293,
      "step": 8368
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.71001136302948,
      "learning_rate": 5e-05,
      "loss": 0.3392,
      "step": 8376
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5851548910140991,
      "learning_rate": 5e-05,
      "loss": 0.3452,
      "step": 8384
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6680157780647278,
      "learning_rate": 5e-05,
      "loss": 0.3244,
      "step": 8392
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6394854187965393,
      "learning_rate": 5e-05,
      "loss": 0.3497,
      "step": 8400
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6290327906608582,
      "learning_rate": 5e-05,
      "loss": 0.3466,
      "step": 8408
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6508530378341675,
      "learning_rate": 5e-05,
      "loss": 0.3447,
      "step": 8416
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6724895238876343,
      "learning_rate": 5e-05,
      "loss": 0.3735,
      "step": 8424
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.569744348526001,
      "learning_rate": 5e-05,
      "loss": 0.3485,
      "step": 8432
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5592843890190125,
      "learning_rate": 5e-05,
      "loss": 0.3472,
      "step": 8440
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6775091886520386,
      "learning_rate": 5e-05,
      "loss": 0.3353,
      "step": 8448
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6588370203971863,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 8456
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6746665835380554,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 8464
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6660124063491821,
      "learning_rate": 5e-05,
      "loss": 0.3509,
      "step": 8472
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5930428504943848,
      "learning_rate": 5e-05,
      "loss": 0.3326,
      "step": 8480
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.611423909664154,
      "learning_rate": 5e-05,
      "loss": 0.315,
      "step": 8488
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.565742552280426,
      "learning_rate": 5e-05,
      "loss": 0.3548,
      "step": 8496
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5568079352378845,
      "learning_rate": 5e-05,
      "loss": 0.3284,
      "step": 8504
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6151831746101379,
      "learning_rate": 5e-05,
      "loss": 0.3792,
      "step": 8512
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.528346836566925,
      "learning_rate": 5e-05,
      "loss": 0.344,
      "step": 8520
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.589053750038147,
      "learning_rate": 5e-05,
      "loss": 0.3616,
      "step": 8528
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6011514067649841,
      "learning_rate": 5e-05,
      "loss": 0.3676,
      "step": 8536
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6604706048965454,
      "learning_rate": 5e-05,
      "loss": 0.362,
      "step": 8544
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6358374357223511,
      "learning_rate": 5e-05,
      "loss": 0.3532,
      "step": 8552
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.552217423915863,
      "learning_rate": 5e-05,
      "loss": 0.3641,
      "step": 8560
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5809979438781738,
      "learning_rate": 5e-05,
      "loss": 0.3331,
      "step": 8568
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6533288359642029,
      "learning_rate": 5e-05,
      "loss": 0.3646,
      "step": 8576
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6672095656394958,
      "learning_rate": 5e-05,
      "loss": 0.3811,
      "step": 8584
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7775825262069702,
      "learning_rate": 5e-05,
      "loss": 0.363,
      "step": 8592
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5773653388023376,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 8600
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6133593320846558,
      "learning_rate": 5e-05,
      "loss": 0.3377,
      "step": 8608
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5720426440238953,
      "learning_rate": 5e-05,
      "loss": 0.3584,
      "step": 8616
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7288686037063599,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 8624
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5944106578826904,
      "learning_rate": 5e-05,
      "loss": 0.3431,
      "step": 8632
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6125343441963196,
      "learning_rate": 5e-05,
      "loss": 0.3637,
      "step": 8640
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7650557160377502,
      "learning_rate": 5e-05,
      "loss": 0.3343,
      "step": 8648
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6752827763557434,
      "learning_rate": 5e-05,
      "loss": 0.3356,
      "step": 8656
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5633997321128845,
      "learning_rate": 5e-05,
      "loss": 0.3325,
      "step": 8664
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7414013743400574,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 8672
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.647980272769928,
      "learning_rate": 5e-05,
      "loss": 0.3272,
      "step": 8680
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6650108695030212,
      "learning_rate": 5e-05,
      "loss": 0.3452,
      "step": 8688
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5537152290344238,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 8696
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5759073495864868,
      "learning_rate": 5e-05,
      "loss": 0.3558,
      "step": 8704
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.536453902721405,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 8712
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6036005020141602,
      "learning_rate": 5e-05,
      "loss": 0.3453,
      "step": 8720
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5511422157287598,
      "learning_rate": 5e-05,
      "loss": 0.3269,
      "step": 8728
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6918953061103821,
      "learning_rate": 5e-05,
      "loss": 0.391,
      "step": 8736
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6134482622146606,
      "learning_rate": 5e-05,
      "loss": 0.3536,
      "step": 8744
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6695532202720642,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 8752
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5688367486000061,
      "learning_rate": 5e-05,
      "loss": 0.3764,
      "step": 8760
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6384128928184509,
      "learning_rate": 5e-05,
      "loss": 0.3382,
      "step": 8768
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5480718612670898,
      "learning_rate": 5e-05,
      "loss": 0.3755,
      "step": 8776
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6090676188468933,
      "learning_rate": 5e-05,
      "loss": 0.3888,
      "step": 8784
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6313332319259644,
      "learning_rate": 5e-05,
      "loss": 0.339,
      "step": 8792
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5519629120826721,
      "learning_rate": 5e-05,
      "loss": 0.3431,
      "step": 8800
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7331362366676331,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 8808
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6293515563011169,
      "learning_rate": 5e-05,
      "loss": 0.3347,
      "step": 8816
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.617060124874115,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 8824
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5198825597763062,
      "learning_rate": 5e-05,
      "loss": 0.3276,
      "step": 8832
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6158912181854248,
      "learning_rate": 5e-05,
      "loss": 0.3185,
      "step": 8840
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6605769395828247,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 8848
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6875571012496948,
      "learning_rate": 5e-05,
      "loss": 0.3161,
      "step": 8856
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6639633774757385,
      "learning_rate": 5e-05,
      "loss": 0.3344,
      "step": 8864
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.576273500919342,
      "learning_rate": 5e-05,
      "loss": 0.3432,
      "step": 8872
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6854588389396667,
      "learning_rate": 5e-05,
      "loss": 0.331,
      "step": 8880
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7099196910858154,
      "learning_rate": 5e-05,
      "loss": 0.3581,
      "step": 8888
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6001710295677185,
      "learning_rate": 5e-05,
      "loss": 0.337,
      "step": 8896
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6085677742958069,
      "learning_rate": 5e-05,
      "loss": 0.3455,
      "step": 8904
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6484902501106262,
      "learning_rate": 5e-05,
      "loss": 0.3191,
      "step": 8912
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.614024817943573,
      "learning_rate": 5e-05,
      "loss": 0.3547,
      "step": 8920
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7354898452758789,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 8928
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5752454400062561,
      "learning_rate": 5e-05,
      "loss": 0.3706,
      "step": 8936
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5394926071166992,
      "learning_rate": 5e-05,
      "loss": 0.3651,
      "step": 8944
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.668512225151062,
      "learning_rate": 5e-05,
      "loss": 0.3306,
      "step": 8952
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5941529273986816,
      "learning_rate": 5e-05,
      "loss": 0.3731,
      "step": 8960
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.63729327917099,
      "learning_rate": 5e-05,
      "loss": 0.3483,
      "step": 8968
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7011899948120117,
      "learning_rate": 5e-05,
      "loss": 0.3568,
      "step": 8976
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6345776319503784,
      "learning_rate": 5e-05,
      "loss": 0.3636,
      "step": 8984
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7651150822639465,
      "learning_rate": 5e-05,
      "loss": 0.3784,
      "step": 8992
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.588824450969696,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 9000
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5911611318588257,
      "learning_rate": 5e-05,
      "loss": 0.3504,
      "step": 9008
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6655896306037903,
      "learning_rate": 5e-05,
      "loss": 0.3555,
      "step": 9016
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7109131813049316,
      "learning_rate": 5e-05,
      "loss": 0.3387,
      "step": 9024
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6732499003410339,
      "learning_rate": 5e-05,
      "loss": 0.3772,
      "step": 9032
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5790193676948547,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 9040
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6522354483604431,
      "learning_rate": 5e-05,
      "loss": 0.3589,
      "step": 9048
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5304358601570129,
      "learning_rate": 5e-05,
      "loss": 0.3601,
      "step": 9056
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6469336152076721,
      "learning_rate": 5e-05,
      "loss": 0.3395,
      "step": 9064
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5226542353630066,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 9072
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7475666999816895,
      "learning_rate": 5e-05,
      "loss": 0.3506,
      "step": 9080
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7492047548294067,
      "learning_rate": 5e-05,
      "loss": 0.3541,
      "step": 9088
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6536954641342163,
      "learning_rate": 5e-05,
      "loss": 0.3333,
      "step": 9096
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5891969203948975,
      "learning_rate": 5e-05,
      "loss": 0.3481,
      "step": 9104
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6468742489814758,
      "learning_rate": 5e-05,
      "loss": 0.342,
      "step": 9112
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5873314738273621,
      "learning_rate": 5e-05,
      "loss": 0.3402,
      "step": 9120
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6170479655265808,
      "learning_rate": 5e-05,
      "loss": 0.3605,
      "step": 9128
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7873182892799377,
      "learning_rate": 5e-05,
      "loss": 0.3528,
      "step": 9136
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5944752097129822,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 9144
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6717749834060669,
      "learning_rate": 5e-05,
      "loss": 0.3618,
      "step": 9152
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6017326712608337,
      "learning_rate": 5e-05,
      "loss": 0.3355,
      "step": 9160
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5754019021987915,
      "learning_rate": 5e-05,
      "loss": 0.3616,
      "step": 9168
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6363253593444824,
      "learning_rate": 5e-05,
      "loss": 0.348,
      "step": 9176
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7244840264320374,
      "learning_rate": 5e-05,
      "loss": 0.3543,
      "step": 9184
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6535961031913757,
      "learning_rate": 5e-05,
      "loss": 0.35,
      "step": 9192
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5875368118286133,
      "learning_rate": 5e-05,
      "loss": 0.3127,
      "step": 9200
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6280619502067566,
      "learning_rate": 5e-05,
      "loss": 0.3482,
      "step": 9208
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7061858177185059,
      "learning_rate": 5e-05,
      "loss": 0.336,
      "step": 9216
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5930199027061462,
      "learning_rate": 5e-05,
      "loss": 0.3611,
      "step": 9224
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5667454600334167,
      "learning_rate": 5e-05,
      "loss": 0.3457,
      "step": 9232
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6227200627326965,
      "learning_rate": 5e-05,
      "loss": 0.3693,
      "step": 9240
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6817746758460999,
      "learning_rate": 5e-05,
      "loss": 0.3418,
      "step": 9248
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6109651923179626,
      "learning_rate": 5e-05,
      "loss": 0.337,
      "step": 9256
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5925818681716919,
      "learning_rate": 5e-05,
      "loss": 0.3469,
      "step": 9264
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6112819314002991,
      "learning_rate": 5e-05,
      "loss": 0.3359,
      "step": 9272
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7136321067810059,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 9280
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5647997856140137,
      "learning_rate": 5e-05,
      "loss": 0.307,
      "step": 9288
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6494283080101013,
      "learning_rate": 5e-05,
      "loss": 0.3502,
      "step": 9296
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6162636280059814,
      "learning_rate": 5e-05,
      "loss": 0.3262,
      "step": 9304
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6211550235748291,
      "learning_rate": 5e-05,
      "loss": 0.3451,
      "step": 9312
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6998536586761475,
      "learning_rate": 5e-05,
      "loss": 0.3801,
      "step": 9320
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6397119164466858,
      "learning_rate": 5e-05,
      "loss": 0.3393,
      "step": 9328
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6087839603424072,
      "learning_rate": 5e-05,
      "loss": 0.3821,
      "step": 9336
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6075975298881531,
      "learning_rate": 5e-05,
      "loss": 0.3519,
      "step": 9344
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6807860732078552,
      "learning_rate": 5e-05,
      "loss": 0.346,
      "step": 9352
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6444447040557861,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 9360
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7180876135826111,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 9368
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5803179144859314,
      "learning_rate": 5e-05,
      "loss": 0.343,
      "step": 9376
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6235408186912537,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 9384
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8040823936462402,
      "learning_rate": 5e-05,
      "loss": 0.344,
      "step": 9392
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.649468183517456,
      "learning_rate": 5e-05,
      "loss": 0.3475,
      "step": 9400
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6502532958984375,
      "learning_rate": 5e-05,
      "loss": 0.3483,
      "step": 9408
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7133030295372009,
      "learning_rate": 5e-05,
      "loss": 0.3435,
      "step": 9416
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6149529218673706,
      "learning_rate": 5e-05,
      "loss": 0.3773,
      "step": 9424
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6910591721534729,
      "learning_rate": 5e-05,
      "loss": 0.3642,
      "step": 9432
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6084316968917847,
      "learning_rate": 5e-05,
      "loss": 0.3522,
      "step": 9440
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6535433530807495,
      "learning_rate": 5e-05,
      "loss": 0.3655,
      "step": 9448
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5648796558380127,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 9456
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5797359347343445,
      "learning_rate": 5e-05,
      "loss": 0.3348,
      "step": 9464
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5797637701034546,
      "learning_rate": 5e-05,
      "loss": 0.3414,
      "step": 9472
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5059338808059692,
      "learning_rate": 5e-05,
      "loss": 0.3642,
      "step": 9480
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6557013988494873,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 9488
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7317408323287964,
      "learning_rate": 5e-05,
      "loss": 0.3715,
      "step": 9496
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7108855843544006,
      "learning_rate": 5e-05,
      "loss": 0.3522,
      "step": 9504
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6205467581748962,
      "learning_rate": 5e-05,
      "loss": 0.37,
      "step": 9512
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.78375244140625,
      "learning_rate": 5e-05,
      "loss": 0.3733,
      "step": 9520
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5294294953346252,
      "learning_rate": 5e-05,
      "loss": 0.3433,
      "step": 9528
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6781508326530457,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 9536
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6128746867179871,
      "learning_rate": 5e-05,
      "loss": 0.332,
      "step": 9544
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6176176071166992,
      "learning_rate": 5e-05,
      "loss": 0.3546,
      "step": 9552
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6463011503219604,
      "learning_rate": 5e-05,
      "loss": 0.3338,
      "step": 9560
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6596962213516235,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 9568
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.6599847674369812,
      "learning_rate": 5e-05,
      "loss": 0.3134,
      "step": 9576
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7292823195457458,
      "learning_rate": 5e-05,
      "loss": 0.3489,
      "step": 9584
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7256297469139099,
      "learning_rate": 5e-05,
      "loss": 0.3513,
      "step": 9592
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5782173871994019,
      "learning_rate": 5e-05,
      "loss": 0.3299,
      "step": 9600
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6121291518211365,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 9608
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6243419051170349,
      "learning_rate": 5e-05,
      "loss": 0.3578,
      "step": 9616
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6114562153816223,
      "learning_rate": 5e-05,
      "loss": 0.3382,
      "step": 9624
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5970224142074585,
      "learning_rate": 5e-05,
      "loss": 0.35,
      "step": 9632
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5907062292098999,
      "learning_rate": 5e-05,
      "loss": 0.3581,
      "step": 9640
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5972834825515747,
      "learning_rate": 5e-05,
      "loss": 0.3459,
      "step": 9648
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6074556708335876,
      "learning_rate": 5e-05,
      "loss": 0.3494,
      "step": 9656
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5706593990325928,
      "learning_rate": 5e-05,
      "loss": 0.356,
      "step": 9664
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6754753589630127,
      "learning_rate": 5e-05,
      "loss": 0.3503,
      "step": 9672
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6521404385566711,
      "learning_rate": 5e-05,
      "loss": 0.3409,
      "step": 9680
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7222023606300354,
      "learning_rate": 5e-05,
      "loss": 0.363,
      "step": 9688
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5881794691085815,
      "learning_rate": 5e-05,
      "loss": 0.3116,
      "step": 9696
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5398850440979004,
      "learning_rate": 5e-05,
      "loss": 0.3198,
      "step": 9704
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.581136167049408,
      "learning_rate": 5e-05,
      "loss": 0.3362,
      "step": 9712
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5956916809082031,
      "learning_rate": 5e-05,
      "loss": 0.3599,
      "step": 9720
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6803138852119446,
      "learning_rate": 5e-05,
      "loss": 0.3306,
      "step": 9728
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6729646921157837,
      "learning_rate": 5e-05,
      "loss": 0.3233,
      "step": 9736
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.5663095116615295,
      "learning_rate": 5e-05,
      "loss": 0.3312,
      "step": 9744
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6365085244178772,
      "learning_rate": 5e-05,
      "loss": 0.3437,
      "step": 9752
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5770068168640137,
      "learning_rate": 5e-05,
      "loss": 0.3357,
      "step": 9760
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7388527989387512,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 9768
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7403141856193542,
      "learning_rate": 5e-05,
      "loss": 0.3202,
      "step": 9776
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6255847811698914,
      "learning_rate": 5e-05,
      "loss": 0.3465,
      "step": 9784
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8290424942970276,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 9792
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6433355212211609,
      "learning_rate": 5e-05,
      "loss": 0.3592,
      "step": 9800
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6478896141052246,
      "learning_rate": 5e-05,
      "loss": 0.3518,
      "step": 9808
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6441794633865356,
      "learning_rate": 5e-05,
      "loss": 0.343,
      "step": 9816
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7041612863540649,
      "learning_rate": 5e-05,
      "loss": 0.3394,
      "step": 9824
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6739304065704346,
      "learning_rate": 5e-05,
      "loss": 0.3545,
      "step": 9832
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6181038618087769,
      "learning_rate": 5e-05,
      "loss": 0.352,
      "step": 9840
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6259612441062927,
      "learning_rate": 5e-05,
      "loss": 0.3428,
      "step": 9848
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7800707221031189,
      "learning_rate": 5e-05,
      "loss": 0.3391,
      "step": 9856
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6328000426292419,
      "learning_rate": 5e-05,
      "loss": 0.3541,
      "step": 9864
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6658515930175781,
      "learning_rate": 5e-05,
      "loss": 0.3468,
      "step": 9872
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6509082317352295,
      "learning_rate": 5e-05,
      "loss": 0.3433,
      "step": 9880
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6005882620811462,
      "learning_rate": 5e-05,
      "loss": 0.3356,
      "step": 9888
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.589457631111145,
      "learning_rate": 5e-05,
      "loss": 0.3771,
      "step": 9896
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.529535710811615,
      "learning_rate": 5e-05,
      "loss": 0.3866,
      "step": 9904
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5138219594955444,
      "learning_rate": 5e-05,
      "loss": 0.3299,
      "step": 9912
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6838698983192444,
      "learning_rate": 5e-05,
      "loss": 0.3565,
      "step": 9920
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6393750309944153,
      "learning_rate": 5e-05,
      "loss": 0.3433,
      "step": 9928
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6215286254882812,
      "learning_rate": 5e-05,
      "loss": 0.35,
      "step": 9936
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5725412964820862,
      "learning_rate": 5e-05,
      "loss": 0.3446,
      "step": 9944
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6777254939079285,
      "learning_rate": 5e-05,
      "loss": 0.341,
      "step": 9952
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.646955132484436,
      "learning_rate": 5e-05,
      "loss": 0.3427,
      "step": 9960
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.602975606918335,
      "learning_rate": 5e-05,
      "loss": 0.3317,
      "step": 9968
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6027189493179321,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 9976
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6220915913581848,
      "learning_rate": 5e-05,
      "loss": 0.299,
      "step": 9984
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5722907185554504,
      "learning_rate": 5e-05,
      "loss": 0.3599,
      "step": 9992
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6302173733711243,
      "learning_rate": 5e-05,
      "loss": 0.3278,
      "step": 10000
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6362392902374268,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 10008
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5909924507141113,
      "learning_rate": 5e-05,
      "loss": 0.3536,
      "step": 10016
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5994694828987122,
      "learning_rate": 5e-05,
      "loss": 0.3464,
      "step": 10024
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5634900331497192,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 10032
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6404736042022705,
      "learning_rate": 5e-05,
      "loss": 0.351,
      "step": 10040
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6499990820884705,
      "learning_rate": 5e-05,
      "loss": 0.3365,
      "step": 10048
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6272135972976685,
      "learning_rate": 5e-05,
      "loss": 0.3473,
      "step": 10056
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5806309580802917,
      "learning_rate": 5e-05,
      "loss": 0.3242,
      "step": 10064
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5997813940048218,
      "learning_rate": 5e-05,
      "loss": 0.3235,
      "step": 10072
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7424765825271606,
      "learning_rate": 5e-05,
      "loss": 0.3255,
      "step": 10080
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.604141354560852,
      "learning_rate": 5e-05,
      "loss": 0.351,
      "step": 10088
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5992528200149536,
      "learning_rate": 5e-05,
      "loss": 0.3767,
      "step": 10096
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6392810344696045,
      "learning_rate": 5e-05,
      "loss": 0.3597,
      "step": 10104
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5479956865310669,
      "learning_rate": 5e-05,
      "loss": 0.3214,
      "step": 10112
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6016069054603577,
      "learning_rate": 5e-05,
      "loss": 0.3325,
      "step": 10120
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.564572274684906,
      "learning_rate": 5e-05,
      "loss": 0.3334,
      "step": 10128
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6454585194587708,
      "learning_rate": 5e-05,
      "loss": 0.3525,
      "step": 10136
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7716056108474731,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 10144
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.604827880859375,
      "learning_rate": 5e-05,
      "loss": 0.3281,
      "step": 10152
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6170438528060913,
      "learning_rate": 5e-05,
      "loss": 0.3335,
      "step": 10160
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.644131064414978,
      "learning_rate": 5e-05,
      "loss": 0.3702,
      "step": 10168
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6076132655143738,
      "learning_rate": 5e-05,
      "loss": 0.3312,
      "step": 10176
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.565792977809906,
      "learning_rate": 5e-05,
      "loss": 0.3783,
      "step": 10184
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5517925024032593,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 10192
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6292794346809387,
      "learning_rate": 5e-05,
      "loss": 0.3406,
      "step": 10200
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6881963014602661,
      "learning_rate": 5e-05,
      "loss": 0.376,
      "step": 10208
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5300009250640869,
      "learning_rate": 5e-05,
      "loss": 0.3407,
      "step": 10216
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6516249179840088,
      "learning_rate": 5e-05,
      "loss": 0.3377,
      "step": 10224
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.637910008430481,
      "learning_rate": 5e-05,
      "loss": 0.3558,
      "step": 10232
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6221020817756653,
      "learning_rate": 5e-05,
      "loss": 0.3292,
      "step": 10240
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5503045320510864,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 10248
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6418464779853821,
      "learning_rate": 5e-05,
      "loss": 0.3214,
      "step": 10256
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7441507577896118,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 10264
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5605108737945557,
      "learning_rate": 5e-05,
      "loss": 0.3255,
      "step": 10272
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5813406109809875,
      "learning_rate": 5e-05,
      "loss": 0.3391,
      "step": 10280
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6301025748252869,
      "learning_rate": 5e-05,
      "loss": 0.3355,
      "step": 10288
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5858177542686462,
      "learning_rate": 5e-05,
      "loss": 0.3295,
      "step": 10296
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6021513342857361,
      "learning_rate": 5e-05,
      "loss": 0.3503,
      "step": 10304
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5902355313301086,
      "learning_rate": 5e-05,
      "loss": 0.365,
      "step": 10312
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.654870331287384,
      "learning_rate": 5e-05,
      "loss": 0.3832,
      "step": 10320
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6239087581634521,
      "learning_rate": 5e-05,
      "loss": 0.3545,
      "step": 10328
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5571798086166382,
      "learning_rate": 5e-05,
      "loss": 0.3326,
      "step": 10336
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6477366089820862,
      "learning_rate": 5e-05,
      "loss": 0.3564,
      "step": 10344
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7031348943710327,
      "learning_rate": 5e-05,
      "loss": 0.3189,
      "step": 10352
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5501176118850708,
      "learning_rate": 5e-05,
      "loss": 0.3419,
      "step": 10360
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.64726722240448,
      "learning_rate": 5e-05,
      "loss": 0.3709,
      "step": 10368
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7400737404823303,
      "learning_rate": 5e-05,
      "loss": 0.3489,
      "step": 10376
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.8474286794662476,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 10384
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5797052979469299,
      "learning_rate": 5e-05,
      "loss": 0.3438,
      "step": 10392
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6199132800102234,
      "learning_rate": 5e-05,
      "loss": 0.3559,
      "step": 10400
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5519037842750549,
      "learning_rate": 5e-05,
      "loss": 0.3494,
      "step": 10408
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.554459273815155,
      "learning_rate": 5e-05,
      "loss": 0.3415,
      "step": 10416
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6183328628540039,
      "learning_rate": 5e-05,
      "loss": 0.3408,
      "step": 10424
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6297204494476318,
      "learning_rate": 5e-05,
      "loss": 0.3511,
      "step": 10432
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6594551205635071,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 10440
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6226522922515869,
      "learning_rate": 5e-05,
      "loss": 0.333,
      "step": 10448
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6478168964385986,
      "learning_rate": 5e-05,
      "loss": 0.3431,
      "step": 10456
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6940062642097473,
      "learning_rate": 5e-05,
      "loss": 0.3625,
      "step": 10464
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6314160823822021,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 10472
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6513607501983643,
      "learning_rate": 5e-05,
      "loss": 0.3843,
      "step": 10480
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5526154637336731,
      "learning_rate": 5e-05,
      "loss": 0.3455,
      "step": 10488
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.8775279521942139,
      "learning_rate": 5e-05,
      "loss": 0.3298,
      "step": 10496
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5560509562492371,
      "learning_rate": 5e-05,
      "loss": 0.3224,
      "step": 10504
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5778529047966003,
      "learning_rate": 5e-05,
      "loss": 0.3685,
      "step": 10512
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6410844326019287,
      "learning_rate": 5e-05,
      "loss": 0.3162,
      "step": 10520
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5998594760894775,
      "learning_rate": 5e-05,
      "loss": 0.3249,
      "step": 10528
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6463562250137329,
      "learning_rate": 5e-05,
      "loss": 0.3127,
      "step": 10536
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6450938582420349,
      "learning_rate": 5e-05,
      "loss": 0.3163,
      "step": 10544
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5884114503860474,
      "learning_rate": 5e-05,
      "loss": 0.3489,
      "step": 10552
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6611165404319763,
      "learning_rate": 5e-05,
      "loss": 0.3357,
      "step": 10560
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5823475122451782,
      "learning_rate": 5e-05,
      "loss": 0.3668,
      "step": 10568
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.563648521900177,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 10576
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.9878438115119934,
      "learning_rate": 5e-05,
      "loss": 0.3521,
      "step": 10584
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6065982580184937,
      "learning_rate": 5e-05,
      "loss": 0.3222,
      "step": 10592
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6551468968391418,
      "learning_rate": 5e-05,
      "loss": 0.3203,
      "step": 10600
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7198858857154846,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 10608
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5762655138969421,
      "learning_rate": 5e-05,
      "loss": 0.3478,
      "step": 10616
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6698052883148193,
      "learning_rate": 5e-05,
      "loss": 0.3498,
      "step": 10624
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6115674376487732,
      "learning_rate": 5e-05,
      "loss": 0.3522,
      "step": 10632
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5664824843406677,
      "learning_rate": 5e-05,
      "loss": 0.3661,
      "step": 10640
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.65317302942276,
      "learning_rate": 5e-05,
      "loss": 0.3138,
      "step": 10648
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.749488115310669,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 10656
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6492491364479065,
      "learning_rate": 5e-05,
      "loss": 0.3391,
      "step": 10664
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6170140504837036,
      "learning_rate": 5e-05,
      "loss": 0.3688,
      "step": 10672
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6336861252784729,
      "learning_rate": 5e-05,
      "loss": 0.3462,
      "step": 10680
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7694577574729919,
      "learning_rate": 5e-05,
      "loss": 0.3474,
      "step": 10688
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7011191844940186,
      "learning_rate": 5e-05,
      "loss": 0.3584,
      "step": 10696
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6249873638153076,
      "learning_rate": 5e-05,
      "loss": 0.3291,
      "step": 10704
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6357990503311157,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 10712
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5841068625450134,
      "learning_rate": 5e-05,
      "loss": 0.3428,
      "step": 10720
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5870151519775391,
      "learning_rate": 5e-05,
      "loss": 0.3487,
      "step": 10728
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6107615232467651,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 10736
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5828002691268921,
      "learning_rate": 5e-05,
      "loss": 0.3204,
      "step": 10744
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6050103902816772,
      "learning_rate": 5e-05,
      "loss": 0.3272,
      "step": 10752
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5784862041473389,
      "learning_rate": 5e-05,
      "loss": 0.3432,
      "step": 10760
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.517630398273468,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 10768
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6252790689468384,
      "learning_rate": 5e-05,
      "loss": 0.3413,
      "step": 10776
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7657874822616577,
      "learning_rate": 5e-05,
      "loss": 0.3407,
      "step": 10784
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6817314028739929,
      "learning_rate": 5e-05,
      "loss": 0.3286,
      "step": 10792
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5828979015350342,
      "learning_rate": 5e-05,
      "loss": 0.3542,
      "step": 10800
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.578768253326416,
      "learning_rate": 5e-05,
      "loss": 0.3637,
      "step": 10808
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5837962627410889,
      "learning_rate": 5e-05,
      "loss": 0.3363,
      "step": 10816
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6682158708572388,
      "learning_rate": 5e-05,
      "loss": 0.3456,
      "step": 10824
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6196942329406738,
      "learning_rate": 5e-05,
      "loss": 0.351,
      "step": 10832
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5874452590942383,
      "learning_rate": 5e-05,
      "loss": 0.3415,
      "step": 10840
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6019752025604248,
      "learning_rate": 5e-05,
      "loss": 0.3397,
      "step": 10848
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7565913200378418,
      "learning_rate": 5e-05,
      "loss": 0.328,
      "step": 10856
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5937519073486328,
      "learning_rate": 5e-05,
      "loss": 0.3564,
      "step": 10864
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5705145001411438,
      "learning_rate": 5e-05,
      "loss": 0.3422,
      "step": 10872
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7445230484008789,
      "learning_rate": 5e-05,
      "loss": 0.3433,
      "step": 10880
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6128610372543335,
      "learning_rate": 5e-05,
      "loss": 0.3488,
      "step": 10888
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6183469295501709,
      "learning_rate": 5e-05,
      "loss": 0.3564,
      "step": 10896
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6469431519508362,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 10904
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6991655826568604,
      "learning_rate": 5e-05,
      "loss": 0.3742,
      "step": 10912
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5919038653373718,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 10920
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6870927214622498,
      "learning_rate": 5e-05,
      "loss": 0.3306,
      "step": 10928
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5992401242256165,
      "learning_rate": 5e-05,
      "loss": 0.3051,
      "step": 10936
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6179762482643127,
      "learning_rate": 5e-05,
      "loss": 0.3657,
      "step": 10944
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5827714800834656,
      "learning_rate": 5e-05,
      "loss": 0.3376,
      "step": 10952
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6052665710449219,
      "learning_rate": 5e-05,
      "loss": 0.3464,
      "step": 10960
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6729798316955566,
      "learning_rate": 5e-05,
      "loss": 0.3444,
      "step": 10968
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5659819841384888,
      "learning_rate": 5e-05,
      "loss": 0.3426,
      "step": 10976
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7152904272079468,
      "learning_rate": 5e-05,
      "loss": 0.3202,
      "step": 10984
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5540343523025513,
      "learning_rate": 5e-05,
      "loss": 0.3274,
      "step": 10992
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6801552772521973,
      "learning_rate": 5e-05,
      "loss": 0.3603,
      "step": 11000
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.588629424571991,
      "learning_rate": 5e-05,
      "loss": 0.3658,
      "step": 11008
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5577260255813599,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 11016
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5970852971076965,
      "learning_rate": 5e-05,
      "loss": 0.3399,
      "step": 11024
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6134562492370605,
      "learning_rate": 5e-05,
      "loss": 0.3438,
      "step": 11032
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5613155961036682,
      "learning_rate": 5e-05,
      "loss": 0.3403,
      "step": 11040
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5898996591567993,
      "learning_rate": 5e-05,
      "loss": 0.3366,
      "step": 11048
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.567963182926178,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 11056
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.775697648525238,
      "learning_rate": 5e-05,
      "loss": 0.3446,
      "step": 11064
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.622167706489563,
      "learning_rate": 5e-05,
      "loss": 0.3612,
      "step": 11072
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6163332462310791,
      "learning_rate": 5e-05,
      "loss": 0.3266,
      "step": 11080
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5907239317893982,
      "learning_rate": 5e-05,
      "loss": 0.3474,
      "step": 11088
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6789774298667908,
      "learning_rate": 5e-05,
      "loss": 0.3648,
      "step": 11096
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6408699750900269,
      "learning_rate": 5e-05,
      "loss": 0.3579,
      "step": 11104
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5748620629310608,
      "learning_rate": 5e-05,
      "loss": 0.3277,
      "step": 11112
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6034413576126099,
      "learning_rate": 5e-05,
      "loss": 0.3517,
      "step": 11120
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6540772318840027,
      "learning_rate": 5e-05,
      "loss": 0.3806,
      "step": 11128
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6810333132743835,
      "learning_rate": 5e-05,
      "loss": 0.3594,
      "step": 11136
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.562409520149231,
      "learning_rate": 5e-05,
      "loss": 0.3254,
      "step": 11144
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5871105194091797,
      "learning_rate": 5e-05,
      "loss": 0.3604,
      "step": 11152
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7245427966117859,
      "learning_rate": 5e-05,
      "loss": 0.3305,
      "step": 11160
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6568953990936279,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 11168
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6171261072158813,
      "learning_rate": 5e-05,
      "loss": 0.3221,
      "step": 11176
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5288340449333191,
      "learning_rate": 5e-05,
      "loss": 0.3209,
      "step": 11184
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6304508447647095,
      "learning_rate": 5e-05,
      "loss": 0.3446,
      "step": 11192
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7031382322311401,
      "learning_rate": 5e-05,
      "loss": 0.3415,
      "step": 11200
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.612901508808136,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 11208
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6426002979278564,
      "learning_rate": 5e-05,
      "loss": 0.3575,
      "step": 11216
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5787346959114075,
      "learning_rate": 5e-05,
      "loss": 0.3285,
      "step": 11224
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.628742516040802,
      "learning_rate": 5e-05,
      "loss": 0.3486,
      "step": 11232
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5947917103767395,
      "learning_rate": 5e-05,
      "loss": 0.3479,
      "step": 11240
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5434396266937256,
      "learning_rate": 5e-05,
      "loss": 0.3243,
      "step": 11248
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6459410190582275,
      "learning_rate": 5e-05,
      "loss": 0.3116,
      "step": 11256
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.710117518901825,
      "learning_rate": 5e-05,
      "loss": 0.3378,
      "step": 11264
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.7025057673454285,
      "learning_rate": 5e-05,
      "loss": 0.3725,
      "step": 11272
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6564143896102905,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 11280
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6024602651596069,
      "learning_rate": 5e-05,
      "loss": 0.3489,
      "step": 11288
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.590985119342804,
      "learning_rate": 5e-05,
      "loss": 0.2998,
      "step": 11296
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.7937561869621277,
      "learning_rate": 5e-05,
      "loss": 0.3549,
      "step": 11304
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6184043288230896,
      "learning_rate": 5e-05,
      "loss": 0.3442,
      "step": 11312
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6843296885490417,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 11320
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5732327699661255,
      "learning_rate": 5e-05,
      "loss": 0.3066,
      "step": 11328
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.8154037594795227,
      "learning_rate": 5e-05,
      "loss": 0.3279,
      "step": 11336
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6709175109863281,
      "learning_rate": 5e-05,
      "loss": 0.3351,
      "step": 11344
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6492621898651123,
      "learning_rate": 5e-05,
      "loss": 0.3707,
      "step": 11352
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5709981322288513,
      "learning_rate": 5e-05,
      "loss": 0.3473,
      "step": 11360
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6829319596290588,
      "learning_rate": 5e-05,
      "loss": 0.3634,
      "step": 11368
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5756194591522217,
      "learning_rate": 5e-05,
      "loss": 0.3332,
      "step": 11376
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6401761770248413,
      "learning_rate": 5e-05,
      "loss": 0.3408,
      "step": 11384
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6658797860145569,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 11392
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5130249261856079,
      "learning_rate": 5e-05,
      "loss": 0.3273,
      "step": 11400
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6292341947555542,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 11408
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5527123212814331,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 11416
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6405094265937805,
      "learning_rate": 5e-05,
      "loss": 0.3504,
      "step": 11424
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6521744132041931,
      "learning_rate": 5e-05,
      "loss": 0.3582,
      "step": 11432
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5815507173538208,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 11440
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.547877311706543,
      "learning_rate": 5e-05,
      "loss": 0.3395,
      "step": 11448
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5339456796646118,
      "learning_rate": 5e-05,
      "loss": 0.3492,
      "step": 11456
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.7082332372665405,
      "learning_rate": 5e-05,
      "loss": 0.3579,
      "step": 11464
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5176277160644531,
      "learning_rate": 5e-05,
      "loss": 0.3488,
      "step": 11472
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.569380521774292,
      "learning_rate": 5e-05,
      "loss": 0.3233,
      "step": 11480
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.691709578037262,
      "learning_rate": 5e-05,
      "loss": 0.3291,
      "step": 11488
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6718136072158813,
      "learning_rate": 5e-05,
      "loss": 0.3506,
      "step": 11496
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.685575544834137,
      "learning_rate": 5e-05,
      "loss": 0.3278,
      "step": 11504
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.7056499123573303,
      "learning_rate": 5e-05,
      "loss": 0.3368,
      "step": 11512
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.636131227016449,
      "learning_rate": 5e-05,
      "loss": 0.3323,
      "step": 11520
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5660071969032288,
      "learning_rate": 5e-05,
      "loss": 0.3591,
      "step": 11528
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.698265552520752,
      "learning_rate": 5e-05,
      "loss": 0.3574,
      "step": 11536
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5842968821525574,
      "learning_rate": 5e-05,
      "loss": 0.3296,
      "step": 11544
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5728145837783813,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 11552
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6298828125,
      "learning_rate": 5e-05,
      "loss": 0.3555,
      "step": 11560
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5318267345428467,
      "learning_rate": 5e-05,
      "loss": 0.3126,
      "step": 11568
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6056036353111267,
      "learning_rate": 5e-05,
      "loss": 0.3488,
      "step": 11576
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.59639972448349,
      "learning_rate": 5e-05,
      "loss": 0.3416,
      "step": 11584
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6202359795570374,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 11592
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.592189610004425,
      "learning_rate": 5e-05,
      "loss": 0.3168,
      "step": 11600
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7520476579666138,
      "learning_rate": 5e-05,
      "loss": 0.3291,
      "step": 11608
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5891563892364502,
      "learning_rate": 5e-05,
      "loss": 0.3433,
      "step": 11616
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6591809988021851,
      "learning_rate": 5e-05,
      "loss": 0.3462,
      "step": 11624
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6342686414718628,
      "learning_rate": 5e-05,
      "loss": 0.3345,
      "step": 11632
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.595903217792511,
      "learning_rate": 5e-05,
      "loss": 0.3466,
      "step": 11640
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6058556437492371,
      "learning_rate": 5e-05,
      "loss": 0.301,
      "step": 11648
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7033528685569763,
      "learning_rate": 5e-05,
      "loss": 0.3442,
      "step": 11656
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6492971181869507,
      "learning_rate": 5e-05,
      "loss": 0.3532,
      "step": 11664
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6569737792015076,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 11672
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.771705687046051,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 11680
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7161868810653687,
      "learning_rate": 5e-05,
      "loss": 0.3243,
      "step": 11688
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5440450310707092,
      "learning_rate": 5e-05,
      "loss": 0.3366,
      "step": 11696
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5649595260620117,
      "learning_rate": 5e-05,
      "loss": 0.3177,
      "step": 11704
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6772236227989197,
      "learning_rate": 5e-05,
      "loss": 0.3506,
      "step": 11712
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5580647587776184,
      "learning_rate": 5e-05,
      "loss": 0.3074,
      "step": 11720
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5987511277198792,
      "learning_rate": 5e-05,
      "loss": 0.3566,
      "step": 11728
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6047521829605103,
      "learning_rate": 5e-05,
      "loss": 0.3304,
      "step": 11736
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6377179622650146,
      "learning_rate": 5e-05,
      "loss": 0.3549,
      "step": 11744
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5707436800003052,
      "learning_rate": 5e-05,
      "loss": 0.3392,
      "step": 11752
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5507115721702576,
      "learning_rate": 5e-05,
      "loss": 0.353,
      "step": 11760
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7092676162719727,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 11768
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.635123074054718,
      "learning_rate": 5e-05,
      "loss": 0.3399,
      "step": 11776
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5835289359092712,
      "learning_rate": 5e-05,
      "loss": 0.3374,
      "step": 11784
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.606419026851654,
      "learning_rate": 5e-05,
      "loss": 0.3399,
      "step": 11792
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7099804282188416,
      "learning_rate": 5e-05,
      "loss": 0.328,
      "step": 11800
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5196685194969177,
      "learning_rate": 5e-05,
      "loss": 0.3215,
      "step": 11808
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5853439569473267,
      "learning_rate": 5e-05,
      "loss": 0.3132,
      "step": 11816
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5489302277565002,
      "learning_rate": 5e-05,
      "loss": 0.3337,
      "step": 11824
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.716905951499939,
      "learning_rate": 5e-05,
      "loss": 0.3293,
      "step": 11832
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7937130928039551,
      "learning_rate": 5e-05,
      "loss": 0.2975,
      "step": 11840
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6678540110588074,
      "learning_rate": 5e-05,
      "loss": 0.3343,
      "step": 11848
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5902584791183472,
      "learning_rate": 5e-05,
      "loss": 0.3313,
      "step": 11856
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6163379549980164,
      "learning_rate": 5e-05,
      "loss": 0.326,
      "step": 11864
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6304711103439331,
      "learning_rate": 5e-05,
      "loss": 0.3268,
      "step": 11872
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5409927368164062,
      "learning_rate": 5e-05,
      "loss": 0.3591,
      "step": 11880
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6160233616828918,
      "learning_rate": 5e-05,
      "loss": 0.3252,
      "step": 11888
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6242266297340393,
      "learning_rate": 5e-05,
      "loss": 0.3593,
      "step": 11896
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6340054273605347,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 11904
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.5362910032272339,
      "learning_rate": 5e-05,
      "loss": 0.3524,
      "step": 11912
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5531531572341919,
      "learning_rate": 5e-05,
      "loss": 0.3184,
      "step": 11920
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6106785535812378,
      "learning_rate": 5e-05,
      "loss": 0.3285,
      "step": 11928
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6344780921936035,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 11936
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6520143151283264,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 11944
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.531554639339447,
      "learning_rate": 5e-05,
      "loss": 0.332,
      "step": 11952
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7452819347381592,
      "learning_rate": 5e-05,
      "loss": 0.3465,
      "step": 11960
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5295295119285583,
      "learning_rate": 5e-05,
      "loss": 0.3271,
      "step": 11968
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0487278699874878,
      "learning_rate": 5e-05,
      "loss": 0.343,
      "step": 11976
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6453499794006348,
      "learning_rate": 5e-05,
      "loss": 0.3475,
      "step": 11984
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7360194325447083,
      "learning_rate": 5e-05,
      "loss": 0.328,
      "step": 11992
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6470568776130676,
      "learning_rate": 5e-05,
      "loss": 0.3626,
      "step": 12000
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6865128874778748,
      "learning_rate": 5e-05,
      "loss": 0.3506,
      "step": 12008
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5563745498657227,
      "learning_rate": 5e-05,
      "loss": 0.3329,
      "step": 12016
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8236521482467651,
      "learning_rate": 5e-05,
      "loss": 0.3594,
      "step": 12024
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5963562726974487,
      "learning_rate": 5e-05,
      "loss": 0.3268,
      "step": 12032
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5890541076660156,
      "learning_rate": 5e-05,
      "loss": 0.3296,
      "step": 12040
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6132841110229492,
      "learning_rate": 5e-05,
      "loss": 0.34,
      "step": 12048
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8229798078536987,
      "learning_rate": 5e-05,
      "loss": 0.3399,
      "step": 12056
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6437252163887024,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 12064
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5740798115730286,
      "learning_rate": 5e-05,
      "loss": 0.3483,
      "step": 12072
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5985463261604309,
      "learning_rate": 5e-05,
      "loss": 0.3286,
      "step": 12080
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5400152206420898,
      "learning_rate": 5e-05,
      "loss": 0.3679,
      "step": 12088
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6278745532035828,
      "learning_rate": 5e-05,
      "loss": 0.3287,
      "step": 12096
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5749889016151428,
      "learning_rate": 5e-05,
      "loss": 0.3178,
      "step": 12104
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6737114191055298,
      "learning_rate": 5e-05,
      "loss": 0.3327,
      "step": 12112
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6487053632736206,
      "learning_rate": 5e-05,
      "loss": 0.3558,
      "step": 12120
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6157284379005432,
      "learning_rate": 5e-05,
      "loss": 0.3354,
      "step": 12128
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5321904420852661,
      "learning_rate": 5e-05,
      "loss": 0.3385,
      "step": 12136
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6395238041877747,
      "learning_rate": 5e-05,
      "loss": 0.3327,
      "step": 12144
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5717371702194214,
      "learning_rate": 5e-05,
      "loss": 0.3616,
      "step": 12152
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6063881516456604,
      "learning_rate": 5e-05,
      "loss": 0.3152,
      "step": 12160
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6649309992790222,
      "learning_rate": 5e-05,
      "loss": 0.3516,
      "step": 12168
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5974660515785217,
      "learning_rate": 5e-05,
      "loss": 0.3606,
      "step": 12176
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6559849381446838,
      "learning_rate": 5e-05,
      "loss": 0.319,
      "step": 12184
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.567161500453949,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 12192
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6056874394416809,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 12200
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.7146872282028198,
      "learning_rate": 5e-05,
      "loss": 0.3642,
      "step": 12208
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6598911285400391,
      "learning_rate": 5e-05,
      "loss": 0.3412,
      "step": 12216
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6921074390411377,
      "learning_rate": 5e-05,
      "loss": 0.3213,
      "step": 12224
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6323990821838379,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 12232
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6512022614479065,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 12240
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6099566221237183,
      "learning_rate": 5e-05,
      "loss": 0.3382,
      "step": 12248
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5910882353782654,
      "learning_rate": 5e-05,
      "loss": 0.3006,
      "step": 12256
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6301530003547668,
      "learning_rate": 5e-05,
      "loss": 0.3446,
      "step": 12264
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.715918242931366,
      "learning_rate": 5e-05,
      "loss": 0.3673,
      "step": 12272
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8084911704063416,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 12280
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5876929759979248,
      "learning_rate": 5e-05,
      "loss": 0.3359,
      "step": 12288
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6956793665885925,
      "learning_rate": 5e-05,
      "loss": 0.3503,
      "step": 12296
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7090005874633789,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 12304
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5381858944892883,
      "learning_rate": 5e-05,
      "loss": 0.336,
      "step": 12312
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8120433688163757,
      "learning_rate": 5e-05,
      "loss": 0.3436,
      "step": 12320
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6244792938232422,
      "learning_rate": 5e-05,
      "loss": 0.337,
      "step": 12328
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7137452960014343,
      "learning_rate": 5e-05,
      "loss": 0.342,
      "step": 12336
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6996443271636963,
      "learning_rate": 5e-05,
      "loss": 0.376,
      "step": 12344
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5973717570304871,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 12352
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8399800658226013,
      "learning_rate": 5e-05,
      "loss": 0.3082,
      "step": 12360
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6962427496910095,
      "learning_rate": 5e-05,
      "loss": 0.3647,
      "step": 12368
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6286700963973999,
      "learning_rate": 5e-05,
      "loss": 0.3286,
      "step": 12376
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5887457132339478,
      "learning_rate": 5e-05,
      "loss": 0.3212,
      "step": 12384
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6213966012001038,
      "learning_rate": 5e-05,
      "loss": 0.3429,
      "step": 12392
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6727046966552734,
      "learning_rate": 5e-05,
      "loss": 0.3571,
      "step": 12400
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.49093547463417053,
      "learning_rate": 5e-05,
      "loss": 0.3427,
      "step": 12408
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7003321647644043,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 12416
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6371675729751587,
      "learning_rate": 5e-05,
      "loss": 0.3299,
      "step": 12424
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6463663578033447,
      "learning_rate": 5e-05,
      "loss": 0.3414,
      "step": 12432
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7057577967643738,
      "learning_rate": 5e-05,
      "loss": 0.3096,
      "step": 12440
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6851235628128052,
      "learning_rate": 5e-05,
      "loss": 0.3702,
      "step": 12448
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6244515180587769,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 12456
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6771531701087952,
      "learning_rate": 5e-05,
      "loss": 0.3431,
      "step": 12464
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6031821966171265,
      "learning_rate": 5e-05,
      "loss": 0.3085,
      "step": 12472
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5300830602645874,
      "learning_rate": 5e-05,
      "loss": 0.3071,
      "step": 12480
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6917369961738586,
      "learning_rate": 5e-05,
      "loss": 0.3413,
      "step": 12488
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6523709893226624,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 12496
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6497446894645691,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 12504
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6984732747077942,
      "learning_rate": 5e-05,
      "loss": 0.3367,
      "step": 12512
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5801413655281067,
      "learning_rate": 5e-05,
      "loss": 0.3271,
      "step": 12520
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5526894927024841,
      "learning_rate": 5e-05,
      "loss": 0.372,
      "step": 12528
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6348097324371338,
      "learning_rate": 5e-05,
      "loss": 0.3454,
      "step": 12536
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7753379940986633,
      "learning_rate": 5e-05,
      "loss": 0.3101,
      "step": 12544
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5370038151741028,
      "learning_rate": 5e-05,
      "loss": 0.328,
      "step": 12552
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6746319532394409,
      "learning_rate": 5e-05,
      "loss": 0.3545,
      "step": 12560
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5898613333702087,
      "learning_rate": 5e-05,
      "loss": 0.3168,
      "step": 12568
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.621984601020813,
      "learning_rate": 5e-05,
      "loss": 0.3454,
      "step": 12576
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5768471360206604,
      "learning_rate": 5e-05,
      "loss": 0.3318,
      "step": 12584
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.608839213848114,
      "learning_rate": 5e-05,
      "loss": 0.3328,
      "step": 12592
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6616581082344055,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 12600
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6114498376846313,
      "learning_rate": 5e-05,
      "loss": 0.3455,
      "step": 12608
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6122312545776367,
      "learning_rate": 5e-05,
      "loss": 0.3299,
      "step": 12616
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6086902618408203,
      "learning_rate": 5e-05,
      "loss": 0.3279,
      "step": 12624
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6335570216178894,
      "learning_rate": 5e-05,
      "loss": 0.3355,
      "step": 12632
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5268168449401855,
      "learning_rate": 5e-05,
      "loss": 0.3479,
      "step": 12640
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5810368061065674,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 12648
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6622350811958313,
      "learning_rate": 5e-05,
      "loss": 0.3597,
      "step": 12656
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5566619634628296,
      "learning_rate": 5e-05,
      "loss": 0.3634,
      "step": 12664
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6710377931594849,
      "learning_rate": 5e-05,
      "loss": 0.3278,
      "step": 12672
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.840349555015564,
      "learning_rate": 5e-05,
      "loss": 0.3417,
      "step": 12680
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6069295406341553,
      "learning_rate": 5e-05,
      "loss": 0.3427,
      "step": 12688
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.55525141954422,
      "learning_rate": 5e-05,
      "loss": 0.3389,
      "step": 12696
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6987987756729126,
      "learning_rate": 5e-05,
      "loss": 0.3293,
      "step": 12704
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6269935965538025,
      "learning_rate": 5e-05,
      "loss": 0.3539,
      "step": 12712
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6381461024284363,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 12720
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6536773443222046,
      "learning_rate": 5e-05,
      "loss": 0.3424,
      "step": 12728
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6597931385040283,
      "learning_rate": 5e-05,
      "loss": 0.374,
      "step": 12736
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.7067801356315613,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 12744
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5479772090911865,
      "learning_rate": 5e-05,
      "loss": 0.3145,
      "step": 12752
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6588044166564941,
      "learning_rate": 5e-05,
      "loss": 0.3174,
      "step": 12760
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6457242369651794,
      "learning_rate": 5e-05,
      "loss": 0.3468,
      "step": 12768
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.597835123538971,
      "learning_rate": 5e-05,
      "loss": 0.3695,
      "step": 12776
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.640159547328949,
      "learning_rate": 5e-05,
      "loss": 0.351,
      "step": 12784
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6107673645019531,
      "learning_rate": 5e-05,
      "loss": 0.3362,
      "step": 12792
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.658789336681366,
      "learning_rate": 5e-05,
      "loss": 0.3339,
      "step": 12800
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5814934372901917,
      "learning_rate": 5e-05,
      "loss": 0.341,
      "step": 12808
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6060069799423218,
      "learning_rate": 5e-05,
      "loss": 0.357,
      "step": 12816
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.7148295044898987,
      "learning_rate": 5e-05,
      "loss": 0.3442,
      "step": 12824
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6135331392288208,
      "learning_rate": 5e-05,
      "loss": 0.3033,
      "step": 12832
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5604245066642761,
      "learning_rate": 5e-05,
      "loss": 0.3143,
      "step": 12840
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.610996425151825,
      "learning_rate": 5e-05,
      "loss": 0.3575,
      "step": 12848
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6522879600524902,
      "learning_rate": 5e-05,
      "loss": 0.3221,
      "step": 12856
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6367505788803101,
      "learning_rate": 5e-05,
      "loss": 0.3547,
      "step": 12864
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6158141493797302,
      "learning_rate": 5e-05,
      "loss": 0.3579,
      "step": 12872
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6268600821495056,
      "learning_rate": 5e-05,
      "loss": 0.3361,
      "step": 12880
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6379494071006775,
      "learning_rate": 5e-05,
      "loss": 0.3554,
      "step": 12888
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5740927457809448,
      "learning_rate": 5e-05,
      "loss": 0.3539,
      "step": 12896
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6430952548980713,
      "learning_rate": 5e-05,
      "loss": 0.3754,
      "step": 12904
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6251527070999146,
      "learning_rate": 5e-05,
      "loss": 0.3721,
      "step": 12912
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6260532140731812,
      "learning_rate": 5e-05,
      "loss": 0.3051,
      "step": 12920
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6182217597961426,
      "learning_rate": 5e-05,
      "loss": 0.3338,
      "step": 12928
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7064961194992065,
      "learning_rate": 5e-05,
      "loss": 0.3219,
      "step": 12936
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6281842589378357,
      "learning_rate": 5e-05,
      "loss": 0.3121,
      "step": 12944
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7901157140731812,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 12952
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6756327748298645,
      "learning_rate": 5e-05,
      "loss": 0.3123,
      "step": 12960
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6468445658683777,
      "learning_rate": 5e-05,
      "loss": 0.352,
      "step": 12968
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6575661897659302,
      "learning_rate": 5e-05,
      "loss": 0.3332,
      "step": 12976
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6398690938949585,
      "learning_rate": 5e-05,
      "loss": 0.3306,
      "step": 12984
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7061160206794739,
      "learning_rate": 5e-05,
      "loss": 0.3561,
      "step": 12992
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7768189311027527,
      "learning_rate": 5e-05,
      "loss": 0.3464,
      "step": 13000
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6080247759819031,
      "learning_rate": 5e-05,
      "loss": 0.303,
      "step": 13008
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.568785548210144,
      "learning_rate": 5e-05,
      "loss": 0.3749,
      "step": 13016
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.617634117603302,
      "learning_rate": 5e-05,
      "loss": 0.3338,
      "step": 13024
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7300850749015808,
      "learning_rate": 5e-05,
      "loss": 0.3111,
      "step": 13032
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5489813089370728,
      "learning_rate": 5e-05,
      "loss": 0.3342,
      "step": 13040
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5304684042930603,
      "learning_rate": 5e-05,
      "loss": 0.316,
      "step": 13048
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6757089495658875,
      "learning_rate": 5e-05,
      "loss": 0.3417,
      "step": 13056
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5326083898544312,
      "learning_rate": 5e-05,
      "loss": 0.3204,
      "step": 13064
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5400723814964294,
      "learning_rate": 5e-05,
      "loss": 0.3496,
      "step": 13072
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6855474710464478,
      "learning_rate": 5e-05,
      "loss": 0.3402,
      "step": 13080
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.675593376159668,
      "learning_rate": 5e-05,
      "loss": 0.3412,
      "step": 13088
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6486648321151733,
      "learning_rate": 5e-05,
      "loss": 0.3294,
      "step": 13096
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6330901384353638,
      "learning_rate": 5e-05,
      "loss": 0.3336,
      "step": 13104
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6656292080879211,
      "learning_rate": 5e-05,
      "loss": 0.325,
      "step": 13112
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6310739517211914,
      "learning_rate": 5e-05,
      "loss": 0.3161,
      "step": 13120
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.7094528675079346,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 13128
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6470767259597778,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 13136
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.703521728515625,
      "learning_rate": 5e-05,
      "loss": 0.3212,
      "step": 13144
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5986424088478088,
      "learning_rate": 5e-05,
      "loss": 0.3443,
      "step": 13152
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.636019766330719,
      "learning_rate": 5e-05,
      "loss": 0.3147,
      "step": 13160
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5563703179359436,
      "learning_rate": 5e-05,
      "loss": 0.3625,
      "step": 13168
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5875962972640991,
      "learning_rate": 5e-05,
      "loss": 0.3573,
      "step": 13176
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6761206388473511,
      "learning_rate": 5e-05,
      "loss": 0.3323,
      "step": 13184
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5899589657783508,
      "learning_rate": 5e-05,
      "loss": 0.3304,
      "step": 13192
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6160292625427246,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 13200
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5893645286560059,
      "learning_rate": 5e-05,
      "loss": 0.3327,
      "step": 13208
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.722973644733429,
      "learning_rate": 5e-05,
      "loss": 0.3383,
      "step": 13216
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6306309700012207,
      "learning_rate": 5e-05,
      "loss": 0.3186,
      "step": 13224
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6907533407211304,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 13232
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6854202747344971,
      "learning_rate": 5e-05,
      "loss": 0.3484,
      "step": 13240
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6367377638816833,
      "learning_rate": 5e-05,
      "loss": 0.3235,
      "step": 13248
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5603188872337341,
      "learning_rate": 5e-05,
      "loss": 0.3296,
      "step": 13256
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6324942708015442,
      "learning_rate": 5e-05,
      "loss": 0.3104,
      "step": 13264
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.568720281124115,
      "learning_rate": 5e-05,
      "loss": 0.3573,
      "step": 13272
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6612778306007385,
      "learning_rate": 5e-05,
      "loss": 0.3628,
      "step": 13280
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6704469919204712,
      "learning_rate": 5e-05,
      "loss": 0.3411,
      "step": 13288
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7068712115287781,
      "learning_rate": 5e-05,
      "loss": 0.3367,
      "step": 13296
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6891135573387146,
      "learning_rate": 5e-05,
      "loss": 0.3538,
      "step": 13304
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6896678805351257,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 13312
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6856591105461121,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 13320
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6525436639785767,
      "learning_rate": 5e-05,
      "loss": 0.379,
      "step": 13328
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6710067987442017,
      "learning_rate": 5e-05,
      "loss": 0.3182,
      "step": 13336
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6060940027236938,
      "learning_rate": 5e-05,
      "loss": 0.3373,
      "step": 13344
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7508033514022827,
      "learning_rate": 5e-05,
      "loss": 0.3297,
      "step": 13352
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6774634718894958,
      "learning_rate": 5e-05,
      "loss": 0.3367,
      "step": 13360
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6474097967147827,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 13368
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.592530369758606,
      "learning_rate": 5e-05,
      "loss": 0.3148,
      "step": 13376
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6060763597488403,
      "learning_rate": 5e-05,
      "loss": 0.3507,
      "step": 13384
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6278625130653381,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 13392
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5591433644294739,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 13400
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5794306993484497,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 13408
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.672698974609375,
      "learning_rate": 5e-05,
      "loss": 0.3303,
      "step": 13416
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6143240332603455,
      "learning_rate": 5e-05,
      "loss": 0.3502,
      "step": 13424
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6505647301673889,
      "learning_rate": 5e-05,
      "loss": 0.3352,
      "step": 13432
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5838440656661987,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 13440
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6989253759384155,
      "learning_rate": 5e-05,
      "loss": 0.3051,
      "step": 13448
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5670658349990845,
      "learning_rate": 5e-05,
      "loss": 0.3358,
      "step": 13456
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.600796639919281,
      "learning_rate": 5e-05,
      "loss": 0.3643,
      "step": 13464
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6952493190765381,
      "learning_rate": 5e-05,
      "loss": 0.3476,
      "step": 13472
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5928500294685364,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 13480
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6590718626976013,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 13488
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6487753391265869,
      "learning_rate": 5e-05,
      "loss": 0.3344,
      "step": 13496
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7143438458442688,
      "learning_rate": 5e-05,
      "loss": 0.3182,
      "step": 13504
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7359451055526733,
      "learning_rate": 5e-05,
      "loss": 0.3451,
      "step": 13512
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5602722764015198,
      "learning_rate": 5e-05,
      "loss": 0.3532,
      "step": 13520
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6258971691131592,
      "learning_rate": 5e-05,
      "loss": 0.3375,
      "step": 13528
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6704174280166626,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 13536
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7885693907737732,
      "learning_rate": 5e-05,
      "loss": 0.3126,
      "step": 13544
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6394743323326111,
      "learning_rate": 5e-05,
      "loss": 0.329,
      "step": 13552
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6512138247489929,
      "learning_rate": 5e-05,
      "loss": 0.3235,
      "step": 13560
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.9445533752441406,
      "learning_rate": 5e-05,
      "loss": 0.3383,
      "step": 13568
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5462286472320557,
      "learning_rate": 5e-05,
      "loss": 0.2971,
      "step": 13576
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5993353724479675,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 13584
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6178168654441833,
      "learning_rate": 5e-05,
      "loss": 0.3176,
      "step": 13592
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6208893060684204,
      "learning_rate": 5e-05,
      "loss": 0.3339,
      "step": 13600
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6044240593910217,
      "learning_rate": 5e-05,
      "loss": 0.3125,
      "step": 13608
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6414117217063904,
      "learning_rate": 5e-05,
      "loss": 0.3494,
      "step": 13616
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6194561719894409,
      "learning_rate": 5e-05,
      "loss": 0.3141,
      "step": 13624
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.963716447353363,
      "learning_rate": 5e-05,
      "loss": 0.346,
      "step": 13632
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6472750902175903,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 13640
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6420692801475525,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 13648
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6100112795829773,
      "learning_rate": 5e-05,
      "loss": 0.3477,
      "step": 13656
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6425687074661255,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 13664
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6155884265899658,
      "learning_rate": 5e-05,
      "loss": 0.2936,
      "step": 13672
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6760955452919006,
      "learning_rate": 5e-05,
      "loss": 0.3263,
      "step": 13680
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5732349753379822,
      "learning_rate": 5e-05,
      "loss": 0.3394,
      "step": 13688
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6102427840232849,
      "learning_rate": 5e-05,
      "loss": 0.3549,
      "step": 13696
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5485654473304749,
      "learning_rate": 5e-05,
      "loss": 0.3462,
      "step": 13704
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5769220590591431,
      "learning_rate": 5e-05,
      "loss": 0.3048,
      "step": 13712
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5918337106704712,
      "learning_rate": 5e-05,
      "loss": 0.3698,
      "step": 13720
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5899944305419922,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 13728
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.631452202796936,
      "learning_rate": 5e-05,
      "loss": 0.3699,
      "step": 13736
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6984722018241882,
      "learning_rate": 5e-05,
      "loss": 0.3194,
      "step": 13744
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6541369557380676,
      "learning_rate": 5e-05,
      "loss": 0.3612,
      "step": 13752
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.641700267791748,
      "learning_rate": 5e-05,
      "loss": 0.3384,
      "step": 13760
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6158364415168762,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 13768
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6352589130401611,
      "learning_rate": 5e-05,
      "loss": 0.3335,
      "step": 13776
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6964265704154968,
      "learning_rate": 5e-05,
      "loss": 0.3381,
      "step": 13784
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.7183162569999695,
      "learning_rate": 5e-05,
      "loss": 0.3417,
      "step": 13792
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6766141057014465,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 13800
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6082723140716553,
      "learning_rate": 5e-05,
      "loss": 0.3263,
      "step": 13808
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5787392258644104,
      "learning_rate": 5e-05,
      "loss": 0.3668,
      "step": 13816
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.7151544690132141,
      "learning_rate": 5e-05,
      "loss": 0.3123,
      "step": 13824
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5462286472320557,
      "learning_rate": 5e-05,
      "loss": 0.3384,
      "step": 13832
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6337451934814453,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 13840
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5825706124305725,
      "learning_rate": 5e-05,
      "loss": 0.3236,
      "step": 13848
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.8408116698265076,
      "learning_rate": 5e-05,
      "loss": 0.3717,
      "step": 13856
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6286413669586182,
      "learning_rate": 5e-05,
      "loss": 0.3347,
      "step": 13864
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5989090204238892,
      "learning_rate": 5e-05,
      "loss": 0.3249,
      "step": 13872
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.7416523098945618,
      "learning_rate": 5e-05,
      "loss": 0.3401,
      "step": 13880
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5157090425491333,
      "learning_rate": 5e-05,
      "loss": 0.3487,
      "step": 13888
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5507614016532898,
      "learning_rate": 5e-05,
      "loss": 0.3375,
      "step": 13896
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.7078441381454468,
      "learning_rate": 5e-05,
      "loss": 0.3532,
      "step": 13904
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5865012407302856,
      "learning_rate": 5e-05,
      "loss": 0.2942,
      "step": 13912
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5893558859825134,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 13920
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7535320520401001,
      "learning_rate": 5e-05,
      "loss": 0.3395,
      "step": 13928
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5951166152954102,
      "learning_rate": 5e-05,
      "loss": 0.3407,
      "step": 13936
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7058011889457703,
      "learning_rate": 5e-05,
      "loss": 0.3468,
      "step": 13944
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6508421897888184,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 13952
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5979045033454895,
      "learning_rate": 5e-05,
      "loss": 0.3331,
      "step": 13960
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6682398319244385,
      "learning_rate": 5e-05,
      "loss": 0.3358,
      "step": 13968
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6537430286407471,
      "learning_rate": 5e-05,
      "loss": 0.3161,
      "step": 13976
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5988871455192566,
      "learning_rate": 5e-05,
      "loss": 0.3475,
      "step": 13984
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6864838600158691,
      "learning_rate": 5e-05,
      "loss": 0.336,
      "step": 13992
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6882311701774597,
      "learning_rate": 5e-05,
      "loss": 0.3512,
      "step": 14000
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6271689534187317,
      "learning_rate": 5e-05,
      "loss": 0.3164,
      "step": 14008
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6261739730834961,
      "learning_rate": 5e-05,
      "loss": 0.3432,
      "step": 14016
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5739495754241943,
      "learning_rate": 5e-05,
      "loss": 0.3383,
      "step": 14024
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5990906953811646,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 14032
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6063523292541504,
      "learning_rate": 5e-05,
      "loss": 0.3526,
      "step": 14040
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5971913933753967,
      "learning_rate": 5e-05,
      "loss": 0.3059,
      "step": 14048
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7656026482582092,
      "learning_rate": 5e-05,
      "loss": 0.3238,
      "step": 14056
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6767055988311768,
      "learning_rate": 5e-05,
      "loss": 0.3442,
      "step": 14064
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6358397603034973,
      "learning_rate": 5e-05,
      "loss": 0.3459,
      "step": 14072
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6460497975349426,
      "learning_rate": 5e-05,
      "loss": 0.3565,
      "step": 14080
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6322004795074463,
      "learning_rate": 5e-05,
      "loss": 0.3695,
      "step": 14088
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.7252414226531982,
      "learning_rate": 5e-05,
      "loss": 0.365,
      "step": 14096
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.7393078804016113,
      "learning_rate": 5e-05,
      "loss": 0.3175,
      "step": 14104
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.701934814453125,
      "learning_rate": 5e-05,
      "loss": 0.3219,
      "step": 14112
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6205943822860718,
      "learning_rate": 5e-05,
      "loss": 0.3434,
      "step": 14120
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6233163475990295,
      "learning_rate": 5e-05,
      "loss": 0.3371,
      "step": 14128
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5938499569892883,
      "learning_rate": 5e-05,
      "loss": 0.3077,
      "step": 14136
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6789815425872803,
      "learning_rate": 5e-05,
      "loss": 0.3049,
      "step": 14144
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5949331521987915,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 14152
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.49891090393066406,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 14160
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5912777781486511,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 14168
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6043924689292908,
      "learning_rate": 5e-05,
      "loss": 0.346,
      "step": 14176
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5648824572563171,
      "learning_rate": 5e-05,
      "loss": 0.3378,
      "step": 14184
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6076279282569885,
      "learning_rate": 5e-05,
      "loss": 0.3554,
      "step": 14192
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6202168464660645,
      "learning_rate": 5e-05,
      "loss": 0.3436,
      "step": 14200
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5547422170639038,
      "learning_rate": 5e-05,
      "loss": 0.3623,
      "step": 14208
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6896571516990662,
      "learning_rate": 5e-05,
      "loss": 0.3527,
      "step": 14216
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6047708988189697,
      "learning_rate": 5e-05,
      "loss": 0.3656,
      "step": 14224
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6682305335998535,
      "learning_rate": 5e-05,
      "loss": 0.3385,
      "step": 14232
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.8274959921836853,
      "learning_rate": 5e-05,
      "loss": 0.3098,
      "step": 14240
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.7170155644416809,
      "learning_rate": 5e-05,
      "loss": 0.3317,
      "step": 14248
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6643698215484619,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 14256
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6926830410957336,
      "learning_rate": 5e-05,
      "loss": 0.3591,
      "step": 14264
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6446549296379089,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 14272
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.8057438731193542,
      "learning_rate": 5e-05,
      "loss": 0.3206,
      "step": 14280
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7741034030914307,
      "learning_rate": 5e-05,
      "loss": 0.3301,
      "step": 14288
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5753659605979919,
      "learning_rate": 5e-05,
      "loss": 0.3146,
      "step": 14296
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7607994079589844,
      "learning_rate": 5e-05,
      "loss": 0.3256,
      "step": 14304
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.643658459186554,
      "learning_rate": 5e-05,
      "loss": 0.3398,
      "step": 14312
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6480057835578918,
      "learning_rate": 5e-05,
      "loss": 0.3173,
      "step": 14320
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6134008765220642,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 14328
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6274653077125549,
      "learning_rate": 5e-05,
      "loss": 0.3592,
      "step": 14336
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6430363059043884,
      "learning_rate": 5e-05,
      "loss": 0.3233,
      "step": 14344
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6588088870048523,
      "learning_rate": 5e-05,
      "loss": 0.3403,
      "step": 14352
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6460215449333191,
      "learning_rate": 5e-05,
      "loss": 0.3406,
      "step": 14360
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6017736196517944,
      "learning_rate": 5e-05,
      "loss": 0.3501,
      "step": 14368
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6312772631645203,
      "learning_rate": 5e-05,
      "loss": 0.3418,
      "step": 14376
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6971310377120972,
      "learning_rate": 5e-05,
      "loss": 0.3603,
      "step": 14384
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7097848653793335,
      "learning_rate": 5e-05,
      "loss": 0.3365,
      "step": 14392
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.7371177673339844,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 14400
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6874468922615051,
      "learning_rate": 5e-05,
      "loss": 0.336,
      "step": 14408
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.550162136554718,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 14416
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6348473429679871,
      "learning_rate": 5e-05,
      "loss": 0.3406,
      "step": 14424
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5614758133888245,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 14432
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6299082636833191,
      "learning_rate": 5e-05,
      "loss": 0.34,
      "step": 14440
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6924964189529419,
      "learning_rate": 5e-05,
      "loss": 0.3438,
      "step": 14448
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5224334597587585,
      "learning_rate": 5e-05,
      "loss": 0.3023,
      "step": 14456
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6675623059272766,
      "learning_rate": 5e-05,
      "loss": 0.3327,
      "step": 14464
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.7367401123046875,
      "learning_rate": 5e-05,
      "loss": 0.3208,
      "step": 14472
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6660493612289429,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 14480
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.7211965918540955,
      "learning_rate": 5e-05,
      "loss": 0.3281,
      "step": 14488
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5733621716499329,
      "learning_rate": 5e-05,
      "loss": 0.3432,
      "step": 14496
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.578900158405304,
      "learning_rate": 5e-05,
      "loss": 0.3362,
      "step": 14504
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5760042071342468,
      "learning_rate": 5e-05,
      "loss": 0.3324,
      "step": 14512
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.630338728427887,
      "learning_rate": 5e-05,
      "loss": 0.3722,
      "step": 14520
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5959977507591248,
      "learning_rate": 5e-05,
      "loss": 0.3471,
      "step": 14528
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5858907699584961,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 14536
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.7231881618499756,
      "learning_rate": 5e-05,
      "loss": 0.3334,
      "step": 14544
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6340751051902771,
      "learning_rate": 5e-05,
      "loss": 0.3354,
      "step": 14552
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5452953577041626,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 14560
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6270202994346619,
      "learning_rate": 5e-05,
      "loss": 0.3468,
      "step": 14568
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6271148920059204,
      "learning_rate": 5e-05,
      "loss": 0.3327,
      "step": 14576
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6815518140792847,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 14584
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.7207859754562378,
      "learning_rate": 5e-05,
      "loss": 0.3112,
      "step": 14592
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6768799424171448,
      "learning_rate": 5e-05,
      "loss": 0.3326,
      "step": 14600
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6510359644889832,
      "learning_rate": 5e-05,
      "loss": 0.3464,
      "step": 14608
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6733402609825134,
      "learning_rate": 5e-05,
      "loss": 0.3164,
      "step": 14616
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6138720512390137,
      "learning_rate": 5e-05,
      "loss": 0.3495,
      "step": 14624
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6035426259040833,
      "learning_rate": 5e-05,
      "loss": 0.3424,
      "step": 14632
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5780410170555115,
      "learning_rate": 5e-05,
      "loss": 0.3237,
      "step": 14640
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.65375816822052,
      "learning_rate": 5e-05,
      "loss": 0.3241,
      "step": 14648
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5271547436714172,
      "learning_rate": 5e-05,
      "loss": 0.3396,
      "step": 14656
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6635586619377136,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 14664
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6630707383155823,
      "learning_rate": 5e-05,
      "loss": 0.3367,
      "step": 14672
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5852751135826111,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 14680
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6363378763198853,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 14688
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.7804304361343384,
      "learning_rate": 5e-05,
      "loss": 0.3013,
      "step": 14696
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.7162718772888184,
      "learning_rate": 5e-05,
      "loss": 0.3679,
      "step": 14704
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6137699484825134,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 14712
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.613239586353302,
      "learning_rate": 5e-05,
      "loss": 0.3422,
      "step": 14720
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6461473107337952,
      "learning_rate": 5e-05,
      "loss": 0.3209,
      "step": 14728
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5674158930778503,
      "learning_rate": 5e-05,
      "loss": 0.3458,
      "step": 14736
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5472066402435303,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 14744
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6640939712524414,
      "learning_rate": 5e-05,
      "loss": 0.3007,
      "step": 14752
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5756812691688538,
      "learning_rate": 5e-05,
      "loss": 0.3253,
      "step": 14760
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6964619755744934,
      "learning_rate": 5e-05,
      "loss": 0.3447,
      "step": 14768
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6198366284370422,
      "learning_rate": 5e-05,
      "loss": 0.362,
      "step": 14776
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.7361032962799072,
      "learning_rate": 5e-05,
      "loss": 0.3423,
      "step": 14784
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.641174852848053,
      "learning_rate": 5e-05,
      "loss": 0.3432,
      "step": 14792
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6275263428688049,
      "learning_rate": 5e-05,
      "loss": 0.3327,
      "step": 14800
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.654048502445221,
      "learning_rate": 5e-05,
      "loss": 0.3362,
      "step": 14808
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5947369337081909,
      "learning_rate": 5e-05,
      "loss": 0.344,
      "step": 14816
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5171740055084229,
      "learning_rate": 5e-05,
      "loss": 0.343,
      "step": 14824
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.8174650073051453,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 14832
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6239714026451111,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 14840
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5075523257255554,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 14848
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6661487221717834,
      "learning_rate": 5e-05,
      "loss": 0.3476,
      "step": 14856
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6460945010185242,
      "learning_rate": 5e-05,
      "loss": 0.3099,
      "step": 14864
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5619222521781921,
      "learning_rate": 5e-05,
      "loss": 0.3508,
      "step": 14872
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6421956419944763,
      "learning_rate": 5e-05,
      "loss": 0.3557,
      "step": 14880
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6210119128227234,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 14888
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6211260557174683,
      "learning_rate": 5e-05,
      "loss": 0.3531,
      "step": 14896
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5589381456375122,
      "learning_rate": 5e-05,
      "loss": 0.3153,
      "step": 14904
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.6466391682624817,
      "learning_rate": 5e-05,
      "loss": 0.3396,
      "step": 14912
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.819715142250061,
      "learning_rate": 5e-05,
      "loss": 0.3348,
      "step": 14920
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.7990780472755432,
      "learning_rate": 5e-05,
      "loss": 0.3037,
      "step": 14928
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6591547131538391,
      "learning_rate": 5e-05,
      "loss": 0.3375,
      "step": 14936
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.590907871723175,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 14944
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6510206460952759,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 14952
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6034669280052185,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 14960
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6004384160041809,
      "learning_rate": 5e-05,
      "loss": 0.3343,
      "step": 14968
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6659711599349976,
      "learning_rate": 5e-05,
      "loss": 0.3431,
      "step": 14976
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6275471448898315,
      "learning_rate": 5e-05,
      "loss": 0.3492,
      "step": 14984
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.7524515390396118,
      "learning_rate": 5e-05,
      "loss": 0.3143,
      "step": 14992
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5764949917793274,
      "learning_rate": 5e-05,
      "loss": 0.3309,
      "step": 15000
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.665448009967804,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 15008
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6187744736671448,
      "learning_rate": 5e-05,
      "loss": 0.3458,
      "step": 15016
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.641676664352417,
      "learning_rate": 5e-05,
      "loss": 0.3391,
      "step": 15024
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5197027921676636,
      "learning_rate": 5e-05,
      "loss": 0.3757,
      "step": 15032
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.63315349817276,
      "learning_rate": 5e-05,
      "loss": 0.3379,
      "step": 15040
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5927134156227112,
      "learning_rate": 5e-05,
      "loss": 0.315,
      "step": 15048
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6712798476219177,
      "learning_rate": 5e-05,
      "loss": 0.3311,
      "step": 15056
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6106196641921997,
      "learning_rate": 5e-05,
      "loss": 0.3097,
      "step": 15064
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.7430312037467957,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 15072
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6048809289932251,
      "learning_rate": 5e-05,
      "loss": 0.3338,
      "step": 15080
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6163102388381958,
      "learning_rate": 5e-05,
      "loss": 0.3339,
      "step": 15088
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.531665027141571,
      "learning_rate": 5e-05,
      "loss": 0.319,
      "step": 15096
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6227003335952759,
      "learning_rate": 5e-05,
      "loss": 0.301,
      "step": 15104
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6837709546089172,
      "learning_rate": 5e-05,
      "loss": 0.326,
      "step": 15112
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6226503849029541,
      "learning_rate": 5e-05,
      "loss": 0.3382,
      "step": 15120
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5145841240882874,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 15128
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5379015803337097,
      "learning_rate": 5e-05,
      "loss": 0.3264,
      "step": 15136
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6802403330802917,
      "learning_rate": 5e-05,
      "loss": 0.3404,
      "step": 15144
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6617621779441833,
      "learning_rate": 5e-05,
      "loss": 0.3352,
      "step": 15152
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.8279242515563965,
      "learning_rate": 5e-05,
      "loss": 0.3197,
      "step": 15160
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.7393010854721069,
      "learning_rate": 5e-05,
      "loss": 0.3537,
      "step": 15168
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.584282636642456,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 15176
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6154348254203796,
      "learning_rate": 5e-05,
      "loss": 0.3396,
      "step": 15184
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6927316188812256,
      "learning_rate": 5e-05,
      "loss": 0.3208,
      "step": 15192
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6438578367233276,
      "learning_rate": 5e-05,
      "loss": 0.3258,
      "step": 15200
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.7102755904197693,
      "learning_rate": 5e-05,
      "loss": 0.3425,
      "step": 15208
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5879109501838684,
      "learning_rate": 5e-05,
      "loss": 0.3333,
      "step": 15216
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6180247068405151,
      "learning_rate": 5e-05,
      "loss": 0.3058,
      "step": 15224
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6974659562110901,
      "learning_rate": 5e-05,
      "loss": 0.3482,
      "step": 15232
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6124638319015503,
      "learning_rate": 5e-05,
      "loss": 0.3499,
      "step": 15240
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.7472484707832336,
      "learning_rate": 5e-05,
      "loss": 0.3586,
      "step": 15248
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5591773986816406,
      "learning_rate": 5e-05,
      "loss": 0.321,
      "step": 15256
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5596306920051575,
      "learning_rate": 5e-05,
      "loss": 0.3218,
      "step": 15264
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6233142018318176,
      "learning_rate": 5e-05,
      "loss": 0.3341,
      "step": 15272
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6326671242713928,
      "learning_rate": 5e-05,
      "loss": 0.3436,
      "step": 15280
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6013649702072144,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 15288
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6783411502838135,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 15296
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6246435046195984,
      "learning_rate": 5e-05,
      "loss": 0.3594,
      "step": 15304
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6873055696487427,
      "learning_rate": 5e-05,
      "loss": 0.3222,
      "step": 15312
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6353723406791687,
      "learning_rate": 5e-05,
      "loss": 0.32,
      "step": 15320
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.7415704131126404,
      "learning_rate": 5e-05,
      "loss": 0.3691,
      "step": 15328
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5767685174942017,
      "learning_rate": 5e-05,
      "loss": 0.347,
      "step": 15336
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.7173144221305847,
      "learning_rate": 5e-05,
      "loss": 0.3447,
      "step": 15344
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.753494381904602,
      "learning_rate": 5e-05,
      "loss": 0.3372,
      "step": 15352
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5898199081420898,
      "learning_rate": 5e-05,
      "loss": 0.3211,
      "step": 15360
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6339695453643799,
      "learning_rate": 5e-05,
      "loss": 0.3159,
      "step": 15368
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5876471400260925,
      "learning_rate": 5e-05,
      "loss": 0.3336,
      "step": 15376
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5861139893531799,
      "learning_rate": 5e-05,
      "loss": 0.3327,
      "step": 15384
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.548846423625946,
      "learning_rate": 5e-05,
      "loss": 0.3269,
      "step": 15392
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5897868275642395,
      "learning_rate": 5e-05,
      "loss": 0.3574,
      "step": 15400
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6897438168525696,
      "learning_rate": 5e-05,
      "loss": 0.3487,
      "step": 15408
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5661571025848389,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 15416
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7300810813903809,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 15424
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.8479360342025757,
      "learning_rate": 5e-05,
      "loss": 0.3384,
      "step": 15432
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5713685750961304,
      "learning_rate": 5e-05,
      "loss": 0.3522,
      "step": 15440
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5728732347488403,
      "learning_rate": 5e-05,
      "loss": 0.3123,
      "step": 15448
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.584173321723938,
      "learning_rate": 5e-05,
      "loss": 0.3576,
      "step": 15456
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6365965008735657,
      "learning_rate": 5e-05,
      "loss": 0.34,
      "step": 15464
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6299555897712708,
      "learning_rate": 5e-05,
      "loss": 0.3472,
      "step": 15472
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6428099274635315,
      "learning_rate": 5e-05,
      "loss": 0.3318,
      "step": 15480
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5580781698226929,
      "learning_rate": 5e-05,
      "loss": 0.298,
      "step": 15488
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.565958559513092,
      "learning_rate": 5e-05,
      "loss": 0.3188,
      "step": 15496
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5624712705612183,
      "learning_rate": 5e-05,
      "loss": 0.3099,
      "step": 15504
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7308120131492615,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 15512
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6335224509239197,
      "learning_rate": 5e-05,
      "loss": 0.314,
      "step": 15520
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5261327624320984,
      "learning_rate": 5e-05,
      "loss": 0.3383,
      "step": 15528
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5780175924301147,
      "learning_rate": 5e-05,
      "loss": 0.3514,
      "step": 15536
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6513353586196899,
      "learning_rate": 5e-05,
      "loss": 0.3147,
      "step": 15544
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7251093983650208,
      "learning_rate": 5e-05,
      "loss": 0.327,
      "step": 15552
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5971878170967102,
      "learning_rate": 5e-05,
      "loss": 0.3546,
      "step": 15560
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.6731521487236023,
      "learning_rate": 5e-05,
      "loss": 0.3391,
      "step": 15568
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7622411847114563,
      "learning_rate": 5e-05,
      "loss": 0.3305,
      "step": 15576
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5964089632034302,
      "learning_rate": 5e-05,
      "loss": 0.3564,
      "step": 15584
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5557172894477844,
      "learning_rate": 5e-05,
      "loss": 0.3371,
      "step": 15592
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6300152540206909,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 15600
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5386279225349426,
      "learning_rate": 5e-05,
      "loss": 0.3086,
      "step": 15608
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6851733922958374,
      "learning_rate": 5e-05,
      "loss": 0.3582,
      "step": 15616
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8465833067893982,
      "learning_rate": 5e-05,
      "loss": 0.3579,
      "step": 15624
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.689935028553009,
      "learning_rate": 5e-05,
      "loss": 0.3322,
      "step": 15632
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5743706822395325,
      "learning_rate": 5e-05,
      "loss": 0.3287,
      "step": 15640
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7532995939254761,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 15648
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.662663996219635,
      "learning_rate": 5e-05,
      "loss": 0.3101,
      "step": 15656
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5658909678459167,
      "learning_rate": 5e-05,
      "loss": 0.3033,
      "step": 15664
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6982936859130859,
      "learning_rate": 5e-05,
      "loss": 0.3364,
      "step": 15672
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8146449327468872,
      "learning_rate": 5e-05,
      "loss": 0.3548,
      "step": 15680
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6518686413764954,
      "learning_rate": 5e-05,
      "loss": 0.332,
      "step": 15688
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6803175210952759,
      "learning_rate": 5e-05,
      "loss": 0.3117,
      "step": 15696
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5847231149673462,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 15704
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7453836798667908,
      "learning_rate": 5e-05,
      "loss": 0.3359,
      "step": 15712
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6290698647499084,
      "learning_rate": 5e-05,
      "loss": 0.3247,
      "step": 15720
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7103250622749329,
      "learning_rate": 5e-05,
      "loss": 0.3515,
      "step": 15728
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6969968676567078,
      "learning_rate": 5e-05,
      "loss": 0.3222,
      "step": 15736
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6142731308937073,
      "learning_rate": 5e-05,
      "loss": 0.3377,
      "step": 15744
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6525382399559021,
      "learning_rate": 5e-05,
      "loss": 0.3465,
      "step": 15752
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7036953568458557,
      "learning_rate": 5e-05,
      "loss": 0.311,
      "step": 15760
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5801391005516052,
      "learning_rate": 5e-05,
      "loss": 0.3074,
      "step": 15768
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7830306887626648,
      "learning_rate": 5e-05,
      "loss": 0.3317,
      "step": 15776
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5909987688064575,
      "learning_rate": 5e-05,
      "loss": 0.3342,
      "step": 15784
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.690406322479248,
      "learning_rate": 5e-05,
      "loss": 0.3552,
      "step": 15792
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.8771556615829468,
      "learning_rate": 5e-05,
      "loss": 0.3319,
      "step": 15800
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5432752966880798,
      "learning_rate": 5e-05,
      "loss": 0.3323,
      "step": 15808
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5515533089637756,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 15816
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7326911687850952,
      "learning_rate": 5e-05,
      "loss": 0.325,
      "step": 15824
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7262632846832275,
      "learning_rate": 5e-05,
      "loss": 0.3367,
      "step": 15832
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6966487765312195,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 15840
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7909427285194397,
      "learning_rate": 5e-05,
      "loss": 0.3193,
      "step": 15848
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7080482244491577,
      "learning_rate": 5e-05,
      "loss": 0.3704,
      "step": 15856
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7210623621940613,
      "learning_rate": 5e-05,
      "loss": 0.3183,
      "step": 15864
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6088181138038635,
      "learning_rate": 5e-05,
      "loss": 0.3262,
      "step": 15872
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6201576590538025,
      "learning_rate": 5e-05,
      "loss": 0.3133,
      "step": 15880
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.650176465511322,
      "learning_rate": 5e-05,
      "loss": 0.3221,
      "step": 15888
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6811809539794922,
      "learning_rate": 5e-05,
      "loss": 0.3148,
      "step": 15896
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6686923503875732,
      "learning_rate": 5e-05,
      "loss": 0.3167,
      "step": 15904
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6453628540039062,
      "learning_rate": 5e-05,
      "loss": 0.3469,
      "step": 15912
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6669390201568604,
      "learning_rate": 5e-05,
      "loss": 0.3002,
      "step": 15920
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.652350127696991,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 15928
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5672979950904846,
      "learning_rate": 5e-05,
      "loss": 0.3548,
      "step": 15936
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.589064359664917,
      "learning_rate": 5e-05,
      "loss": 0.3216,
      "step": 15944
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6388972997665405,
      "learning_rate": 5e-05,
      "loss": 0.3425,
      "step": 15952
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6002973318099976,
      "learning_rate": 5e-05,
      "loss": 0.3227,
      "step": 15960
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6274659037590027,
      "learning_rate": 5e-05,
      "loss": 0.3573,
      "step": 15968
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6445728540420532,
      "learning_rate": 5e-05,
      "loss": 0.345,
      "step": 15976
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.745699405670166,
      "learning_rate": 5e-05,
      "loss": 0.3412,
      "step": 15984
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.648573637008667,
      "learning_rate": 5e-05,
      "loss": 0.3378,
      "step": 15992
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5659843683242798,
      "learning_rate": 5e-05,
      "loss": 0.3349,
      "step": 16000
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.8168275952339172,
      "learning_rate": 5e-05,
      "loss": 0.3211,
      "step": 16008
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6253968477249146,
      "learning_rate": 5e-05,
      "loss": 0.3263,
      "step": 16016
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6533424258232117,
      "learning_rate": 5e-05,
      "loss": 0.3373,
      "step": 16024
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5862507224082947,
      "learning_rate": 5e-05,
      "loss": 0.3635,
      "step": 16032
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6541158556938171,
      "learning_rate": 5e-05,
      "loss": 0.3529,
      "step": 16040
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.756331741809845,
      "learning_rate": 5e-05,
      "loss": 0.346,
      "step": 16048
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6778120398521423,
      "learning_rate": 5e-05,
      "loss": 0.3234,
      "step": 16056
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6269719004631042,
      "learning_rate": 5e-05,
      "loss": 0.3472,
      "step": 16064
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6546394228935242,
      "learning_rate": 5e-05,
      "loss": 0.334,
      "step": 16072
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6268028616905212,
      "learning_rate": 5e-05,
      "loss": 0.3167,
      "step": 16080
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.615403413772583,
      "learning_rate": 5e-05,
      "loss": 0.3534,
      "step": 16088
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6077621579170227,
      "learning_rate": 5e-05,
      "loss": 0.3274,
      "step": 16096
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5370884537696838,
      "learning_rate": 5e-05,
      "loss": 0.3285,
      "step": 16104
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.580828845500946,
      "learning_rate": 5e-05,
      "loss": 0.324,
      "step": 16112
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6142880916595459,
      "learning_rate": 5e-05,
      "loss": 0.3505,
      "step": 16120
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5884726643562317,
      "learning_rate": 5e-05,
      "loss": 0.3445,
      "step": 16128
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.74069744348526,
      "learning_rate": 5e-05,
      "loss": 0.3171,
      "step": 16136
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6540603041648865,
      "learning_rate": 5e-05,
      "loss": 0.354,
      "step": 16144
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6286123394966125,
      "learning_rate": 5e-05,
      "loss": 0.3052,
      "step": 16152
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6928887367248535,
      "learning_rate": 5e-05,
      "loss": 0.3492,
      "step": 16160
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6098465323448181,
      "learning_rate": 5e-05,
      "loss": 0.3124,
      "step": 16168
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6110295653343201,
      "learning_rate": 5e-05,
      "loss": 0.3233,
      "step": 16176
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.7306426763534546,
      "learning_rate": 5e-05,
      "loss": 0.34,
      "step": 16184
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5415321588516235,
      "learning_rate": 5e-05,
      "loss": 0.3436,
      "step": 16192
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.7033743262290955,
      "learning_rate": 5e-05,
      "loss": 0.3157,
      "step": 16200
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.7959443926811218,
      "learning_rate": 5e-05,
      "loss": 0.3088,
      "step": 16208
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6711810231208801,
      "learning_rate": 5e-05,
      "loss": 0.3421,
      "step": 16216
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.8242077231407166,
      "learning_rate": 5e-05,
      "loss": 0.338,
      "step": 16224
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6351152658462524,
      "learning_rate": 5e-05,
      "loss": 0.3328,
      "step": 16232
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5565599799156189,
      "learning_rate": 5e-05,
      "loss": 0.349,
      "step": 16240
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6621323823928833,
      "learning_rate": 5e-05,
      "loss": 0.3307,
      "step": 16248
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6007250547409058,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 16256
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5802110433578491,
      "learning_rate": 5e-05,
      "loss": 0.3314,
      "step": 16264
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6424407362937927,
      "learning_rate": 5e-05,
      "loss": 0.3301,
      "step": 16272
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.580826461315155,
      "learning_rate": 5e-05,
      "loss": 0.3256,
      "step": 16280
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6664479374885559,
      "learning_rate": 5e-05,
      "loss": 0.3301,
      "step": 16288
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5391914248466492,
      "learning_rate": 5e-05,
      "loss": 0.3421,
      "step": 16296
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.7472983002662659,
      "learning_rate": 5e-05,
      "loss": 0.3511,
      "step": 16304
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6523351669311523,
      "learning_rate": 5e-05,
      "loss": 0.3462,
      "step": 16312
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6101481318473816,
      "learning_rate": 5e-05,
      "loss": 0.3515,
      "step": 16320
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5908889174461365,
      "learning_rate": 5e-05,
      "loss": 0.3035,
      "step": 16328
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6900827288627625,
      "learning_rate": 5e-05,
      "loss": 0.3289,
      "step": 16336
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.622748613357544,
      "learning_rate": 5e-05,
      "loss": 0.3341,
      "step": 16344
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5763521194458008,
      "learning_rate": 5e-05,
      "loss": 0.3365,
      "step": 16352
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6611760854721069,
      "learning_rate": 5e-05,
      "loss": 0.3218,
      "step": 16360
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6006096601486206,
      "learning_rate": 5e-05,
      "loss": 0.3409,
      "step": 16368
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5809949040412903,
      "learning_rate": 5e-05,
      "loss": 0.3197,
      "step": 16376
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6072642207145691,
      "learning_rate": 5e-05,
      "loss": 0.3726,
      "step": 16384
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5659738779067993,
      "learning_rate": 5e-05,
      "loss": 0.3336,
      "step": 16392
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6066617369651794,
      "learning_rate": 5e-05,
      "loss": 0.3421,
      "step": 16400
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6170592308044434,
      "learning_rate": 5e-05,
      "loss": 0.3251,
      "step": 16408
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6268186569213867,
      "learning_rate": 5e-05,
      "loss": 0.3036,
      "step": 16416
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5766618251800537,
      "learning_rate": 5e-05,
      "loss": 0.3469,
      "step": 16424
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5622395277023315,
      "learning_rate": 5e-05,
      "loss": 0.3369,
      "step": 16432
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6166883707046509,
      "learning_rate": 5e-05,
      "loss": 0.3316,
      "step": 16440
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.7297508120536804,
      "learning_rate": 5e-05,
      "loss": 0.3321,
      "step": 16448
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6103295683860779,
      "learning_rate": 5e-05,
      "loss": 0.3221,
      "step": 16456
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5317435264587402,
      "learning_rate": 5e-05,
      "loss": 0.3283,
      "step": 16464
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6733061671257019,
      "learning_rate": 5e-05,
      "loss": 0.2911,
      "step": 16472
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6558738946914673,
      "learning_rate": 5e-05,
      "loss": 0.3728,
      "step": 16480
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6327794194221497,
      "learning_rate": 5e-05,
      "loss": 0.3282,
      "step": 16488
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.7127636075019836,
      "learning_rate": 5e-05,
      "loss": 0.308,
      "step": 16496
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6946650743484497,
      "learning_rate": 5e-05,
      "loss": 0.3082,
      "step": 16504
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.7256680130958557,
      "learning_rate": 5e-05,
      "loss": 0.3019,
      "step": 16512
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5673621296882629,
      "learning_rate": 5e-05,
      "loss": 0.3346,
      "step": 16520
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6315187215805054,
      "learning_rate": 5e-05,
      "loss": 0.361,
      "step": 16528
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6296806931495667,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 16536
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6235780715942383,
      "learning_rate": 5e-05,
      "loss": 0.3223,
      "step": 16544
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6864469647407532,
      "learning_rate": 5e-05,
      "loss": 0.3105,
      "step": 16552
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5427226424217224,
      "learning_rate": 5e-05,
      "loss": 0.3074,
      "step": 16560
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5800008773803711,
      "learning_rate": 5e-05,
      "loss": 0.3441,
      "step": 16568
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6618474125862122,
      "learning_rate": 5e-05,
      "loss": 0.3407,
      "step": 16576
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.600000262260437,
      "learning_rate": 5e-05,
      "loss": 0.3092,
      "step": 16584
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6200081706047058,
      "learning_rate": 5e-05,
      "loss": 0.3464,
      "step": 16592
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6025885939598083,
      "learning_rate": 5e-05,
      "loss": 0.3359,
      "step": 16600
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6289321780204773,
      "learning_rate": 5e-05,
      "loss": 0.3217,
      "step": 16608
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6955418586730957,
      "learning_rate": 5e-05,
      "loss": 0.313,
      "step": 16616
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.660361647605896,
      "learning_rate": 5e-05,
      "loss": 0.3271,
      "step": 16624
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6659096479415894,
      "learning_rate": 5e-05,
      "loss": 0.3142,
      "step": 16632
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5804049372673035,
      "learning_rate": 5e-05,
      "loss": 0.3245,
      "step": 16640
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6886946558952332,
      "learning_rate": 5e-05,
      "loss": 0.3281,
      "step": 16648
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6338164806365967,
      "learning_rate": 5e-05,
      "loss": 0.3261,
      "step": 16656
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.617459774017334,
      "learning_rate": 5e-05,
      "loss": 0.3308,
      "step": 16664
    }
  ],
  "logging_steps": 8,
  "max_steps": 166700,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 1.0277008627235553e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
